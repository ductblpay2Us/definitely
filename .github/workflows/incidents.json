[{"id":"uhH8cFg1WEzBxFHWWdPs","number":"6003107518946786704","begin":"2022-11-17T12:22:58+00:00","created":"2022-11-17T13:25:30+00:00","modified":"2022-11-17T13:25:30+00:00","external_desc":"Cloud Composer v2 environments autoscaling might not work","updates":[{"created":"2022-11-17T13:25:22+00:00","modified":"2022-11-17T13:25:33+00:00","when":"2022-11-17T13:25:22+00:00","text":"Summary: Cloud Composer v2 environments autoscaling might not work\nDescription: Composer 2 environments upgraded to newer Composer versions might experience problems with autoscaling. The issue might occur if upgrade operation was performed between October 27th and November 17th.\nUsers should not upgrade Composer environments to newer versions until further notice.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-17 10:00 US/Pacific with current details.\nDiagnosis: Airflow workers number will not change\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-17T13:25:22+00:00","modified":"2022-11-17T13:25:33+00:00","when":"2022-11-17T13:25:22+00:00","text":"Summary: Cloud Composer v2 environments autoscaling might not work\nDescription: Composer 2 environments upgraded to newer Composer versions might experience problems with autoscaling. The issue might occur if upgrade operation was performed between October 27th and November 17th.\nUsers should not upgrade Composer environments to newer versions until further notice.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-17 10:00 US/Pacific with current details.\nDiagnosis: Airflow workers number will not change\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"YxkG5FfcC42cQmvBCk4j","service_name":"Google Cloud Composer","affected_products":[{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"}],"uri":"incidents/uhH8cFg1WEzBxFHWWdPs","currently_affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}],"previously_affected_locations":[]},{"id":"jSYPL21Js7PEJro9ophY","number":"505337364211257218","begin":"2022-11-15T17:16:38+00:00","created":"2022-11-15T17:38:03+00:00","end":"2022-11-15T18:58:41+00:00","modified":"2022-11-15T18:58:42+00:00","external_desc":"US Multi-region: Datastore Increased Errors and Latency","updates":[{"created":"2022-11-15T18:58:41+00:00","modified":"2022-11-15T18:58:43+00:00","when":"2022-11-15T18:58:41+00:00","text":"The issue with Datastore has been resolved for all affected users as of Tuesday, 2022-11-15 10:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-15T18:11:53+00:00","modified":"2022-11-15T18:11:55+00:00","when":"2022-11-15T18:11:53+00:00","text":"Summary: US Multi-region: Datastore Increased Errors and Latency\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-11-15 11:10 US/Pacific.\nDiagnosis: Datastore customers will experience increased errors and latency.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-15T17:38:03+00:00","modified":"2022-11-15T17:38:04+00:00","when":"2022-11-15T17:38:03+00:00","text":"Summary: US Multi-region: Datastore Increased Errors and Latency\nDescription: We are experiencing an issue with Datastore and our engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-15 10:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Datastore customers will experience increased errors and latency.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-15T18:58:41+00:00","modified":"2022-11-15T18:58:43+00:00","when":"2022-11-15T18:58:41+00:00","text":"The issue with Datastore has been resolved for all affected users as of Tuesday, 2022-11-15 10:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"CETSkT92V21G6A1x28me","service_name":"Cloud Firestore","affected_products":[{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/jSYPL21Js7PEJro9ophY","currently_affected_locations":[],"previously_affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"rjV26MkG41n1YSAWL97S","number":"15027578062208703215","begin":"2022-11-14T18:50:00+00:00","created":"2022-11-14T20:35:06+00:00","end":"2022-11-14T19:38:00+00:00","modified":"2022-11-15T15:07:53+00:00","external_desc":"We are investigating a potential issue with multiple Google Cloud services.","updates":[{"created":"2022-11-15T06:03:08+00:00","modified":"2022-11-15T15:07:53+00:00","when":"2022-11-15T06:03:08+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Google Workspace Impact Start:** 14 November 2022 10:50\n**Google Workspace Impact End :** 14 November 2022 11:27\n**Duration:** 37 minutes\n**Google Cloud Platform Impact Start:** 14 November 2022 10:50\n**Google Cloud Platform Impact End:** 14 November 2022 11:38\n**Duration:** 48 minutes\n**Description:**\nMultiple Google Workspace and Google Cloud Platform services experienced elevated error rates for a duration of 37 minutes and 48 minutes respectively. From preliminary analysis, the root cause is an issue with Google’s system that authorizes access for enterprise customers.\n**Customer Impact:**\n**Google Workspace Product Impact:**\n- Calendar - Affected customers encountered error 500 when accessing calendar.google.com.\n- Tasks - Affected customers encountered error 500 for Google tasks\n- Gmail - Affected customers encountered error 500 when accessing Gmail\n- Drive - Affected customers encountered error 500 when accessing drive.google.com\n- Docs - Affected customers encountered errors when opening or auto saving documents\n- Meet - Affected customers encountered error 500 when accessing Meet.google.com.\n- Voice - Affected customers saw an increase in latency while attempting to use voice.google.com\n- Keep - Affected customers encountered error 500 while accessing Google Keep.\n- Jamboard - Affected users saw error 500 using Jamboard services.\n- Chat - Affected customers encountered error 500 when accessing Chat.\n- Admin Console - Customers' admin consoles displayed generic logos rather than company specific logos.\n- Groups - Groups User Interface and Settings API served error 500 to all users\n**Google Cloud Product Impact:**\n- Google Compute Engine - Customers experienced elevated API traffic error rates.\n- Google Cloud Console - Customers may have experienced generic unavailable errors.\n- Resource Manager - Customers may have noticed generic status unavailable errors.\n- Google BigQuery - Customers may have encountered error messages that state Policy Checks are unavailable.\n- Cloud Firestore - Customers may have experienced elevated latency, operation deadline expirations and/or error messages that state Policy Checks are unavailable.\n---","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-11-14T20:36:09+00:00","modified":"2022-11-14T20:36:15+00:00","when":"2022-11-14T20:36:09+00:00","text":"The issue with Access Context Manager, Cloud Logging, Google BigQuery, Google Cloud Bigtable, Google Cloud Console, Google Cloud Storage, Google Compute Engine, Identity and Access Management has been resolved for all affected users as of Monday, 2022-11-14 11:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-11-14T20:35:00+00:00","modified":"2022-11-14T20:35:07+00:00","when":"2022-11-14T20:35:00+00:00","text":"Summary: We are investigating a potential issue with multiple Google Cloud services.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-11-14 17:21 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-11-15T06:03:08+00:00","modified":"2022-11-15T15:07:53+00:00","when":"2022-11-15T06:03:08+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Google Workspace Impact Start:** 14 November 2022 10:50\n**Google Workspace Impact End :** 14 November 2022 11:27\n**Duration:** 37 minutes\n**Google Cloud Platform Impact Start:** 14 November 2022 10:50\n**Google Cloud Platform Impact End:** 14 November 2022 11:38\n**Duration:** 48 minutes\n**Description:**\nMultiple Google Workspace and Google Cloud Platform services experienced elevated error rates for a duration of 37 minutes and 48 minutes respectively. From preliminary analysis, the root cause is an issue with Google’s system that authorizes access for enterprise customers.\n**Customer Impact:**\n**Google Workspace Product Impact:**\n- Calendar - Affected customers encountered error 500 when accessing calendar.google.com.\n- Tasks - Affected customers encountered error 500 for Google tasks\n- Gmail - Affected customers encountered error 500 when accessing Gmail\n- Drive - Affected customers encountered error 500 when accessing drive.google.com\n- Docs - Affected customers encountered errors when opening or auto saving documents\n- Meet - Affected customers encountered error 500 when accessing Meet.google.com.\n- Voice - Affected customers saw an increase in latency while attempting to use voice.google.com\n- Keep - Affected customers encountered error 500 while accessing Google Keep.\n- Jamboard - Affected users saw error 500 using Jamboard services.\n- Chat - Affected customers encountered error 500 when accessing Chat.\n- Admin Console - Customers' admin consoles displayed generic logos rather than company specific logos.\n- Groups - Groups User Interface and Settings API served error 500 to all users\n**Google Cloud Product Impact:**\n- Google Compute Engine - Customers experienced elevated API traffic error rates.\n- Google Cloud Console - Customers may have experienced generic unavailable errors.\n- Resource Manager - Customers may have noticed generic status unavailable errors.\n- Google BigQuery - Customers may have encountered error messages that state Policy Checks are unavailable.\n- Cloud Firestore - Customers may have experienced elevated latency, operation deadline expirations and/or error messages that state Policy Checks are unavailable.\n---","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"},{"title":"Cloud Logging","id":"PuCJ6W2ovoDhLcyvZ1xa"},{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"},{"title":"Identity and Access Management","id":"adnGEDEt9zWzs8uF1oKA"},{"title":"Access Context Manager","id":"qar4NvXDickuQgSVbW3G"},{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/rjV26MkG41n1YSAWL97S","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"XbwMLqZGNXcfLUxdBWA9","number":"14543965260377210988","begin":"2022-11-12T05:22:48+00:00","created":"2022-11-12T05:39:45+00:00","end":"2022-11-12T08:20:11+00:00","modified":"2022-11-12T08:20:11+00:00","external_desc":"Cloud Workflows: Increased latency for API actions in us-east5","updates":[{"created":"2022-11-12T08:20:11+00:00","modified":"2022-11-12T08:20:12+00:00","when":"2022-11-12T08:20:11+00:00","text":"The issue with Cloud Workflows is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-11-12T06:34:49+00:00","modified":"2022-11-12T06:34:50+00:00","when":"2022-11-12T06:34:49+00:00","text":"Summary: Cloud Workflows: Increased latency for API actions in us-east5\nDescription: We are experiencing an issue with Cloud Workflows.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-11-12 01:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience increased latency for Cloud Workflows API actions in us-east5.\nWorkaround: Customers can attempt to use a different region.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-12T06:14:23+00:00","modified":"2022-11-12T06:14:24+00:00","when":"2022-11-12T06:14:23+00:00","text":"Summary: Cloud Workflows: Increased latency for API actions in us-east5\nDescription: We are experiencing an issue with Cloud Workflows.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-11-11 23:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience increased latency for Cloud Workflows API actions in us-east5.\nWorkaround: Customers can attempt to use a different region.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-12T05:39:44+00:00","modified":"2022-11-12T05:39:46+00:00","when":"2022-11-12T05:39:44+00:00","text":"Summary: Cloud Workflows: Increased latency for API actions in us-east5\nDescription: We are experiencing an issue with Cloud Workflows.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-11-11 22:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: Customers can attempt to use a different region.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-12T08:20:11+00:00","modified":"2022-11-12T08:20:12+00:00","when":"2022-11-12T08:20:11+00:00","text":"The issue with Cloud Workflows is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"C4P62W9Xc2zZ1Sk52bbw","service_name":"Cloud Workflows","affected_products":[{"title":"Cloud Workflows","id":"C4P62W9Xc2zZ1Sk52bbw"}],"uri":"incidents/XbwMLqZGNXcfLUxdBWA9","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"2A3RbyrrHx3udjrNG1ur","number":"1442495421123953088","begin":"2022-11-11T18:41:16+00:00","created":"2022-11-11T19:07:13+00:00","end":"2022-11-11T19:26:19+00:00","modified":"2022-11-11T19:26:19+00:00","external_desc":"Zonal: Some Cloud Bigtable customers will not be able to restore backups in us-central1-a","updates":[{"created":"2022-11-11T19:26:18+00:00","modified":"2022-11-11T19:26:20+00:00","when":"2022-11-11T19:26:18+00:00","text":"This incident with Google Cloud Bigtable was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-11-11T19:12:34+00:00","modified":"2022-11-11T19:12:35+00:00","when":"2022-11-11T19:12:34+00:00","text":"Summary: Zonal: Cloud Bigtable customers not able to restore backups in us-central1-a\nDescription: We've received a report of an issue with Google Cloud Bigtable as of Friday, 2022-11-11 10:41 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 15:15 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Some customers are not able to restore backups\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-11T19:11:16+00:00","modified":"2022-11-11T19:11:17+00:00","when":"2022-11-11T19:11:16+00:00","text":"Summary: Zonal: Cloud Bigtable customers not able to restore backups in us-central1-a\nDescription: We've received a report of an issue with Google Cloud Bigtable as of Friday, 2022-11-11 10:41 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 15:15 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Customers are not able to restore backups\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-11T19:10:29+00:00","modified":"2022-11-11T19:10:30+00:00","when":"2022-11-11T19:10:29+00:00","text":"Summary: Zonal: Cloud Bigtable customers not able to restore backups in JV in us-central1-a\nDescription: We've received a report of an issue with Google Cloud Bigtable as of Friday, 2022-11-11 10:41 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 15:15 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Customers are not able to restore backups in JV\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-11T19:07:12+00:00","modified":"2022-11-11T19:07:13+00:00","when":"2022-11-11T19:07:12+00:00","text":"Summary: Zonal: Cloud Bigtable customers not able to restore backups in JV Cloud in us-central1-a\nDescription: We've received a report of an issue with Google Cloud Bigtable as of Friday, 2022-11-11 10:41 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 15:15 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Customers are not able to restore backups in JV\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-11T19:26:18+00:00","modified":"2022-11-11T19:26:20+00:00","when":"2022-11-11T19:26:18+00:00","text":"This incident with Google Cloud Bigtable was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LfZSuE3xdQU46YMFV5fy","service_name":"Google Cloud Bigtable","affected_products":[{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"}],"uri":"incidents/2A3RbyrrHx3udjrNG1ur","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"2F2f16DptjjFeUTo8QcF","number":"2863245034375187577","begin":"2022-11-11T16:48:11+00:00","created":"2022-11-11T17:01:27+00:00","end":"2022-11-14T16:25:17+00:00","modified":"2022-11-14T16:25:17+00:00","external_desc":"Global: Some Cloud Filestore Enterprise instances failing to perform customer change requests","updates":[{"created":"2022-11-14T16:25:13+00:00","modified":"2022-11-14T16:25:19+00:00","when":"2022-11-14T16:25:13+00:00","text":"The issue with Cloud Filestore has been resolved for all affected users as of Monday, 2022-11-14 08:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-11T17:13:52+00:00","modified":"2022-11-11T17:13:58+00:00","when":"2022-11-11T17:13:52+00:00","text":"Summary: Global: Some Cloud Filestore Enterprise instances failing to perform customer change requests\nDescription: We've received a report of an issue with Cloud Filestore as of Friday, 2022-11-11 08:48 US/Pacific.\nWe will provide more information by Monday, 2022-11-14 10:00 US/Pacific.\nDiagnosis: When a customer updates an instance capacity, the update fails with an error : \"cannot modify capacity during instance maintenance window\" .\nWorkaround: Customers who are affected and experiencing this error for more than 3 hours, they are being asked to submit a support case.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-11T17:01:44+00:00","modified":"2022-11-11T17:01:45+00:00","when":"2022-11-11T17:01:44+00:00","text":"Summary: Some Cloud Filestore Enterprise instances failing to perform customer change requests\nDescription: We've received a report of an issue with Cloud Filestore as of Friday, 2022-11-11 08:48 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 10:20 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-11T17:01:27+00:00","modified":"2022-11-11T17:01:28+00:00","when":"2022-11-11T17:01:27+00:00","text":"Summary: Some Cloud Firestore Enterprise instances failing to perform customer change requests\nDescription: We've received a report of an issue with Cloud Filestore as of Friday, 2022-11-11 08:48 US/Pacific.\nWe will provide more information by Friday, 2022-11-11 10:20 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-14T16:25:13+00:00","modified":"2022-11-14T16:25:19+00:00","when":"2022-11-14T16:25:13+00:00","text":"The issue with Cloud Filestore has been resolved for all affected users as of Monday, 2022-11-14 08:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"jog4nyYkquiLeSK5s26q","service_name":"Cloud Filestore","affected_products":[{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/2F2f16DptjjFeUTo8QcF","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"NXMPMbVyi51BMicBX3ga","number":"5306905491320904900","begin":"2022-11-10T08:04:00+00:00","created":"2022-11-10T14:08:32+00:00","end":"2022-11-10T16:07:00+00:00","modified":"2022-11-10T22:43:06+00:00","external_desc":"Google Cloud Storage (GCS) in europe-west1 is experiencing unavailability errors","updates":[{"created":"2022-11-10T22:42:40+00:00","modified":"2022-11-10T22:42:40+00:00","when":"2022-11-10T22:42:40+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 10 November 2022 00:04\n**Incident End:** 10 November 2022 08:07\n**Duration:** 8 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Storage\nGoogle BigQuery\n**Regions/Zones:** europe-west1\n**Description:**\nGoogle Cloud Storage experienced intermittent unavailability errors for a period of 8 hours and 3 minutes in europe-west1. From a preliminary analysis, the root cause of the issue was related to a recent change to network traffic routing. This change was rolled back to successfully mitigate the issue. Google will be providing a full Incident Report that will provide additional root cause information.\n**Customer Impact:**\n- Google Cloud Storage customers would have received HTTP 503 errors for read/write operations in europe-west1. Metadata operations such as object listing continued to work successfully.\n- Google BigQuery customers may have received “INTERNAL_ERROR” when running import jobs in europe-west1 during the impact window.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T16:41:27+00:00","modified":"2022-11-10T16:41:31+00:00","when":"2022-11-10T16:41:27+00:00","text":"The issue with Google Cloud Storage has been resolved for all affected users as of Thursday, 2022-11-10 08:07 US/Pacific.\nThe mitigation applied by our engineering team worked as expected\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T16:27:10+00:00","modified":"2022-11-10T16:27:14+00:00","when":"2022-11-10T16:27:10+00:00","text":"Summary: Google Cloud Storage (GCS) in europe-west1 is experiencing unavailability errors\nDescription: We are experiencing an intermittent issue with Google Cloud Storage beginning on Thursday, 2022-11-10 00:04:43 PST US/Pacific.\nThis issue was suspected to be caused by a recently rolled out update. The Engineering team is rolling back the update and current data indicates that roll back is effective in mitigating this issue .\nThe mitigation is expected to completed by Thursday, 2022-11-10 08:40 US/Pacific.\nWe will provide more information by Thursday, 2022-11-10 09:00 US/Pacific.\nDiagnosis: GCS users will experience 503 errors for many operations\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T15:17:16+00:00","modified":"2022-11-10T15:17:21+00:00","when":"2022-11-10T15:17:16+00:00","text":"Summary: Google Cloud Storage (GCS) in europe-west1 is experiencing unavailability errors\nDescription: We are experiencing an intermittent issue with Google Cloud Storage beginning on Thursday, 2022-11-10 00:04:43 PST US/Pacific.\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-11-10 08:35 US/Pacific.\nDiagnosis: GCS users will experience 503 errors for many operations\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T14:41:18+00:00","modified":"2022-11-10T14:41:23+00:00","when":"2022-11-10T14:41:18+00:00","text":"Summary: Google Cloud Storage (GCS) in europe-west1 is experiencing unavailability errors\nDescription: We are experiencing an intermittent issue with Google Cloud Storage beginning on Thursday, 2022-11-10 00:04:43 PST US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-10 07:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS users will experience 503 errors for many operations\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T14:14:02+00:00","modified":"2022-11-10T14:14:08+00:00","when":"2022-11-10T14:14:02+00:00","text":"Summary: Google Cloud Storage (GCS) in europe-west1 is experiencing unavailability errors\nDescription: We are experiencing an intermittent issue with Google Cloud Storage beginning on Thursday, 2022-11-10 05:20:04 PST US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-10 06:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS users will experience errors for many operations\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T14:08:31+00:00","modified":"2022-11-10T14:08:36+00:00","when":"2022-11-10T14:08:31+00:00","text":"Summary: Google Cloud Storage (GCS) in europe-west1 is experience unavailable errors\nDescription: We are experiencing an intermittent issue with Google Cloud Storage beginning on Thursday, 2022-11-10 05:20:04 PST US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-10 06:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCS users will experience errors for many operations\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]}],"most_recent_update":{"created":"2022-11-10T22:42:40+00:00","modified":"2022-11-10T22:42:40+00:00","when":"2022-11-10T22:42:40+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 10 November 2022 00:04\n**Incident End:** 10 November 2022 08:07\n**Duration:** 8 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Storage\nGoogle BigQuery\n**Regions/Zones:** europe-west1\n**Description:**\nGoogle Cloud Storage experienced intermittent unavailability errors for a period of 8 hours and 3 minutes in europe-west1. From a preliminary analysis, the root cause of the issue was related to a recent change to network traffic routing. This change was rolled back to successfully mitigate the issue. Google will be providing a full Incident Report that will provide additional root cause information.\n**Customer Impact:**\n- Google Cloud Storage customers would have received HTTP 503 errors for read/write operations in europe-west1. Metadata operations such as object listing continued to work successfully.\n- Google BigQuery customers may have received “INTERNAL_ERROR” when running import jobs in europe-west1 during the impact window.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"UwaYoXQ5bHYHG6EdiPB8","service_name":"Google Cloud Storage","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"}],"uri":"incidents/NXMPMbVyi51BMicBX3ga","currently_affected_locations":[],"previously_affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"id":"fMoBTKwAsJdvLrxXusAB","number":"7984776864928624241","begin":"2022-11-10T08:04:00+00:00","created":"2022-11-10T16:17:43+00:00","end":"2022-11-10T16:07:00+00:00","modified":"2022-11-10T22:44:02+00:00","external_desc":"Google BigQuery: Customers may get INTERNAL_ERROR when running import jobs in regions/europe-west1","updates":[{"created":"2022-11-10T22:43:42+00:00","modified":"2022-11-10T22:43:42+00:00","when":"2022-11-10T22:43:42+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 10 November 2022 00:04\n**Incident End:** 10 November 2022 08:07\n**Duration:** 8 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Storage\nGoogle BigQuery\n**Regions/Zones:** europe-west1\n**Description:**\nGoogle Cloud Storage experienced intermittent unavailability errors for a period of 8 hours and 3 minutes in europe-west1. From a preliminary analysis, the root cause of the issue was related to a recent change to network traffic routing. This change was rolled back to successfully mitigate the issue. Google will be providing a full Incident Report that will provide additional root cause information.\n**Customer Impact:**\n- Google Cloud Storage customers would have received HTTP 503 errors for read/write operations in europe-west1. Metadata operations such as object listing continued to work successfully.\n- Google BigQuery customers may have received “INTERNAL_ERROR” when running import jobs in europe-west1 during the impact window.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T16:22:16+00:00","modified":"2022-11-10T16:22:21+00:00","when":"2022-11-10T16:22:16+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2022-11-10 08:22 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T16:18:52+00:00","modified":"2022-11-10T16:19:03+00:00","when":"2022-11-10T16:18:52+00:00","text":"Summary: Google BigQuery: Customers may get INTERNAL_ERROR when running import jobs in regions/europe-west1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-11-10 09:30 US/Pacific.\nWe will provide more information by Thursday, 2022-11-10 09:30 US/Pacific.\nDiagnosis: Customers may get INTERNAL_ERROR when running import jobs\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-11-10T16:17:36+00:00","modified":"2022-11-10T16:17:45+00:00","when":"2022-11-10T16:17:36+00:00","text":"Summary: Google BigQuery: Customers may get INTERNAL_ERROR when running import jobs in regions/europe-west1\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-11-10 08:50 US/Pacific with current details.\nDiagnosis: Customers may get INTERNAL_ERROR when running import jobs\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]}],"most_recent_update":{"created":"2022-11-10T22:43:42+00:00","modified":"2022-11-10T22:43:42+00:00","when":"2022-11-10T22:43:42+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 10 November 2022 00:04\n**Incident End:** 10 November 2022 08:07\n**Duration:** 8 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Cloud Storage\nGoogle BigQuery\n**Regions/Zones:** europe-west1\n**Description:**\nGoogle Cloud Storage experienced intermittent unavailability errors for a period of 8 hours and 3 minutes in europe-west1. From a preliminary analysis, the root cause of the issue was related to a recent change to network traffic routing. This change was rolled back to successfully mitigate the issue. Google will be providing a full Incident Report that will provide additional root cause information.\n**Customer Impact:**\n- Google Cloud Storage customers would have received HTTP 503 errors for read/write operations in europe-west1. Metadata operations such as object listing continued to work successfully.\n- Google BigQuery customers may have received “INTERNAL_ERROR” when running import jobs in europe-west1 during the impact window.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/fMoBTKwAsJdvLrxXusAB","currently_affected_locations":[],"previously_affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"id":"AdiGr14zx3PAWWj4C8mQ","number":"8129329061862296329","begin":"2022-11-09T19:23:51+00:00","created":"2022-11-09T19:59:04+00:00","modified":"2022-11-16T17:27:01+00:00","external_desc":"Zonal: GCE VM's Experiencing delayed maintenance","updates":[{"created":"2022-11-16T17:27:01+00:00","modified":"2022-11-16T17:27:02+00:00","when":"2022-11-16T17:27:01+00:00","text":"Summary: Zonal: GCE VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-11-17 10:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-15T20:50:15+00:00","modified":"2022-11-15T20:50:17+00:00","when":"2022-11-15T20:50:15+00:00","text":"Summary: Zonal: GCE VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-11-16 12:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-15T19:53:28+00:00","modified":"2022-11-15T19:53:30+00:00","when":"2022-11-15T19:53:28+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-11-16 12:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-14T18:34:24+00:00","modified":"2022-11-14T18:34:25+00:00","when":"2022-11-14T18:34:24+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-11-15 12:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-11T22:06:35+00:00","modified":"2022-11-11T22:06:36+00:00","when":"2022-11-11T22:06:35+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-11-14 12:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-11T18:09:21+00:00","modified":"2022-11-11T18:09:23+00:00","when":"2022-11-11T18:09:21+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-11-11 15:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-11T05:24:31+00:00","modified":"2022-11-11T05:24:38+00:00","when":"2022-11-11T05:24:31+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-11-11 10:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-11T04:38:59+00:00","modified":"2022-11-11T04:39:06+00:00","when":"2022-11-11T04:38:59+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-11-10 21:30 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T21:11:46+00:00","modified":"2022-11-10T21:11:47+00:00","when":"2022-11-10T21:11:46+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-11-10 21:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T21:09:24+00:00","modified":"2022-11-10T21:09:26+00:00","when":"2022-11-10T21:09:24+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window in us-east4-c and us-east4-b\nWe will provide an update by Thursday, 2022-11-10 20:05 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T17:46:46+00:00","modified":"2022-11-10T17:46:48+00:00","when":"2022-11-10T17:46:46+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window in us-east4-c and us-east4-b\nWe will provide an update by Thursday, 2022-11-10 13:05 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T03:04:45+00:00","modified":"2022-11-10T03:04:46+00:00","when":"2022-11-10T03:04:45+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window in us-east4-c and us-east4-b\nWe will provide an update by Thursday, 2022-11-10 10:05 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T02:28:26+00:00","modified":"2022-11-10T02:28:27+00:00","when":"2022-11-10T02:28:26+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window\nWe will provide an update by Thursday, 2022-11-10 10:00 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-10T01:35:18+00:00","modified":"2022-11-10T01:35:20+00:00","when":"2022-11-10T01:35:18+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window\nWe will provide an update by Wednesday, 2022-11-09 19:30 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-11-09T22:29:40+00:00","modified":"2022-11-09T22:29:42+00:00","when":"2022-11-09T22:29:40+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window\nWe will provide an update by Wednesday, 2022-11-09 18:30 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-09T20:02:27+00:00","modified":"2022-11-09T20:02:28+00:00","when":"2022-11-09T20:02:27+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window\nWe will provide an update by Wednesday, 2022-11-09 15:00 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-09T19:59:03+00:00","modified":"2022-11-09T19:59:05+00:00","when":"2022-11-09T19:59:03+00:00","text":"Summary: Zonal: GCE Stable Fleet VM's Experiencing delayed maintenance\nDescription: We are experiencing an issue with Google Compute Engine.\nStable Fleet, aims to guarantee that VMs will undergo maintenance at a certain time. This incident is causing VMs to miss that maintenance guarantee window\nWe will provide an update by Wednesday, 2022-11-09 13:06 US/Pacific with current details.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-16T17:27:01+00:00","modified":"2022-11-16T17:27:02+00:00","when":"2022-11-16T17:27:01+00:00","text":"Summary: Zonal: GCE VM's Experiencing delayed maintenance\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-11-17 10:00 US/Pacific.\nDiagnosis: Customers may see delays in when their VMs undergoing maintenance\nCustomers may also see VM maintenance notifications that are beyond their precision window (SLO violation)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/AdiGr14zx3PAWWj4C8mQ","currently_affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}],"previously_affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},{"id":"w7D5XGtVfMGcdcg4Zzud","number":"4973045402662852106","begin":"2022-11-09T14:23:00+00:00","created":"2022-11-09T15:11:28+00:00","end":"2022-11-09T15:11:00+00:00","modified":"2022-11-10T22:09:56+00:00","external_desc":"Firestore databases in nam5 multi-region are unable to issue any streaming reads/writes","updates":[{"created":"2022-11-10T22:08:33+00:00","modified":"2022-11-10T22:08:33+00:00","when":"2022-11-10T22:08:33+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 09 November 2022 06:23\n**Incident End:** 09 November 2022 07:11\n**Duration:** 48 minutes\n**Affected Services and Features:**\nCloud Firestore\n**Regions/Zones:** Multi-region: nam5\n**Description:**\nCloud Firestore in nam5 were under-provisioned during the peak daily load for a period of 48 minutes. From preliminary analysis, the root cause of the issue is due to a bad configuration push, which left nam5 regions at reduced serving capacity and affected performance during peak load. Since the change was applied during nonpeak hours, the impact was not immediately observed.\n**Customer Impact:**\nCustomers using Firestore databases in the nam5 regions observed severe degradation in streaming read","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]},{"created":"2022-11-09T15:40:53+00:00","modified":"2022-11-09T15:40:59+00:00","when":"2022-11-09T15:40:53+00:00","text":"The issue with Cloud Firestore has been resolved for all affected users as of Wednesday, 2022-11-09 07:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]},{"created":"2022-11-09T15:25:11+00:00","modified":"2022-11-09T15:25:16+00:00","when":"2022-11-09T15:25:11+00:00","text":"Summary: Firestore databases in nam5 multi-region are unable to issue any streaming reads/writes\nDescription: We believe the issue with Cloud Firestore is now resolved. We will continue to monitor services for now.\nWe will provide an update by Wednesday, 2022-11-09 08:30 US/Pacific with current details.\nDiagnosis: Firestore databases in nam5 multi-region were unable to issue any streaming reads/writes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]},{"created":"2022-11-09T15:11:20+00:00","modified":"2022-11-09T15:11:30+00:00","when":"2022-11-09T15:11:20+00:00","text":"Summary: Firestore databases in nam5 multi-region are unable to issue any streaming reads/writes\nDescription: We are experiencing an issue with Cloud Firestore beginning at Wednesday, 2022-11-09 06:23 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-11-09 08:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Firestore databases in nam5 multi-region are unable to issue any streaming reads/writes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]}],"most_recent_update":{"created":"2022-11-10T22:08:33+00:00","modified":"2022-11-10T22:08:33+00:00","when":"2022-11-10T22:08:33+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 09 November 2022 06:23\n**Incident End:** 09 November 2022 07:11\n**Duration:** 48 minutes\n**Affected Services and Features:**\nCloud Firestore\n**Regions/Zones:** Multi-region: nam5\n**Description:**\nCloud Firestore in nam5 were under-provisioned during the peak daily load for a period of 48 minutes. From preliminary analysis, the root cause of the issue is due to a bad configuration push, which left nam5 regions at reduced serving capacity and affected performance during peak load. Since the change was applied during nonpeak hours, the impact was not immediately observed.\n**Customer Impact:**\nCustomers using Firestore databases in the nam5 regions observed severe degradation in streaming read","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"CETSkT92V21G6A1x28me","service_name":"Cloud Firestore","affected_products":[{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/w7D5XGtVfMGcdcg4Zzud","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: nam5","id":"nam5"}]},{"id":"hP4n1sd1k6xkj79uRuH7","number":"1893948058172565738","begin":"2022-11-09T02:59:00+00:00","created":"2022-11-09T03:27:02+00:00","end":"2022-11-09T04:25:00+00:00","modified":"2022-11-09T22:48:38+00:00","external_desc":"We are experiencing issues in App Engine Flexible and Cloud Composer","updates":[{"created":"2022-11-09T22:48:07+00:00","modified":"2022-11-09T22:48:07+00:00","when":"2022-11-09T22:48:07+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n**Affected Services and Features:**\nGoogle App Engine - App Engine Flexible\nGoogle Cloud Composer\n**Regions/Zones:** global\n**Description:**\nGoogle App Engine (GAE) Flexible and Google Cloud Composer operations (i.e. create, update, delete operations) had intermittent failures for customers for a total duration of 10 hours, 30 minutes globally.\nFrom preliminary analysis, the root cause of the issue wass slow response to deployment workflows from one of our data centers hosting a backend component that manages deployments.\nThe first two occurrences were self-solved by our automatic processes. While the investigations continued, the issue recurred multiple times. and the potential cause was identified and the traffic was directed away from the slow responding data center mitigating the issue on 09 November 2022 at 08:37 US/Pacific.\nDetailed information on occurrences:\n(All Times US/Pacific)\n**First Occurrence :** Impact Start: 08 November 2022 14:15 Impact End: 08 November 2022 15:05 Impact Duration: 50 minutes\n**Second Occurrence :** Impact Start: 08 November 2022 16:40 Impact End: 08 November 2022 19:37 Impact Duration: 2 hours, 57 minutes\n**Third Occurrence :** Impact Start: 09 November 2022 01:44 Impact End: 09 November 2022 08:27 Impact Duration: 6 hour, 43 minutes\n**Total Duration:** 10 hours, 30 minutes\n**Customer Impact:** * Google App Engine Flexible : 16% of GAE flexible projects may have experienced issues with create, update, delete operations. * Cloud Composer : Composer environment creation operations may have failed, typically with an error that mentions App Engine.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-09T04:25:00+00:00","modified":"2022-11-09T04:25:02+00:00","when":"2022-11-09T04:25:00+00:00","text":"The issue with Google App Engine, Google Cloud Composer has been resolved for all affected projects as of Tuesday, 2022-11-08 20:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-09T04:15:07+00:00","modified":"2022-11-09T04:15:09+00:00","when":"2022-11-09T04:15:07+00:00","text":"Summary: We are experiencing issues in App Engine Flexible and Cloud Composer\nDescription: We are experiencing an issue with Google App Engine, Google Cloud Composer.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 22:03 US/Pacific with current details.\nDiagnosis: App Engine Flexible : Customers may experience App Engine Flexible deployment issues with create/update/delete operations.\nCloud Composer : Composer environment creation operations may fail, typically with an error that mentions App Engine\nWorkaround: Cloud Composer : Customers can retry the operation after it fails, although there is a chance it may fail again.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-09T03:27:01+00:00","modified":"2022-11-09T03:27:03+00:00","when":"2022-11-09T03:27:01+00:00","text":"Summary: App Engine Flexible deployment failures\nDescription: We are experiencing an issue with Google App Engine beginning at Tuesday, 2022-11-08 14:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 20:55 US/Pacific with current details.\nDiagnosis: Customers may experience App Engine Flexible deployment issues with create/update/delete operations.\nWorkaround: None","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-09T22:48:07+00:00","modified":"2022-11-09T22:48:07+00:00","when":"2022-11-09T22:48:07+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n**Affected Services and Features:**\nGoogle App Engine - App Engine Flexible\nGoogle Cloud Composer\n**Regions/Zones:** global\n**Description:**\nGoogle App Engine (GAE) Flexible and Google Cloud Composer operations (i.e. create, update, delete operations) had intermittent failures for customers for a total duration of 10 hours, 30 minutes globally.\nFrom preliminary analysis, the root cause of the issue wass slow response to deployment workflows from one of our data centers hosting a backend component that manages deployments.\nThe first two occurrences were self-solved by our automatic processes. While the investigations continued, the issue recurred multiple times. and the potential cause was identified and the traffic was directed away from the slow responding data center mitigating the issue on 09 November 2022 at 08:37 US/Pacific.\nDetailed information on occurrences:\n(All Times US/Pacific)\n**First Occurrence :** Impact Start: 08 November 2022 14:15 Impact End: 08 November 2022 15:05 Impact Duration: 50 minutes\n**Second Occurrence :** Impact Start: 08 November 2022 16:40 Impact End: 08 November 2022 19:37 Impact Duration: 2 hours, 57 minutes\n**Third Occurrence :** Impact Start: 09 November 2022 01:44 Impact End: 09 November 2022 08:27 Impact Duration: 6 hour, 43 minutes\n**Total Duration:** 10 hours, 30 minutes\n**Customer Impact:** * Google App Engine Flexible : 16% of GAE flexible projects may have experienced issues with create, update, delete operations. * Cloud Composer : Composer environment creation operations may have failed, typically with an error that mentions App Engine.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/hP4n1sd1k6xkj79uRuH7","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"7wwcABbumVD2AhRmdBPX","number":"11061142623939374060","begin":"2022-11-08T20:01:24+00:00","created":"2022-11-08T21:17:12+00:00","end":"2022-11-09T03:31:24+00:00","modified":"2022-11-09T03:31:24+00:00","external_desc":"Autopilot (clusters versions \u003e= 1.23) may break some workloads","updates":[{"created":"2022-11-09T03:31:24+00:00","modified":"2022-11-09T03:31:26+00:00","when":"2022-11-09T03:31:24+00:00","text":"The issue with Google Kubernetes Engine has been resolved for all affected users as of Tuesday, 2022-11-08 19:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-09T01:14:55+00:00","modified":"2022-11-09T01:14:56+00:00","when":"2022-11-09T01:14:55+00:00","text":"Summary: Autopilot (clusters versions \u003e= 1.23) may break some workloads\nDescription: We are experiencing an issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 19:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: 1. Customers are unable to apply partner workloads (twistlock,Splunk Otel-Connector)\n2. Customer may experience workloads admitted in 1.22, unable to create/schedule new pods as part of deployment after upgrading to 1.23+\nWorkaround: Action Required:\nUpgrades of Autopilot clusters to 1.23+ should be blocked to prevent more clusters from migrating from allowlistv1 to allowlistv2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-09T00:01:39+00:00","modified":"2022-11-09T00:01:41+00:00","when":"2022-11-09T00:01:39+00:00","text":"Summary: Autopilot (clusters versions \u003e= 1.23) may break some workloads\nDescription: We are experiencing an issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 17:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: 1. Customers are unable to apply partner workloads (twistlock,Splunk Otel-Connector)\n2. Customer may experience workloads admitted in 1.22, unable to create/schedule new pods as part of deployment after upgrading to 1.23+\nWorkaround: Action Required:\nUpgrades of Autopilot clusters to 1.23+ should be blocked to prevent more clusters from migrating from allowlistv1 to allowlistv2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-08T21:17:53+00:00","modified":"2022-11-08T21:17:54+00:00","when":"2022-11-08T21:17:53+00:00","text":"Summary: Autopilot (clusters versions \u003e= 1.23) may break some workloads\nDescription: We are experiencing an issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: 1. Customers are unable to apply partner workloads (twistlock,Splunk Otel-Connector)\n2. Customer may experience workloads admitted in 1.22, unable to create/schedule new pods as part of deployment after upgrading to 1.23+\nWorkaround: Action Required:\nUpgrades of Autopilot clusters to 1.23+ should be blocked to prevent more clusters from migrating from allowlistv1 to allowlistv2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-08T21:17:12+00:00","modified":"2022-11-08T21:17:13+00:00","when":"2022-11-08T21:17:12+00:00","text":"Summary: Autopilot (clusters versions \u003e= 1.23) may break some workloads\nDescription: We are experiencing an issue with Google Kubernetes Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-11-08 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: 1. Customers are unable to apply partner workloads (twistlock,Splunk Otel-Connector)\n2. Customer may experience workloads admitted in 1.22, unable to create/schedule new pods as part of deployment after upgrading to 1.23+\nWorkaround: Action Required:\nUpgrades of Autopilot clusters to 1.23+ should be blocked to prevent more clusters from migrating from allowlistv1 to allowlistv2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-09T03:31:24+00:00","modified":"2022-11-09T03:31:26+00:00","when":"2022-11-09T03:31:24+00:00","text":"The issue with Google Kubernetes Engine has been resolved for all affected users as of Tuesday, 2022-11-08 19:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LCSbT57h59oR4W98NHuz","service_name":"Google Kubernetes Engine","affected_products":[{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"}],"uri":"incidents/7wwcABbumVD2AhRmdBPX","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"UUxFtN51bnAeczApc7WP","number":"7543947841703297260","begin":"2022-11-08T17:32:12+00:00","created":"2022-11-08T18:24:08+00:00","end":"2022-11-08T19:39:54+00:00","modified":"2022-11-08T19:39:54+00:00","external_desc":"Global: Cloud Eventarc customers experiencing operation failures","updates":[{"created":"2022-11-08T19:39:49+00:00","modified":"2022-11-08T19:39:55+00:00","when":"2022-11-08T19:39:49+00:00","text":"The issue with Eventarc has been resolved for all affected users as of Tuesday, 2022-11-08 11:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-11-08T19:32:10+00:00","modified":"2022-11-08T19:32:12+00:00","when":"2022-11-08T19:32:10+00:00","text":"Summary: Global: Cloud Eventarc customers experiencing operation failures\nDescription: We've received a report of an issue with Eventarc as of Tuesday, 2022-11-08 09:32 US/Pacific.\nWe will provide more information by Tuesday, 2022-11-08 14:30 US/Pacific.\nDiagnosis: CreateTrigger operations with GCS event type are failing with internal errors\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-08T18:24:02+00:00","modified":"2022-11-08T18:24:08+00:00","when":"2022-11-08T18:24:02+00:00","text":"Summary: Global: Cloud Eventarc customers experiencing operation failures\nDescription: We've received a report of an issue with Eventarc as of Tuesday, 2022-11-08 09:32 US/Pacific.\nWe will provide more information by Tuesday, 2022-11-08 12:05 US/Pacific.\nDiagnosis: CreateTrigger operations with GCS event type are failing with internal errors\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-08T19:39:49+00:00","modified":"2022-11-08T19:39:55+00:00","when":"2022-11-08T19:39:49+00:00","text":"The issue with Eventarc has been resolved for all affected users as of Tuesday, 2022-11-08 11:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"YaFawoMaXnqgY4keUBnW","service_name":"Eventarc","affected_products":[{"title":"Eventarc","id":"YaFawoMaXnqgY4keUBnW"}],"uri":"incidents/UUxFtN51bnAeczApc7WP","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"rmDuydhBoavJqwu3eeXB","number":"7028732407928098035","begin":"2022-11-08T01:03:46+00:00","created":"2022-11-08T01:18:47+00:00","end":"2022-11-08T02:24:51+00:00","modified":"2022-11-08T02:24:51+00:00","external_desc":"App Engine: Flex deployment operations failing","updates":[{"created":"2022-11-08T02:24:51+00:00","modified":"2022-11-08T02:24:52+00:00","when":"2022-11-08T02:24:51+00:00","text":"The issue with Google App Engine has been resolved for all affected users as of Monday, 2022-11-07 16:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-08T01:18:46+00:00","modified":"2022-11-08T01:18:48+00:00","when":"2022-11-08T01:18:46+00:00","text":"Summary: App Engine: Flex deployment operations failing\nDescription: We are experiencing an issue with Google App Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-11-07 18:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience failures for create/update/delete operations for App Engine flex deployments.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-08T02:24:51+00:00","modified":"2022-11-08T02:24:52+00:00","when":"2022-11-08T02:24:51+00:00","text":"The issue with Google App Engine has been resolved for all affected users as of Monday, 2022-11-07 16:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/rmDuydhBoavJqwu3eeXB","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"UN4QaH2KqrGSqvAnX3xW","number":"9280396131140458633","begin":"2022-11-07T19:53:40+00:00","created":"2022-11-07T20:18:16+00:00","end":"2022-11-07T22:13:25+00:00","modified":"2022-11-07T22:13:25+00:00","external_desc":"Global: High latency observed for Cloud Run customers.","updates":[{"created":"2022-11-07T22:13:24+00:00","modified":"2022-11-07T22:13:26+00:00","when":"2022-11-07T22:13:24+00:00","text":"The issue with Cloud Run has been resolved for all affected projects as of Monday, 2022-11-07 13:18 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-07T21:19:40+00:00","modified":"2022-11-07T21:19:41+00:00","when":"2022-11-07T21:19:40+00:00","text":"Summary: Global: High latency observed for Cloud Run customers.\nDescription: Our engineering team is currently investigating the issue.\nWe will provide an update by Monday, 2022-11-07 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will observe higher response latencies and increased time to complete deployments.\nCustomers will also observe issues with scaling of Apps on changes in demand.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-07T20:18:15+00:00","modified":"2022-11-07T20:26:21+00:00","when":"2022-11-07T20:18:15+00:00","text":"Summary: Global: High latency observed for Cloud Run customers.\nDescription: We are experiencing an issue with Cloud Run beginning on Friday, 2022-11-04 17:58 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-11-07 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will observe higher response latencies and increased time to complete deployments.\nCustomers will also observe issues with scaling of Apps on changes in demand.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-07T22:13:24+00:00","modified":"2022-11-07T22:13:26+00:00","when":"2022-11-07T22:13:24+00:00","text":"The issue with Cloud Run has been resolved for all affected projects as of Monday, 2022-11-07 13:18 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9D7d2iNBQWN24zc1VamE","service_name":"Cloud Run","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"}],"uri":"incidents/UN4QaH2KqrGSqvAnX3xW","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"PzWZ4Hb4rXivbGynoE8F","number":"11412485234641402302","begin":"2022-11-05T20:00:54+00:00","created":"2022-11-05T20:46:54+00:00","end":"2022-11-06T06:47:33+00:00","modified":"2022-11-06T06:47:33+00:00","external_desc":"Cloud Logging logs-based metrics data points may be missing or delayed","updates":[{"created":"2022-11-06T06:47:33+00:00","modified":"2022-11-06T06:47:34+00:00","when":"2022-11-06T06:47:33+00:00","text":"The issue with Cloud Logging has been resolved for all affected users as of Saturday, 2022-11-05 23:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-11-06T04:14:40+00:00","modified":"2022-11-06T04:14:42+00:00","when":"2022-11-06T04:14:40+00:00","text":"Summary: Cloud Logging logs-based metrics data points may be missing or delayed\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide an update by Sunday, 2022-11-06 00:30 US/Pacific with current details.\nDiagnosis: Logs-based metrics data points may be missing or delayed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-06T02:32:07+00:00","modified":"2022-11-06T02:32:10+00:00","when":"2022-11-06T02:32:07+00:00","text":"Summary: Cloud Logging logs-based metrics data points may be missing or delayed\nDescription: We are experiencing an issue with Cloud Logging beginning at Saturday, 2022-11-05 19:46 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-11-05 22:00 US/Pacific with current details.\nDiagnosis: Logs-based metrics data points may be missing or delayed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-05T23:10:55+00:00","modified":"2022-11-05T23:10:57+00:00","when":"2022-11-05T23:10:55+00:00","text":"Summary: Cloud Logging logs-based metrics data points may be missing or delayed\nDescription: We are experiencing an issue with Cloud Logging beginning at Saturday, 2022-11-05 19:46 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-11-05 20:30 US/Pacific with current details.\nDiagnosis: Logs-based metrics data points may be missing or delayed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-05T21:49:29+00:00","modified":"2022-11-05T21:49:36+00:00","when":"2022-11-05T21:49:29+00:00","text":"Summary: Cloud Logging logs-based metrics data points may be missing or delayed\nDescription: We are experiencing an issue with Cloud Logging beginning at Saturday, 2022-11-05 19:46 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-11-05 16:30 US/Pacific with current details.\nDiagnosis: Logs-based metrics data points may be missing or delayed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-11-05T20:46:53+00:00","modified":"2022-11-05T20:46:55+00:00","when":"2022-11-05T20:46:53+00:00","text":"Summary: Cloud Logging logs-based metrics data points may be missing or delayed\nDescription: We are experiencing an issue with Cloud Logging beginning at Saturday, 2022-11-05 19:46 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-11-05 15:00 US/Pacific with current details.\nDiagnosis: Logs-based metrics data points may be missing or delayed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-06T06:47:33+00:00","modified":"2022-11-06T06:47:34+00:00","when":"2022-11-06T06:47:33+00:00","text":"The issue with Cloud Logging has been resolved for all affected users as of Saturday, 2022-11-05 23:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Cloud Logging","id":"PuCJ6W2ovoDhLcyvZ1xa"}],"uri":"incidents/PzWZ4Hb4rXivbGynoE8F","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"C2zCMDqWecoUzuLNvBBS","number":"11111428374734998368","begin":"2022-10-27T21:00:39+00:00","created":"2022-10-27T21:17:45+00:00","end":"2022-10-27T21:32:40+00:00","modified":"2022-10-27T21:32:40+00:00","external_desc":"Global: Cloud Data fusion experiencing issues with instance creation","updates":[{"created":"2022-10-27T21:32:39+00:00","modified":"2022-10-27T21:32:41+00:00","when":"2022-10-27T21:32:39+00:00","text":"The issue with Cloud Data Fusion instance creation has been resolved for all affected users as of Thursday, 2022-10-27 14:17 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-27T21:27:02+00:00","modified":"2022-10-27T21:27:08+00:00","when":"2022-10-27T21:27:02+00:00","text":"Summary: Global: Cloud Data fusion experiencing issues with instance creation\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-10-27 15:00 US/Pacific.\nDiagnosis: Customers will experience instance creation timing out\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-27T21:17:39+00:00","modified":"2022-10-27T21:17:46+00:00","when":"2022-10-27T21:17:39+00:00","text":"Summary: Global: Cloud Data fusion experiencing issues with instance creation\nDescription: We are experiencing an issue with Cloud Data Fusion beginning at Thursday, 2022-10-27 13:40 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-27 14:54 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will experience instance creation timing out\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-10-27T21:32:39+00:00","modified":"2022-10-27T21:32:41+00:00","when":"2022-10-27T21:32:39+00:00","text":"The issue with Cloud Data Fusion instance creation has been resolved for all affected users as of Thursday, 2022-10-27 14:17 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"rLKDHeeaBiXTeutF1air","service_name":"Cloud Data Fusion","affected_products":[{"title":"Cloud Data Fusion","id":"rLKDHeeaBiXTeutF1air"}],"uri":"incidents/C2zCMDqWecoUzuLNvBBS","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"uvc41Z35bq2kaGVV796C","number":"3068250751135355954","begin":"2022-10-27T19:10:36+00:00","created":"2022-10-27T19:25:04+00:00","end":"2022-10-28T03:59:31+00:00","modified":"2022-10-28T03:59:32+00:00","external_desc":"us-west1: Degraded performance for PD-Standard devices","updates":[{"created":"2022-10-28T03:59:31+00:00","modified":"2022-10-28T03:59:33+00:00","when":"2022-10-28T03:59:31+00:00","text":"The issue with Persistent Disk has been resolved for all affected users as of Thursday, 2022-10-27 19:49 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-28T01:54:45+00:00","modified":"2022-10-28T01:54:46+00:00","when":"2022-10-28T01:54:45+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: Our engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Thursday, 2022-10-27 21:00 US/Pacific with current details.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b.\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-28T00:06:35+00:00","modified":"2022-10-28T00:06:42+00:00","when":"2022-10-28T00:06:35+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: Our engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Thursday, 2022-10-27 19:07 US/Pacific with current details.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b.\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-27T22:42:27+00:00","modified":"2022-10-27T22:42:28+00:00","when":"2022-10-27T22:42:27+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-10-27 17:00 US/Pacific.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b.\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-27T21:52:41+00:00","modified":"2022-10-27T21:52:42+00:00","when":"2022-10-27T21:52:41+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-10-27 16:01 US/Pacific.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b.\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-27T20:12:45+00:00","modified":"2022-10-27T20:12:46+00:00","when":"2022-10-27T20:12:45+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: Our engineering team is currently investigating the issue.\nWe will provide an update by Thursday, 2022-10-27 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b.\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-10-27T19:25:03+00:00","modified":"2022-10-27T19:25:06+00:00","when":"2022-10-27T19:25:03+00:00","text":"Summary: us-west1: Degraded performance for PD-Standard devices\nDescription: We are experiencing an issue with Persistent Disk beginning at Thursday, 2022-10-27 10:45 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-27 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Slow or stuck operations for zonal PD-Standard devices in us-west1-b\nWorkaround: Use disks in a zone other than us-west1-b. Use another SKU of PD disks.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-28T03:59:31+00:00","modified":"2022-10-28T03:59:33+00:00","when":"2022-10-28T03:59:31+00:00","text":"The issue with Persistent Disk has been resolved for all affected users as of Thursday, 2022-10-27 19:49 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"}],"uri":"incidents/uvc41Z35bq2kaGVV796C","currently_affected_locations":[],"previously_affected_locations":[{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"rFFx63ViPX6ZbA8NHAjt","number":"15384632202394832906","begin":"2022-10-27T08:48:53+00:00","created":"2022-10-27T09:13:07+00:00","end":"2022-10-27T09:14:19+00:00","modified":"2022-10-27T09:14:19+00:00","external_desc":"Cloud Filestore AutoQuota increase requests are not succeeding via console","updates":[{"created":"2022-10-27T09:14:18+00:00","modified":"2022-10-27T09:14:22+00:00","when":"2022-10-27T09:14:18+00:00","text":"The issue with Cloud Filestore is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T09:12:59+00:00","modified":"2022-10-27T09:13:09+00:00","when":"2022-10-27T09:12:59+00:00","text":"Summary: Cloud Filestore AutoQuota increase requests are not succeeding via console\nDescription: We are experiencing an issue with Cloud Filestore.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-27 03:30 US/Pacific with current details.\nDiagnosis: When requesting Quota through the Pantheon console the requests are submitted without any errors but are not proceeding\nWorkaround: Please submit a support ticket quota increase request whilst we're resolving the issue","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-10-27T09:14:18+00:00","modified":"2022-10-27T09:14:22+00:00","when":"2022-10-27T09:14:18+00:00","text":"The issue with Cloud Filestore is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"jog4nyYkquiLeSK5s26q","service_name":"Cloud Filestore","affected_products":[{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/rFFx63ViPX6ZbA8NHAjt","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"qv2VvxMoAzY8xgH4bsLQ","number":"5660777101985201844","begin":"2022-10-27T05:32:21+00:00","created":"2022-10-27T05:32:28+00:00","end":"2022-11-02T18:47:35+00:00","modified":"2022-11-02T18:47:35+00:00","external_desc":"VMs using Local SSD are experiencing intermittent terminations.","updates":[{"created":"2022-11-02T18:47:29+00:00","modified":"2022-11-02T18:47:36+00:00","when":"2022-11-02T18:47:29+00:00","text":"The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2022-11-02 08:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-28T22:34:36+00:00","modified":"2022-10-28T22:34:37+00:00","when":"2022-10-28T22:34:36+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: We have completed all short term mitigation work to prevent impact to customers. VMs with Local SSD may still see a \u003e0.008% chance of being terminated.\nWe have identified a fix for the remaining failures, and are working on a plan to roll out the fix, with our next update by Friday, 2022-11-04 16:00 US/Pacific.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Customers can reduce the possibility of being impacted by setting automaticRestart to false when scheduling the VM under the host maintenance policy of a VM. Please see https://cloud.google.com/compute/docs/instances/setting-vm-host-options for details of the effects of setting automaticRestart to false.\nFor VMs that are terminated, restarting the VM will restore the VM back to a working state.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T22:44:18+00:00","modified":"2022-10-27T22:44:20+00:00","when":"2022-10-27T22:44:18+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-10-28 16:30 US/Pacific.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Set automaticRestart to false for scheduling the VM under the host maintenance policy of a VM. Please see https://cloud.google.com/compute/docs/instances/setting-vm-host-options for details of the effects of setting automaticRestart to false.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T17:12:16+00:00","modified":"2022-10-27T17:12:18+00:00","when":"2022-10-27T17:12:16+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: Our engineering team continues to investigate the issue.\nThe impact of this issue was experienced beginning at Thursday, 2022-09-22 03:14 US/Pacific.\nWe will provide an update by Thursday, 2022-10-27 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Set automaticRestart to false for scheduling the VM under the host maintenance policy of a VM. Please see https://cloud.google.com/compute/docs/instances/setting-vm-host-options for details of the effects of setting automaticRestart to false.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T08:20:30+00:00","modified":"2022-10-27T08:20:31+00:00","when":"2022-10-27T08:20:30+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: We are experiencing an intermittent issue with Google Compute Engine beginning at Friday, 2022-09-30 15:48 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-27 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Set automaticRestart to false for scheduling the VM under the host maintenance policy of a VM. Please see https://cloud.google.com/compute/docs/instances/setting-vm-host-options for details of the effects of setting automaticRestart to false.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T05:40:28+00:00","modified":"2022-10-27T05:40:34+00:00","when":"2022-10-27T05:40:28+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: We are experiencing an intermittent issue with Google Compute Engine beginning at Friday, 2022-09-30 15:48 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-27 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Set the automaticRestart=false for scheduling the VM under host maintenance policy of a VM.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-27T05:32:22+00:00","modified":"2022-10-27T05:32:29+00:00","when":"2022-10-27T05:32:22+00:00","text":"Summary: VMs using Local SSD are experiencing intermittent terminations.\nDescription: We are experiencing an intermittent issue with Google Compute Engine beginning at Friday, 2022-09-30 15:48 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-10-26 23:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using Local SSD on VMs could see the VM terminated unexpectedly, which shows in the console as an Instance Termination by Compute Engine.\nWorkaround: Set the automaticRestart=false for scheduling the VM under host maintenance policy of a VM.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-11-02T18:47:29+00:00","modified":"2022-11-02T18:47:36+00:00","when":"2022-11-02T18:47:29+00:00","text":"The issue with Google Compute Engine has been resolved for all affected users as of Wednesday, 2022-11-02 08:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/qv2VvxMoAzY8xgH4bsLQ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"ZF9vMrevw5iPafdrhUPf","number":"9018463931068218508","begin":"2022-10-26T15:25:00+00:00","created":"2022-10-26T15:48:00+00:00","end":"2022-10-26T19:31:32+00:00","modified":"2022-10-26T19:31:32+00:00","external_desc":"Global: Major version upgrades for postgres instances are failing","updates":[{"created":"2022-10-26T19:31:32+00:00","modified":"2022-10-26T19:31:33+00:00","when":"2022-10-26T19:31:32+00:00","text":"The issue with Google Cloud SQL postgres instances has been resolved for all affected projects as of Wednesday, 2022-10-26 12:30 US/Pacific.\nThere are further actions required from the customers and the major version upgrades will now go through successfully.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-26T19:16:52+00:00","modified":"2022-10-26T19:16:53+00:00","when":"2022-10-26T19:16:52+00:00","text":"Summary: Global: Major version upgrades for postgres instances are failing\nDescription: Mitigation work is still underway by our engineering team.\nWe currently do not have an ETA for the mitigation.\nWe will provide more information by Wednesday, 2022-10-26 14:10 US/Pacific.\nDiagnosis: Customers can not run major version upgrades on the postgres instances (all regions, all versions are affected)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-26T18:50:52+00:00","modified":"2022-10-26T18:50:53+00:00","when":"2022-10-26T18:50:52+00:00","text":"Summary: Global: Major version upgrades for postgres instances are failing\nDescription: Mitigation work is still underway by our engineering team.\nWe currently do not have an ETA for the mitigation.\nWe will provide more information by Wednesday, 2022-10-26 14:00 US/Pacific.\nDiagnosis: Customers can not run major version upgrades on the postgres instances (all regions, all versions are affected)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-26T17:59:11+00:00","modified":"2022-10-26T17:59:19+00:00","when":"2022-10-26T17:59:11+00:00","text":"Summary: Global: Major version upgrades for postgres instances are failing\nDescription: Engineering team has identified the root cause of the issue and have initiated the steps to rollback the changes affecting this issue.\nWe will provide an update by Wednesday, 2022-10-26 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can not run major version upgrades on the postgres instances (all regions, all versions are affected)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-26T16:33:40+00:00","modified":"2022-10-26T16:33:42+00:00","when":"2022-10-26T16:33:40+00:00","text":"Summary: Global: Major version upgrades for postgres instances are failing\nDescription: Our engineering team is currently working on the mitigation steps and investigating the root cause.\nWe will provide an update by Wednesday, 2022-10-26 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can not run major version upgrades on the postgres instances (all regions, all versions are affected)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-26T15:48:00+00:00","modified":"2022-10-26T15:48:02+00:00","when":"2022-10-26T15:48:00+00:00","text":"Summary: Global: Major version upgrades for postgres instances are failing\nDescription: We are experiencing an issue with Google Cloud SQL where major version upgrades for postgres instances are failing.\nOur engineering team continues to investigate the issue and working on the mitigation of the issue.\nWe will provide an update by Wednesday, 2022-10-26 09:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can not run major version upgrades on the postgres instances (all regions, all versions are affected)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-26T19:31:32+00:00","modified":"2022-10-26T19:31:33+00:00","when":"2022-10-26T19:31:32+00:00","text":"The issue with Google Cloud SQL postgres instances has been resolved for all affected projects as of Wednesday, 2022-10-26 12:30 US/Pacific.\nThere are further actions required from the customers and the major version upgrades will now go through successfully.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/ZF9vMrevw5iPafdrhUPf","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"vahM4soitCANy8LH84HH","number":"18362826821939278219","begin":"2022-10-25T15:59:07+00:00","created":"2022-10-25T16:07:08+00:00","end":"2022-10-25T16:48:17+00:00","modified":"2022-10-25T16:48:17+00:00","external_desc":"Failure in Config changes in Cloud Monitoring","updates":[{"created":"2022-10-25T16:48:11+00:00","modified":"2022-10-25T16:48:18+00:00","when":"2022-10-25T16:48:11+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected projects as of Tuesday, 2022-10-25 09:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-10-25T16:07:01+00:00","modified":"2022-10-25T16:07:10+00:00","when":"2022-10-25T16:07:01+00:00","text":"Summary: Failure in Config changes in Cloud Monarch\nDescription: We are experiencing an issue with Cloud Monitoring.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-10-25 09:40 US/Pacific with current details.\nDiagnosis: Customers may face issues while modifying their configs\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-25T16:48:11+00:00","modified":"2022-10-25T16:48:18+00:00","when":"2022-10-25T16:48:11+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected projects as of Tuesday, 2022-10-25 09:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"}],"uri":"incidents/vahM4soitCANy8LH84HH","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"7BkNzwMsik35A2V5j6vM","number":"13135920605234193835","begin":"2022-10-24T10:00:00+00:00","created":"2022-11-02T10:27:14+00:00","end":"2022-11-03T03:00:00+00:00","modified":"2022-11-03T19:54:37+00:00","external_desc":"Some VPCs are missing dynamic routes from peered networks","updates":[{"created":"2022-11-03T19:54:01+00:00","modified":"2022-11-03T19:54:01+00:00","when":"2022-11-03T19:54:01+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 24 October 2022 03:00\n**Incident End:** 02 November 2022 20:00\n**Duration:** 9 days, 17 hours\n**Affected Services and Features:**\nVirtual Private Cloud\n**Regions/Zones:** global\n**Description:**\nVirtual Private Cloud (VPC) experienced connectivity issues between instances and/or with on-premises machines. In some cases, data plane components in affected regions did not get dynamic routes from peered networks.\nFrom preliminary analysis, the root cause of the issue is a rollout to virtual network controllers. The rollout started on 24 October 2022 to a small subset of controllers and gradually scaled over time to other controllers.\nThe issue was mitigated on 02 November 2022 by rolling back.\n**Customer Impact:**\nCustomers were unable to access their Cloud Volume Service (CVS) storage across GCP Regions.\nCustomers may have faced issues with traffic routing In some cases where dynamic routes were not propagated appropriately on peered networks across regions.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-03T03:20:11+00:00","modified":"2022-11-03T03:20:13+00:00","when":"2022-11-03T03:20:11+00:00","text":"We experienced an issue with Virtual Private Cloud (VPC) beginning at Wednesday, 2022-11-02 02:46 US/Pacific.\nThe issue has been resolved for all affected users as of Wednesday, 2022-11-02 20:14 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-03T02:58:05+00:00","modified":"2022-11-03T02:58:07+00:00","when":"2022-11-03T02:58:05+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: Mitigation work is still underway by our engineering team.\nMitigation has been fully applied in:\neurope-west1-b,\neurope-west1-c,\neurope-west1-d,\nus-west1,\nus-west2.\nThe engineering team has started a rollout of the mitigation globally.\nWe will provide more information by Wednesday, 2022-11-02 20:30 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-03T00:50:17+00:00","modified":"2022-11-03T00:50:24+00:00","when":"2022-11-03T00:50:17+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: Mitigation work is still underway by our engineering team.\nMitigation has been fully applied in:\neurope-west1-b,\neurope-west1-c,\neurope-west1-d,\nus-west1,\nus-west2.\nThe engineering team has started a rollout of the mitigation globally.\nThe mitigation is expected to complete by Wednesday, 2022-11-02 20:00 US/Pacific.}\nWe will provide more information by Wednesday, 2022-11-02 20:00 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T22:31:04+00:00","modified":"2022-11-02T22:31:11+00:00","when":"2022-11-02T22:31:04+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: Mitigation work is still underway by our engineering team.\nMitigation has been fully applied in:\neurope-west1-b,\neurope-west1-c,\neurope-west1-d,\nus-west1,\nus-west2.\nThe engineering team has started a rollout of the mitigation globally.\nThe mitigation is expected to complete by Wednesday, 2022-11-02 18:00 US/Pacific.}\nWe will provide more information by Wednesday, 2022-11-02 18:00 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T19:31:24+00:00","modified":"2022-11-02T19:31:32+00:00","when":"2022-11-02T19:31:24+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: Mitigation work is still underway by our engineering team.\nMitigation has been fully applied in:\neurope-west1-b,\neurope-west1-c,\neurope-west1-d,\nus-west1,\nus-west2.\nThe engineering team has started a rollout of the mitigation globally.\nThe mitigation is expected to complete by Wednesday, 2022-11-02 16:00 US/Pacific.}\nWe will provide more information by Wednesday, 2022-11-02 16:00 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T14:44:50+00:00","modified":"2022-11-02T14:44:54+00:00","when":"2022-11-02T14:44:50+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: We've received a report of an issue with Virtual Private Cloud (VPC).\nMitigation has been fully applied in:\neurope-west1-b,\neurope-west1-c,\neurope-west1-d,\nus-west1\nus-west2.\nThe engineering team has started a rollout of the mitigation globally.\nWe do not have an ETA for rolling out mitigation globally at this point.\nWe will provide more information by Wednesday, 2022-11-02 14:43 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T13:33:16+00:00","modified":"2022-11-02T13:33:28+00:00","when":"2022-11-02T13:33:16+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: We've received a report of an issue with Virtual Private Cloud (VPC).\nMitigation work has been fully applied in europe-west-1-B, europe-west-1-C, and europe-west-1-D and it continues to be rolled out to other regions by the engineering team.\nWe do not have an ETA for rolling out mitigation globally at this point.\nWe will provide more information by Wednesday, 2022-11-02 07:43 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T12:38:43+00:00","modified":"2022-11-02T12:38:47+00:00","when":"2022-11-02T12:38:43+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: We've received a report of an issue with Virtual Private Cloud (VPC).\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-11-02 06:43 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T11:26:38+00:00","modified":"2022-11-02T11:26:43+00:00","when":"2022-11-02T11:26:38+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: We've received a report of an issue with Virtual Private Cloud (VPC).\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-11-02 05:43 US/Pacific.\nDiagnosis: Some users are experiencing connectivity issues between VMs or with onprem. Some data plane components in affected regions are in some cases not getting dynamic routes from peered networks.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-11-02T10:27:05+00:00","modified":"2022-11-02T10:27:16+00:00","when":"2022-11-02T10:27:05+00:00","text":"Summary: Some VPCs are missing dynamic routes from peered networks\nDescription: We've received a report of an issue with Virtual Private Cloud (VPC).\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-11-02 04:25 US/Pacific.\nDiagnosis: Some customers are unable to access their Cloud Volume Service (CVS) storage across GCP Regions\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-11-03T19:54:01+00:00","modified":"2022-11-03T19:54:01+00:00","when":"2022-11-03T19:54:01+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 24 October 2022 03:00\n**Incident End:** 02 November 2022 20:00\n**Duration:** 9 days, 17 hours\n**Affected Services and Features:**\nVirtual Private Cloud\n**Regions/Zones:** global\n**Description:**\nVirtual Private Cloud (VPC) experienced connectivity issues between instances and/or with on-premises machines. In some cases, data plane components in affected regions did not get dynamic routes from peered networks.\nFrom preliminary analysis, the root cause of the issue is a rollout to virtual network controllers. The rollout started on 24 October 2022 to a small subset of controllers and gradually scaled over time to other controllers.\nThe issue was mitigated on 02 November 2022 by rolling back.\n**Customer Impact:**\nCustomers were unable to access their Cloud Volume Service (CVS) storage across GCP Regions.\nCustomers may have faced issues with traffic routing In some cases where dynamic routes were not propagated appropriately on peered networks across regions.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/7BkNzwMsik35A2V5j6vM","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"1ynCd7pD7sLpyiqnQsbR","number":"6787896321207270462","begin":"2022-10-21T02:47:36+00:00","created":"2022-10-21T03:04:32+00:00","end":"2022-10-21T15:36:09+00:00","modified":"2022-10-21T15:36:10+00:00","external_desc":"File Attachments issues from Customer Care Portal and Google Cloud console","updates":[{"created":"2022-10-21T15:36:02+00:00","modified":"2022-10-21T15:36:12+00:00","when":"2022-10-21T15:36:02+00:00","text":"The issue with File Attachments has been resolved for all affected users as of Friday, 2022-10-21 08:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-10-21T14:39:54+00:00","modified":"2022-10-21T14:40:05+00:00","when":"2022-10-21T14:39:54+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: We believe the issue with File Attachments is partially resolved.\nUploading attachments on existing cases is now working as expected, however the issue still occurs during new cases creation.\nWe will provide an update by Friday, 2022-10-21 09:30 US/Pacific with current details.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Users should be able to upload attachment after opening cases.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-21T07:16:09+00:00","modified":"2022-10-21T07:16:10+00:00","when":"2022-10-21T07:16:09+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-10-21 09:45 US/Pacific.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Once the case is created, users can email the attachments to the agent assigned.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-21T06:20:30+00:00","modified":"2022-10-21T06:20:31+00:00","when":"2022-10-21T06:20:30+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-10-21 00:45 US/Pacific.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Once the case is created, users can email the attachments to the agent assigned.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-21T03:32:21+00:00","modified":"2022-10-21T03:32:22+00:00","when":"2022-10-21T03:32:21+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-10-20 23:45 US/Pacific.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Once the case is created, users can email the attachments to the agent assigned.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-21T03:22:42+00:00","modified":"2022-10-21T03:22:43+00:00","when":"2022-10-21T03:22:42+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-10-20 23:45 US/Pacific.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Once the case is assigned to an agent, user can email attachments that they need to share with the agent","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-10-21T03:04:26+00:00","modified":"2022-10-21T03:04:33+00:00","when":"2022-10-21T03:04:26+00:00","text":"Summary: File Attachments issues from Customer Care Portal and Google Cloud console\nDescription: We are experiencing an issue with Google Cloud Support.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-20 21:25 US/Pacific with current details.\nDiagnosis: Customers may not able to upload File Attachments from Customer Care Portal (For workspace) and Google Cloud console (For GCP)\nWorkaround: Once the case is assigned to an agent, user can email attachments that they need to share with the agent","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-21T15:36:02+00:00","modified":"2022-10-21T15:36:12+00:00","when":"2022-10-21T15:36:02+00:00","text":"The issue with File Attachments has been resolved for all affected users as of Friday, 2022-10-21 08:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"bGThzF7oEGP5jcuDdMuk","service_name":"Google Cloud Support","affected_products":[{"title":"Google Cloud Support","id":"bGThzF7oEGP5jcuDdMuk"}],"uri":"incidents/1ynCd7pD7sLpyiqnQsbR","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"4dy8veZsrCWE6SNhbabD","number":"894154813030404243","begin":"2022-10-18T22:49:18+00:00","created":"2022-10-18T23:27:36+00:00","end":"2022-10-19T15:47:04+00:00","modified":"2022-10-19T15:47:04+00:00","external_desc":"Google BigQuery experiencing high query latency","updates":[{"created":"2022-10-19T15:47:03+00:00","modified":"2022-10-19T15:47:05+00:00","when":"2022-10-19T15:47:03+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Wednesday, 2022-10-19 08:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-19T03:52:14+00:00","modified":"2022-10-19T08:11:42+00:00","when":"2022-10-19T03:52:14+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: Google BigQuery continues to experience increased latency when submitting queries. Based on preliminary mitigations, we are continuing to see improvement in query latency in affected regions.\nMitigation work is actively underway by our engineering team.\nWe will provide more information by Wednesday, 2022-10-19 09:31 US/Pacific\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: eu","id":"eu"},{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-19T01:30:21+00:00","modified":"2022-10-19T01:30:23+00:00","when":"2022-10-19T01:30:21+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: Google BigQuery continues to experience increased latency when submitting queries. Based on preliminary mitigations, we are continuing to see improvement in query latency in affected regions.\nWe will provide an update by Tuesday, 2022-10-18 21:30 US/Pacific with updated details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-19T00:57:59+00:00","modified":"2022-10-19T00:58:00+00:00","when":"2022-10-19T00:57:59+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: Google BigQuery continues to experience increased latency when submitting queries. Based on preliminary mitigations, we are beginning to see improvement in query latency in affected regions.\nWe will provide an update by Tuesday, 2022-10-18 18:30 US/Pacific with updated details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-19T00:25:44+00:00","modified":"2022-10-19T00:25:45+00:00","when":"2022-10-19T00:25:44+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: Google BigQuery continues to experience increased latency when submitting queries. Based on preliminary mitigations, we are beginning to see improvement in query latency in affected regions.\nWe will provide an update by Tuesday, 2022-10-18 18:00 US/Pacific with updated details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-18T23:52:46+00:00","modified":"2022-10-18T23:52:48+00:00","when":"2022-10-18T23:52:46+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: Google BigQuery continues to experience increased latency when submitting queries. Mitigation work is currently underway by our engineering team. We do not have an ETA for mitigation at this point.\nWe will provide an update by Tuesday, 2022-10-18 17:30 US/Pacific with updated details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-10-18T23:27:36+00:00","modified":"2022-10-18T23:27:37+00:00","when":"2022-10-18T23:27:36+00:00","text":"Summary: Google BigQuery experiencing high query latency\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-10-18 16:54 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience increased latency when submitting queries.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-10-19T15:47:03+00:00","modified":"2022-10-19T15:47:05+00:00","when":"2022-10-19T15:47:03+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Wednesday, 2022-10-19 08:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/4dy8veZsrCWE6SNhbabD","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: eu","id":"eu"},{"title":"Multi-region: us","id":"us"}]},{"id":"cpjg1BS9Go8fmW6rAs9V","number":"5366654761210216498","begin":"2022-10-17T18:05:21+00:00","created":"2022-10-17T18:40:14+00:00","end":"2022-10-17T20:59:49+00:00","modified":"2022-10-17T20:59:49+00:00","external_desc":"Multiregion: Dataproc jobs missing from the console","updates":[{"created":"2022-10-17T20:59:49+00:00","modified":"2022-10-17T20:59:49+00:00","when":"2022-10-17T20:59:49+00:00","text":"The issue with Google Cloud Dataproc has been resolved for all affected users as of Monday, 2022-10-17 13:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-10-17T19:06:17+00:00","modified":"2022-10-17T19:06:24+00:00","when":"2022-10-17T19:06:17+00:00","text":"Summary: Multiregion: Dataproc jobs missing from the console\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-10-17 14:00 US/Pacific.\nWe will provide more information by Monday, 2022-10-17 15:00 US/Pacific.\nDiagnosis: Customers may see older jobs (finished more than 180 days ago) and jobs which are currently running disappear from the Console and API output. Jobs which are currently running will see data plane errors if the control plane job resource is deleted.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-10-17T18:40:13+00:00","modified":"2022-10-17T18:40:16+00:00","when":"2022-10-17T18:40:13+00:00","text":"Summary: Multiregion: Dataproc jobs missing from the console\nDescription: We are experiencing an issue with Google Cloud Dataproc.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-10-17 12:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may see older jobs (finished more than 180 days ago) and jobs which are currently running disappear from the Console and API output. Jobs which are currently running will see data plane errors if the control plane job resource is deleted.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-10-17T20:59:49+00:00","modified":"2022-10-17T20:59:49+00:00","when":"2022-10-17T20:59:49+00:00","text":"The issue with Google Cloud Dataproc has been resolved for all affected users as of Monday, 2022-10-17 13:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"yjXrEg3Yvy26BauMwr69","service_name":"Google Cloud Dataproc","affected_products":[{"title":"Google Cloud Dataproc","id":"yjXrEg3Yvy26BauMwr69"}],"uri":"incidents/cpjg1BS9Go8fmW6rAs9V","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"mREMLwZFe3FuLLn3zfTw","number":"8997005448411858781","begin":"2022-10-14T06:30:00+00:00","created":"2022-10-14T11:41:13+00:00","end":"2022-10-14T11:30:00+00:00","modified":"2022-10-31T18:56:14+00:00","external_desc":"BigQuery is experiencing issues with streaming API in US region","updates":[{"created":"2022-10-31T18:56:14+00:00","modified":"2022-10-31T18:56:14+00:00","when":"2022-10-31T18:56:14+00:00","text":"# Incident Report\n## Summary\nOn 13 October 2022, BigQuery Storage WriteAPI observed elevated error rates in the US Multi-Region for a period of 5 hours. To our BigQuery Storage WriteAPI customers who were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve our service.\n## Root Cause\nBigQuery Storage Write API is the high-traffic, unified data ingestion API in BigQuery [1].\nOn 13 October 2022 23:30 US/Pacific, there was an unexpected increase of incoming and logging traffic combined with a bug in Google’s internal streaming RPC library that triggered a deadlock and caused the Write API Streaming frontend to be overloaded.\nGoogle’s internal automation correctly kicked in and attempted to resolve the issue by increasing memory and scaling up more instances. But because of the bug in the Write API, the existing instances remained stuck, and because of the effects of load balancing the elevated error rates continued to affect customers accessing the Write API. The fix was to restart the stuck instances which was completed by our engineers.\n## Remediation and Prevention\nThe issue was brought to our attention through internal alert on 13 October 2022 23:47 US/Pacific, and Google engineers immediately started an investigation. Google’s automated systems automatically tried increasing memory on the stuck instances at 13 October 23:40 US/Pacific, and Google engineers manually increased the maximum number of Write API instances from 200 to 1000, however neither of them resolved the issue. Between 14 October 02:30 and 02:50 US/Pacific, Google engineers continued to add resources, until it was discovered that the stuck instances needed to be restarted. This action commenced between 14 October 03:20 US/Pacific and 04:30 US/Pacific. The issue was fully mitigated on 14 October 2022 04:30 US/ Pacific.\nGoogle is committed preventing a repeat of this issue in the future and is completing the following actions:\nFix the bug in Google’s internal RPC library (COMPLETED)\nFix the bug in the Write API which caused the cascading deadlock (COMPLETED)\nDeploying additional automation in the Write API back end to automatically load balance based on concurrent connections, at the same time providing improved error handling to reduce unavailability errors.\n## Detailed Description of Impact\nOn 13 October 2022 23:30 US/Pacific, customers making calls using Write API in the US Multi-Region observed increased levels of connection failures. Customers making calls using InsertAll API in the US also may have observed a slight increase in failures due to the subsequent increase in traffic.\n**Reference(s):**\n[1] https://cloud.google.com/bigquery/docs/write-api","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-10-14T21:32:29+00:00","modified":"2022-10-17T18:47:04+00:00","when":"2022-10-14T21:32:29+00:00","text":"**Mini Incident Report**\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support. Google will be providing a full Incident Report to include a finalized root cause and appropriate preventative action items to ensure that this type of outage won’t recur.\n(All Times US/Pacific)\n**Incident Start:** 13 October 2022 23:30\n**Incident End:** 14 October 2022 04:30\n**Duration:** 5 hours\n**Affected Services and Features:**\nBigQuery - Storage Write API\n**Regions/Zones:** Multi-Region (US)\n**Description:**\nCustomers making calls to the streaming API using BigQuery observed elevated error rates in US regions for a period of 5 hours. The issue was mitigated by appropriately increasing resources and manually restarting old tasks, which were overloaded with pending connections.\nFrom preliminary analysis, an increase in calls to the Write API, a unified data-ingestion API in BigQuery [1], caused frontend resources to be overloaded. A suboptimal distribution of the load resulted in an elevated error rate. Google engineering is continuing to investigate the matter, and we will publish a final root cause analysis on the Google Cloud Service Health Dashboard as part of a formal Incident Report.\n**Customer Impact:**\nDuring this period of time:\nCustomers making calls using Write API in the US region observed increased levels of connection failures.\nCustomers making calls using InsertAll API in the US region may also have observed a slight increase in failures due to subsequent increase in traffic.\n**Reference(s):**\n[1] https://cloud.google.com/bigquery/docs/write-api","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-10-14T11:51:24+00:00","modified":"2022-10-14T11:51:30+00:00","when":"2022-10-14T11:51:24+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-10-14 04:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-10-14T11:41:11+00:00","modified":"2022-10-14T11:41:17+00:00","when":"2022-10-14T11:41:11+00:00","text":"Summary: BigQuery is experiencing issues with streaming API in US region\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-10-14 05:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers making calls to streaming API in the US region may see raised levels of errors.\nWorkaround: None.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-10-31T18:56:14+00:00","modified":"2022-10-31T18:56:14+00:00","when":"2022-10-31T18:56:14+00:00","text":"# Incident Report\n## Summary\nOn 13 October 2022, BigQuery Storage WriteAPI observed elevated error rates in the US Multi-Region for a period of 5 hours. To our BigQuery Storage WriteAPI customers who were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve our service.\n## Root Cause\nBigQuery Storage Write API is the high-traffic, unified data ingestion API in BigQuery [1].\nOn 13 October 2022 23:30 US/Pacific, there was an unexpected increase of incoming and logging traffic combined with a bug in Google’s internal streaming RPC library that triggered a deadlock and caused the Write API Streaming frontend to be overloaded.\nGoogle’s internal automation correctly kicked in and attempted to resolve the issue by increasing memory and scaling up more instances. But because of the bug in the Write API, the existing instances remained stuck, and because of the effects of load balancing the elevated error rates continued to affect customers accessing the Write API. The fix was to restart the stuck instances which was completed by our engineers.\n## Remediation and Prevention\nThe issue was brought to our attention through internal alert on 13 October 2022 23:47 US/Pacific, and Google engineers immediately started an investigation. Google’s automated systems automatically tried increasing memory on the stuck instances at 13 October 23:40 US/Pacific, and Google engineers manually increased the maximum number of Write API instances from 200 to 1000, however neither of them resolved the issue. Between 14 October 02:30 and 02:50 US/Pacific, Google engineers continued to add resources, until it was discovered that the stuck instances needed to be restarted. This action commenced between 14 October 03:20 US/Pacific and 04:30 US/Pacific. The issue was fully mitigated on 14 October 2022 04:30 US/ Pacific.\nGoogle is committed preventing a repeat of this issue in the future and is completing the following actions:\nFix the bug in Google’s internal RPC library (COMPLETED)\nFix the bug in the Write API which caused the cascading deadlock (COMPLETED)\nDeploying additional automation in the Write API back end to automatically load balance based on concurrent connections, at the same time providing improved error handling to reduce unavailability errors.\n## Detailed Description of Impact\nOn 13 October 2022 23:30 US/Pacific, customers making calls using Write API in the US Multi-Region observed increased levels of connection failures. Customers making calls using InsertAll API in the US also may have observed a slight increase in failures due to the subsequent increase in traffic.\n**Reference(s):**\n[1] https://cloud.google.com/bigquery/docs/write-api","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/mREMLwZFe3FuLLn3zfTw","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"5Qmw8CdU6NxVRDFohwwT","number":"17707351382649865205","begin":"2022-10-07T13:13:48+00:00","created":"2022-10-07T13:21:22+00:00","end":"2022-10-07T21:30:03+00:00","modified":"2022-10-07T21:30:03+00:00","external_desc":"Connecting GitHub repository is not working","updates":[{"created":"2022-10-07T21:30:03+00:00","modified":"2022-10-07T21:30:04+00:00","when":"2022-10-07T21:30:03+00:00","text":"The issue with Cloud Build has been resolved for all affected projects as of Friday, 2022-10-07 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T19:07:55+00:00","modified":"2022-10-07T19:07:56+00:00","when":"2022-10-07T19:07:55+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Saturday, 2022-10-08 03:00 US/Pacific.\nWe will provide more information by Saturday, 2022-10-08 03:00 US/Pacific.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build and are getting the following\nerror: \"Unable to list GitHub repositories\"\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T19:06:55+00:00","modified":"2022-10-07T19:06:57+00:00","when":"2022-10-07T19:06:55+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Friday, 2022-10-07 13:00 US/Pacific.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build and are getting the following\nerror: \"Unable to list GitHub repositories\"\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T17:16:26+00:00","modified":"2022-10-07T17:16:28+00:00","when":"2022-10-07T17:16:26+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Friday, 2022-10-07 12:00 US/Pacific.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build and are getting the following\nerror: \"Unable to list GitHub repositories\"\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T15:52:38+00:00","modified":"2022-10-07T15:52:40+00:00","when":"2022-10-07T15:52:38+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: Our engineering team is working on the mitigation steps.\nWe will provide an update by Friday, 2022-10-07 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build and are getting the following\nerror: \"Unable to list GitHub repositories\"\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T14:21:27+00:00","modified":"2022-10-07T14:21:34+00:00","when":"2022-10-07T14:21:27+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: We are experiencing an issue with Cloud Build beginning at Thursday, 2022-10-06 06:40 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-10-07 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build,\nerror \"Unable to list GitHub repositories\" is observed\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-07T13:21:13+00:00","modified":"2022-10-07T13:21:25+00:00","when":"2022-10-07T13:21:13+00:00","text":"Summary: Connecting GitHub repository is not working\nDescription: We are experiencing an issue with Cloud Build beginning at Thursday, 2022-10-06 06:40 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-10-07 07:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users are unable to connect GitHub repository to Cloud Build,\nerror \"Unable to list GitHub repositories\" is observed\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-10-07T21:30:03+00:00","modified":"2022-10-07T21:30:04+00:00","when":"2022-10-07T21:30:03+00:00","text":"The issue with Cloud Build has been resolved for all affected projects as of Friday, 2022-10-07 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Developer Tools","id":"BGJQ6jbGK4kUuBTQFZ1G"},{"title":"Cloud Build","id":"fw8GzBdZdqy4THau7e1y"}],"uri":"incidents/5Qmw8CdU6NxVRDFohwwT","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"UjJ6XHN6kG69FDiyAfLD","number":"1563550227631806068","begin":"2022-10-06T15:05:05+00:00","created":"2022-10-06T15:05:16+00:00","end":"2022-10-06T16:21:13+00:00","modified":"2022-10-06T16:21:13+00:00","external_desc":"SEV VMs on RHEL image fail to boot in zones -a and -b in all regions","updates":[{"created":"2022-10-06T16:21:12+00:00","modified":"2022-10-06T16:21:15+00:00","when":"2022-10-06T16:21:12+00:00","text":"The issue with Google Compute Engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-06T15:05:08+00:00","modified":"2022-10-06T15:05:19+00:00","when":"2022-10-06T15:05:08+00:00","text":"Summary: SEV VMs on RHEL image fail to boot in zones -a and -b in all regions\nDescription: We are experiencing an issue with Google Compute Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-06 10:00 US/Pacific with current details.\nDiagnosis: Any customer running a confidential VM in zones -a or -b with sev enabled and using the image rhel-8 may not be able to boot their vm and the vm experiences a kernel panic\nWorkaround: - Run the confidential VMs in zones ending with -c - Disable either secure boot or SEV for your VM - Don't use the RHEL-8 image. (RHEL-9 seems to be working)","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-10-06T16:21:12+00:00","modified":"2022-10-06T16:21:15+00:00","when":"2022-10-06T16:21:12+00:00","text":"The issue with Google Compute Engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/UjJ6XHN6kG69FDiyAfLD","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"1YfiHrPee4d8Cvofxxwp","number":"4026832376331877718","begin":"2022-10-06T14:55:00+00:00","created":"2022-10-06T16:42:58+00:00","end":"2022-10-06T16:51:00+00:00","modified":"2022-10-06T20:32:24+00:00","external_desc":"Google Cloud Networking is experiencing issues in South America","updates":[{"created":"2022-10-06T20:32:07+00:00","modified":"2022-10-06T20:32:07+00:00","when":"2022-10-06T20:32:07+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 6 October 2022 07:55 US/Pacific\n**Incident End:** 6 October 2022 09:51 US/Pacific\n**Duration:** 1 hour, 56 minutes\n**Affected Services and Features:**\nCloud Load Balancing, Google Cloud Networking, Google Cloud Storage, Google Compute Engine\n**Regions/Zones:** southamerica-east1a, australia-southeast2b, southamerica-east1c, southamerica-west1a\n**Description:**\nOn 6 October 2022, 07:55 US/Pacific, Google Cloud Networking experienced an instantaneous spike in traffic for a period of 1 hour and 56 minutes. Our Google Engineers were alerted through existing monitoring and started looking into the root cause immediately.\nUpon investigation, Google engineers noted that the traffic spike was arising from one specific IP address, which was eventually throttled to mitigate the issue on 6 October 2022 09:51 US/Pacific.\n**Customer Impact:**\nCustomers may have lost internal access to multiple Cloud services in South America, including Cloud Load Balancing, Google Cloud Storage, Google Compute Engine","status":"AVAILABLE","affected_locations":[]},{"created":"2022-10-06T16:56:58+00:00","modified":"2022-10-06T16:57:05+00:00","when":"2022-10-06T16:56:58+00:00","text":"The issue with Cloud Load Balancing, Google Cloud Networking, Google Cloud Storage, Google Compute Engine has been resolved for all affected projects as of Thursday, 2022-10-06 09:51 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-10-06T16:42:57+00:00","modified":"2022-10-06T16:43:00+00:00","when":"2022-10-06T16:42:57+00:00","text":"Summary: Google Cloud Networking is experiencing issues in South America\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-10-06 07:55 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-10-06 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will experience issues connecting to internal Cloud Services\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-06T20:32:07+00:00","modified":"2022-10-06T20:32:07+00:00","when":"2022-10-06T20:32:07+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 6 October 2022 07:55 US/Pacific\n**Incident End:** 6 October 2022 09:51 US/Pacific\n**Duration:** 1 hour, 56 minutes\n**Affected Services and Features:**\nCloud Load Balancing, Google Cloud Networking, Google Cloud Storage, Google Compute Engine\n**Regions/Zones:** southamerica-east1a, australia-southeast2b, southamerica-east1c, southamerica-west1a\n**Description:**\nOn 6 October 2022, 07:55 US/Pacific, Google Cloud Networking experienced an instantaneous spike in traffic for a period of 1 hour and 56 minutes. Our Google Engineers were alerted through existing monitoring and started looking into the root cause immediately.\nUpon investigation, Google engineers noted that the traffic spike was arising from one specific IP address, which was eventually throttled to mitigate the issue on 6 October 2022 09:51 US/Pacific.\n**Customer Impact:**\nCustomers may have lost internal access to multiple Cloud services in South America, including Cloud Load Balancing, Google Cloud Storage, Google Compute Engine","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/1YfiHrPee4d8Cvofxxwp","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"MGQTanrU9ETiKdQM8MxH","number":"3541218370821106437","begin":"2022-10-04T23:45:49+00:00","created":"2022-10-04T23:45:51+00:00","end":"2022-10-05T21:29:30+00:00","modified":"2022-10-05T21:29:30+00:00","external_desc":"Google Cloud Functions v2 deployments failing in europe-west4","updates":[{"created":"2022-10-05T21:29:25+00:00","modified":"2022-10-05T21:29:32+00:00","when":"2022-10-05T21:29:25+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Wednesday, 2022-10-05 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-10-04T23:45:50+00:00","modified":"2022-10-04T23:45:52+00:00","when":"2022-10-04T23:45:50+00:00","text":"Summary: Google Cloud Functions v2 deployments failing in europe-west4\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-10-05 17:00 US/Pacific.\nWe will provide more information by Wednesday, 2022-10-05 17:00 US/Pacific.\nDiagnosis: Customers are unable to deploy gen2 functions in europe-west4\nWorkaround: Use gen1 functions or use a different region","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-05T21:29:25+00:00","modified":"2022-10-05T21:29:32+00:00","when":"2022-10-05T21:29:25+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Wednesday, 2022-10-05 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"oW4vJ7VNqyxTWNzSHopX","service_name":"Google Cloud Functions","affected_products":[{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/MGQTanrU9ETiKdQM8MxH","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"MwqWZK7xGGEXFuKDxFY3","number":"3035339388912766919","begin":"2022-10-04T16:28:42+00:00","created":"2022-10-04T16:28:50+00:00","end":"2022-10-05T15:39:34+00:00","modified":"2022-10-05T15:39:34+00:00","external_desc":"Multiregion: GCFv2 First-time Deployments experiencing failures","updates":[{"created":"2022-10-05T15:39:28+00:00","modified":"2022-10-05T15:39:35+00:00","when":"2022-10-05T15:39:28+00:00","text":"The issue with Cloud Run, Google Cloud Functions has been resolved for all affected projects as of Tuesday, 2022-10-04 18:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T22:45:40+00:00","modified":"2022-10-04T22:45:47+00:00","when":"2022-10-04T22:45:40+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: Our engineering team is currently working on the mitigation of the issue and deploying the fix.\nWe will provide an update by Wednesday, 2022-10-05 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T21:51:13+00:00","modified":"2022-10-04T21:51:22+00:00","when":"2022-10-04T21:51:13+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: Our engineering team is currently working on the mitigation of the issue and deploying the fix.\nWe will provide an update by Tuesday, 2022-10-04 17:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T17:57:31+00:00","modified":"2022-10-04T17:57:33+00:00","when":"2022-10-04T17:57:31+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: Our engineering team is currently working on the mitigation of the issue and deploying the fix.\nWe will provide an update by Tuesday, 2022-10-04 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T16:49:43+00:00","modified":"2022-10-04T16:49:50+00:00","when":"2022-10-04T16:49:43+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: Our engineering team continues to investigate the issue and is working on the mitigation steps.\nWe will provide an update by Tuesday, 2022-10-04 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T16:30:17+00:00","modified":"2022-10-04T16:30:24+00:00","when":"2022-10-04T16:30:17+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: We are experiencing an issue with Google Cloud Functions.\nCustomers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will be affected by this issue.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-10-04 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-10-04T16:28:43+00:00","modified":"2022-10-04T16:28:52+00:00","when":"2022-10-04T16:28:43+00:00","text":"Summary: Multiregion: GCFv2 First-time Deployments experiencing failures\nDescription: We are experiencing an issue with Google Cloud Functions.\nCustomers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will be affected by this issue.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-10-04 09:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers who are deploying GCFv2 functions and who have never enabled Cloud Run API before will observe failures with deployments.\nWorkaround: Customers can enable Cloud Run API manually","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-10-05T15:39:28+00:00","modified":"2022-10-05T15:39:35+00:00","when":"2022-10-05T15:39:28+00:00","text":"The issue with Cloud Run, Google Cloud Functions has been resolved for all affected projects as of Tuesday, 2022-10-04 18:54 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"},{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/MwqWZK7xGGEXFuKDxFY3","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"CAbbaRV5dc3LdkjJ8mt3","number":"17523342997890503595","begin":"2022-09-29T21:53:14+00:00","created":"2022-09-29T21:53:15+00:00","end":"2022-10-01T22:24:21+00:00","modified":"2022-10-01T22:24:21+00:00","external_desc":"Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+","updates":[{"created":"2022-10-01T22:24:15+00:00","modified":"2022-10-01T22:24:22+00:00","when":"2022-10-01T22:24:15+00:00","text":"The issue with Google Kubernetes Engine has been resolved as of Saturday, 2022-10-01 01:30 US/Pacific.\nThe fix is now available in all locations in the following GKE versions, GKE v1.24.4-gke.500+, 1.23.11-gke.300+, and 1.22.14-gke.300+. Customers can manually upgrade to the fixed version, or, clusters on the RAPID, REGULAR or STABLE release channels using 1.22, 1.23 or 1.24 will upgrade automatically over coming weeks.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-01T14:10:20+00:00","modified":"2022-10-01T14:10:26+00:00","when":"2022-10-01T14:10:20+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Monday, 2022-10-03 10:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-01T02:41:57+00:00","modified":"2022-10-01T02:41:58+00:00","when":"2022-10-01T02:41:57+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Saturday, 2022-10-01 08:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-30T22:27:54+00:00","modified":"2022-09-30T22:27:56+00:00","when":"2022-09-30T22:27:54+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-30 20:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-30T21:57:56+00:00","modified":"2022-09-30T21:57:57+00:00","when":"2022-09-30T21:57:56+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-30 17:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-30T15:35:20+00:00","modified":"2022-09-30T15:35:22+00:00","when":"2022-09-30T15:35:20+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-30 15:10 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T21:53:14+00:00","modified":"2022-09-29T21:53:15+00:00","when":"2022-09-29T21:53:14+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-30 15:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-01T22:24:15+00:00","modified":"2022-10-01T22:24:22+00:00","when":"2022-10-01T22:24:15+00:00","text":"The issue with Google Kubernetes Engine has been resolved as of Saturday, 2022-10-01 01:30 US/Pacific.\nThe fix is now available in all locations in the following GKE versions, GKE v1.24.4-gke.500+, 1.23.11-gke.300+, and 1.22.14-gke.300+. Customers can manually upgrade to the fixed version, or, clusters on the RAPID, REGULAR or STABLE release channels using 1.22, 1.23 or 1.24 will upgrade automatically over coming weeks.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LCSbT57h59oR4W98NHuz","service_name":"Google Kubernetes Engine","affected_products":[{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"}],"uri":"incidents/CAbbaRV5dc3LdkjJ8mt3","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"eXTnrpxXmcgK36bMxrtD","number":"13516617131524230523","begin":"2022-09-29T18:01:42+00:00","created":"2022-09-29T18:01:43+00:00","end":"2022-09-29T22:02:11+00:00","modified":"2022-09-29T22:02:11+00:00","external_desc":"Multiregion: BigQuery persistent errors for some customers' DML operations","updates":[{"created":"2022-09-29T22:02:06+00:00","modified":"2022-09-29T22:02:13+00:00","when":"2022-09-29T22:02:06+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-29T20:37:21+00:00","modified":"2022-09-29T20:37:22+00:00","when":"2022-09-29T20:37:21+00:00","text":"Summary: Multiregion: BigQuery persistent errors for some customers' DML operations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-09-29 15:30 US/Pacific.\nDiagnosis: Some customers may experience persistent INTERNAL_ERRORS performing DML on some tables with internal debug info and will contain an error message:\n\"Source storage for $project:$dataset.$table is not available in write target $cell\"\nWorkaround: Affected customers should still be able to query or copy their tables.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-29T18:32:31+00:00","modified":"2022-09-29T18:32:32+00:00","when":"2022-09-29T18:32:31+00:00","text":"Summary: Multiregion: BigQuery persistent errors for some customers' DML operations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-09-29 13:30 US/Pacific.\nDiagnosis: Some customers may experience persistent INTERNAL_ERRORS performing DML on some tables with internal debug info and will contain an error message:\n\"Source storage for $project:$dataset.$table is not available in write target $cell\"\nWorkaround: Affected customers should still be able to query or copy their tables.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-29T18:01:43+00:00","modified":"2022-09-29T18:01:44+00:00","when":"2022-09-29T18:01:43+00:00","text":"Summary: Multiregion: BigQuery persistent errors for some customers' DML operations\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-29 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some customers may experience persistent INTERNAL_ERRORS performing DML on some tables with internal debug info and will contain an error message:\n\"Source storage for $project:$dataset.$table is not available in write target $cell\"\nWorkaround: Affected customers should still be able to query or copy their tables.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-09-29T22:02:06+00:00","modified":"2022-09-29T22:02:13+00:00","when":"2022-09-29T22:02:06+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/eXTnrpxXmcgK36bMxrtD","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"id":"QDGjaHNBytaX4kad7zsb","number":"5607330982132901285","begin":"2022-09-28T22:52:00+00:00","created":"2022-09-29T13:41:16+00:00","end":"2022-09-29T16:47:00+00:00","modified":"2022-09-29T21:06:06+00:00","external_desc":"Cloud Monitoring - Uptime - 100% error rate in southamerica-east1","updates":[{"created":"2022-09-29T21:03:53+00:00","modified":"2022-09-29T21:06:06+00:00","when":"2022-09-29T21:03:53+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 28 September 2022 15:52\n**Incident End:** 29 September 2022 09:47\n**Duration:** 17 hours, 55 minutes\n**Affected Services and Features:**\nCloud Monitoring - Uptime Monitoring\n**Regions/Zones:** southamerica-east1\n**Description:**\nCloud Uptime Monitoring experienced near 100% unavailability in the affected region for a duration of 17 hours, 55 minutes. From preliminary analysis, the root cause of the issue is due to a severed link in Google’s backend network in South America. The issue was mitigated once engineers redirected traffic to alternate links. Additional review is underway to prevent potential impact in the future.\n**Customer Impact:**\n- Public Uptime Checks were not able to egress from South America during the incident period. Affected customers would have observed partial or absent metric data from this location.\n- Private Uptime Checks were unaffected.\n- Default alert policies against Public Uptime Checks were unaffected.\n- Custom alert policies against Public Uptime Checks may have triggered if a \"metric absence\" condition is present in the policy (https://cloud.google.com/monitoring/alerts/concepts-indepth#partial-metric-data) and the policy is configured to only measure Uptime metrics from South America.\n---","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-29T13:55:46+00:00","modified":"2022-09-29T13:55:52+00:00","when":"2022-09-29T13:55:46+00:00","text":"The issue with Uptime has been resolved for all affected users as of Thursday, 2022-09-29 06:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-29T13:44:42+00:00","modified":"2022-09-29T13:44:46+00:00","when":"2022-09-29T13:44:42+00:00","text":"Summary: Cloud Monitoring - Uptime - 100% error rate in southamerica-east1\nDescription: We are experiencing an issue with Uptime beginning at Wednesday, 2022-09-28 15:52 US/Pacific.\nMitigation is currently underway and we believe the issue is now partially resolved. We do not have an ETA for full resolution at this point.\nWe will provide more information by Thursday, 2022-09-29 08:00 US/Pacific.\nDiagnosis: Uptime - a websites monitoring product - has been unavailable in southamerica-east1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-09-29T13:41:12+00:00","modified":"2022-09-29T13:41:17+00:00","when":"2022-09-29T13:41:12+00:00","text":"Summary: Cloud Monitoring - Uptime 100% error rate in southamerica-east1\nDescription: We are experiencing an issue with Uptime beginning at Wednesday, 2022-09-28 15:52 US/Pacific.\nMitigation is currently underway and we believe the issue is now partially resolved. We do not have an ETA for full resolution at this point.\nWe will provide more information by Thursday, 2022-09-29 08:00 US/Pacific.\nDiagnosis: Uptime - a websites monitoring product - has been available in southamerica-east1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-29T21:03:53+00:00","modified":"2022-09-29T21:06:06+00:00","when":"2022-09-29T21:03:53+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 28 September 2022 15:52\n**Incident End:** 29 September 2022 09:47\n**Duration:** 17 hours, 55 minutes\n**Affected Services and Features:**\nCloud Monitoring - Uptime Monitoring\n**Regions/Zones:** southamerica-east1\n**Description:**\nCloud Uptime Monitoring experienced near 100% unavailability in the affected region for a duration of 17 hours, 55 minutes. From preliminary analysis, the root cause of the issue is due to a severed link in Google’s backend network in South America. The issue was mitigated once engineers redirected traffic to alternate links. Additional review is underway to prevent potential impact in the future.\n**Customer Impact:**\n- Public Uptime Checks were not able to egress from South America during the incident period. Affected customers would have observed partial or absent metric data from this location.\n- Private Uptime Checks were unaffected.\n- Default alert policies against Public Uptime Checks were unaffected.\n- Custom alert policies against Public Uptime Checks may have triggered if a \"metric absence\" condition is present in the policy (https://cloud.google.com/monitoring/alerts/concepts-indepth#partial-metric-data) and the policy is configured to only measure Uptime metrics from South America.\n---","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"}],"uri":"incidents/QDGjaHNBytaX4kad7zsb","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"LqkdnzZu922W6jCkRhPh","number":"8115480193828306570","begin":"2022-09-28T20:26:56+00:00","created":"2022-09-28T20:26:57+00:00","end":"2022-09-28T20:28:08+00:00","modified":"2022-09-28T20:28:08+00:00","external_desc":"europe-central2-c: GCE instances not autoscaling","updates":[{"created":"2022-09-28T20:28:08+00:00","modified":"2022-09-28T20:28:09+00:00","when":"2022-09-28T20:28:08+00:00","text":"The issue with Google Compute Engine has been resolved for all affected projects as of Wednesday, 2022-09-28 13:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-28T20:26:57+00:00","modified":"2022-09-28T20:26:58+00:00","when":"2022-09-28T20:26:57+00:00","text":"Summary: europe-central2-c: GCE instances not autoscaling\nDescription: We are experiencing an issue with Google Compute Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-28 14:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCE instances in europe-central2-c will not autoscale.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-28T20:28:08+00:00","modified":"2022-09-28T20:28:09+00:00","when":"2022-09-28T20:28:08+00:00","text":"The issue with Google Compute Engine has been resolved for all affected projects as of Wednesday, 2022-09-28 13:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/LqkdnzZu922W6jCkRhPh","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"qW6EH55S8a6dD4mDRCUN","number":"16196594838853900777","begin":"2022-09-28T03:57:42+00:00","created":"2022-09-28T04:13:21+00:00","end":"2022-09-28T06:07:52+00:00","modified":"2022-09-28T06:07:52+00:00","external_desc":"We are experiencing an issue with Google BigQuery.","updates":[{"created":"2022-09-28T06:07:52+00:00","modified":"2022-09-28T06:07:53+00:00","when":"2022-09-28T06:07:52+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Tuesday, 2022-09-27 21:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Netherlands (europe-west4)","id":"europe-west4"}]},{"created":"2022-09-28T05:10:50+00:00","modified":"2022-09-28T05:10:51+00:00","when":"2022-09-28T05:10:50+00:00","text":"Summary: We are experiencing an issue with Google BigQuery.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-09-28 00:00 US/Pacific.\nDiagnosis: Customers will experience increased latency. Query (and other) jobs will timeout, or fail.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Netherlands (europe-west4)","id":"europe-west4"}]},{"created":"2022-09-28T04:13:20+00:00","modified":"2022-09-28T04:13:21+00:00","when":"2022-09-28T04:13:20+00:00","text":"Summary: We are experiencing an issue with Google BigQuery.\nDescription: We are experiencing an issue with Google BigQuery beginning at Tuesday, 2022-09-27 19:56 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-27 22:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will experience increased latency. Query (and other) jobs will timeout, or fail.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Netherlands (europe-west4)","id":"europe-west4"}]}],"most_recent_update":{"created":"2022-09-28T06:07:52+00:00","modified":"2022-09-28T06:07:53+00:00","when":"2022-09-28T06:07:52+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Tuesday, 2022-09-27 21:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Netherlands (europe-west4)","id":"europe-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/qW6EH55S8a6dD4mDRCUN","currently_affected_locations":[],"previously_affected_locations":[{"title":"Netherlands (europe-west4)","id":"europe-west4"}]},{"id":"fSKnyAispFXgYg5AnEW9","number":"5768348178361707048","begin":"2022-09-27T12:58:00+00:00","created":"2022-09-27T13:06:50+00:00","end":"2022-10-03T16:00:00+00:00","modified":"2022-10-04T13:47:16+00:00","external_desc":"MemoryStore for Redis - instances update/export failures","updates":[{"created":"2022-10-04T13:47:05+00:00","modified":"2022-10-04T13:47:05+00:00","when":"2022-10-04T13:47:05+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 26 September 2022 05:58\n**Incident End:** 03 October 2022 09:00\n**Duration:** 7 days, 3 hours, 2 minutes\n**Affected Services and Features:**\nCloud MemoryStore\n**Regions/Zones:** Regional\n**Description:**\nOn 26 September 2022, 05:58 AM US/Pacific Cloud Memory Store experienced failures and errors when attempting to start, update, scale or export instances. From preliminary investigation the root cause appears to be due to a configuration version mismatch, as a result instances operations were never started and would timeout. Google implemented an update to fix the configuration mismatch which restored service and the issue was mitigated 03 October 2022 09:00 US/Pacific.\n**Additional details:**\nSome basic and standard tier instances experienced instance failures like scaling or export with timeouts errors.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-10-03T16:16:15+00:00","modified":"2022-10-03T16:16:17+00:00","when":"2022-10-03T16:16:15+00:00","text":"The issue with Cloud Memorystore has been resolved for all affected users as of Monday, 2022-10-03 09:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-30T18:11:49+00:00","modified":"2022-09-30T18:11:50+00:00","when":"2022-09-30T18:11:49+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Wednesday, 2022-10-05 12:00 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-30T16:38:20+00:00","modified":"2022-09-30T16:38:21+00:00","when":"2022-09-30T16:38:20+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Friday, 2022-09-30 12:00 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T21:13:12+00:00","modified":"2022-09-29T21:13:14+00:00","when":"2022-09-29T21:13:12+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Friday, 2022-09-30 10:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T18:59:30+00:00","modified":"2022-09-29T18:59:31+00:00","when":"2022-09-29T18:59:30+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Thursday, 2022-09-29 15:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T18:05:02+00:00","modified":"2022-09-29T18:05:03+00:00","when":"2022-09-29T18:05:02+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Thursday, 2022-09-29 12:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T17:04:11+00:00","modified":"2022-09-29T17:04:13+00:00","when":"2022-09-29T17:04:11+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Thursday, 2022-09-29 11:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-29T01:43:44+00:00","modified":"2022-09-29T01:43:45+00:00","when":"2022-09-29T01:43:44+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team. Most of the affected instances have recovered.\nWe do not have an ETA for mitigation completion at this point.\nWe will provide more information by Thursday, 2022-09-29 10:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T23:52:17+00:00","modified":"2022-09-28T23:52:19+00:00","when":"2022-09-28T23:52:17+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-09-28 19:00 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T21:34:53+00:00","modified":"2022-09-28T21:34:54+00:00","when":"2022-09-28T21:34:53+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 17:00 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T20:02:08+00:00","modified":"2022-09-28T20:02:09+00:00","when":"2022-09-28T20:02:08+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 14:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T19:02:01+00:00","modified":"2022-09-28T19:02:02+00:00","when":"2022-09-28T19:02:01+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 13:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T18:35:53+00:00","modified":"2022-09-28T18:35:55+00:00","when":"2022-09-28T18:35:53+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 12:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-28T17:12:58+00:00","modified":"2022-09-28T17:13:03+00:00","when":"2022-09-28T17:12:58+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 11:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-27T21:15:04+00:00","modified":"2022-09-27T21:15:05+00:00","when":"2022-09-27T21:15:04+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Wednesday, 2022-09-28 09:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-27T21:09:30+00:00","modified":"2022-09-27T21:09:32+00:00","when":"2022-09-27T21:09:30+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Tuesday, 2022-09-27 17:30 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-27T19:57:19+00:00","modified":"2022-09-27T19:57:20+00:00","when":"2022-09-27T19:57:19+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Tuesday, 2022-09-27 15:10 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-27T13:06:42+00:00","modified":"2022-09-27T13:06:52+00:00","when":"2022-09-27T13:06:42+00:00","text":"Summary: MemoryStore for Redis - instances update/export failures\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Tuesday, 2022-09-27 15:00 US/Pacific.\nDiagnosis: Customers may see failures while attempting to update/export their basic tier instances.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-10-04T13:47:05+00:00","modified":"2022-10-04T13:47:05+00:00","when":"2022-10-04T13:47:05+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 26 September 2022 05:58\n**Incident End:** 03 October 2022 09:00\n**Duration:** 7 days, 3 hours, 2 minutes\n**Affected Services and Features:**\nCloud MemoryStore\n**Regions/Zones:** Regional\n**Description:**\nOn 26 September 2022, 05:58 AM US/Pacific Cloud Memory Store experienced failures and errors when attempting to start, update, scale or export instances. From preliminary investigation the root cause appears to be due to a configuration version mismatch, as a result instances operations were never started and would timeout. Google implemented an update to fix the configuration mismatch which restored service and the issue was mitigated 03 October 2022 09:00 US/Pacific.\n**Additional details:**\nSome basic and standard tier instances experienced instance failures like scaling or export with timeouts errors.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"LGPLu3M5pcUAKU1z6eP3","service_name":"Cloud Memorystore","affected_products":[{"title":"Cloud Memorystore","id":"LGPLu3M5pcUAKU1z6eP3"}],"uri":"incidents/fSKnyAispFXgYg5AnEW9","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"riSP7URjvJ5yrdAV16Mo","number":"4028235457030430469","begin":"2022-09-27T07:02:00+00:00","created":"2022-09-27T08:13:12+00:00","end":"2022-09-27T08:49:00+00:00","modified":"2022-09-27T18:44:31+00:00","external_desc":"Firestore degraded performance in europe-west3","updates":[{"created":"2022-09-27T18:44:29+00:00","modified":"2022-09-27T18:44:29+00:00","when":"2022-09-27T18:44:29+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 27 September 2022 00:02\n**Incident End:** 27 September 2022 01:49\n**Duration:** 1 hour, 47 minutes\n**Affected Services and Features:**\nCloud Firestore\n**Regions/Zones:** europe-west3\n**Description:**\nCloud Firestore native and Firestore in Datastore mode customers experienced elevated error rates and latency for a duration of 1 hour, 47 minutes. From preliminary analysis, the issue was triggered by degraded query performance from a project causing an isolation issue and led to performance degradation in the europe-west3 region. The problematic project was isolated, mitigating the issue. Additional review is underway to prevent potential impact in the future.\n**Customer Impact:**\n- Approximately 66% of projects in europe-west3 were affected.\n- Datastore native projects were not affected.\n---","status":"AVAILABLE","affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]},{"created":"2022-09-27T09:06:53+00:00","modified":"2022-09-27T09:07:04+00:00","when":"2022-09-27T09:06:53+00:00","text":"The issue with Cloud Firestore has been resolved for all affected users as of Tuesday, 2022-09-27 02:00 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]},{"created":"2022-09-27T08:33:13+00:00","modified":"2022-09-27T08:41:38+00:00","when":"2022-09-27T08:33:13+00:00","text":"Summary: Firestore degraded performance in europe-west3\nDescription: We are experiencing an issue with Cloud Firestore beginning at Tuesday, 2022-09-27 00:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-27 02:15 US/Pacific with current details.\nDiagnosis: Firestore native and Firestore in Datastore mode customers may experience high error rates and high latency\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]},{"created":"2022-09-27T08:13:12+00:00","modified":"2022-09-27T08:15:31+00:00","when":"2022-09-27T08:13:12+00:00","text":"Summary: Firestore degraded performance in europe-west3\nDescription: We are experiencing an issue with Cloud Firestore beginning at Tuesday, 2022-09-27 00:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-27 02:00 US/Pacific with current details.\nDiagnosis: Firestore native customers may experience high error rates and high latency for Firestore requests.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]}],"most_recent_update":{"created":"2022-09-27T18:44:29+00:00","modified":"2022-09-27T18:44:29+00:00","when":"2022-09-27T18:44:29+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 27 September 2022 00:02\n**Incident End:** 27 September 2022 01:49\n**Duration:** 1 hour, 47 minutes\n**Affected Services and Features:**\nCloud Firestore\n**Regions/Zones:** europe-west3\n**Description:**\nCloud Firestore native and Firestore in Datastore mode customers experienced elevated error rates and latency for a duration of 1 hour, 47 minutes. From preliminary analysis, the issue was triggered by degraded query performance from a project causing an isolation issue and led to performance degradation in the europe-west3 region. The problematic project was isolated, mitigating the issue. Additional review is underway to prevent potential impact in the future.\n**Customer Impact:**\n- Approximately 66% of projects in europe-west3 were affected.\n- Datastore native projects were not affected.\n---","status":"AVAILABLE","affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"CETSkT92V21G6A1x28me","service_name":"Cloud Firestore","affected_products":[{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/riSP7URjvJ5yrdAV16Mo","currently_affected_locations":[],"previously_affected_locations":[{"title":"Frankfurt (europe-west3)","id":"europe-west3"}]},{"id":"BpLRiwzxkF3BBtS24PuB","number":"14036744414784685574","begin":"2022-09-26T15:32:15+00:00","created":"2022-09-26T15:56:50+00:00","end":"2022-09-26T22:04:04+00:00","modified":"2022-09-26T22:04:04+00:00","external_desc":"Google Cloud Console is experiencing issue with displaying the list of compute instances.","updates":[{"created":"2022-09-26T22:04:03+00:00","modified":"2022-09-26T22:04:04+00:00","when":"2022-09-26T22:04:03+00:00","text":"The issue with Google Cloud Console has been resolved for all affected users as of Monday, 2022-09-26 14:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T21:41:56+00:00","modified":"2022-09-26T21:41:57+00:00","when":"2022-09-26T21:41:56+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We believe the issue with Google Cloud Console is partially resolved.\nCustomers should now be able to list instances and snapshots with out any issues.\nOur engineering team is continuing to work on mitigation for disk listing issues.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Monday, 2022-09-26 16:30 US/Pacific with current details.\nDiagnosis: List of VMs on instances page may show stale data (e.g. deleted VMs still shown, added VMs not shown, existing VMs show stale status).\nWorkaround: Customers can click on \"Refresh\" button in the VM list view to get the fresh / update-to-date list after every page load or can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T21:31:06+00:00","modified":"2022-09-26T21:31:08+00:00","when":"2022-09-26T21:31:06+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-09-26 16:00 US/Pacific.\nDiagnosis: List of VMs on instances page may show stale data (e.g. deleted VMs still shown, added VMs not shown, existing VMs show stale status).\nWorkaround: Customers can click on \"Refresh\" button in the VM list view to get the fresh / update-to-date list after every page load or can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T20:49:41+00:00","modified":"2022-09-26T20:49:42+00:00","when":"2022-09-26T20:49:41+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: List of VMs on instances page may show stale data (e.g. deleted VMs still shown, added VMs not shown, existing VMs show stale status).\nWorkaround: Customers can click on \"Refresh\" button in the VM list view to get the fresh / update-to-date list after every page load or can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T20:05:57+00:00","modified":"2022-09-26T20:05:59+00:00","when":"2022-09-26T20:05:57+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: List of VMs on instances page may show stale data (e.g. deleted VMs still shown, added VMs not shown, existing VMs show stale status).\nWorkaround: Customers can click on \"Refresh\" button in the VM list view to get the fresh / update-to-date list after every page load or can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T18:56:00+00:00","modified":"2022-09-26T18:56:01+00:00","when":"2022-09-26T18:56:00+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: List of VMs on instances page may show stale data (e.g. deleted VMs still shown, added VMs not shown, existing VMs show stale status).\nWorkaround: Customers can click on \"Refresh\" button in the VM list view to get the fresh / update-to-date list after every page load or can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T17:52:27+00:00","modified":"2022-09-26T17:52:29+00:00","when":"2022-09-26T17:52:27+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see their compute instances listed multiple times in Cloud Console.\nWorkaround: Customers can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T17:05:03+00:00","modified":"2022-09-26T17:05:04+00:00","when":"2022-09-26T17:05:03+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see their compute instances listed multiple times in Cloud Console.\nWorkaround: Customers can use gCloud CLI to get a list of instances\nhttps://cloud.google.com/compute/docs/instances/get-list#gcloud","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T16:54:34+00:00","modified":"2022-09-26T16:54:40+00:00","when":"2022-09-26T16:54:34+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see their compute instances listed multiple times in Cloud Console.\nWorkaround: Users can click the \"Refresh\" button on the VM list view to get the fresh / update-to-date list.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T16:22:35+00:00","modified":"2022-09-26T16:22:37+00:00","when":"2022-09-26T16:22:35+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see their compute instances listed multiple times in Cloud Console.\nWorkaround: Users can click the \"Refresh\" button on the VM list view to get the fresh / update-to-date list.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-26T15:56:44+00:00","modified":"2022-09-26T15:56:52+00:00","when":"2022-09-26T15:56:44+00:00","text":"Summary: Google Cloud Console is experiencing issue with displaying the list of compute instances.\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-26 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see their compute instances listed multiple times in Cloud Console.\nWorkaround: Users can click the \"Refresh\" button on the VM list view to get the fresh / update-to-date list.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-09-26T22:04:03+00:00","modified":"2022-09-26T22:04:04+00:00","when":"2022-09-26T22:04:03+00:00","text":"The issue with Google Cloud Console has been resolved for all affected users as of Monday, 2022-09-26 14:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"Wdsr1n5vyDvCt78qEifm","service_name":"Google Cloud Console","affected_products":[{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"}],"uri":"incidents/BpLRiwzxkF3BBtS24PuB","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"MzXRzD5WSRyyuYaJsX9Y","number":"11892784250885827269","begin":"2022-09-22T11:28:00+00:00","created":"2022-09-22T12:30:58+00:00","end":"2022-09-22T11:50:00+00:00","modified":"2022-10-03T19:36:25+00:00","external_desc":"Customers experienced a cloud networking disruption from 04:28 AM - 04:50 AM US/Pacific","updates":[{"created":"2022-10-03T19:35:10+00:00","modified":"2022-10-03T19:35:10+00:00","when":"2022-10-03T19:35:10+00:00","text":"# INCIDENT REPORT\n## Summary\nOn Friday, 22 September 2022, Google Cloud experienced a traffic disruption in the wide-area network connecting the us-east1 and us-central1 cloud regions. Inter-region traffic in Google Cloud, and Internet-to-Google Cloud traffic, may have been disrupted if it transited this network path. We are aware of potential impact in several Cloud regions including asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, northamerica-northeast1, us-central1, us-east1, us-east4, us-west1, us-west2, us-west4, as well as to Google Workspace, with a total duration of 22 minutes.\n## Root Cause\nThe traffic disruption in Google's wide-area network was triggered by brief failures in fiber-optic cables, in the presence of a pre-existing failure nearby in the network.\nThese brief failures occurred progressively across a 18-minute period on Friday, 22 September 2022, from 04:28 to 04:46 US/Pacific. Each event required a rerouting of traffic, extending the impact to 04:50.\nThe pre-existing failure occurred on Wednesday, 20 September 2022 22:10 US/Pacific, and was still under repair at the time of the second failure on Friday 22nd September.\nGoogle's interregional backbone is designed with multiple levels of redundancy and is provisioned to reroute Cloud traffic with minimal disruption under all common failure scenarios. In this case, the backbone was designed with appropriate redundancy to survive this dual-failure scenario, but traffic in the affected regions experienced longer rerouting delays. Traffic flowing over other network links experienced disruption as rerouted traffic sought alternate, less congested backup paths.\n## Remediation and Prevention\nGoogle's network reacted automatically to the 04:28 to 04:46 events, rerouting within our design goals and fully recovered by 04:50.\nOur network controls software automatically removed the impacted links from service for our engineers to investigate, since unreliable paths cause more short-term impact than failed paths. There was no shortage of capacity at any time; all disruptions were caused by rerouting.\nThe probability and impact of these scenarios is exhaustively modeled to ensure such double\nfailures occur very infrequently and do not exceed long-term (yearly \u0026 multi-year) availability targets.\nGoogle is committed preventing a repeat of this issue in the future and is completing the following actions:\n- Verify fiber-optic cable maintenance procedures adequately manage the risk of physical interruption during repair and other maintenance activity, including hitless proactive traffic moves where appropriate.\n- Ensuring capacity modeling software is correctly assessing the risk of dual failures, and allowing more headroom for rerouted traffic where those failures are more likely.\n- Ensuring automatic removal of unreliable capacity is acting aggressively enough to avoid areas with progressive failures.\n## Detailed Description of Impact\nOn 22 September 2022, between 04:28 to 04:50 US/Pacific unless otherwise noted the following services (but not limited to) may have been impacted for various customers in the following cloud regions: asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, northamerica-northeast1, us-central1, us-east1, us-east4, us-west1, us-west2, us-west4, unless otherwise noted.\n### Google Compute Engine\nAffected Google Compute Engine customers may have experienced increased latency and packet loss between Compute Engine instances in affected regions.\n### Google Cloud BigTable\nA small percentage of customers may have experienced errors in API calls from 04:29 through 04:51 in asia-east1, us-central1, us-south1, us-west1, and us-west4.\n### Google Chat\nAffected Google Chat customers would have experienced errors when accessing, creating, or responding to chats from 04:28 through 04:51.\n### Google Voice\nGoogle Voice users might have experienced some of their actions failing during the impact window due to an internal error. This includes all actions such as sending SMS, placing \u0026 receiving calls, loading call history, etc. Affected web, Android, and iOS users.\n### Google Cloud Storage\nA small percentage of Google Cloud Storage customers may have experienced errors in requests to GCS buckets in asia-south2, asia-southeast2, us-west1 and us-west2.\n### Google Cloud Load Balancing\nAffected Google Cloud Load Balancing customers may have experienced increased HTTP 5XX errors. Globally around 3M queries were served with 5XX response during the two outage windows and us-west1, asia-east1, asia-south1, asia-south2 and asia-southeast1 saw the most of the failing queries.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-22T21:22:31+00:00","modified":"2022-10-03T19:35:56+00:00","when":"2022-09-22T21:22:31+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n(All Times US/Pacific)\n**Occurrence 1**\n**Incident Start:** 22 September 2022 04:30\n**Incident End:** 22 September 2022 04:38\n**Duration:** 8 minutes\n**Occurrence 2**\n**Incident Start:** 22 September 2022 04:48\n**Incident End:** 22 September 2022 04:58\n**Duration:** 10 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:** us-central1, us-east1, us-west1\n**Description:**\nCustomers using Google Cloud Networking experienced a network traffic disruption in us-central1, us-east1, us-west1 regions on 22 September 2022 for 8 minutes starting 04:30 US/Pacific and for 10 minutes starting 04:48 US/Pacific (total duration of 18 minutes). From preliminary analysis, the root cause of the issue was identified as failures of a high fraction of transport links between the affected regions.\n**Customer Impact:**\nThe incident had the following impact for our customers.\nSome customers using Cloud Networking experienced severe traffic disruption for the two occurrences of the incident.\nSome cloud customers communicating outside the affected regions (including to the Internet) would have seen two periods of disruption, ~8 minutes at 04:30 AM, ~10 minutes at 04:48 AM US/Pacific.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-22T12:45:46+00:00","modified":"2022-09-22T12:45:55+00:00","when":"2022-09-22T12:45:46+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Thursday, 2022-09-22 05:23 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-22T12:30:50+00:00","modified":"2022-09-22T12:31:00+00:00","when":"2022-09-22T12:30:50+00:00","text":"Summary: Customers experienced a cloud networking disruption from 04:30 AM - 04:58 AM US/Pacific\nDescription: Customers might have experienced a cloud networking disruption from 04:30 AM - 04:58 AM US/Pacific as a result of an issue on physical network.\nWe believe the network connectivity is currently stable.\nWe will provide an update by Thursday, 2022-09-22 06:45 US/Pacific with current details.\nDiagnosis: All cloud customers communicating outside the region (including to the internet) would have seen two periods of disruption, ~8m at 04:30 AM, ~10m at 04:48 AM US/Pacific\nWorkaround: None","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]}],"most_recent_update":{"created":"2022-10-03T19:35:10+00:00","modified":"2022-10-03T19:35:10+00:00","when":"2022-10-03T19:35:10+00:00","text":"# INCIDENT REPORT\n## Summary\nOn Friday, 22 September 2022, Google Cloud experienced a traffic disruption in the wide-area network connecting the us-east1 and us-central1 cloud regions. Inter-region traffic in Google Cloud, and Internet-to-Google Cloud traffic, may have been disrupted if it transited this network path. We are aware of potential impact in several Cloud regions including asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, northamerica-northeast1, us-central1, us-east1, us-east4, us-west1, us-west2, us-west4, as well as to Google Workspace, with a total duration of 22 minutes.\n## Root Cause\nThe traffic disruption in Google's wide-area network was triggered by brief failures in fiber-optic cables, in the presence of a pre-existing failure nearby in the network.\nThese brief failures occurred progressively across a 18-minute period on Friday, 22 September 2022, from 04:28 to 04:46 US/Pacific. Each event required a rerouting of traffic, extending the impact to 04:50.\nThe pre-existing failure occurred on Wednesday, 20 September 2022 22:10 US/Pacific, and was still under repair at the time of the second failure on Friday 22nd September.\nGoogle's interregional backbone is designed with multiple levels of redundancy and is provisioned to reroute Cloud traffic with minimal disruption under all common failure scenarios. In this case, the backbone was designed with appropriate redundancy to survive this dual-failure scenario, but traffic in the affected regions experienced longer rerouting delays. Traffic flowing over other network links experienced disruption as rerouted traffic sought alternate, less congested backup paths.\n## Remediation and Prevention\nGoogle's network reacted automatically to the 04:28 to 04:46 events, rerouting within our design goals and fully recovered by 04:50.\nOur network controls software automatically removed the impacted links from service for our engineers to investigate, since unreliable paths cause more short-term impact than failed paths. There was no shortage of capacity at any time; all disruptions were caused by rerouting.\nThe probability and impact of these scenarios is exhaustively modeled to ensure such double\nfailures occur very infrequently and do not exceed long-term (yearly \u0026 multi-year) availability targets.\nGoogle is committed preventing a repeat of this issue in the future and is completing the following actions:\n- Verify fiber-optic cable maintenance procedures adequately manage the risk of physical interruption during repair and other maintenance activity, including hitless proactive traffic moves where appropriate.\n- Ensuring capacity modeling software is correctly assessing the risk of dual failures, and allowing more headroom for rerouted traffic where those failures are more likely.\n- Ensuring automatic removal of unreliable capacity is acting aggressively enough to avoid areas with progressive failures.\n## Detailed Description of Impact\nOn 22 September 2022, between 04:28 to 04:50 US/Pacific unless otherwise noted the following services (but not limited to) may have been impacted for various customers in the following cloud regions: asia-east1, asia-northeast1, asia-southeast1, australia-southeast1, europe-west1, europe-west2, europe-west3, europe-west4, northamerica-northeast1, us-central1, us-east1, us-east4, us-west1, us-west2, us-west4, unless otherwise noted.\n### Google Compute Engine\nAffected Google Compute Engine customers may have experienced increased latency and packet loss between Compute Engine instances in affected regions.\n### Google Cloud BigTable\nA small percentage of customers may have experienced errors in API calls from 04:29 through 04:51 in asia-east1, us-central1, us-south1, us-west1, and us-west4.\n### Google Chat\nAffected Google Chat customers would have experienced errors when accessing, creating, or responding to chats from 04:28 through 04:51.\n### Google Voice\nGoogle Voice users might have experienced some of their actions failing during the impact window due to an internal error. This includes all actions such as sending SMS, placing \u0026 receiving calls, loading call history, etc. Affected web, Android, and iOS users.\n### Google Cloud Storage\nA small percentage of Google Cloud Storage customers may have experienced errors in requests to GCS buckets in asia-south2, asia-southeast2, us-west1 and us-west2.\n### Google Cloud Load Balancing\nAffected Google Cloud Load Balancing customers may have experienced increased HTTP 5XX errors. Globally around 3M queries were served with 5XX response during the two outage windows and us-west1, asia-east1, asia-south1, asia-south2 and asia-southeast1 saw the most of the failing queries.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/MzXRzD5WSRyyuYaJsX9Y","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"VwYPkFLRVN72LijtLvDa","number":"2318485575586137500","begin":"2022-09-20T22:31:31+00:00","created":"2022-09-20T22:48:47+00:00","end":"2022-09-20T23:31:52+00:00","modified":"2022-09-20T23:31:52+00:00","external_desc":"us-east1: Cloud SQL instance creation failures","updates":[{"created":"2022-09-20T23:31:47+00:00","modified":"2022-09-20T23:31:53+00:00","when":"2022-09-20T23:31:47+00:00","text":"The issue with Google Cloud SQL has been resolved for all affected projects as of Tuesday, 2022-09-20 16:31 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-09-20T22:48:46+00:00","modified":"2022-09-20T22:48:48+00:00","when":"2022-09-20T22:48:46+00:00","text":"Summary: us-east1: Cloud SQL instance creation failures\nDescription: We are experiencing an issue with Google Cloud SQL.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-20 17:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience failures when attempting to create new Cloud SQL instances in us-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-09-20T23:31:47+00:00","modified":"2022-09-20T23:31:53+00:00","when":"2022-09-20T23:31:47+00:00","text":"The issue with Google Cloud SQL has been resolved for all affected projects as of Tuesday, 2022-09-20 16:31 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/VwYPkFLRVN72LijtLvDa","currently_affected_locations":[],"previously_affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"tK27wxVTmR9qpxvE1oJw","number":"2162750357331353237","begin":"2022-09-19T16:51:00+00:00","created":"2022-09-19T17:19:47+00:00","end":"2022-09-19T19:40:00+00:00","modified":"2022-09-21T15:17:37+00:00","external_desc":"[False Positive] - Agents unable to receive phone calls","updates":[{"created":"2022-09-20T22:07:04+00:00","modified":"2022-09-20T22:07:04+00:00","when":"2022-09-20T22:07:04+00:00","text":"We wanted to provide additional information about the outage communications we provided on 19 September 2022 for Dialogflow CX and Cloud Machine Learning. Upon further investigation, our engineering teams concluded the outage was misdiagnosed as impacting Dialogflow CX and Cloud Machine Learning. Our investigations revealed the issue did not impact any Google Cloud products or our customers ability to reach Google Cloud support. The impact was limited to Google internal systems only. We apologize to our customers for any confusion.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-19T19:40:54+00:00","modified":"2022-09-19T19:40:56+00:00","when":"2022-09-19T19:40:54+00:00","text":"The issue with Dialogflow CX has been resolved for all affected users as of Monday, 2022-09-19 12:06 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-19T18:51:21+00:00","modified":"2022-09-19T18:51:22+00:00","when":"2022-09-19T18:51:21+00:00","text":"Summary: Dialogflow Agents unable to receive phone calls\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-09-19 13:00 US/Pacific.\nWe will provide more information by Monday, 2022-09-19 13:15 US/Pacific.\nDiagnosis: Phone calls may not be reachable to Dialogflow agents, and customers may also expect longer wait times on the calls.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-19T17:42:49+00:00","modified":"2022-09-19T17:42:51+00:00","when":"2022-09-19T17:42:49+00:00","text":"Summary: Agents unable to receive phone calls\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-09-19 12:00 US/Pacific.\nWe will provide more information by Monday, 2022-09-19 12:15 US/Pacific.\nDiagnosis: Phone calls may not be reachable to agents. Agents may also expect longer wait times on the calls.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-19T17:27:05+00:00","modified":"2022-09-19T17:27:06+00:00","when":"2022-09-19T17:27:05+00:00","text":"Summary: Agents unable to receive phone calls\nDescription: We are experiencing an issue with Dialogflow CX.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-19 11:26 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Phone calls may not be reachable to agents. Agents may also expect longer wait times on the calls.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-19T17:19:41+00:00","modified":"2022-09-19T17:19:49+00:00","when":"2022-09-19T17:19:41+00:00","text":"Summary: Agents unable to receive phone calls\nDescription: We are experiencing an issue with Dialogflow CX.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-09-19 11:26 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Phone calls may not be reachable to agents. Agents may also expect longer wait times on the calls.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-20T22:07:04+00:00","modified":"2022-09-20T22:07:04+00:00","when":"2022-09-20T22:07:04+00:00","text":"We wanted to provide additional information about the outage communications we provided on 19 September 2022 for Dialogflow CX and Cloud Machine Learning. Upon further investigation, our engineering teams concluded the outage was misdiagnosed as impacting Dialogflow CX and Cloud Machine Learning. Our investigations revealed the issue did not impact any Google Cloud products or our customers ability to reach Google Cloud support. The impact was limited to Google internal systems only. We apologize to our customers for any confusion.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Dialogflow CX","id":"BnCicQdHSdxaCv8Ya6Vm"},{"title":"Cloud Machine Learning","id":"z9PfKanGZYvYNUbnKzRJ"}],"uri":"incidents/tK27wxVTmR9qpxvE1oJw","currently_affected_locations":[],"previously_affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"bNT9EzAvFZsPygifzs66","number":"12819118958340641273","begin":"2022-09-18T07:30:22+00:00","created":"2022-09-18T08:45:51+00:00","end":"2022-09-18T09:31:02+00:00","modified":"2022-09-18T09:31:02+00:00","external_desc":"Google Engineer investigating issues with initiation of new DB migrations. Please use API directly if you are experiencing failures.","updates":[{"created":"2022-09-18T09:31:00+00:00","modified":"2022-09-18T09:31:06+00:00","when":"2022-09-18T09:31:00+00:00","text":"The issue with Database Migration Service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-18T09:19:13+00:00","modified":"2022-09-18T09:19:19+00:00","when":"2022-09-18T09:19:13+00:00","text":"Summary: Google Engineer investigating issues with initiation of new DB migrations. Please use API directly if you are experiencing failures.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday , 2022-09-21 10:30 US/Pacific.\nWe will provide more information by Wednesday, 2022-09-21 10:00 US/Pacific.\nDiagnosis: Cloud customers trying to migrate their on-prem PG DB or CSQL TU PG DB to AlloyDB, will always fail to start the migration job. They will always get an error when trying to test the migration job\nWorkaround: Please use API directly to initiate DB migration","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-18T08:45:43+00:00","modified":"2022-09-18T08:45:55+00:00","when":"2022-09-18T08:45:43+00:00","text":"Summary: Google Engineer investigating issues with initiation of new DB migrations. Please use API directly if you are experiencing failures.\nDescription: We are experiencing an issue with Database Migration Service.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-09-18 02:30 US/Pacific with current details.\nDiagnosis: Cloud customers trying to migrate their on-prem PG DB or CSQL TU PG DB to AlloyDB, will always fail to start the migration job. They will always get an error when trying to test the migration job\nWorkaround: PLease use API directly","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-18T09:31:00+00:00","modified":"2022-09-18T09:31:06+00:00","when":"2022-09-18T09:31:00+00:00","text":"The issue with Database Migration Service is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"vY4CRgRFNbqUXWWyYGFS","service_name":"Database Migration Service","affected_products":[{"title":"Database Migration Service","id":"vY4CRgRFNbqUXWWyYGFS"}],"uri":"incidents/bNT9EzAvFZsPygifzs66","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"GpFv3Us3JmmekbEzhkcQ","number":"15134510973246781416","begin":"2022-09-18T03:07:43+00:00","created":"2022-09-18T03:07:44+00:00","end":"2022-09-18T05:12:20+00:00","modified":"2022-09-18T05:12:20+00:00","external_desc":"Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates","updates":[{"created":"2022-09-18T05:12:19+00:00","modified":"2022-09-18T05:12:21+00:00","when":"2022-09-18T05:12:19+00:00","text":"The issue with Dialogflow CX, Dialogflow ES, Speech-to-Text has been resolved for all affected users as of Saturday, 2022-09-17 21:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-18T04:07:58+00:00","modified":"2022-09-18T04:07:59+00:00","when":"2022-09-18T04:07:58+00:00","text":"Summary: Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Saturday, 2022-09-17 22:30 US/Pacific.\nWe will provide more information by Saturday, 2022-09-17 22:45 US/Pacific.\nDiagnosis: Users for Cloud Dialogflow using Speech-to-Text will experience elevated error rates.\nUser may see Availability drop for Cloud Speech-to-Text across global endpoints.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-18T04:00:04+00:00","modified":"2022-09-18T04:00:05+00:00","when":"2022-09-18T04:00:04+00:00","text":"Summary: Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-09-17 22:00 US/Pacific.\nDiagnosis: Users for Cloud Dialogflow using Speech-to-Text will experience elevated error rates.\nUser may see Availability drop for Cloud Speech-to-Text across global endpoints.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-18T03:10:35+00:00","modified":"2022-09-18T03:10:37+00:00","when":"2022-09-18T03:10:35+00:00","text":"Summary: Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates\nDescription: We are experiencing an issue with Dialogflow CX, Speech-to-Text, Dialogflow ES beginning at Saturday, 2022-09-17 19:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-09-17 21:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users for Cloud Dialogflow using Speech-to-Text will experience elevated error rates.\nUser may see Availability drop for Cloud Speech-to-Text across global endpoints.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-18T03:07:43+00:00","modified":"2022-09-18T03:07:45+00:00","when":"2022-09-18T03:07:43+00:00","text":"Summary: Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates\nDescription: We are experiencing an issue with Dialogflow CX, Speech-to-Text, Dialogflow ES beginning at Saturday, 2022-09-17 19:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-09-17 21:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users for Cloud Dialogflow using Speech-to-Text will experience elevated error rates. Availability drop for Cloud Speech-to-Text across global endpoints.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]}],"most_recent_update":{"created":"2022-09-18T05:12:19+00:00","modified":"2022-09-18T05:12:21+00:00","when":"2022-09-18T05:12:19+00:00","text":"The issue with Dialogflow CX, Dialogflow ES, Speech-to-Text has been resolved for all affected users as of Saturday, 2022-09-17 21:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Speech-to-Text","id":"5f5oET9B3whnSFHfwy4d"},{"title":"Dialogflow CX","id":"BnCicQdHSdxaCv8Ya6Vm"},{"title":"Dialogflow ES","id":"sQqrYvhjMT5crPHKWJFY"},{"title":"Cloud Machine Learning","id":"z9PfKanGZYvYNUbnKzRJ"}],"uri":"incidents/GpFv3Us3JmmekbEzhkcQ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"D3gYxpd69zbYrqpN1aES","number":"948197335093773401","begin":"2022-09-17T19:43:53+00:00","created":"2022-09-17T20:02:15+00:00","end":"2022-09-17T20:06:18+00:00","modified":"2022-09-17T20:06:18+00:00","external_desc":"Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates","updates":[{"created":"2022-09-17T20:06:17+00:00","modified":"2022-09-17T20:06:19+00:00","when":"2022-09-17T20:06:17+00:00","text":"The issue with Dialogflow CX, Dialogflow ES, Speech-to-Text has been resolved for all affected users as of Saturday, 2022-09-17 13:06 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-09-17T20:02:14+00:00","modified":"2022-09-17T20:02:16+00:00","when":"2022-09-17T20:02:14+00:00","text":"Summary: Global: Cloud Dialogflow with Speech-to-Text experiencing elevated error rates\nDescription: We are experiencing an issue with Dialogflow CX, Speech-to-Text, Dialogflow ES.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-09-17 14:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users for Cloud Dialogflow using Speech-to-Text will experience elevated error rates.\nAvailability drop for Cloud Speech-to-Text across global endpoints.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]}],"most_recent_update":{"created":"2022-09-17T20:06:17+00:00","modified":"2022-09-17T20:06:19+00:00","when":"2022-09-17T20:06:17+00:00","text":"The issue with Dialogflow CX, Dialogflow ES, Speech-to-Text has been resolved for all affected users as of Saturday, 2022-09-17 13:06 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Speech-to-Text","id":"5f5oET9B3whnSFHfwy4d"},{"title":"Dialogflow CX","id":"BnCicQdHSdxaCv8Ya6Vm"},{"title":"Dialogflow ES","id":"sQqrYvhjMT5crPHKWJFY"},{"title":"Cloud Machine Learning","id":"z9PfKanGZYvYNUbnKzRJ"}],"uri":"incidents/D3gYxpd69zbYrqpN1aES","currently_affected_locations":[],"previously_affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"1wLJzpF7zkXbsZEGFgf4","number":"9796867894639866041","begin":"2022-09-16T18:07:28+00:00","created":"2022-09-16T18:25:46+00:00","end":"2022-09-16T20:31:38+00:00","modified":"2022-09-16T20:31:38+00:00","external_desc":"Global: Cloud Monitoring Dashboard experiencing issues editing tables","updates":[{"created":"2022-09-16T20:31:38+00:00","modified":"2022-09-16T20:31:39+00:00","when":"2022-09-16T20:31:38+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected users as of Friday, 2022-09-16 13:31 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-16T20:30:42+00:00","modified":"2022-09-16T20:30:48+00:00","when":"2022-09-16T20:30:42+00:00","text":"Summary: Global: Cloud Monitoring Dashboard experiencing issues editing tables\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-09-16 13:40 US/Pacific.\nDiagnosis: Users experience an error when attempting to edit tables or any other dashboard component on a dashboard that has at least one table on it.\nDashboards without tables can still be edited normally.\nWorkaround: Customers can use the gcloud command to edit the JSON/YAML representation of their dashboards to work around the UI error:\nhttps://cloud.google.com/sdk/gcloud/reference/monitoring/dashboards/update","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-16T19:23:07+00:00","modified":"2022-09-16T19:23:13+00:00","when":"2022-09-16T19:23:07+00:00","text":"Summary: Global: Cloud Monitoring Dashboard experiencing issues editing tables\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-09-16 13:30 US/Pacific.\nDiagnosis: Users experience an error when attempting to edit tables or any other dashboard component on a dashboard that has at least one table on it.\nDashboards without tables can still be edited normally.\nWorkaround: Customers can use the gcloud command to edit the JSON/YAML representation of their dashboards to work around the UI error:\nhttps://cloud.google.com/sdk/gcloud/reference/monitoring/dashboards/update","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-16T18:35:17+00:00","modified":"2022-09-16T18:35:18+00:00","when":"2022-09-16T18:35:17+00:00","text":"Summary: Global: Cloud Monitoring Dashboard experiencing issues editing tables\nDescription: We are experiencing an issue with Cloud Monitoring.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-09-16 12:45 US/Pacific with current details.\nDiagnosis: Users experience an error when attempting to edit tables or any other dashboard component on a dashboard that has at least one table on it.\nDashboards without tables can still be edited normally.\nWorkaround: Customers can use the gcloud command to edit the JSON/YAML representation of their dashboards to work around the UI error:\nhttps://cloud.google.com/sdk/gcloud/reference/monitoring/dashboards/update","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-16T18:25:40+00:00","modified":"2022-09-16T18:25:46+00:00","when":"2022-09-16T18:25:40+00:00","text":"Summary: Global: Cloud Monitoring Dashboard experiencing issues editing tables\nDescription: We are experiencing an issue with Cloud Monitoring.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-09-16 12:45 US/Pacific with current details.\nDiagnosis: Users experience an error when attempting to edit tables or any other dashboard component on a dashboard that has at least one table on it.\nDashboards without tables can still be edited normally.\nWorkaround: none","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-16T20:31:38+00:00","modified":"2022-09-16T20:31:39+00:00","when":"2022-09-16T20:31:38+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected users as of Friday, 2022-09-16 13:31 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"}],"uri":"incidents/1wLJzpF7zkXbsZEGFgf4","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"urNR4xD4gBNsyaZj3W1i","number":"8605665058763432284","begin":"2022-09-15T23:01:57+00:00","created":"2022-09-15T23:01:58+00:00","end":"2022-09-29T20:49:04+00:00","modified":"2022-09-29T20:49:04+00:00","external_desc":"Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+","updates":[{"created":"2022-09-29T20:49:04+00:00","modified":"2022-09-29T20:49:05+00:00","when":"2022-09-29T20:49:04+00:00","text":"The issue with Google Kubernetes Engine has been resolved for all affected users as of Thursday, 2022-09-29 13:45 US/Pacific.\nA fix is available in GKE v1.24.4-gke.800 and available in v1.23 and v1.22\nCustomers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-23T22:48:05+00:00","modified":"2022-09-23T22:48:06+00:00","when":"2022-09-23T22:48:05+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck Terminating or Pending after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release, which has now started. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-30 15:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-23T22:06:12+00:00","modified":"2022-09-23T22:06:19+00:00","when":"2022-09-23T22:06:12+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck terminating after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\n- All 1.22 GKE versions\n- All 1.23 GKE versions\n- 1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-23 16:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-21T21:56:05+00:00","modified":"2022-09-21T21:56:13+00:00","when":"2022-09-21T21:56:05+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck terminating after upgrading to 1.22+\nDescription: The following GKE versions are vulnerable to a race condition when using the Calico Network Policy, resulting in pods stuck Terminating or Pending:\n- All 1.22 GKE versions\n- All 1.23 GKE versions\n- 1.24 versions before 1.24.4-gke.800\nOnly a small number of GKE clusters have actually experienced stuck pods. Use of cluster autoscaler can increase the chance of hitting the race condition.\nA fix is available in GKE v1.24.4-gke.800 or later. The fix is also being made available in v1.23 and v1.22, as part of the next release. Once available, customers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.\nWe will provide an update by Friday, 2022-09-23 15:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Customers currently experiencing the issue, are requested to take one of the following actions:\n1. [Recommended] Manually upgrade to GKE v1.24.4-gke.800 or later (if viable), or reach out to Google Cloud Support to have an internal patch applied\n2. Restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-16T22:22:52+00:00","modified":"2022-09-16T22:22:53+00:00","when":"2022-09-16T22:22:52+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck terminating after upgrading to 1.22+\nDescription: GKE clusters running the following versions that use Calico Network Policy might experience issues with pods under some conditions.\nAll 1.22 GKE versions\nAll 1.23 GKE versions\n1.24 versions before 1.24.4-gke.800\nA fix is available in GKE v1.24.4-gke.800 or later. After qualification completes, we will expedite the backport of the fix to 1.22 and 1.23. Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks, or customers can manually upgrade to the fixed version.\nWe will provide an update by Wednesday, 2022-09-21 15:00 US/Pacific with current details.\nThe issue was introduced in the Calico component, and GKE has been working closely with the Calico project to produce a fix. We apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin shows the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Affected customers may try the following:\n1. [Recommended] Customers on affected versions can reach out to Google Cloud Support to have an internal patch applied.\n2. Customers can restart the kubelet and calico-node to get the pods unstuck.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T23:01:57+00:00","modified":"2022-09-15T23:10:08+00:00","when":"2022-09-15T23:01:57+00:00","text":"Summary: Global: Calico enabled GKE clusters’ pods may get stuck terminating after upgrading to 1.22+\nDescription: GKE clusters running versions 1.22 or later and that use Calico Network Policy might experience issues with terminating Pods under some conditions.\nOur engineering team continues to investigate the issue and are qualifying a potential mitigation for release to the Rapid channel 1.24. After all the qualifications are done, we will expedite the backport of the fix to 1.22 as soon as possible.\nWe will provide an update by Friday, 2022-09-16 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The Calico CNI plugin will show the following error terminating Pods:\n“Warning FailedKillPod 36m (x389 over 121m) kubelet error killing pod: failed to \"KillPodSandbox\" for \"af9ab8f9-d6d6-4828-9b8c-a58441dd1f86\" with KillPodSandboxError: \"rpc error: code = Unknown desc = networkPlugin cni failed to teardown pod \"myclient-pod-6474c76996\" network: error getting ClusterInformation: connection is unauthorized: Unauthorized\"\nWorkaround: Affected customers may try the following:\n1. Restart the kubelet and calico-node can help getting the pods unstuck.\n2. Disable the Calico network policy. (workaround #1 is recommended, as this workaround is only viable if the customer does not have a strong need for Calico).","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-29T20:49:04+00:00","modified":"2022-09-29T20:49:05+00:00","when":"2022-09-29T20:49:04+00:00","text":"The issue with Google Kubernetes Engine has been resolved for all affected users as of Thursday, 2022-09-29 13:45 US/Pacific.\nA fix is available in GKE v1.24.4-gke.800 and available in v1.23 and v1.22\nCustomers can manually upgrade to the fixed version. Or, Clusters on the RAPID, REGULAR or STABLE release channels using 1.22 or 1.23 will upgrade automatically over coming weeks.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LCSbT57h59oR4W98NHuz","service_name":"Google Kubernetes Engine","affected_products":[{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"}],"uri":"incidents/urNR4xD4gBNsyaZj3W1i","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"H1ezzg8Ks93xvAWn8KNw","number":"10376434512372040340","begin":"2022-09-15T21:39:45+00:00","created":"2022-09-15T21:59:17+00:00","end":"2022-09-16T00:03:17+00:00","modified":"2022-09-16T00:03:17+00:00","external_desc":"Global: Cloud Run deployment time outs and failures","updates":[{"created":"2022-09-16T00:03:16+00:00","modified":"2022-09-16T00:03:18+00:00","when":"2022-09-16T00:03:16+00:00","text":"The issue with Cloud Run has been resolved for all affected users as of Thursday, 2022-09-15 16:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-15T22:50:28+00:00","modified":"2022-09-15T22:50:30+00:00","when":"2022-09-15T22:50:28+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-09-15 18:30 US/Pacific.\nDiagnosis: Customers may observe deployment failures and timeout errors.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T22:22:34+00:00","modified":"2022-09-15T22:22:35+00:00","when":"2022-09-15T22:22:34+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: We are experiencing an issue with Cloud Run deployments timing out and failing.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 16:00 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-15T21:59:16+00:00","modified":"2022-09-15T21:59:17+00:00","when":"2022-09-15T21:59:16+00:00","text":"Summary: Global: Cloud Run deployments time outs and failures\nDescription: We are experiencing an issue with Cloud Run deployments timing out and failing.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-16T00:03:16+00:00","modified":"2022-09-16T00:03:18+00:00","when":"2022-09-16T00:03:16+00:00","text":"The issue with Cloud Run has been resolved for all affected users as of Thursday, 2022-09-15 16:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9D7d2iNBQWN24zc1VamE","service_name":"Cloud Run","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"}],"uri":"incidents/H1ezzg8Ks93xvAWn8KNw","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"CH7e9xRDMZx1NqPU3UKG","number":"932279567059219721","begin":"2022-09-15T19:56:09+00:00","created":"2022-09-15T20:27:00+00:00","end":"2022-09-15T20:57:55+00:00","modified":"2022-09-15T20:57:55+00:00","external_desc":"Issue with creating new Stream instance","updates":[{"created":"2022-09-15T20:57:54+00:00","modified":"2022-09-15T20:57:55+00:00","when":"2022-09-15T20:57:54+00:00","text":"This incident with Google Cloud Networking was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},{"created":"2022-09-15T20:26:59+00:00","modified":"2022-09-15T20:27:01+00:00","when":"2022-09-15T20:26:59+00:00","text":"Summary: Issue with creating new Stream instance\nDescription: We are experiencing an issue with Google Cloud Networking.\nIf customers are trying to create new Stream Instance, the newly created Stream Instance will not be able to stream their content although it's showing \"Ready\".\nBut existing Stream Instances are working and good to use.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: If customers are trying to create new Stream Instance, the newly created Stream Instance will not be able to stream their content although it's showing \"Ready\"\nBut existing Stream Instances are working and good to use.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]}],"most_recent_update":{"created":"2022-09-15T20:57:54+00:00","modified":"2022-09-15T20:57:55+00:00","when":"2022-09-15T20:57:54+00:00","text":"This incident with Google Cloud Networking was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/CH7e9xRDMZx1NqPU3UKG","currently_affected_locations":[],"previously_affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},{"id":"5kFqcg27NjQ1nkYFpfMM","number":"5270185420647628931","begin":"2022-09-15T19:20:07+00:00","created":"2022-09-15T19:20:13+00:00","end":"2022-09-15T21:39:21+00:00","modified":"2022-09-15T21:39:21+00:00","external_desc":"Global: Cloud Run deployment time outs and failures","updates":[{"created":"2022-09-15T21:39:21+00:00","modified":"2022-09-15T21:39:22+00:00","when":"2022-09-15T21:39:21+00:00","text":"The issue with Cloud Run has been resolved for all affected users as of Thursday, 2022-09-15 14:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T20:52:26+00:00","modified":"2022-09-15T20:52:27+00:00","when":"2022-09-15T20:52:26+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 15:30 US/Pacific with current details.\nDiagnosis: Customers are seeing deployments time out and fail\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T20:17:27+00:00","modified":"2022-09-15T20:17:28+00:00","when":"2022-09-15T20:17:27+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 14:30 US/Pacific with current details.\nDiagnosis: Customers are seeing deployments time out and fail\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T20:17:11+00:00","modified":"2022-09-15T20:17:12+00:00","when":"2022-09-15T20:17:11+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 13:30 US/Pacific with current details.\nDiagnosis: Customers are seeing deployments time out and fail\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T19:44:11+00:00","modified":"2022-09-15T19:44:12+00:00","when":"2022-09-15T19:44:11+00:00","text":"Summary: Global: Cloud Run deployment time outs and failures\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 13:14 US/Pacific with current details.\nDiagnosis: Customers are seeing deployments time out and fail\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T19:33:52+00:00","modified":"2022-09-15T19:33:53+00:00","when":"2022-09-15T19:33:52+00:00","text":"Summary: Global: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 13:14 US/Pacific with current details.\nDiagnosis: Customers are seeing deployments time out and fail\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T19:21:43+00:00","modified":"2022-09-15T19:21:44+00:00","when":"2022-09-15T19:21:43+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 13:14 US/Pacific with current details.\nDiagnosis: Cloud Run deployments are timing out and failing\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T19:20:07+00:00","modified":"2022-09-15T19:20:13+00:00","when":"2022-09-15T19:20:07+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 13:14 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-15T21:39:21+00:00","modified":"2022-09-15T21:39:22+00:00","when":"2022-09-15T21:39:21+00:00","text":"The issue with Cloud Run has been resolved for all affected users as of Thursday, 2022-09-15 14:39 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9D7d2iNBQWN24zc1VamE","service_name":"Cloud Run","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"}],"uri":"incidents/5kFqcg27NjQ1nkYFpfMM","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"fL4dE64oQnj87ityy8uU","number":"6383724720146183504","begin":"2022-09-15T00:00:06+00:00","created":"2022-09-15T00:00:07+00:00","end":"2022-09-15T08:13:16+00:00","modified":"2022-09-15T08:13:17+00:00","external_desc":"Multi-Region: Elevated Cloud Run deployment latency","updates":[{"created":"2022-09-15T08:13:16+00:00","modified":"2022-09-15T08:13:17+00:00","when":"2022-09-15T08:13:16+00:00","text":"The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2022-09-15 00:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T06:46:32+00:00","modified":"2022-09-15T06:46:33+00:00","when":"2022-09-15T06:46:32+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: Mitigation work is currently underway by our engineering team. We see that the service is recovering.\nWe will provide more information by Thursday, 2022-09-15 02:30 US/Pacific.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T06:08:51+00:00","modified":"2022-09-15T06:08:52+00:00","when":"2022-09-15T06:08:51+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: Mitigation work is currently underway by our engineering team. We see that the service is recovering.\nWe will provide more information by Thursday, 2022-09-15 02:00 US/Pacific.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T05:30:33+00:00","modified":"2022-09-15T05:30:40+00:00","when":"2022-09-15T05:30:33+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: Mitigation work is currently underway by our engineering team. We see the service has started recovering.\nWe will provide more information by Thursday, 2022-09-15 01:00 US/Pacific.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T03:20:37+00:00","modified":"2022-09-15T03:20:39+00:00","when":"2022-09-15T03:20:37+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: Mitigation work is currently underway by our engineering team. We see the service has started recovering.\nWe will provide more information by Thursday, 2022-09-14 24:00 US/Pacific.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T02:11:52+00:00","modified":"2022-09-15T02:11:59+00:00","when":"2022-09-15T02:11:52+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-14 20:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T01:06:55+00:00","modified":"2022-09-15T01:06:57+00:00","when":"2022-09-15T01:06:55+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-14 19:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe increased latency and deployment failures with Cloud Run.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T00:56:46+00:00","modified":"2022-09-15T00:56:52+00:00","when":"2022-09-15T00:56:46+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-14 19:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe increased latency with Cloud Run deployments.\nWorkaround: Customers may try deploying again.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T00:26:04+00:00","modified":"2022-09-15T00:26:05+00:00","when":"2022-09-15T00:26:04+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-14 18:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe increased latency with Cloud Run deployments.\nWorkaround: Customers may try deploying again.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T00:00:06+00:00","modified":"2022-09-15T00:00:09+00:00","when":"2022-09-15T00:00:06+00:00","text":"Summary: Multi-Region: Elevated Cloud Run deployment latency\nDescription: We are experiencing an issue with Cloud Run.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-09-14 17:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe increased latency with Cloud Run deployments.\nWorkaround: Customers may try deploying again.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-15T08:13:16+00:00","modified":"2022-09-15T08:13:17+00:00","when":"2022-09-15T08:13:16+00:00","text":"The issue with Cloud Run has been resolved for all affected projects as of Thursday, 2022-09-15 00:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9D7d2iNBQWN24zc1VamE","service_name":"Cloud Run","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"}],"uri":"incidents/fL4dE64oQnj87ityy8uU","currently_affected_locations":[],"previously_affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"a39Bb5MP1XYq6utZmssE","number":"1484069176892536273","begin":"2022-09-15T00:00:00+00:00","created":"2022-09-15T15:02:51+00:00","end":"2022-09-15T15:56:00+00:00","modified":"2022-09-15T20:40:56+00:00","external_desc":"Google Engineer are investigating an issues with Cloud GCE.","updates":[{"created":"2022-09-15T20:40:12+00:00","modified":"2022-09-15T20:40:12+00:00","when":"2022-09-15T20:40:12+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n(All Times US/Pacific)\n**Incident Start:** 14 September 2022 17:00\n**Incident End:** 15 September 2022 08:56\n**Duration:** 15 hours, 56 minutes\n**Affected Services and Features:**\nGoogle Compute Engine - Red Hat OS\n**Regions/Zones:** Global\n**Description:**\nGoogle Compute Engine customers running “yum” or “dnf” commands in Red Hat instances experienced 403 forbidden responses when attempting to install packages. The root cause was that the Red Hat Update infrastructure software update [1] combined with an invalid configuration caused a new build of the software to be unusable and that build was mistakenly released to prod via automation.\n[1] https://access.redhat.com/products/red-hat-update-infrastructure\n**Customer Impact:**\n100 % of customers running “yum” in RHEL instances received a 403 - Forbidden response. All Red Hat instances attempting to get updates encountered failures for the duration of the outage.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T16:08:22+00:00","modified":"2022-09-15T16:08:28+00:00","when":"2022-09-15T16:08:22+00:00","text":"The issue with Google Compute Engine has been resolved for all affected users as of Thursday, 2022-09-15 08:56 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T15:11:17+00:00","modified":"2022-09-15T15:11:22+00:00","when":"2022-09-15T15:11:17+00:00","text":"Summary: Google Engineer are investigating an issues with Cloud GCE.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Thursday, 2022-09-15 00:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 09:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using our RedHat licenses are currently unable to update/apply RedHat patches\nWorkaround: none at present","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T15:09:37+00:00","modified":"2022-09-15T15:09:48+00:00","when":"2022-09-15T15:09:37+00:00","text":"Summary: Google Engineer are investigating an issues with Cloud GCE.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Thursday, 2022-09-15 00:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 09:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using our RedHat licenses are currently unable to update/apply RedHat patches\nWorkaround: none at present","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T15:04:35+00:00","modified":"2022-09-15T15:04:39+00:00","when":"2022-09-15T15:04:35+00:00","text":"Summary: Google Engineer are investigating an issues with Cloud GCE.\nDescription: We are experiencing an issue with Google Compute Engine {IF START TIME KNOWN, beginning at Thursday, 2022-09-15 00:00 US/Pacific}.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 09:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using our RedHat licenses are currently unable to update/apply RedHat patches\nWorkaround: none at present","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-15T15:02:43+00:00","modified":"2022-09-15T15:02:53+00:00","when":"2022-09-15T15:02:43+00:00","text":"Summary: Google Engineer are investigating an issues with Cloud GCE.\nDescription: We are experiencing an issue with Google Kubernetes Engine {IF START TIME KNOWN, beginning at Thursday, 2022-09-15 00:00 US/Pacific}.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-15 09:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers using our RedHat licenses are currently unable to update/apply RedHat patches\nWorkaround: none at present","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-15T20:40:12+00:00","modified":"2022-09-15T20:40:12+00:00","when":"2022-09-15T20:40:12+00:00","text":"## Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n(All Times US/Pacific)\n**Incident Start:** 14 September 2022 17:00\n**Incident End:** 15 September 2022 08:56\n**Duration:** 15 hours, 56 minutes\n**Affected Services and Features:**\nGoogle Compute Engine - Red Hat OS\n**Regions/Zones:** Global\n**Description:**\nGoogle Compute Engine customers running “yum” or “dnf” commands in Red Hat instances experienced 403 forbidden responses when attempting to install packages. The root cause was that the Red Hat Update infrastructure software update [1] combined with an invalid configuration caused a new build of the software to be unusable and that build was mistakenly released to prod via automation.\n[1] https://access.redhat.com/products/red-hat-update-infrastructure\n**Customer Impact:**\n100 % of customers running “yum” in RHEL instances received a 403 - Forbidden response. All Red Hat instances attempting to get updates encountered failures for the duration of the outage.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/a39Bb5MP1XYq6utZmssE","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"X8SNkK2BPyCrc1sveeiu","number":"16739274872265070232","begin":"2022-09-13T14:38:00+00:00","created":"2022-09-13T16:46:32+00:00","end":"2022-09-13T17:42:00+00:00","modified":"2022-09-26T22:10:16+00:00","external_desc":"Cloud Filestore ListInstances API failed with error code 429 globally","updates":[{"created":"2022-09-26T22:10:16+00:00","modified":"2022-09-26T22:10:16+00:00","when":"2022-09-26T22:10:16+00:00","text":"## INCIDENT REPORT ##\n**Summary:**\nOn Tuesday, 13 September 2022 07:30 US/Pacific, an issue with Google Cloud Filestore resulted in all read-only API requests failing for a period of 3 hours, 12 minutes. The issue was fully mitigated on Tuesday, 13 September 2022 at 10:42 US/Pacific.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability of the service in the future.\n**Root Cause:**\nFilestore enforces a global limit on API requests to limit impact in overload scenarios. The outage was triggered when an internal Google service managing a large number of GCP projects malfunctioned and overloaded the Filestore API with requests, causing global throttling of the Filestore API. This continued until the internal service was manually paused.\nAs a result of this throttling, read-only API access was unavailable for all customers. This affected customers in all locations, due to a global quota that applies to Filestore. Console, gcloud and API access (List, GetOperation, etc.) calls all failed for a duration of 3 hours, 12 minutes.\nMutate operations (CreateInstance, UpdateInstance, CreateBackup, etc.) still succeeded, but customers were unable to check on operation progress.\n**Remediation and Prevention**\nOur engineers were alerted of the issue through automated alerts on Tuesday, 13 September 2022 07:47 US/Pacific. Once the nature and scope of the issue became clear, Google engineers started shutting down the internal service overloading our APIs at 10:33 and the issue was completely resolved at 10:42.\nGoogle is committed to preventing recurrence by implementing the following action items:\n- Removal of the global quotas which resulted in a local overload causing a global impact.\n- Improve alerting and monitoring to respond more promptly when approaching internal limits, improving time to detection and mitigation.\nWe appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact:**\nOn Tuesday, 13 September 2022 from 07:30 to 10:42 US/Pacific, Google Cloud Filestore experienced an issue where ListInstances API requests failed with error code 429. This impacted read-only API access for customers globally. Pantheon, gcloud and API access (List, GetOperation, etc.) calls failed during this time. Mutate operations (CreateInstance, UpdateInstance, CreateBackup, etc.) still succeeded, however clients were not able to check on operation progress.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-13T18:46:03+00:00","modified":"2022-09-13T18:46:03+00:00","when":"2022-09-13T18:46:03+00:00","text":"## MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 13 September 2022 07:38\n**Incident End:** 13 September 2022 10:42\n**Duration:** 3 hours, 04 minutes\n**Affected Services and Features:**\nGoogle Cloud Filestore - API requests\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Filestore experienced an issue where ListInstances API requests failed with error code 429 for a duration of 3 hours, 04 minutes. From preliminary analysis, the root cause of the issue is an unexpected spike in traffic from internal backend services.\n**Customer Impact:**\nCustomers encountered error 429 when listing Cloud Filestore instances using API, gcloud CLI, and Google Cloud Console UI.\n-------------------","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-13T17:46:25+00:00","modified":"2022-09-13T17:46:27+00:00","when":"2022-09-13T17:46:25+00:00","text":"The issue with Cloud Filestore has been resolved for all affected users as of Tuesday, 2022-09-13 10:42 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-13T17:33:54+00:00","modified":"2022-09-13T17:34:01+00:00","when":"2022-09-13T17:33:54+00:00","text":"Summary: Cloud Filestore ListInstances API failed with error code 429 globally\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-09-13 07:38 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-13 11:32 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may see the error code 429 globally in Pantheon when they are viewing the list of instances in the Filestore UI.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-13T16:46:26+00:00","modified":"2022-09-13T16:46:34+00:00","when":"2022-09-13T16:46:26+00:00","text":"Summary: Cloud Filestore ListInstances API failed with error code 429 globally\nDescription: We are experiencing an issue with Cloud Filestore.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-13 10:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may see the error code 429 globally in Pantheon when they are viewing the list of instances in the Filestore UI.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-26T22:10:16+00:00","modified":"2022-09-26T22:10:16+00:00","when":"2022-09-26T22:10:16+00:00","text":"## INCIDENT REPORT ##\n**Summary:**\nOn Tuesday, 13 September 2022 07:30 US/Pacific, an issue with Google Cloud Filestore resulted in all read-only API requests failing for a period of 3 hours, 12 minutes. The issue was fully mitigated on Tuesday, 13 September 2022 at 10:42 US/Pacific.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability of the service in the future.\n**Root Cause:**\nFilestore enforces a global limit on API requests to limit impact in overload scenarios. The outage was triggered when an internal Google service managing a large number of GCP projects malfunctioned and overloaded the Filestore API with requests, causing global throttling of the Filestore API. This continued until the internal service was manually paused.\nAs a result of this throttling, read-only API access was unavailable for all customers. This affected customers in all locations, due to a global quota that applies to Filestore. Console, gcloud and API access (List, GetOperation, etc.) calls all failed for a duration of 3 hours, 12 minutes.\nMutate operations (CreateInstance, UpdateInstance, CreateBackup, etc.) still succeeded, but customers were unable to check on operation progress.\n**Remediation and Prevention**\nOur engineers were alerted of the issue through automated alerts on Tuesday, 13 September 2022 07:47 US/Pacific. Once the nature and scope of the issue became clear, Google engineers started shutting down the internal service overloading our APIs at 10:33 and the issue was completely resolved at 10:42.\nGoogle is committed to preventing recurrence by implementing the following action items:\n- Removal of the global quotas which resulted in a local overload causing a global impact.\n- Improve alerting and monitoring to respond more promptly when approaching internal limits, improving time to detection and mitigation.\nWe appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact:**\nOn Tuesday, 13 September 2022 from 07:30 to 10:42 US/Pacific, Google Cloud Filestore experienced an issue where ListInstances API requests failed with error code 429. This impacted read-only API access for customers globally. Pantheon, gcloud and API access (List, GetOperation, etc.) calls failed during this time. Mutate operations (CreateInstance, UpdateInstance, CreateBackup, etc.) still succeeded, however clients were not able to check on operation progress.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"jog4nyYkquiLeSK5s26q","service_name":"Cloud Filestore","affected_products":[{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/X8SNkK2BPyCrc1sveeiu","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"pEgU6tNHVw4PHr2DRdCF","number":"10471931045992956499","begin":"2022-09-13T04:02:00+00:00","created":"2022-09-16T22:49:56+00:00","end":"2022-09-17T00:22:00+00:00","modified":"2022-09-25T02:54:14+00:00","external_desc":"Support Systems Salesforce case updates fails with row lock error.","updates":[{"created":"2022-09-20T03:58:19+00:00","modified":"2022-09-25T02:54:14+00:00","when":"2022-09-20T03:58:19+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 12 September 2022 21:02\n**Incident End:** 16 September 2022 17:22\n**Duration:** 3 days, 20 hours, 20 minutes\n**Affected Services and Features:**\nGoogle Cloud Support systems\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Support Systems experienced an intermittent issue where case updates from the portal were failing for a brief period. Retrying the same update may have succeeded in some cases. From preliminary analysis, the root cause of the issue is a large backlog of update actions that built up in the entitlement process.\n**Customer Impact:** * Less than 0.1% of Google Cloud and Google Workspace customers experienced delays in contacting, providing and getting updates to and from Google Support Agents. The issue impacted support’s ability to send updates to customers via the case management system. Following are the scenarios in which errors were received. * While sending emails to customers, the send action is unavailable due to errors. * Error while changing case ownership. * Error while posting comments on the case. * Some customers experienced an error “There was an error adding your comment. Please try again” while updating cases from the support portal.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-17T00:29:06+00:00","modified":"2022-09-17T00:29:07+00:00","when":"2022-09-17T00:29:06+00:00","text":"The issue with Google Cloud Support has been resolved for all affected users as of Friday, 2022-09-16 17:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-16T22:49:55+00:00","modified":"2022-09-16T22:49:56+00:00","when":"2022-09-16T22:49:55+00:00","text":"Summary: Support Systems Salesforce case updates fails with row lock error.\nDescription: Our engineering team continues to investigate the issue with Cloud support systems and are currently working the mitigation.\nCustomer impact:\n- Customers are unable to update the support cases from the support portal.\nWe will provide an update by Friday, 2022-09-16 18:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Support case updates are failing with error.\nWorkaround: Retrying the update action successfully update the support case.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-09-20T03:58:19+00:00","modified":"2022-09-25T02:54:14+00:00","when":"2022-09-20T03:58:19+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 12 September 2022 21:02\n**Incident End:** 16 September 2022 17:22\n**Duration:** 3 days, 20 hours, 20 minutes\n**Affected Services and Features:**\nGoogle Cloud Support systems\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Support Systems experienced an intermittent issue where case updates from the portal were failing for a brief period. Retrying the same update may have succeeded in some cases. From preliminary analysis, the root cause of the issue is a large backlog of update actions that built up in the entitlement process.\n**Customer Impact:** * Less than 0.1% of Google Cloud and Google Workspace customers experienced delays in contacting, providing and getting updates to and from Google Support Agents. The issue impacted support’s ability to send updates to customers via the case management system. Following are the scenarios in which errors were received. * While sending emails to customers, the send action is unavailable due to errors. * Error while changing case ownership. * Error while posting comments on the case. * Some customers experienced an error “There was an error adding your comment. Please try again” while updating cases from the support portal.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"bGThzF7oEGP5jcuDdMuk","service_name":"Google Cloud Support","affected_products":[{"title":"Google Cloud Support","id":"bGThzF7oEGP5jcuDdMuk"}],"uri":"incidents/pEgU6tNHVw4PHr2DRdCF","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"qyBbHRx9BCz3bMw3kiL3","number":"3854927666133782192","begin":"2022-09-09T01:15:48+00:00","created":"2022-09-09T01:23:49+00:00","end":"2022-09-09T04:07:23+00:00","modified":"2022-09-09T04:07:23+00:00","external_desc":"Asia: Data Catalog Search seeing high error rate in APAC and US","updates":[{"created":"2022-09-09T04:07:23+00:00","modified":"2022-09-09T04:07:24+00:00","when":"2022-09-09T04:07:23+00:00","text":"The issue with Data Catalog has been resolved for all affected users as of Thursday, 2022-09-08 20:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: asia","id":"asia"},{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-09T03:22:19+00:00","modified":"2022-09-09T03:22:21+00:00","when":"2022-09-09T03:22:19+00:00","text":"Summary: Asia: Data Catalog Search seeing high error rate in APAC and US\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Thursday, 2022-09-08 22:37 US/Pacific.\nDiagnosis: Data catalog search is seeing issues.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: asia","id":"asia"},{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-09T02:57:27+00:00","modified":"2022-09-09T02:57:31+00:00","when":"2022-09-09T02:57:27+00:00","text":"Summary: Asia: Data Catalog Search seeing high error rate in APAC and US\nDescription: We are experiencing an issue with Data Catalog.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-08 21:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Data catalog search is seeing issues.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: asia","id":"asia"},{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-09T02:19:05+00:00","modified":"2022-09-09T02:19:06+00:00","when":"2022-09-09T02:19:05+00:00","text":"Summary: Asia: Data Catalog APAC Search seeing high error rate\nDescription: We are experiencing an issue with Data Catalog.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-08 21:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Data catalog search is seeing issues.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: asia","id":"asia"}]},{"created":"2022-09-09T01:23:42+00:00","modified":"2022-09-09T01:23:50+00:00","when":"2022-09-09T01:23:42+00:00","text":"Summary: Asia: Data Catalog APAC Search seeing high error rate\nDescription: We are experiencing an issue with Data Catalog.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-08 19:22 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Data catalog search is seeing issues.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: asia","id":"asia"}]}],"most_recent_update":{"created":"2022-09-09T04:07:23+00:00","modified":"2022-09-09T04:07:24+00:00","when":"2022-09-09T04:07:23+00:00","text":"The issue with Data Catalog has been resolved for all affected users as of Thursday, 2022-09-08 20:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: asia","id":"asia"},{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"TFedVRYgKGRGMSJrUpup","service_name":"Data Catalog","affected_products":[{"title":"Data Catalog","id":"TFedVRYgKGRGMSJrUpup"}],"uri":"incidents/qyBbHRx9BCz3bMw3kiL3","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: asia","id":"asia"},{"title":"Multi-region: us","id":"us"}]},{"id":"MPyRe8eVsGt5Zib7P9gd","number":"9391544233897048253","begin":"2022-09-08T08:37:09+00:00","created":"2022-09-08T08:52:01+00:00","end":"2022-09-08T10:27:37+00:00","modified":"2022-09-08T10:27:37+00:00","external_desc":"Google Engineer are actively investigating an issues with BigQuery Early indication is customer in the EU area are being impacted.","updates":[{"created":"2022-09-08T10:27:35+00:00","modified":"2022-09-08T10:27:39+00:00","when":"2022-09-08T10:27:35+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2022-09-08 03:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-09-08T09:47:55+00:00","modified":"2022-09-08T09:48:00+00:00","when":"2022-09-08T09:47:55+00:00","text":"Summary: Google Engineer are actively investigating an issues with BigQuery Early indication is customer in the EU area are being impacted.\nDescription: Mitigation work is currently underway by our engineering team.\nETA for mitigation completion is approx 2 hours.\nWe will provide more information by Thursday, 2022-09-08 05:00 US/Pacific.\nDiagnosis: Customers receive INTERNAL_ERROR for some queries\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-08T09:47:15+00:00","modified":"2022-09-08T09:47:20+00:00","when":"2022-09-08T09:47:15+00:00","text":"Summary: Google Engineer are actively investigating an issues with BigQuery Early indication is customer in the EU area are being impacted.\nDescription: Mitigation work is currently underway by our engineering team.\nETA for mitigation is approx 2 hours.\nWe will provide more information by Thursday, 2022-09-08 05:00 US/Pacific.\nDiagnosis: Customers receive INTERNAL_ERROR for some queries\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-08T09:46:00+00:00","modified":"2022-09-08T09:46:12+00:00","when":"2022-09-08T09:46:00+00:00","text":"Summary: Google Engineer are actively investigating an issues with BigQuery Early indication is customer in the EU area are being impacted.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-09-08 05:00 US/Pacific.\nDiagnosis: Customers receive INTERNAL_ERROR for some queries\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-09-08T08:51:53+00:00","modified":"2022-09-08T08:52:05+00:00","when":"2022-09-08T08:51:53+00:00","text":"Summary: Google Engineer are actively investigating an issues with BigQuery Early indication is customer in the EU area are being impacted.\nDescription: We are experiencing an issue with Google BigQuery beginning at Thursday, 2022-09-08 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-08 02:43 US/Pacific with current details.\nDiagnosis: Customers receive INTERNAL_ERROR for some queries\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-08T10:27:35+00:00","modified":"2022-09-08T10:27:39+00:00","when":"2022-09-08T10:27:35+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2022-09-08 03:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/MPyRe8eVsGt5Zib7P9gd","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"LQnCJ3wv217cYwhiaWSz","number":"12100379670414005436","begin":"2022-09-07T01:02:09+00:00","created":"2022-09-07T01:02:15+00:00","end":"2022-09-07T03:02:24+00:00","modified":"2022-09-07T03:02:25+00:00","external_desc":"BigQuery Data Transfer Service for Google Ad Manager transfer runs failing with error","updates":[{"created":"2022-09-07T03:02:24+00:00","modified":"2022-09-07T03:02:25+00:00","when":"2022-09-07T03:02:24+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Tuesday, 2022-09-06 19:48 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-07T01:42:30+00:00","modified":"2022-09-07T01:42:31+00:00","when":"2022-09-07T01:42:30+00:00","text":"Summary: BigQuery Data Transfer Service for Google Ad Manager transfer runs failing with error\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-06 20:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Impacted customers will see transfer runs failing as \"Error code 3 : Invalid subtask batch. Should have at least 1 subtask.\"\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-09-07T01:02:10+00:00","modified":"2022-09-07T01:02:16+00:00","when":"2022-09-07T01:02:10+00:00","text":"Summary: BigQuery Data Transfer Service for Google Ad Manager transfer runs failing with error\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-06 19:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Impacted customers will see transfer runs failing as \"Error code 3 : Invalid subtask batch. Should have at least 1 subtask.\"\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-07T03:02:24+00:00","modified":"2022-09-07T03:02:25+00:00","when":"2022-09-07T03:02:24+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Tuesday, 2022-09-06 19:48 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/LQnCJ3wv217cYwhiaWSz","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"DVaEf77NdnLsyW19hk8Q","number":"17228246557319730470","begin":"2022-09-06T16:16:14+00:00","created":"2022-09-06T16:16:20+00:00","end":"2022-09-06T18:09:14+00:00","modified":"2022-09-06T18:09:14+00:00","external_desc":"US-Central1: Cloud Dataflow jobs experiencing issues","updates":[{"created":"2022-09-06T18:09:14+00:00","modified":"2022-09-06T18:09:15+00:00","when":"2022-09-06T18:09:14+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Tuesday, 2022-09-06 11:09 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-09-06T17:59:49+00:00","modified":"2022-09-06T17:59:50+00:00","when":"2022-09-06T17:59:49+00:00","text":"Summary: US-Central1: Cloud Dataflow jobs experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-09-06 11:30 US/Pacific.\nDiagnosis: Jobs are stuck and make no progress.\nWorkaround: Batch jobs can be cancelled and restarted.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-09-06T17:59:25+00:00","modified":"2022-09-06T17:59:32+00:00","when":"2022-09-06T17:59:25+00:00","text":"Summary: US-Central1: Cloud Dataflow jobs experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-09-06 11:39 US/Pacific.\nDiagnosis: Jobs are stuck and make no progress.\nWorkaround: Batch jobs can be cancelled and restarted.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-09-06T16:50:52+00:00","modified":"2022-09-06T16:50:53+00:00","when":"2022-09-06T16:50:52+00:00","text":"Summary: US-Central1: Cloud Dataflow jobs experiencing issues\nDescription: We are experiencing an issue with Google Cloud Dataflow.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-06 11:30 US/Pacific with current details.\nDiagnosis: Jobs are stuck and make no progress.\nWorkaround: Batch jobs can be cancelled and restarted.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-09-06T16:16:14+00:00","modified":"2022-09-06T16:16:21+00:00","when":"2022-09-06T16:16:14+00:00","text":"Summary: US-Central1: Cloud Dataflow jobs experiencing issues\nDescription: We are experiencing an issue with Google Cloud Dataflow.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-06 09:50 US/Pacific with current details.\nDiagnosis: Jobs are stuck and make no progress.\nWorkaround: Batch jobs can be cancelled and restarted.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-09-06T18:09:14+00:00","modified":"2022-09-06T18:09:15+00:00","when":"2022-09-06T18:09:14+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Tuesday, 2022-09-06 11:09 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"T9bFoXPqG8w8g1YbWTKY","service_name":"Google Cloud Dataflow","affected_products":[{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"}],"uri":"incidents/DVaEf77NdnLsyW19hk8Q","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"m4b47Ln94TRKJz93setH","number":"16600744945116450948","begin":"2022-09-06T14:30:00+00:00","created":"2022-09-06T15:53:21+00:00","end":"2022-09-06T16:13:00+00:00","modified":"2022-09-06T18:47:19+00:00","external_desc":"Global: Cloud Armor Security Policy Change Propagation Failures","updates":[{"created":"2022-09-06T18:47:16+00:00","modified":"2022-09-06T18:47:16+00:00","when":"2022-09-06T18:47:16+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 06 September 2022 07:30\n**Incident End:** 06 September 2022 09:13\n**Duration:** 1 hour, 43 minutes\n**Affected Services and Features:**\nCloud Armor - Security Policy\n**Regions/Zones:** Global\n**Description:**\nCloud Armor experienced security policy update failures globally for 1 hour, 43 minutes. From preliminary analysis, this was due to failures in a backend storage component which caused stuck operations for several downstream operations.\n**Customer Impact:**\n- All changes made to security policies made by customers after 07:30 US/Pacific were not propagated. Affected customers would see their submitted change did not take effect until 09:30 US/Pacific. This was also visible in the log files.\n- Existing security policies were unaffected.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-06T16:18:12+00:00","modified":"2022-09-06T16:18:14+00:00","when":"2022-09-06T16:18:12+00:00","text":"The issue with Cloud Armor has been resolved for all affected users as of Tuesday, 2022-09-06 09:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-09-06T15:53:14+00:00","modified":"2022-09-06T15:53:23+00:00","when":"2022-09-06T15:53:14+00:00","text":"Summary: Global: Cloud Armor Security Policy Change Propagation Failures\nDescription: We are experiencing an issue with Cloud Armor beginning at Tuesday, 2022-09-06 07:48 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-09-06 09:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Changes to security policies performed by Customers are not propagating. Existing security policies are unaffected.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-09-06T18:47:16+00:00","modified":"2022-09-06T18:47:16+00:00","when":"2022-09-06T18:47:16+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 06 September 2022 07:30\n**Incident End:** 06 September 2022 09:13\n**Duration:** 1 hour, 43 minutes\n**Affected Services and Features:**\nCloud Armor - Security Policy\n**Regions/Zones:** Global\n**Description:**\nCloud Armor experienced security policy update failures globally for 1 hour, 43 minutes. From preliminary analysis, this was due to failures in a backend storage component which caused stuck operations for several downstream operations.\n**Customer Impact:**\n- All changes made to security policies made by customers after 07:30 US/Pacific were not propagated. Affected customers would see their submitted change did not take effect until 09:30 US/Pacific. This was also visible in the log files.\n- Existing security policies were unaffected.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"Kakg69gTC3xFyeJCY2va","service_name":"Cloud Armor","affected_products":[{"title":"Cloud Armor","id":"Kakg69gTC3xFyeJCY2va"}],"uri":"incidents/m4b47Ln94TRKJz93setH","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"pvxkedFYwu87YuHVe9YD","number":"18302692338471051641","begin":"2022-09-01T19:33:31+00:00","created":"2022-09-01T20:38:05+00:00","end":"2022-09-07T19:38:19+00:00","modified":"2022-09-07T19:38:19+00:00","external_desc":"Global: Google Cloud Functions Gen 2 customers experiencing issues","updates":[{"created":"2022-09-07T19:38:19+00:00","modified":"2022-09-07T19:38:20+00:00","when":"2022-09-07T19:38:19+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected projects as of Wednesday, 2022-09-07 12:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-07T18:06:50+00:00","modified":"2022-09-07T18:06:51+00:00","when":"2022-09-07T18:06:50+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nA fix has been identified, which is currently still in progress. We will provide more information by Wednesday, 2022 09-07 12:30 Us/Pacific.\nWe will provide more information by Wednesday, 2022-09-07 12:30 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-07T18:03:20+00:00","modified":"2022-09-07T18:03:22+00:00","when":"2022-09-07T18:03:20+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nA fix has been identified, which will be rolling out over the weekend. We will provide more information by Wednesday, 2022 09-07 11:00 Us/Pacific.\nWe will provide more information by Wednesday, 2022-09-07 11:30 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-06T19:49:06+00:00","modified":"2022-09-06T19:49:07+00:00","when":"2022-09-06T19:49:06+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nA fix has been identified, which will be rolling out over the weekend. We will provide more information by Wednesday, 2022 09-07 11:00 Us/Pacific.\nWe will provide more information by Wednesday, 2022-09-07 11:00 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-06T15:46:58+00:00","modified":"2022-09-06T15:47:05+00:00","when":"2022-09-06T15:46:58+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nA fix has been identified, which will be rolling out over the weekend. We will provide more information by Tuesday, 2022 09-06 13:00 Us/Pacific.\nWe will provide more information by Tuesday, 2022-09-06 13:00 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-02T14:30:54+00:00","modified":"2022-09-02T14:30:56+00:00","when":"2022-09-02T14:30:54+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nA fix has been identified, which will be rolling out over the weekend. We will provide more information by Tuesday, 2022 09-06 09:00 Us/Pacific.\nWe will provide more information by Tuesday, 2022-09-06 09:00 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-01T21:46:21+00:00","modified":"2022-09-01T21:46:23+00:00","when":"2022-09-01T21:46:21+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nMitigation work is expected to continue through Friday. We do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-09-02 09:00 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-01T21:41:04+00:00","modified":"2022-09-01T21:41:05+00:00","when":"2022-09-01T21:41:04+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-09-02 09:00 US/Pacific.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-01T20:38:00+00:00","modified":"2022-09-01T20:38:06+00:00","when":"2022-09-01T20:38:00+00:00","text":"Summary: Global: Google Cloud Functions Gen 2 customers experiencing issues\nDescription: We are experiencing an issue with Google Cloud Functions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-09-01 14:47 US/Pacific with current details.\nDiagnosis: Cloud Functions Gen 2 customers are missing metrics and experiencing incorrect billing for their SKUs.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-07T19:38:19+00:00","modified":"2022-09-07T19:38:20+00:00","when":"2022-09-07T19:38:19+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected projects as of Wednesday, 2022-09-07 12:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"oW4vJ7VNqyxTWNzSHopX","service_name":"Google Cloud Functions","affected_products":[{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/pvxkedFYwu87YuHVe9YD","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"f2T9veB57h1racANQHXW","number":"6502680748827686726","begin":"2022-08-31T17:01:56+00:00","created":"2022-08-31T17:01:57+00:00","end":"2022-08-31T22:29:06+00:00","modified":"2022-08-31T22:29:07+00:00","external_desc":"Global: Classic template job names do not accept underscores for Dataflow jobs","updates":[{"created":"2022-08-31T22:29:06+00:00","modified":"2022-08-31T22:29:08+00:00","when":"2022-08-31T22:29:06+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected projects as of Wednesday, 2022-08-31 15:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T18:34:01+00:00","modified":"2022-08-31T20:30:47+00:00","when":"2022-08-31T18:34:01+00:00","text":"Summary: Global: Classic Template job names do not accept underscores or upper-case letters for Dataflow jobs\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-08-31 18:00 US/Pacific.\nThe issue does not affect existing jobs which are running.\nCustomer action: - Utilize another region for running the affected job (unaffected regions listed under Workaround section). - Retry the request for affected jobs (affected regions listed under Workaround section).\nWe will provide an update by Wednesday, 2022-08-31 18:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers unable to submit new Classic Template jobs with underscores in job name.\nWorkaround: Utilize different regions or retry the request for affected jobs.\nList of regions available for mitigation (unaffected): - asia-northeast1 - asia-northeast3 - asia-south2 - asia-southeast1 - europe-central2 - europe-north1 - europe-west1 - europe-west2 - europe-west9 - northamerica-northeast1 - northamerica-northeast2 - southamerica-east1 - us-east5 - us-south1 - us-west1 - us-west4\nList of partially affected regions: - asia-east1 - asia-east2 - asia-northeast2 - asia-south1 - asia-southeast2 - australia-southeast1 - australia-southeast2 - europe-southwest1 - europe-west3 - europe-west4 - europe-west6 - europe-west8 - southamerica-west1 - us-central1 - us-east1 - us-east4 - us-west2 - us-west3","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T17:59:25+00:00","modified":"2022-08-31T17:59:26+00:00","when":"2022-08-31T17:59:25+00:00","text":"Summary: Global: Classic template job names do not accept underscores for Dataflow jobs\nDescription: Our engineering team has initiated rollback of the changes that affected this use case.\nWe are currently working on the ETA for the mitigation to complete.\nWe will provide an update by Wednesday, 2022-08-31 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers unable to submit new Classic Template jobs with underscores in job name.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T17:01:57+00:00","modified":"2022-08-31T17:01:59+00:00","when":"2022-08-31T17:01:57+00:00","text":"Summary: Global: Classic template job names do not accept underscores for Dataflow jobs\nDescription: We are experiencing an issue with Google Cloud Dataflow beginning at Wednesday, 2022-08-29 10:00 US/Pacific.\nOur engineering team continues to investigate the issue and working on mitigation steps.\nWe will provide an update by Wednesday, 2022-08-31 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers unable to submit jobs\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-08-31T22:29:06+00:00","modified":"2022-08-31T22:29:08+00:00","when":"2022-08-31T22:29:06+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected projects as of Wednesday, 2022-08-31 15:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"T9bFoXPqG8w8g1YbWTKY","service_name":"Google Cloud Dataflow","affected_products":[{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"}],"uri":"incidents/f2T9veB57h1racANQHXW","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"9siV4viU2tMqkJrVWjBf","number":"6193219508083455952","begin":"2022-08-30T19:33:15+00:00","created":"2022-08-30T19:33:21+00:00","end":"2022-09-02T04:46:46+00:00","modified":"2022-09-02T04:46:46+00:00","external_desc":"Global: Increase in failure rate for SQLServer Instance Creation","updates":[{"created":"2022-09-02T04:46:46+00:00","modified":"2022-09-02T04:46:47+00:00","when":"2022-09-02T04:46:46+00:00","text":"The issue with Google Cloud SQL has been resolved for all affected users as of Thursday, 2022-09-01 16:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-09-01T14:55:12+00:00","modified":"2022-09-01T14:55:24+00:00","when":"2022-09-01T14:55:12+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Our engineering team continues to work on mitigation.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-09-02 17:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T20:28:55+00:00","modified":"2022-08-31T20:29:01+00:00","when":"2022-08-31T20:28:55+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-09-01 08:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T18:48:41+00:00","modified":"2022-08-31T18:48:48+00:00","when":"2022-08-31T18:48:41+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-31 14:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T17:04:16+00:00","modified":"2022-08-31T17:04:17+00:00","when":"2022-08-31T17:04:16+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-31 12:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T13:49:45+00:00","modified":"2022-08-31T13:49:55+00:00","when":"2022-08-31T13:49:45+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is still underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-31 10:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-31T02:35:14+00:00","modified":"2022-08-31T02:35:15+00:00","when":"2022-08-31T02:35:14+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-31 07:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T23:02:45+00:00","modified":"2022-08-30T23:02:46+00:00","when":"2022-08-30T23:02:45+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-08-30 20:00 US/Pacific.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T23:01:16+00:00","modified":"2022-08-30T23:01:22+00:00","when":"2022-08-30T23:01:16+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Cloud SQL for SQL Server is seeing a spike in instance creation failures globally. We are actively investigating the issue. In the meantime, we have confirmed retrying the failed operation will succeed and recommend that for customers impacted by this problem.\nWe will provide an update by Tuesday, 2022-08-30 17:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T20:37:07+00:00","modified":"2022-08-30T20:37:08+00:00","when":"2022-08-30T20:37:07+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Cloud SQL for SQL Server is seeing a spike in instance creation failures globally. We are actively investigating the issue. In the meantime, we have confirmed retrying the failed operation will succeed and recommend that for customers impacted by this problem.\nWe will provide an update by Tuesday, 2022-08-30 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T20:23:19+00:00","modified":"2022-08-30T20:23:20+00:00","when":"2022-08-30T20:23:19+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: Our engineering team continues to investigate the issue and working on mitigation steps.\nWe will provide an update by Tuesday, 2022-08-30 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T19:33:15+00:00","modified":"2022-08-30T19:33:22+00:00","when":"2022-08-30T19:33:15+00:00","text":"Summary: Global: Increase in failure rate for SQLServer Instance Creation\nDescription: We are experiencing an issue with Google Cloud SQL.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-30 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased failure rate for SQLServer instance creation\nWorkaround: Retry instance creation after failure","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-09-02T04:46:46+00:00","modified":"2022-09-02T04:46:47+00:00","when":"2022-09-02T04:46:46+00:00","text":"The issue with Google Cloud SQL has been resolved for all affected users as of Thursday, 2022-09-01 16:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/9siV4viU2tMqkJrVWjBf","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"q5jsbB2eCwgdCb2WBPFk","number":"17733899624498699220","begin":"2022-08-30T11:58:44+00:00","created":"2022-08-30T12:02:57+00:00","end":"2022-08-30T12:58:11+00:00","modified":"2022-08-30T12:58:11+00:00","external_desc":"App Engine Standard deployments issues in asia-south1","updates":[{"created":"2022-08-30T12:58:10+00:00","modified":"2022-08-30T12:58:15+00:00","when":"2022-08-30T12:58:10+00:00","text":"The issue with Google App Engine is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Mumbai (asia-south1)","id":"asia-south1"}]},{"created":"2022-08-30T12:02:49+00:00","modified":"2022-08-30T12:03:00+00:00","when":"2022-08-30T12:02:49+00:00","text":"Summary: App Engine Standard deployments issues in asia-south1\nDescription: We are experiencing an issue with Google App Engine beginning on Monday, 2022-08-29 11:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-30 06:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: About 20% of users are seeing their deployments to App Engine Standard failing.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Mumbai (asia-south1)","id":"asia-south1"}]}],"most_recent_update":{"created":"2022-08-30T12:58:10+00:00","modified":"2022-08-30T12:58:15+00:00","when":"2022-08-30T12:58:10+00:00","text":"The issue with Google App Engine is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Mumbai (asia-south1)","id":"asia-south1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/q5jsbB2eCwgdCb2WBPFk","currently_affected_locations":[],"previously_affected_locations":[{"title":"Mumbai (asia-south1)","id":"asia-south1"}]},{"id":"D1t8fKU8oCrUMPwGu8CQ","number":"15397420927985090402","begin":"2022-08-29T16:32:51+00:00","created":"2022-08-29T16:47:50+00:00","end":"2022-08-29T23:16:57+00:00","modified":"2022-08-29T23:16:57+00:00","external_desc":"Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL","updates":[{"created":"2022-08-29T23:16:57+00:00","modified":"2022-08-29T23:16:58+00:00","when":"2022-08-29T23:16:57+00:00","text":"The issue with Google Cloud SQL is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T22:03:57+00:00","modified":"2022-08-29T22:03:59+00:00","when":"2022-08-29T22:03:57+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: Our engineering team continues to work on the mitigation of the issue.\nWe will provide an update by Monday, 2022-08-29 17:30 US/Pacific with current details.\nDiagnosis: Customers may experience replication failure after maintenance on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: In most cases, internal automation should resolve the issue within 30 minutes.\nIf internal automation does not resolve the issue, or if it is critical to restore service sooner, customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure. Please refer to documentation [1]\n[1] https://cloud.google.com/sql/docs/mysql/replication/manage-replicas","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T20:24:41+00:00","modified":"2022-08-29T20:24:42+00:00","when":"2022-08-29T20:24:41+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: Our engineering team continues to work on the mitigation of the issue.\nWe will provide an update by Monday, 2022-08-29 15:30 US/Pacific with current details.\nDiagnosis: Customer may experience replication failure on the new CSA rollout on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: Customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure.\nCustomers can use gcloud command to enable replication again on a failed replica server\ngcloud sql instances patch REPLICA_NAME \\\n--enable-database-replication","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T19:44:53+00:00","modified":"2022-08-29T19:44:59+00:00","when":"2022-08-29T19:44:53+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: Our engineering team continues to work on the mitigation of the issue.\nWe will provide an update by Monday, 2022-08-29 13:30 US/Pacific with current details.\nDiagnosis: Customer may experience replication failure on the new CSA rollout on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: Customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure.\nCustomers can use gcloud command to enable replication again on a failed replica server\ngcloud sql instances patch REPLICA_NAME \\\n--enable-database-replication","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T18:22:26+00:00","modified":"2022-08-29T18:22:28+00:00","when":"2022-08-29T18:22:26+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: Our engineering team is currently investigating the issue and working on mitigation steps.\nWe will provide an update by Monday, 2022-08-29 13:00 US/Pacific with current details.\nDiagnosis: Customer may experience replication failure on the new CSA rollout on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: Customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure.\nCustomers can use gcloud command to enable replication again on a failed replica server\ngcloud sql instances patch REPLICA_NAME \\\n--enable-database-replication","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T17:55:46+00:00","modified":"2022-08-29T17:55:47+00:00","when":"2022-08-29T17:55:46+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: Our engineering team is currently investigating the issue and working on mitigation steps.\nWe will provide an update by Monday, 2022-08-29 12:00 US/Pacific with current details.\nDiagnosis: Customer may experience replication failure on the new CSA rollout on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: Customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure.\nCustomers can use gcloud command to enable replication again on a failed replica server\ngcloud sql instances patch REPLICA_NAME \\\n--enable-database-replication","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-29T16:47:44+00:00","modified":"2022-08-29T16:47:51+00:00","when":"2022-08-29T16:47:44+00:00","text":"Summary: Global: Conflict with timezone refresh and replica startup causes replication failure for Google Cloud SQL\nDescription: We are experiencing an issue with Google Cloud SQL.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-08-29 11:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer may experience replication failure on the new CSA rollout on replica, if the master instance is busy with INSERTs/UPDATEs on tables with timestamp column and session timezone is set to other than SYSTEM.\nWorkaround: Customers can DISABLE REPLICA and ENABLE REPLICA on their replica instances to fix the replication failure.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-08-29T23:16:57+00:00","modified":"2022-08-29T23:16:58+00:00","when":"2022-08-29T23:16:57+00:00","text":"The issue with Google Cloud SQL is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/D1t8fKU8oCrUMPwGu8CQ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"uZGvvADp63kQfwcMjshJ","number":"9368654706017741754","begin":"2022-08-29T12:30:00+00:00","created":"2022-08-30T16:32:36+00:00","end":"2022-08-30T18:02:00+00:00","modified":"2022-08-30T22:04:57+00:00","external_desc":"Global: Cloud Spanner Query and Data UI pages not returning results for tables","updates":[{"created":"2022-08-30T22:04:55+00:00","modified":"2022-08-30T22:04:55+00:00","when":"2022-08-30T22:04:55+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 29 August 2022 05:30\n**Incident End:** 30 August 2022 11:02\n**Duration:** 29 hours, 32 minutes\n**Affected Services and Features:**\nGoogle Cloud Platform - Cloud Spanner Console\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Spanner Query and Data UI pages, in the Cloud Console, experienced issues returning results for tables globally for 29 hours and 32 minutes. From preliminary analysis, the root cause of the issue was a change in formatting of array column types for display that did not account for nulls.\n**Customer Impact:**\n- Affected customers may have experienced issues rendering query results on the data page and query page if the table included an array.\n- This only affected the Spanner Console, gCloud interface worked as expected.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T18:22:19+00:00","modified":"2022-08-30T18:22:20+00:00","when":"2022-08-30T18:22:19+00:00","text":"The issue with Cloud Spanner has been resolved for all affected users as of Tuesday, 2022-08-30 11:02 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T17:54:18+00:00","modified":"2022-08-30T17:54:20+00:00","when":"2022-08-30T17:54:18+00:00","text":"Summary: Global: Cloud Spanner Query and Data UI pages not returning results for tables\nDescription: We believe the issue with Cloud Spanner is partially resolved. Our engineers are working to validate the fix is working as expected.\nWe will provide an update by Tuesday, 2022-08-30 11:30 US/Pacific with current details.\nDiagnosis: Data page and Query page will not render query results if the table has an array. This is only affecting the console only, gCloud interface is working as expected.\nWorkaround: Users may use alternative interfaces such as Cloud SDK (gcloud) or client libraries to query the affected tables.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T17:24:11+00:00","modified":"2022-08-30T17:24:13+00:00","when":"2022-08-30T17:24:11+00:00","text":"Summary: Global: Cloud Spanner Query and Data UI pages not returning results for tables\nDescription: We believe the issue with Cloud Spanner is partially resolved. Our engineers are working to validate the fix is working as expected.\nWe will provide an update by Tuesday, 2022-08-30 11:00 US/Pacific with current details.\nDiagnosis: Data page and Query page will not render query results if the table has an array. This is only affecting the console only, gCloud interface is working as expected.\nWorkaround: Users may use alternative interfaces such as Cloud SDK (gcloud) or client libraries to query the affected tables.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T16:36:56+00:00","modified":"2022-08-30T16:36:57+00:00","when":"2022-08-30T16:36:56+00:00","text":"Summary: Global: Cloud Spanner Query and Data UI pages not returning results for tables\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2022-08-30 10:00 US/Pacific.\nWe will provide more information by Tuesday, 2022-08-30 10:30 US/Pacific.\nDiagnosis: Data page and Query page will not render query results if the table has an array. This is only affecting the console only, gCloud interface is working as expected.\nWorkaround: Users may use alternative interfaces such as Cloud SDK (gcloud) or client libraries to query the affected tables.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-30T16:32:36+00:00","modified":"2022-08-30T16:32:38+00:00","when":"2022-08-30T16:32:36+00:00","text":"Summary: Global: Cloud Spanner Query and Data UI pages not returning results for tables\nDescription: We are experiencing an issue with Cloud Spanner.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-30 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Data page and Query page will not render query results if the table has an array. This is only affecting the console only, gCloud interface is working as expected.\nWorkaround: Users may use alternative interfaces such as Cloud SDK (gcloud) or client libraries to query the affected tables.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-08-30T22:04:55+00:00","modified":"2022-08-30T22:04:55+00:00","when":"2022-08-30T22:04:55+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 29 August 2022 05:30\n**Incident End:** 30 August 2022 11:02\n**Duration:** 29 hours, 32 minutes\n**Affected Services and Features:**\nGoogle Cloud Platform - Cloud Spanner Console\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Spanner Query and Data UI pages, in the Cloud Console, experienced issues returning results for tables globally for 29 hours and 32 minutes. From preliminary analysis, the root cause of the issue was a change in formatting of array column types for display that did not account for nulls.\n**Customer Impact:**\n- Affected customers may have experienced issues rendering query results on the data page and query page if the table included an array.\n- This only affected the Spanner Console, gCloud interface worked as expected.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"EcNGGUgBtBLrtm4mWvqC","service_name":"Cloud Spanner","affected_products":[{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"}],"uri":"incidents/uZGvvADp63kQfwcMjshJ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Dallas (us-south1)","id":"us-south1"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"xQf7hNUq6FGPmMGE7LoY","number":"3915515412783481876","begin":"2022-08-25T08:53:19+00:00","created":"2022-08-25T09:19:20+00:00","end":"2022-08-25T10:05:51+00:00","modified":"2022-08-25T10:05:52+00:00","external_desc":"Some cloud config files are unable to be changed","updates":[{"created":"2022-08-25T10:05:42+00:00","modified":"2022-08-25T10:05:53+00:00","when":"2022-08-25T10:05:42+00:00","text":"All updates regarding this issue will be provided on our Google Cloud Service Health moving forward\nhttps://status.cloud.google.com/incidents/c8KN35RKVPWq9uCkVDsr#RP1d9aZLNFZEJmTBk8e1","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T09:56:45+00:00","modified":"2022-08-25T09:56:53+00:00","when":"2022-08-25T09:56:45+00:00","text":"Summary: Some cloud config files are unable to be changed\nDescription: We are experiencing an issue with Google Cloud DNS, Service Directory, Traffic Director\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-25 03:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some cloud config files are unable to be changed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T09:19:09+00:00","modified":"2022-08-25T09:19:24+00:00","when":"2022-08-25T09:19:09+00:00","text":"Summary: Some cloud config files are unable to be changed\nDescription: We are experiencing an issue with Google Cloud DNS, Service Directory, Traffic Director\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-25 03:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some cloud config files are unable to be changed\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-08-25T10:05:42+00:00","modified":"2022-08-25T10:05:53+00:00","when":"2022-08-25T10:05:42+00:00","text":"All updates regarding this issue will be provided on our Google Cloud Service Health moving forward\nhttps://status.cloud.google.com/incidents/c8KN35RKVPWq9uCkVDsr#RP1d9aZLNFZEJmTBk8e1","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Traffic Director","id":"NroZwL2UMMionesUGP87"},{"title":"Google Cloud DNS","id":"TUZUsWSJUVJGW97Jq2sH"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Service Directory","id":"vmq8TsEZwitKYM6V9BaM"}],"uri":"incidents/xQf7hNUq6FGPmMGE7LoY","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"c8KN35RKVPWq9uCkVDsr","number":"8544834224444607540","begin":"2022-08-25T08:29:00+00:00","created":"2022-08-25T09:49:57+00:00","end":"2022-08-25T09:30:00+00:00","modified":"2022-09-06T21:21:39+00:00","external_desc":"Multiple services impacted in us-central1 region","updates":[{"created":"2022-09-06T21:21:39+00:00","modified":"2022-09-06T21:21:39+00:00","when":"2022-09-06T21:21:39+00:00","text":"# Incident Report\n**Summary:**\nOn Thursday, 25 August 2022, Google Cloud Networking experienced increased latency in us-central1 starting at 25 August 2022 01:29 for a duration of 1 hour and 1 minute. This caused errors and failures in several downstream services. To our customers that were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve our service.\n**Root Cause:**\nGoogle Cloud Networking utilizes physical routers to aggregate traffic across our network. Periodically, these routers need to be rebooted for various maintenance activities. Google regularly deploys updates to our network control plane to enhance performance, security, and reliability. We also take steps to ensure these reboots take place in a way that minimizes any downtime or customer impact by moving traffic away from the device before the reboot.\nDuring routine maintenance, and after draining existing network traffic, one of the routers being rebooted in us-central1 failed to boot from the primary boot media. Instead, it booted from the alternative boot media, which contained an outdated configuration that was missing updated routing information. That configuration caused the router to attract traffic that it was unable to route correctly. The changes in the network since the outdated configuration meant that our existing fail-safe to make the router take itself out of service again was ineffective.\n**Remediation and Prevention:**\nThis failure was automatically remediated by Google’s automation systems by pushing the updated configuration on Thursday, 25 August 2022, 02:21 US/Pacific. The proper routes were restored by 02:30. The configuration push is one of the steps taken by automation before closing on the maintenance.\nGoogle is committed to preventing this type of disruption from reoccurring and is taking the follow actions:\nComplete an audit of old router configurations and remove them, and prevent them from accidentally being re-enabled. This is expected to be completed by 9 September 2022.\nDeploy additional monitoring to notify Google engineers when a device is expected to be out of service (i.e. drained) but is re-attracting traffic to reduce future outage durations. This will be rolled out by 30 September 2022.\n**Detailed Description of Impact:**\nOn Thursday, 25 August 2022, from 01:29 to 02:30 US/Pacific unless otherwise noted:\n## Cloud Pub/Sub ##\nCustomers in us-central1 experienced reduced availability in the form of http 502 and 503 (retriable) errors across both publish and subscribe (Pub/Sub) operations. Less than 1% of customer projects were affected. Backlog statistics freshness was also impacted with less than 1% of subscriptions experiencing stale backlog data.\n## Google Compute Engine (GCE) ##\nAll GCE Compute API globally would have experienced a 20% rate of errors or requests hanging. Retries would have helped to get a successful request. Additionally, 50% of the compute.instance.insert operations in the us-central1-a zone succeeded.\n## Cloud Key Management Service (KMS) ##\nAffected Cloud KMS customers would receive errors in nam-eur-asia1, nam7, nam9, nam10, nam11, and nam12 for a small subset of methods. Approximately 3% of requests over the impact period would see an Unavailable error.\n## Cloud Bigtable ##\nLess than 2% of Cloud Bigtable customers (approximately 10% of requests) experienced elevated latency and errors in the Data API and Admin API from 01:29 to 2:30 on 25 August in us-central1. The disruption also impacted users of Key Visualizer for Cloud Bigtable during this time.\n## Cloud DataFlow ##\nDuring the incident (01:29 to 02:30 PT), affected customers may have been temporarily unable to create new DataFlow jobs, both Batch and Streaming (~2% of all customer projects). Information about existing jobs may have been temporarily unavailable (~57.5% of all customer projects). Some Streaming jobs may have been stuck (~4.2% of us-central1 Streaming jobs).\n## Google Cloud Storage ##\nApproximately 0.5% of customer uploads and downloads saw authentication errors during the impact period of 01:31 PDT to 02:24 PDT. Customers would have experienced errors indicating deadline exceeded.\n## Cloud Spanner ##\nLess than 5% of Cloud Spanner customers (approximately 15% of requests) experienced elevated latency and errors in the Data API and Admin API from 01:29 to 2:30 on 25 August in us-central1.\n## Cloud Load Balancing\nAffected customers using cloud load balancing products would have been unable to submit configuration changes in us-central1 between 01:29 to 2:30. Already configured load balancers would continue serving traffic.\n## Service Directory ##\n10 - 20% of registration operations and 0.2% of resolve operations to Service Directory in us-central1 failed during the affected period.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-29T20:38:03+00:00","modified":"2022-09-06T20:13:10+00:00","when":"2022-08-29T20:38:03+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 25 August 2022 01:29\n**Incident End:** 25 August 2022 02:30\n**Duration:** 1 hour, 1 minute\n**Affected Services and Features:**\nCloud Pub/Sub\nGoogle Compute Engine\nCloud Key Management Service\nCloud BigTable\nCloud DataFlow\nGoogle Cloud Storage\nCloud Spanner\nCloud Load Balancing, Service Directory, Traffic Director, Dataplex\n**Regions/Zones:** us-central1\n**Description:**\nMultiple Google Cloud services experienced increased latency, errors, and failures in us-central-1 for a period of 1 hour and 1 minute. From preliminary analysis, the root cause of the issue appears to be a new rollout to our network control plane, in which a networking component was rebooted and returned to an old configuration.\n**Customer Impact:**\nCustomers experienced an increase in error rates across all the listed impacted services.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T10:22:38+00:00","modified":"2022-08-25T10:22:51+00:00","when":"2022-08-25T10:22:38+00:00","text":"The issue with Cloud Key Management Service, Cloud Load Balancing, Cloud Spanner, Dataplex, Google Cloud Bigtable, Google Cloud Dataflow, Google Cloud Pub/Sub, Google Cloud Storage, Google Compute Engine, Service Directory, Traffic Director has been resolved for all affected users as of Thursday, 2022-08-25 02:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T10:14:33+00:00","modified":"2022-08-25T10:14:44+00:00","when":"2022-08-25T10:14:33+00:00","text":"Summary: Multiple services impacted in us-central1 region\nDescription: We are experiencing an issue with Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Cloud Load Balancing, Google Cloud Pub/Sub, Service Directory, Traffic Director, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Google Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-25 03:40 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can observe errors while using services in us-central1\nWorkaround: None at this time","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T09:53:32+00:00","modified":"2022-08-25T09:53:49+00:00","when":"2022-08-25T09:53:32+00:00","text":"Summary: Multiple services impacted in us-central1 region\nDescription: We are experiencing an issue with Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Cloud Load Balancing, Google Cloud Pub/Sub, Service Directory, Traffic Director, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Google Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-25 03:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can observe errors while using services in us-central1\nWorkaround: None at this time","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-08-25T09:49:50+00:00","modified":"2022-08-25T09:50:01+00:00","when":"2022-08-25T09:49:50+00:00","text":"Summary: Multiple services impacted in us-central1 region\nDescription: We are experiencing an issue with Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Cloud Load Balancing, Google Cloud Pub/Sub, Service Directory, Traffic Director, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Cloud Load Balancing, Traffic Director, Service Directory, Google Compute Engine, Google Cloud Pub/Sub, Dataplex, Google Cloud Bigtable.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-25 03:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers can observe errors while using services in us-central1\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-09-06T21:21:39+00:00","modified":"2022-09-06T21:21:39+00:00","when":"2022-09-06T21:21:39+00:00","text":"# Incident Report\n**Summary:**\nOn Thursday, 25 August 2022, Google Cloud Networking experienced increased latency in us-central1 starting at 25 August 2022 01:29 for a duration of 1 hour and 1 minute. This caused errors and failures in several downstream services. To our customers that were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability. We have conducted an internal investigation and are taking steps to improve our service.\n**Root Cause:**\nGoogle Cloud Networking utilizes physical routers to aggregate traffic across our network. Periodically, these routers need to be rebooted for various maintenance activities. Google regularly deploys updates to our network control plane to enhance performance, security, and reliability. We also take steps to ensure these reboots take place in a way that minimizes any downtime or customer impact by moving traffic away from the device before the reboot.\nDuring routine maintenance, and after draining existing network traffic, one of the routers being rebooted in us-central1 failed to boot from the primary boot media. Instead, it booted from the alternative boot media, which contained an outdated configuration that was missing updated routing information. That configuration caused the router to attract traffic that it was unable to route correctly. The changes in the network since the outdated configuration meant that our existing fail-safe to make the router take itself out of service again was ineffective.\n**Remediation and Prevention:**\nThis failure was automatically remediated by Google’s automation systems by pushing the updated configuration on Thursday, 25 August 2022, 02:21 US/Pacific. The proper routes were restored by 02:30. The configuration push is one of the steps taken by automation before closing on the maintenance.\nGoogle is committed to preventing this type of disruption from reoccurring and is taking the follow actions:\nComplete an audit of old router configurations and remove them, and prevent them from accidentally being re-enabled. This is expected to be completed by 9 September 2022.\nDeploy additional monitoring to notify Google engineers when a device is expected to be out of service (i.e. drained) but is re-attracting traffic to reduce future outage durations. This will be rolled out by 30 September 2022.\n**Detailed Description of Impact:**\nOn Thursday, 25 August 2022, from 01:29 to 02:30 US/Pacific unless otherwise noted:\n## Cloud Pub/Sub ##\nCustomers in us-central1 experienced reduced availability in the form of http 502 and 503 (retriable) errors across both publish and subscribe (Pub/Sub) operations. Less than 1% of customer projects were affected. Backlog statistics freshness was also impacted with less than 1% of subscriptions experiencing stale backlog data.\n## Google Compute Engine (GCE) ##\nAll GCE Compute API globally would have experienced a 20% rate of errors or requests hanging. Retries would have helped to get a successful request. Additionally, 50% of the compute.instance.insert operations in the us-central1-a zone succeeded.\n## Cloud Key Management Service (KMS) ##\nAffected Cloud KMS customers would receive errors in nam-eur-asia1, nam7, nam9, nam10, nam11, and nam12 for a small subset of methods. Approximately 3% of requests over the impact period would see an Unavailable error.\n## Cloud Bigtable ##\nLess than 2% of Cloud Bigtable customers (approximately 10% of requests) experienced elevated latency and errors in the Data API and Admin API from 01:29 to 2:30 on 25 August in us-central1. The disruption also impacted users of Key Visualizer for Cloud Bigtable during this time.\n## Cloud DataFlow ##\nDuring the incident (01:29 to 02:30 PT), affected customers may have been temporarily unable to create new DataFlow jobs, both Batch and Streaming (~2% of all customer projects). Information about existing jobs may have been temporarily unavailable (~57.5% of all customer projects). Some Streaming jobs may have been stuck (~4.2% of us-central1 Streaming jobs).\n## Google Cloud Storage ##\nApproximately 0.5% of customer uploads and downloads saw authentication errors during the impact period of 01:31 PDT to 02:24 PDT. Customers would have experienced errors indicating deadline exceeded.\n## Cloud Spanner ##\nLess than 5% of Cloud Spanner customers (approximately 15% of requests) experienced elevated latency and errors in the Data API and Admin API from 01:29 to 2:30 on 25 August in us-central1.\n## Cloud Load Balancing\nAffected customers using cloud load balancing products would have been unable to submit configuration changes in us-central1 between 01:29 to 2:30. Already configured load balancers would continue serving traffic.\n## Service Directory ##\n10 - 20% of registration operations and 0.2% of resolve operations to Service Directory in us-central1 failed during the affected period.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Key Management Service","id":"67cSySTL7dwJZo9JWUGU"},{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"},{"title":"Traffic Director","id":"NroZwL2UMMionesUGP87"},{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"},{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Dataplex","id":"Xx5qm9U2ovrN11z2Gd9Q"},{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Service Directory","id":"vmq8TsEZwitKYM6V9BaM"}],"uri":"incidents/c8KN35RKVPWq9uCkVDsr","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"JW3dWx6mNFZJPfToA8oa","number":"1706532387933032122","begin":"2022-08-24T14:59:00+00:00","created":"2022-08-24T15:36:21+00:00","end":"2022-08-26T00:16:00+00:00","modified":"2022-08-26T19:07:41+00:00","external_desc":"SCC onboarding failed to enable Container Threat Detection (KTD)","updates":[{"created":"2022-08-26T19:07:21+00:00","modified":"2022-08-26T19:07:21+00:00","when":"2022-08-26T19:07:21+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Detection Time:** 24 August 2022 07:59\n**Incident End:** 25 August 2022 17:16\n**Duration:** 1 day 9 hours, 17 minutes\n**Affected Services and Features:**\nCloud Security Command Center (SCC) - Container Threat Detection (KTD) was not monitoring some customer clusters.\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Security Command Center (SCC) experienced an issue with enabling Container Threat Detection(KTD) during the SCC Premium onboarding process. During the onboarding process if a customer accepted the default service settings, it would show all detection services as Enabled, but the SCC User Interface (UI) would fail to save the settings for Container Threat Detection(KTD) causing this detection to be in disabled state unless the customer explicitly enabled it at a later point.\nThe issue was first detected on 24 August 2022 at 07:59 US/Pacific while Google Engineers were working on analyzing a future code release. From preliminary analysis, the root cause of the issue is a latent bug in the SCC UI. The issue was resolved on 25 August 2022 at 17:16 US/Pacific after a mitigation was rolled out to the SCC Settings backend that changed the default state of Container Threat Detection to Enabled.\n**Customer Impact:**\nAffected customers failed to receive Container Threat Detection (KTD) coverage.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-26T00:36:39+00:00","modified":"2022-08-26T00:36:41+00:00","when":"2022-08-26T00:36:39+00:00","text":"The issue with Cloud Security Command Center has been resolved for all affected users as of Thursday, 2022-08-25 17:16 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-25T22:45:58+00:00","modified":"2022-08-25T22:45:59+00:00","when":"2022-08-25T22:45:58+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-08-25 18:10 US/Pacific.\nWe will provide more information by Thursday, 2022-08-25 18:15 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-25T20:46:49+00:00","modified":"2022-08-25T20:46:50+00:00","when":"2022-08-25T20:46:49+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is still underway by our engineering team and is taking longer than expected.\nWe do not have a new ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-25 16:30 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-25T20:37:24+00:00","modified":"2022-08-25T20:37:26+00:00","when":"2022-08-25T20:37:24+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Thursday, 2022-08-25 14:30 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-25T13:45:48+00:00","modified":"2022-08-25T13:45:53+00:00","when":"2022-08-25T13:45:48+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-08-25 13:30 US/Pacific.\nWe will provide more information by Thursday, 2022-08-25 13:30 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T23:41:43+00:00","modified":"2022-08-24T23:41:45+00:00","when":"2022-08-24T23:41:43+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-25 10:30 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T22:20:45+00:00","modified":"2022-08-24T22:20:51+00:00","when":"2022-08-24T22:20:45+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-24 17:00 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T20:20:12+00:00","modified":"2022-08-24T20:20:13+00:00","when":"2022-08-24T20:20:12+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-08-24 16:00 US/Pacific.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T18:28:03+00:00","modified":"2022-08-24T18:28:04+00:00","when":"2022-08-24T18:28:03+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: We are experiencing an issue with Cloud Security Command Center\nOur engineering team continues to investigate the issue and are working on a mitigation strategy.\nWe will provide an update by Wednesday, 2022-08-24 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T17:27:25+00:00","modified":"2022-08-24T17:27:27+00:00","when":"2022-08-24T17:27:25+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: We are experiencing an issue with Cloud Security Command Center\nOur engineering team continues to investigate the issue and are working on a mitigation strategy.\nWe will provide an update by Wednesday, 2022-08-24 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T16:51:26+00:00","modified":"2022-08-24T16:51:33+00:00","when":"2022-08-24T16:51:26+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: We are experiencing an issue with Cloud Security Command Center\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-24 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings.\nWorkaround: Customers can enable KTD in SCC settings.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-24T15:36:18+00:00","modified":"2022-08-24T15:36:23+00:00","when":"2022-08-24T15:36:18+00:00","text":"Summary: SCC onboarding failed to enable Container Threat Detection (KTD)\nDescription: We are experiencing an issue with Cloud Security Command Center\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-24 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Container Threat Detection is not monitoring customers cluster in organizations that have not explicitly enabled Container Threat Detection in their SCC settings\nWorkaround: Customers can enable KTD in SCC settings","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-26T19:07:21+00:00","modified":"2022-08-26T19:07:21+00:00","when":"2022-08-26T19:07:21+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Detection Time:** 24 August 2022 07:59\n**Incident End:** 25 August 2022 17:16\n**Duration:** 1 day 9 hours, 17 minutes\n**Affected Services and Features:**\nCloud Security Command Center (SCC) - Container Threat Detection (KTD) was not monitoring some customer clusters.\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Security Command Center (SCC) experienced an issue with enabling Container Threat Detection(KTD) during the SCC Premium onboarding process. During the onboarding process if a customer accepted the default service settings, it would show all detection services as Enabled, but the SCC User Interface (UI) would fail to save the settings for Container Threat Detection(KTD) causing this detection to be in disabled state unless the customer explicitly enabled it at a later point.\nThe issue was first detected on 24 August 2022 at 07:59 US/Pacific while Google Engineers were working on analyzing a future code release. From preliminary analysis, the root cause of the issue is a latent bug in the SCC UI. The issue was resolved on 25 August 2022 at 17:16 US/Pacific after a mitigation was rolled out to the SCC Settings backend that changed the default state of Container Threat Detection to Enabled.\n**Customer Impact:**\nAffected customers failed to receive Container Threat Detection (KTD) coverage.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"csyyfUYy88hkeqbv23Mc","service_name":"Cloud Security Command Center","affected_products":[{"title":"Cloud Security Command Center","id":"csyyfUYy88hkeqbv23Mc"}],"uri":"incidents/JW3dWx6mNFZJPfToA8oa","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"Mer2vhvXsDVbFLVRcKdw","number":"77878222730657180","begin":"2022-08-24T00:57:56+00:00","created":"2022-08-24T01:38:43+00:00","end":"2022-08-24T04:09:34+00:00","modified":"2022-08-24T04:09:34+00:00","external_desc":"Issue with starting dataflow flex template jobs in asia-northeast1 and asia-east1","updates":[{"created":"2022-08-24T04:09:33+00:00","modified":"2022-08-24T04:09:35+00:00","when":"2022-08-24T04:09:33+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Tuesday, 2022-08-23 20:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},{"created":"2022-08-24T03:36:03+00:00","modified":"2022-08-24T03:36:04+00:00","when":"2022-08-24T03:36:03+00:00","text":"Summary: Issue with starting dataflow flex template jobs in asia-northeast1 and asia-east1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-08-23 21:30 US/Pacific.\nDiagnosis: Dataflow flex template job will fail when at creating a launcher VM with UNAVAILABLE error\nError message:\nFailed to start the VM, launcher-...,\nused for launching because of status code: UNAVAILABLE, reason: Persistent retriable error, maximum number of retries (10) reached.\nWorkaround: Customers could launch their jobs in different regions.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},{"created":"2022-08-24T01:47:03+00:00","modified":"2022-08-24T01:47:04+00:00","when":"2022-08-24T01:47:03+00:00","text":"Summary: Issue with starting dataflow flex template jobs in asia-northeast1 and asia-east1\nDescription: We are experiencing an issue with Google Cloud Dataflow.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-23 21:05 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Dataflow flex template job will fail when at creating a launcher VM with UNAVAILABLE error\nError message:\nFailed to start the VM, launcher-...,\nused for launching because of status code: UNAVAILABLE, reason: Persistent retriable error, maximum number of retries (10) reached.\nWorkaround: Customers could launch their jobs in different regions.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},{"created":"2022-08-24T01:39:26+00:00","modified":"2022-08-24T01:39:28+00:00","when":"2022-08-24T01:39:26+00:00","text":"Summary: Issue with starting dataflow flex template jobs in asia-northeast1 and asia-east1\nDescription: We are experiencing an issue with Google Cloud Dataflow.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-23 21:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Dataflow flex template job will fail when at creating a launcher VM with UNAVAILABLE error\nError message:\nFailed to start the VM, launcher-...,\nused for launching because of status code: UNAVAILABLE, reason: Persistent retriable error, maximum number of retries (10) reached.\nWorkaround: Customers could launch their jobs in different regions.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},{"created":"2022-08-24T01:38:43+00:00","modified":"2022-08-24T01:38:44+00:00","when":"2022-08-24T01:38:43+00:00","text":"Summary: Issue with starting dataflow flex template jobs in asia-northeast1 and asia-east1\nDescription: We are experiencing an issue with Google Cloud Dataflow.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-23 19:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Dataflow flex template job will fail when at creating a launcher VM with UNAVAILABLE error\nError message:\nFailed to start the VM, launcher-...,\nused for launching because of status code: UNAVAILABLE, reason: Persistent retriable error, maximum number of retries (10) reached.\nWorkaround: Customers could launch their jobs in different regions.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]}],"most_recent_update":{"created":"2022-08-24T04:09:33+00:00","modified":"2022-08-24T04:09:35+00:00","when":"2022-08-24T04:09:33+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Tuesday, 2022-08-23 20:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"T9bFoXPqG8w8g1YbWTKY","service_name":"Google Cloud Dataflow","affected_products":[{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"}],"uri":"incidents/Mer2vhvXsDVbFLVRcKdw","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"}]},{"id":"KVM7mPBRCJoedGLFLvwy","number":"722830095872533115","begin":"2022-08-20T12:25:00+00:00","created":"2022-08-20T14:30:24+00:00","end":"2022-08-20T15:20:00+00:00","modified":"2022-08-30T00:08:31+00:00","external_desc":"Cloud Monitoring is serving query failures, errors, and metrics unavailability impacting Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run in us-central","updates":[{"created":"2022-08-26T19:28:25+00:00","modified":"2022-08-30T00:08:31+00:00","when":"2022-08-26T19:28:25+00:00","text":"**Full Incident Report**\n**Background:**\nCloud Monitoring relies on an indexing service to look up data relevant to queries. Each region’s index is dynamically built from data, and then acts as a routing layer for all queries. The index is authoritative, and without it, queries will fail or return empty results.\n**SUMMARY:**\nOn Saturday, 20 August 2022 starting at 05:25 US/Pacific, some Cloud Monitoring queries and metrics were unavailable for multiple Google Cloud products (Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run) for a period of 2 hours and 55 minutes. Google Compute Engine (GCE) Autoscaling (for virtual machines on GCE) may have been impacted during the incident, as it relies on the Cloud Monitoring metrics.\n**ROOT CAUSE:**\nAn increase in storage layer tasks triggered a previously unknown bug in the indexing service. All instances of the indexing service in the us-central1 and us-central2 regions repeatedly crashed and were unable to provide routing lookups to any queries. As a result, Cloud Monitoring queries did not retrieve data stored in us-central1 and us-central2 or failed in a smaller fraction of cases.\n**REMEDIATION AND PREVENTION:**\nGoogle Engineers were first alerted to the issue Saturday, 20 August 2022 at 05:33 US/Pacific by internal monitoring systems. The issue was then mitigated by reducing the number of storage layer tasks. Services were fully recovered at 08:20 US/Pacific.\nGoogle is committed to preventing future issues like this and is completing the following actions to prevent a recurrence:\n- Enhancing the indexing service to support a larger number of tasks (beyond the current threshold).\n- Improving testing to ensure we detect any similar limitations in the future before they reach production.\nWe apologize for the length and severity of this incident. We are taking immediate steps to improve reliability in the future.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-23T20:04:19+00:00","modified":"2022-08-23T20:04:19+00:00","when":"2022-08-23T20:04:19+00:00","text":"**Mini Incident Report while full Incident Report is prepared**\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 20 Aug 2022 05:25\n**Incident End:** 20 Aug 2022 08:20\n**Duration:** 2 hours, 55 minutes\n**Affected Services and Features:**\nGoogle Compute Engine, Cloud Spanner, Google Cloud Dataflow, Google Cloud Bigtable, Cloud AppEngine, Google Kubernetes Engine, Google Cloud Pub/Sub, Cloud Run, Operations, Cloud Monitoring\n**Regions/Zones:** us-central1 and us-central2\n**Description:**\nCloud Monitoring metrics for multiple Google Cloud products (Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run) were missing for a period of 2 hours and 55 minutes. During the same period of time, Google Compute Engine (GCE) Autoscaling (for virtual machines on GCE) also was not functioning, as it relies on the Cloud Monitoring metrics.\nFrom preliminary analysis, the root cause of the issue was an overload in the system that is responsible for handling the metrics in Cloud Monitoring. This resulted in the failure of the queries which provide these metrics.\n**Customer Impact:**\nCustomers lost their ability to comprehensively observe various cloud operations at scale for the impacted services. Customers who use these metrics retroactively may be missing this information for the duration of the impact. While the custom metrics will be available again, a few that are system-generated shall not be available any more due to system limitations.\n**Additional details:**\nThe issue was mitigated by reducing the number of storage layer tasks. To prevent recurrence, engineers are also actively working on bolstering the system responsible for handling metrics to support a larger number of tasks (beyond the current threshold).","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-20T15:33:12+00:00","modified":"2022-08-20T15:33:14+00:00","when":"2022-08-20T15:33:12+00:00","text":"The issue with Cloud Monitoring, Cloud Run, Cloud Spanner, Google App Engine, Google Cloud Bigtable, Google Cloud Dataflow, Google Cloud Pub/Sub, Google Compute Engine, Google Kubernetes Engine has been resolved for all affected users as of Saturday, 2022-08-20 08:32 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-20T15:29:52+00:00","modified":"2022-08-20T15:30:00+00:00","when":"2022-08-20T15:29:52+00:00","text":"Summary: Cloud Monitoring is serving query failures, errors, and metrics unavailability impacting Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run in us-central\nDescription: We are experiencing an issue with Cloud Monitoring,\nIdentified impacted services Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-08-20 09:30 US/Pacific with current details.\nDiagnosis: Customers may experience queries failure, errors and metrics being not available in us-central.\nWorkaround: None at the moment.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-20T14:55:58+00:00","modified":"2022-08-20T14:56:00+00:00","when":"2022-08-20T14:55:58+00:00","text":"Summary: Cloud Monitoring is serving query failures, errors, and metrics unavailability impacting Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine in us-central\nDescription: We are experiencing an issue with Cloud Monitoring,\nIdentified impacted services Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-08-20 09:30 US/Pacific with current details.\nDiagnosis: Customers may experience queries failure, errors and metrics being not available in us-central.\nWorkaround: None at the moment.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-08-20T14:30:15+00:00","modified":"2022-08-20T14:30:28+00:00","when":"2022-08-20T14:30:15+00:00","text":"Summary: Cloud Monitoring is serving bad queries (errors and/or empty results) in Cloud Monarch us-central.\nDescription: We are experiencing an issue with Cloud Monitoring, Google Compute Engine.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-08-20 09:30 US/Pacific with current details.\nDiagnosis: Customers may experience queries failure, errors and metrics being not available in us-central.\nWorkaround: None at the moment.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-26T19:28:25+00:00","modified":"2022-08-30T00:08:31+00:00","when":"2022-08-26T19:28:25+00:00","text":"**Full Incident Report**\n**Background:**\nCloud Monitoring relies on an indexing service to look up data relevant to queries. Each region’s index is dynamically built from data, and then acts as a routing layer for all queries. The index is authoritative, and without it, queries will fail or return empty results.\n**SUMMARY:**\nOn Saturday, 20 August 2022 starting at 05:25 US/Pacific, some Cloud Monitoring queries and metrics were unavailable for multiple Google Cloud products (Google Compute Engine, Cloud Spanner, Cloud Dataflow, Cloud Bigtable, Cloud AppEngine, Kubernetes Engine, Cloud Pub/Sub, Cloud Run) for a period of 2 hours and 55 minutes. Google Compute Engine (GCE) Autoscaling (for virtual machines on GCE) may have been impacted during the incident, as it relies on the Cloud Monitoring metrics.\n**ROOT CAUSE:**\nAn increase in storage layer tasks triggered a previously unknown bug in the indexing service. All instances of the indexing service in the us-central1 and us-central2 regions repeatedly crashed and were unable to provide routing lookups to any queries. As a result, Cloud Monitoring queries did not retrieve data stored in us-central1 and us-central2 or failed in a smaller fraction of cases.\n**REMEDIATION AND PREVENTION:**\nGoogle Engineers were first alerted to the issue Saturday, 20 August 2022 at 05:33 US/Pacific by internal monitoring systems. The issue was then mitigated by reducing the number of storage layer tasks. Services were fully recovered at 08:20 US/Pacific.\nGoogle is committed to preventing future issues like this and is completing the following actions to prevent a recurrence:\n- Enhancing the indexing service to support a larger number of tasks (beyond the current threshold).\n- Improving testing to ensure we detect any similar limitations in the future before they reach production.\nWe apologize for the length and severity of this incident. We are taking immediate steps to improve reliability in the future.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"},{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"},{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/KVM7mPBRCJoedGLFLvwy","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"XCBDehwBA59WmvYPit7i","number":"16961585759579459084","begin":"2022-08-18T14:19:54+00:00","created":"2022-08-18T14:20:01+00:00","end":"2022-08-19T17:03:15+00:00","modified":"2022-08-19T17:03:15+00:00","external_desc":"User timers broken for certain Dataflow streaming pipelines in multiple locations","updates":[{"created":"2022-08-19T17:03:10+00:00","modified":"2022-08-19T17:03:16+00:00","when":"2022-08-19T17:03:10+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Friday, 2022-08-19 09:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-19T15:08:34+00:00","modified":"2022-08-19T15:08:39+00:00","when":"2022-08-19T15:08:34+00:00","text":"Summary: User timers broken for certain Dataflow streaming pipelines in multiple locations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-08-19 11:00 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-19T04:33:27+00:00","modified":"2022-08-19T04:33:29+00:00","when":"2022-08-19T04:33:27+00:00","text":"Summary: User timers broken for certain Dataflow streaming pipelines in multiple locations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-08-19 08:30 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-19T03:19:08+00:00","modified":"2022-08-19T03:19:09+00:00","when":"2022-08-19T03:19:08+00:00","text":"Summary: User timers broken for certain Dataflow streaming pipelines in multiple locations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-18 21:30 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-19T02:44:59+00:00","modified":"2022-08-19T02:45:02+00:00","when":"2022-08-19T02:44:59+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-18 21:30 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-18T22:57:02+00:00","modified":"2022-08-18T22:57:03+00:00","when":"2022-08-18T22:57:02+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-18 20:00 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-18T17:49:18+00:00","modified":"2022-08-18T17:49:19+00:00","when":"2022-08-18T17:49:18+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-18 16:00 US/Pacific.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-18T15:08:34+00:00","modified":"2022-08-18T15:08:38+00:00","when":"2022-08-18T15:08:34+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: We are experiencing an issue with Google Cloud Dataflow beginning at Tuesday, 2022-08-09 08:35 US/Pacific.\nMissing output data due to Dataflow streaming pipelines using Runner v2 and setting user timers issue in the regions mentioned. in southamerica-west1 europe-west5 australia-southeast2 asia-south2 northamerica-northeast2 us-west3 us-east7 europe-central2 asia-northeast2 europe-west6 asia-east2 us-central2 southamerica-east1 asia-northeast3 asia-southeast2 us-west4 europe-north1 asia-south1 northamerica-northeast1 asia-east1 asia-northeast1 asia-southeast1 australia-southeast1 europe-southwest1 europe-west1 europe-west2 europe-west3 europe-west4\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-18 11:00 US/Pacific with current details.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-18T15:03:02+00:00","modified":"2022-08-18T15:03:06+00:00","when":"2022-08-18T15:03:02+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: We are experiencing an issue with Google Cloud Dataflow beginning at Tuesday, 2022-08-09 08:35 US/Pacific.\nMissing output data due to Dataflow streaming pipelines using Runner v2 and setting user timers issue in the regions mentioned in southamerica-west1 europe-west5 australia-southeast2 asia-south2 northamerica-northeast2 us-west3 us-east7 europe-central2 asia-northeast2 europe-west6 asia-east2 us-central2 southamerica-east1 asia-northeast3 asia-southeast2 us-west4 europe-north1 asia-south1 northamerica-northeast1 asia-east1 asia-northeast1 asia-southeast1 australia-southeast1 europe-southwest1 europe-west1 europe-west2 europe-west3 europe-west4\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-18 09:00 US/Pacific with current details.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-08-18T14:39:35+00:00","modified":"2022-08-18T14:39:39+00:00","when":"2022-08-18T14:39:35+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: We are experiencing an issue with Google Cloud Dataflow beginning at Tuesday, 2022-08-09 08:35 US/Pacific.\nMissing output data due to Dataflow streaming pipelines using Runner v2 and setting user timers issue in the regions mentioned. in southamerica-west1 europe-west5 australia-southeast2 asia-south2 northamerica-northeast2 us-west3 us-east7 europe-central2 asia-northeast2 europe-west6 asia-east2 us-central2 southamerica-east1 asia-northeast3 asia-southeast2 us-west4 europe-north1 asia-south1 northamerica-northeast1 asia-east1 asia-northeast1 asia-southeast1 australia-southeast1 europe-southwest1 europe-west1 europe-west2 europe-west3 europe-west4\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-18 09:00 US/Pacific with current details.\nDiagnosis: Customers are only affected if they use a particular combination of Dataflow features: 1. they run in one of the affected regions above, 2. they run a streaming pipeline, not batch 3. they have enabled RunnerV2, which is the default for Python streaming, 4. they set user timers.\nThere's no specific error message for this failure mode. The failure manifests in different ways, depending on the code of the pipeline.\nWorkaround: Users can restart their streaming pipelines without RunnerV2, at the cost of having a small interruption of their pipeline.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-18T14:19:59+00:00","modified":"2022-08-18T14:20:03+00:00","when":"2022-08-18T14:19:59+00:00","text":"Summary: [multiregion-us] [multiregion-europe] [multiregion-sia] User timers broken for certain Dataflow streaming pipelines\nDescription: We are experiencing an issue with Google Cloud Dataflow beginning at Tuesday, 2022-08-09 08:35 US/Pacific.\nMissing output data due to Dataflow streaming pipelines using Runner v2 and setting user timers issue in the regions mentioned. in southamerica-west1 europe-west5 australia-southeast2 asia-south2 northamerica-northeast2 us-west3 us-east7 europe-central2 asia-northeast2 europe-west6 asia-east2 us-central2 southamerica-east1 asia-northeast3 asia-southeast2 us-west4 europe-north1 asia-south1 northamerica-northeast1 asia-east1 asia-northeast1 asia-southeast1 australia-southeast1 europe-southwest1 europe-west1 europe-west2 europe-west3 europe-west4\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-18 08:30 US/Pacific with current details.\nDiagnosis: Missing output data due to Dataflow streaming pipelines using Runner v2 and setting user timers issue in the regions mentioned.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-19T17:03:10+00:00","modified":"2022-08-19T17:03:16+00:00","when":"2022-08-19T17:03:10+00:00","text":"The issue with Google Cloud Dataflow has been resolved for all affected users as of Friday, 2022-08-19 09:41 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"T9bFoXPqG8w8g1YbWTKY","service_name":"Google Cloud Dataflow","affected_products":[{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"}],"uri":"incidents/XCBDehwBA59WmvYPit7i","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"4gLW5d7EjRsyv1BKF3nD","number":"3493898785631057705","begin":"2022-08-16T22:49:39+00:00","created":"2022-08-16T23:04:49+00:00","end":"2022-08-17T02:09:03+00:00","modified":"2022-08-17T02:09:03+00:00","external_desc":"Elevated latencies and intermittent failures while creating lakes in Dataplex","updates":[{"created":"2022-08-17T02:08:58+00:00","modified":"2022-08-17T02:09:05+00:00","when":"2022-08-17T02:08:58+00:00","text":"The issue with Dataplex has been resolved for all affected users as of Tuesday, 2022-08-16 18:34 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-08-17T01:04:45+00:00","modified":"2022-08-17T01:04:46+00:00","when":"2022-08-17T01:04:45+00:00","text":"Summary: Elevated latencies and intermittent failures while creating lakes in Dataplex\nDescription: We are experiencing an intermittent issue with Dataplex beginning at Tuesday, 2022-08-16 04:00 US/Pacific, across multiple regions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-16 19:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe latencies or may also face failures while creating lakes across impacted regions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-08-17T00:24:43+00:00","modified":"2022-08-17T00:24:44+00:00","when":"2022-08-17T00:24:43+00:00","text":"Summary: Elevated latencies and intermittent failures while creating lakes in Dataplex\nDescription: We are experiencing an intermittent issue with Dataplex beginning at Tuesday, 2022-08-16 04:00 US/Pacific, across multiple regions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-16 18:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe latencies or may also face failures while creating lakes across impacted regions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-08-16T23:57:32+00:00","modified":"2022-08-16T23:57:34+00:00","when":"2022-08-16T23:57:32+00:00","text":"Summary: Elevated latencies and intermittent failures while creating lakes in Dataplex\nDescription: We are experiencing an intermittent issue with Dataplex beginning at Tuesday, 2022-08-16 04:00 US/Pacific, across multiple regions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-16 17:36 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe latencies or may also face failures while creating lakes across impacted regions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-08-16T23:04:48+00:00","modified":"2022-08-16T23:04:50+00:00","when":"2022-08-16T23:04:48+00:00","text":"Summary: Elevated latencies and intermittent failures while creating lakes in Dataplex\nDescription: We are experiencing an intermittent issue with Dataplex beginning at Tuesday, 2022-08-16 04:00 US/Pacific, across multiple regions.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-16 17:06 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe latencies or may also face failures while creating lakes across impacted regions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]}],"most_recent_update":{"created":"2022-08-17T02:08:58+00:00","modified":"2022-08-17T02:09:05+00:00","when":"2022-08-17T02:08:58+00:00","text":"The issue with Dataplex has been resolved for all affected users as of Tuesday, 2022-08-16 18:34 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"Xx5qm9U2ovrN11z2Gd9Q","service_name":"Dataplex","affected_products":[{"title":"Dataplex","id":"Xx5qm9U2ovrN11z2Gd9Q"}],"uri":"incidents/4gLW5d7EjRsyv1BKF3nD","currently_affected_locations":[],"previously_affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"z1SJaDP8pTycwNQ9uHSZ","number":"9977878967570606115","begin":"2022-08-13T21:34:37+00:00","created":"2022-08-13T22:04:08+00:00","end":"2022-08-14T09:34:43+00:00","modified":"2022-08-14T09:34:44+00:00","external_desc":"us-east1: Transfer product affected for Storage transfer service customers","updates":[{"created":"2022-08-14T09:34:35+00:00","modified":"2022-08-14T09:34:45+00:00","when":"2022-08-14T09:34:35+00:00","text":"The issue with Storage Transfer Service is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-08-14T01:24:36+00:00","modified":"2022-08-14T01:24:38+00:00","when":"2022-08-14T01:24:36+00:00","text":"Summary: us-east1: Transfer product affected for Storage transfer service customers\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Saturday, 2022-08-14 02:30 US/Pacific.\nWe will provide more information by Sunday, 2022-08-14 02:30 US/Pacific.\nDiagnosis: GCP Storage Transfer Service product users who land on the home page to list transfer jobs could experience latency up to 1 minute\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-08-13T22:10:08+00:00","modified":"2022-08-13T22:10:10+00:00","when":"2022-08-13T22:10:08+00:00","text":"Summary: us-east1: Transfer product affected for Storage transfer service customers\nDescription: We are experiencing an issue with Storage Transfer Service.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-08-13 18:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: GCP Storage Transfer Service product users who land on the home page to list transfer jobs will experience latency of over 1 minute\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-08-13T22:04:01+00:00","modified":"2022-08-13T22:04:09+00:00","when":"2022-08-13T22:04:01+00:00","text":"Summary: us-east1: Transfer product affected for Storage transfer service customers\nDescription: We are experiencing an issue with Storage Transfer Service.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-08-13 18:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Transfer product currently unusable in us-east1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-08-14T09:34:35+00:00","modified":"2022-08-14T09:34:45+00:00","when":"2022-08-14T09:34:35+00:00","text":"The issue with Storage Transfer Service is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Storage Transfer Service","id":"reC3xJSY6Gzc8n9eYmmj"}],"uri":"incidents/z1SJaDP8pTycwNQ9uHSZ","currently_affected_locations":[],"previously_affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"pRJnaYPTwBCKMNwYL4yU","number":"10954015400583269388","begin":"2022-08-10T13:47:35+00:00","created":"2022-08-10T14:17:40+00:00","end":"2022-08-11T12:17:12+00:00","modified":"2022-08-11T12:17:12+00:00","external_desc":"Europe West: Deadline_Exceeded errors across multiple Logs Coliseum endpoints","updates":[{"created":"2022-08-11T12:17:08+00:00","modified":"2022-08-11T12:17:16+00:00","when":"2022-08-11T12:17:08+00:00","text":"The issue with Cloud Logging has been resolved for all affected users as of Thursday, 2022-08-11 05:16 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-10T17:15:38+00:00","modified":"2022-08-10T17:15:40+00:00","when":"2022-08-10T17:15:38+00:00","text":"Summary: Europe West: Deadline_Exceeded errors across multiple Logs Coliseum endpoints\nDescription: Our engineering team has confirmed that Europe West region is affected due to this incident. Engineering team is currently investigating the root cause of the issue.\nWe will provide an update by Thursday, 2022-08-11 06:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The page responds slower than usual due to higher latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-10T15:53:01+00:00","modified":"2022-08-10T15:53:08+00:00","when":"2022-08-10T15:53:01+00:00","text":"Summary: Deadline_Exceeded across multiple Logs Coliseum endpoints\nDescription: We are experiencing an issue with Cloud Logging beginning on Wednesday, 2022-08-08 05:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-10 10:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The page responds slower than usual due to higher latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-10T14:56:26+00:00","modified":"2022-08-10T14:56:38+00:00","when":"2022-08-10T14:56:26+00:00","text":"Summary: Deadline_Exceeded across multiple Logs Coliseum endpoints\nDescription: We are experiencing an issue with Cloud Logging beginning on Wednesday, 2022-08-08 05:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-10 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The page responds slower than usual due to higher latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-10T14:19:01+00:00","modified":"2022-08-10T14:19:05+00:00","when":"2022-08-10T14:19:01+00:00","text":"Summary: DEADLINE_EXCEEDED across multiple Logs Coliseum endpoints\nDescription: We are experiencing an issue with Cloud Logging beginning on Wednesday, 2022-08-08 05:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-10 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The page responds slow than usual due to higher latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-10T14:17:37+00:00","modified":"2022-08-10T14:17:41+00:00","when":"2022-08-10T14:17:37+00:00","text":"Summary: We've received a report of an issue with Cloud Logging.\nDescription: We are experiencing an issue with Cloud Logging beginning on Wednesday, 2022-08-08 05:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-08-10 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The page responds slow than usual due to higher latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-08-11T12:17:08+00:00","modified":"2022-08-11T12:17:16+00:00","when":"2022-08-11T12:17:08+00:00","text":"The issue with Cloud Logging has been resolved for all affected users as of Thursday, 2022-08-11 05:16 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Cloud Logging","id":"PuCJ6W2ovoDhLcyvZ1xa"}],"uri":"incidents/pRJnaYPTwBCKMNwYL4yU","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"y1ynLrPJBmwxFoLesmjR","number":"15897178309939252563","begin":"2022-08-04T23:49:37+00:00","created":"2022-08-05T00:13:07+00:00","end":"2022-08-05T01:05:03+00:00","modified":"2022-08-05T01:05:03+00:00","external_desc":"Cloud Workflows experiencing high latency and execution failures in europe-west1","updates":[{"created":"2022-08-05T01:04:58+00:00","modified":"2022-08-05T01:05:04+00:00","when":"2022-08-05T01:04:58+00:00","text":"The issue with Cloud Workflows has been resolved for all affected users as of Thursday, 2022-08-04 18:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"created":"2022-08-05T00:13:07+00:00","modified":"2022-08-05T00:13:08+00:00","when":"2022-08-05T00:13:07+00:00","text":"Summary: Cloud Workflows experiencing high latency and execution failures in europe-west1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-04 18:30 US/Pacific.\nDiagnosis: Users experiencing high latencies for ListExecutions and GetExecutions calls and some workflow executions failures with internal errors.\nWorkaround: Customers are advised to temporarily direct traffic to a different region.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]}],"most_recent_update":{"created":"2022-08-05T01:04:58+00:00","modified":"2022-08-05T01:05:04+00:00","when":"2022-08-05T01:04:58+00:00","text":"The issue with Cloud Workflows has been resolved for all affected users as of Thursday, 2022-08-04 18:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"C4P62W9Xc2zZ1Sk52bbw","service_name":"Cloud Workflows","affected_products":[{"title":"Cloud Workflows","id":"C4P62W9Xc2zZ1Sk52bbw"}],"uri":"incidents/y1ynLrPJBmwxFoLesmjR","currently_affected_locations":[],"previously_affected_locations":[{"title":"Belgium (europe-west1)","id":"europe-west1"}]},{"id":"LXkuK6DKs2uy4aaXgcqb","number":"16697391211648581185","begin":"2022-08-04T12:47:50+00:00","created":"2022-08-04T13:19:43+00:00","end":"2022-08-04T19:09:22+00:00","modified":"2022-08-04T19:09:22+00:00","external_desc":"503 error response can be observed for Google Cloud Functions","updates":[{"created":"2022-08-04T19:09:21+00:00","modified":"2022-08-04T19:09:23+00:00","when":"2022-08-04T19:09:21+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Thursday, 2022-08-04 12:07 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T18:27:20+00:00","modified":"2022-08-04T18:27:22+00:00","when":"2022-08-04T18:27:20+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-04 12:30 US/Pacific.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T17:05:32+00:00","modified":"2022-08-04T17:05:35+00:00","when":"2022-08-04T17:05:32+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-08-04 11:30 US/Pacific.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T15:22:15+00:00","modified":"2022-08-04T15:22:21+00:00","when":"2022-08-04T15:22:15+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-08-04 09:30 US/Pacific.\nWe will provide more information by Thursday, 2022-08-04 09:30 US/Pacific.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T14:47:48+00:00","modified":"2022-08-04T14:47:58+00:00","when":"2022-08-04T14:47:48+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-08-04 08:30 US/Pacific.\nWe will provide more information by Thursday, 2022-08-04 08:30 US/Pacific.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T13:47:27+00:00","modified":"2022-08-04T13:47:32+00:00","when":"2022-08-04T13:47:27+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Thursday, 2022-08-04 08:00 US/Pacific.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-08-04T13:19:35+00:00","modified":"2022-08-04T13:19:45+00:00","when":"2022-08-04T13:19:35+00:00","text":"Summary: 503 error response can be observed for Google Cloud Functions\nDescription: We are experiencing an issue with Google Cloud Functions beginning at Thursday, 2022-08-03 14:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-08-04 07:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud Scheduler jobs are failing due to 503 error from Google Cloud Functions\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"}]}],"most_recent_update":{"created":"2022-08-04T19:09:21+00:00","modified":"2022-08-04T19:09:23+00:00","when":"2022-08-04T19:09:21+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Thursday, 2022-08-04 12:07 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"oW4vJ7VNqyxTWNzSHopX","service_name":"Google Cloud Functions","affected_products":[{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/LXkuK6DKs2uy4aaXgcqb","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"zUCkETi9UyEj7u2MJQnQ","number":"775008935054094337","begin":"2022-08-02T06:56:52+00:00","created":"2022-08-02T07:46:24+00:00","end":"2022-08-02T09:25:54+00:00","modified":"2022-08-02T09:25:55+00:00","external_desc":"Billing User Interfaces are unable to load the data consistently","updates":[{"created":"2022-08-02T09:25:52+00:00","modified":"2022-08-02T09:25:59+00:00","when":"2022-08-02T09:25:52+00:00","text":"The issue with Cloud Billing has been resolved for all affected users as of Tuesday, 2022-08-02 02:06 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-02T08:39:01+00:00","modified":"2022-08-02T08:39:02+00:00","when":"2022-08-02T08:39:01+00:00","text":"Summary: Billing User Interfaces are unable to load the data consistently\nDescription: We are experiencing an issue with Cloud Billing beginning at Monday, 2022-08-01 22:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-02 03:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users may not be able to find consistent information with some Billing UIs that related to cost information. e.g. Reports UI, Cost Table, Budget Edit, Billing Overview etc.\nWorkaround: Users may use Google Cloud Billing BigQuery export while UI is not available.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-02T07:59:40+00:00","modified":"2022-08-02T07:59:41+00:00","when":"2022-08-02T07:59:40+00:00","text":"Summary: Billing User Interfaces are unable to load the data consistently\nDescription: We are experiencing an issue with Cloud Billing beginning at Monday, 2022-08-01 22:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-02 02:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users may not be able to find consistent information with some Billing UIs that related to cost information. e.g. Reports UI, Cost Table, Budget Edit, Billing Overview etc.\nWorkaround: Users may use Google Cloud Billing BigQuery export while UI is not available.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-02T07:46:23+00:00","modified":"2022-08-02T07:46:25+00:00","when":"2022-08-02T07:46:23+00:00","text":"Summary: Billing User Interfaces are unable to load the data consistently\nDescription: We are experiencing an issue with Cloud Billing beginning at Monday, 2022-08-01 22:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-08-02 02:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users may not be able to find consistent information with some Billing UIs that related to cost information. e.g. Reports UI, Cost Table, Budget Edit, Billing Overview etc.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-02T09:25:52+00:00","modified":"2022-08-02T09:25:59+00:00","when":"2022-08-02T09:25:52+00:00","text":"The issue with Cloud Billing has been resolved for all affected users as of Tuesday, 2022-08-02 02:06 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"},{"title":"Cloud Billing","id":"oLCqDYkE9NFWQVgctQTL"}],"uri":"incidents/zUCkETi9UyEj7u2MJQnQ","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"gH9SgGxbNhupNZuMA7RR","number":"17513965297264485501","begin":"2022-08-02T01:58:04+00:00","created":"2022-08-02T02:14:19+00:00","end":"2022-08-02T03:08:16+00:00","modified":"2022-08-02T03:08:16+00:00","external_desc":"GKE cluster control planes unavailable in us-central1-a","updates":[{"created":"2022-08-02T03:08:16+00:00","modified":"2022-08-02T03:08:17+00:00","when":"2022-08-02T03:08:16+00:00","text":"The issue with Google Kubernetes Engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-08-02T03:03:45+00:00","modified":"2022-08-02T03:03:47+00:00","when":"2022-08-02T03:03:45+00:00","text":"Summary: GKE cluster control planes unavailable in us-central1-a\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-08-01 21:15 US/Pacific.\nDiagnosis: Multiple clusters in us-central1-a have an issue accessing Kubernetes control planes. Users may face issues while performing operations like administering cluster, modify workloads etc.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-02T02:43:03+00:00","modified":"2022-08-02T02:43:04+00:00","when":"2022-08-02T02:43:03+00:00","text":"Summary: GKE cluster control planes unavailable in us-central1-a\nDescription: We've received a report of an issue with Google Kubernetes Engine as of Monday, 2022-08-01 18:26 US/Pacific.\nWe will provide more information by Monday, 2022-08-01 20:30 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Multiple clusters in us-central1-a have an issue accessing Kubernetes control planes. Users may face issues while performing operations like administering cluster, modify workloads etc.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-08-02T02:14:19+00:00","modified":"2022-08-02T02:14:20+00:00","when":"2022-08-02T02:14:19+00:00","text":"Summary: GKE cluster control planes unavailable in us-central1-a\nDescription: We've received a report of an issue with Google Kubernetes Engine as of Monday, 2022-08-01 18:26 US/Pacific.\nWe will provide more information by Monday, 2022-08-01 20:00 US/Pacific.\nLocation: us-central1-a\nDiagnosis: Multiple clusters in us-central1-a have an issue accessing Kubernetes control planes. Users may face issues while performing operations like administering cluster, modify workloads etc.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-02T03:08:16+00:00","modified":"2022-08-02T03:08:17+00:00","when":"2022-08-02T03:08:16+00:00","text":"The issue with Google Kubernetes Engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LCSbT57h59oR4W98NHuz","service_name":"Google Kubernetes Engine","affected_products":[{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"}],"uri":"incidents/gH9SgGxbNhupNZuMA7RR","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"qWnuQi9gM9DFwZQMxW6r","number":"9545093270944669703","begin":"2022-07-30T21:06:11+00:00","created":"2022-07-30T21:06:12+00:00","end":"2022-07-30T21:48:36+00:00","modified":"2022-07-30T21:48:36+00:00","external_desc":"Reduced Pub/Sub operations availability in us-central1","updates":[{"created":"2022-07-30T21:48:31+00:00","modified":"2022-07-30T21:48:37+00:00","when":"2022-07-30T21:48:31+00:00","text":"The issue with Google Cloud Pub/Sub has been resolved for all affected users as of Saturday, 2022-07-30 14:47 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-30T21:24:23+00:00","modified":"2022-07-30T21:24:24+00:00","when":"2022-07-30T21:24:23+00:00","text":"Summary: Reduced Pub/Sub operations availability in us-central1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-07-30 16:30 US/Pacific.\nDiagnosis: Customers may experience higher latency for subscribe operations in us-central1.\nWorkaround: Customers should shift traffic to a different region where possible.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-30T21:06:12+00:00","modified":"2022-07-30T21:06:13+00:00","when":"2022-07-30T21:06:12+00:00","text":"Summary: Reduced Pub/Sub operations availability in us-central1\nDescription: We are experiencing an issue with Google Cloud Pub/Sub beginning at Saturday, 2022-07-30 02:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-07-30 14:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience higher latency for subscribe operations in us-central1.\nWorkaround: Customers should shift traffic to a different region where possible.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-30T21:48:31+00:00","modified":"2022-07-30T21:48:37+00:00","when":"2022-07-30T21:48:31+00:00","text":"The issue with Google Cloud Pub/Sub has been resolved for all affected users as of Saturday, 2022-07-30 14:47 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"dFjdLh2v6zuES6t9ADCB","service_name":"Google Cloud Pub/Sub","affected_products":[{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"}],"uri":"incidents/qWnuQi9gM9DFwZQMxW6r","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"HV32E9eBBC2XeMUSYCed","number":"5266280648341901542","begin":"2022-07-28T12:46:32+00:00","created":"2022-07-28T13:01:23+00:00","end":"2022-07-28T20:05:14+00:00","modified":"2022-07-28T20:05:14+00:00","external_desc":"Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1","updates":[{"created":"2022-07-28T20:05:09+00:00","modified":"2022-07-28T20:05:15+00:00","when":"2022-07-28T20:05:09+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Thursday, 2022-07-28 13:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-28T19:25:55+00:00","modified":"2022-07-28T19:26:01+00:00","when":"2022-07-28T19:25:55+00:00","text":"Summary: Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-07-28 05:19 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer can face traffic delay, packets can take longer time to reach the destination between southamerica-east1 and southamerica-west1 regions\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-28T17:46:53+00:00","modified":"2022-07-28T17:46:55+00:00","when":"2022-07-28T17:46:53+00:00","text":"Summary: Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-07-28 05:19 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer can face traffic delay, packets can take longer time to reach the destination between southamerica-east1 and southamerica-west1 regions\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-28T15:42:03+00:00","modified":"2022-07-28T15:42:09+00:00","when":"2022-07-28T15:42:03+00:00","text":"Summary: Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-07-28 05:19 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer can face traffic delay, packets can take longer time to reach the destination between southamerica-east1 and southamerica-west1 regions\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-28T14:36:05+00:00","modified":"2022-07-28T14:36:14+00:00","when":"2022-07-28T14:36:05+00:00","text":"Summary: Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-07-28 05:19 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer can face traffic delay, packets can take longer time to reach the destination between southamerica-east1 and southamerica-west1 regions\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-28T13:01:15+00:00","modified":"2022-07-28T13:01:26+00:00","when":"2022-07-28T13:01:15+00:00","text":"Summary: Latency increase from 50ms to 200ms between Cloud Regions southamerica-east1 and southamerica-west1\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-07-28 05:19 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer can face traffic delay, packets can take longer time to reach the destination between southamerica-east1 and southamerica-west1 regions\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]}],"most_recent_update":{"created":"2022-07-28T20:05:09+00:00","modified":"2022-07-28T20:05:15+00:00","when":"2022-07-28T20:05:09+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Thursday, 2022-07-28 13:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/HV32E9eBBC2XeMUSYCed","currently_affected_locations":[],"previously_affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"id":"y4gfB91tKnACnTcH9hGe","number":"18317308596878743043","begin":"2022-07-28T07:19:34+00:00","created":"2022-07-28T08:21:25+00:00","end":"2022-07-28T09:39:28+00:00","modified":"2022-07-28T09:39:29+00:00","external_desc":"Google Bigquery experiencing increased query error rate in US Multi-region","updates":[{"created":"2022-07-28T09:39:21+00:00","modified":"2022-07-28T09:39:31+00:00","when":"2022-07-28T09:39:21+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2022-07-28 02:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-07-28T08:21:25+00:00","modified":"2022-07-28T08:21:26+00:00","when":"2022-07-28T08:21:25+00:00","text":"Summary: Google Bigquery experiencing increased query error rate in US Multi-region\nDescription: We are experiencing an issue with Google BigQuery beginning at Thursday, 2022-07-27 23:35 US/Pacific. US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-28 02:45 US/Pacific with current details.\nDiagnosis: Queries may be experiencing higher latencies or failures\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-07-28T09:39:21+00:00","modified":"2022-07-28T09:39:31+00:00","when":"2022-07-28T09:39:21+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Thursday, 2022-07-28 02:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/y4gfB91tKnACnTcH9hGe","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"id":"4NoanC58bFNsKiUoKdFP","number":"10059515102074396554","begin":"2022-07-27T19:21:17+00:00","created":"2022-07-27T19:38:07+00:00","end":"2022-07-27T20:05:20+00:00","modified":"2022-07-27T20:05:20+00:00","external_desc":"Google Cloud Networking experiencing elevated latencies in South America regions","updates":[{"created":"2022-07-27T20:05:19+00:00","modified":"2022-07-27T20:05:21+00:00","when":"2022-07-27T20:05:19+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected projects as of Wednesday, 2022-07-27 12:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"created":"2022-07-27T19:38:07+00:00","modified":"2022-07-27T19:38:08+00:00","when":"2022-07-27T19:38:07+00:00","text":"Summary: Google Cloud Networking experiencing elevated latencies in South America regions\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Wednesday, 2022-07-27 12:12 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-07-27 13:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will experience elevated latencies accessing Google Cloud Platform from South America\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]}],"most_recent_update":{"created":"2022-07-27T20:05:19+00:00","modified":"2022-07-27T20:05:21+00:00","when":"2022-07-27T20:05:19+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected projects as of Wednesday, 2022-07-27 12:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/4NoanC58bFNsKiUoKdFP","currently_affected_locations":[],"previously_affected_locations":[{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"}]},{"id":"f8ad45DUcBKG4pbEBpuG","number":"4860330579562207556","begin":"2022-07-26T18:58:46+00:00","created":"2022-07-26T19:22:51+00:00","end":"2022-07-26T19:34:19+00:00","modified":"2022-07-26T19:34:19+00:00","external_desc":"Regional: Cloud/Pubsub push subscriptions reduced availability us-central1","updates":[{"created":"2022-07-26T19:34:14+00:00","modified":"2022-07-26T19:34:20+00:00","when":"2022-07-26T19:34:14+00:00","text":"The issue with Google Cloud Pub/Sub has been resolved for all affected users as of Tuesday, 2022-07-26 12:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-26T19:22:51+00:00","modified":"2022-07-26T19:22:52+00:00","when":"2022-07-26T19:22:51+00:00","text":"Summary: Global: Cloud/Pubsub push subscriptions reduced availability\nDescription: We are experiencing an issue with Google Cloud Pub/Sub.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-26 13:23 US/Pacific with current details.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-07-26T19:34:14+00:00","modified":"2022-07-26T19:34:20+00:00","when":"2022-07-26T19:34:14+00:00","text":"The issue with Google Cloud Pub/Sub has been resolved for all affected users as of Tuesday, 2022-07-26 12:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"dFjdLh2v6zuES6t9ADCB","service_name":"Google Cloud Pub/Sub","affected_products":[{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"}],"uri":"incidents/f8ad45DUcBKG4pbEBpuG","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"mQpMu8hcYQSGbyUdwQwM","number":"17672717321302393856","begin":"2022-07-25T19:09:34+00:00","created":"2022-07-25T19:24:44+00:00","end":"2022-07-26T02:31:53+00:00","modified":"2022-07-26T02:31:53+00:00","external_desc":"Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region","updates":[{"created":"2022-07-26T02:31:53+00:00","modified":"2022-07-26T02:31:54+00:00","when":"2022-07-26T02:31:53+00:00","text":"The issue with Google Cloud Console has been resolved for all affected users as of Monday, 2022-07-25 19:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-26T01:22:17+00:00","modified":"2022-07-26T01:22:18+00:00","when":"2022-07-26T01:22:17+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-07-25 20:00 US/Pacific.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T23:54:39+00:00","modified":"2022-07-25T23:54:41+00:00","when":"2022-07-25T23:54:39+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-07-25 19:00 US/Pacific.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T22:08:26+00:00","modified":"2022-07-25T22:08:32+00:00","when":"2022-07-25T22:08:26+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-07-25 17:00 US/Pacific.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T21:30:12+00:00","modified":"2022-07-25T21:30:19+00:00","when":"2022-07-25T21:30:12+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-25 15:30 US/Pacific with current details.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T21:17:24+00:00","modified":"2022-07-25T21:17:31+00:00","when":"2022-07-25T21:17:24+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-25 14:30 US/Pacific with current details.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T20:21:24+00:00","modified":"2022-07-25T20:21:25+00:00","when":"2022-07-25T20:21:24+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Incorrectly Routed in Singapore Region\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-25 14:00 US/Pacific with current details.\nDiagnosis: Customers attempting to place an order from the Cloud Console UI for a transfer appliance in the Singapore region (asia-southeast1) will see the request incorrectly routed to asia-east1.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T19:52:20+00:00","modified":"2022-07-25T19:52:26+00:00","when":"2022-07-25T19:52:20+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Failures in Singapore\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-25 13:30 US/Pacific with current details.\nDiagnosis: Customers may experience issues placing an order for a transfer appliance in the Singapore region.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-25T19:24:38+00:00","modified":"2022-07-25T19:24:46+00:00","when":"2022-07-25T19:24:38+00:00","text":"Summary: Google Cloud Console Transfer Appliance Order Failures in Singapore\nDescription: We are experiencing an issue with Google Cloud Console.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-25 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience issues placing an order for a transfer appliance in the Singapore region.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-07-26T02:31:53+00:00","modified":"2022-07-26T02:31:54+00:00","when":"2022-07-26T02:31:53+00:00","text":"The issue with Google Cloud Console has been resolved for all affected users as of Monday, 2022-07-25 19:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"Wdsr1n5vyDvCt78qEifm","service_name":"Google Cloud Console","affected_products":[{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"}],"uri":"incidents/mQpMu8hcYQSGbyUdwQwM","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"NAU2p9yeFgrsj8iVU2Xh","number":"7162143630251911501","begin":"2022-07-25T14:08:00+00:00","created":"2022-07-29T02:40:25+00:00","end":"2022-08-03T16:47:00+00:00","modified":"2022-08-19T20:54:30+00:00","external_desc":"Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.","updates":[{"created":"2022-08-19T20:50:10+00:00","modified":"2022-08-19T20:50:10+00:00","when":"2022-08-19T20:50:10+00:00","text":"# Incident Report\n**Summary:**\nOn Monday, 25 July 2022, a problem with Google Cloud Billing resulted in incomplete reporting data in the Billing Console for a duration of 9 days, 9 hours and 5 minutes. Invoices were not impacted during the outage. To our customers whose operations were impacted during this outage, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n**Root Cause:**\nGoogle periodically rolls out updates to its products to improve performance and reliability, and to add new functionality. On Monday, 25 July 2022 07:08 US/Pacific, a rollout to Google Compute Engine (GCE) resulted in a change to usage data which created a mismatch in customer billing information and eventually delayed reporting.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the delay in usage reporting through automated monitoring on Tuesday, 26 July 2022 at 01:10 US/Pacific and immediately started an investigation. Google engineers began rolling out a fix on Tuesday, 26 July 2022 at 20:29. However, during the mitigation engineers identified a second issue, which manifested as duplicated results and overbilled charges displayed for 25 July, 26 July, and 27 July.\nAt 15:27 on Wednesday, 27 July 2022, having found the root cause of the problem Google engineers suspended the relevant GCE rollout and developed a fix to correct the duplicated results. On Thursday, 28 July 2022, Google engineers continued to work on mitigation efforts and completed a comprehensive manual verification of the fix before pushing it to production. On Friday, 29 July 2022, engineers resumed the billing system to reprocess the customer usage data. In parallel, engineers observed a failure in billing reporting due to the large amount of queued corrections.\nThe incident was fully mitigated on Wednesday, 03 August 2022 09:47 US/Pacific, once the correction process completed across all systems.\nThere was no impact to July invoices, which were issued on Monday, 01 August 2022.\nGoogle is committed to preventing future issues like this and is completing the following actions to ensure there is not a recurrence:\n- Implement validation checks to detect the duplicated results that were passed to downstream systems, causing the second issue.\n- Implement end-to-end testing to cover critical user journeys across GCE, Billing, and Invoicing.\n- Implement a change detection program to identify backward incompatible events from GCE to Billing to prevent transient incorrect billing results.\n- Update the GCE rollout procedure to minimize impact when rolling out a new global billing capability for GCE.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact:**\n## Google Compute Engine (GCE), including Google Kubernetes Engine (GKE) and Google App Engine Flex (GAE):\n- 100% of GCE, GAE Flex, and GKE customers may have experienced delays in viewing real-time product usage information in the Cloud Billing Console or in BigQuery export, if used.\n- Cloud Billing usage reporting experienced issues and may have shown inaccurate or incomplete data. - Some customers may have seen up to double their instance usage being billed.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T22:20:10+00:00","modified":"2022-08-03T22:20:10+00:00","when":"2022-08-03T22:20:10+00:00","text":"**Mini-IR (Preliminary IR)**\nWe apologize for the inconvenience this incident may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 25 July 2021 00:00\n**Incident End:** 03 Aug 2022 09:45\n**Duration:** 9 days, 9 hours, 45 minutes\n**Affected Services and Features:** - Google Cloud Console - Billing Export - Google Cloud Billing\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Billing usage reporting experienced issues and may have shown incomplete data for a duration of 9 days, 9 hours, and 5 minutes. From preliminary analysis this was due to an issue with a recent rollout to the Google Compute Engine (GCE) control plane. The rollout produced unforeseen data change that caused a mismatch in Billing, and eventually a delay in the usage reporting.\nComplete Usage data for all days in July are now available in the Cloud Billing Console and BigQuery Export. There was no impact to the invoices for July, which were issued on 1 August 2022.\n**Customer Impact:**\nAffected customers experienced the following: - Customers may have experienced delays in viewing real-time product usage information in the Cloud Billing Console or in BigQuery export, if used. - Cloud Billing usage reporting experienced issues and may have shown inaccurate or incomplete data. - Some customers may have seen up to double their instance usage being billed.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T16:53:48+00:00","modified":"2022-08-03T16:53:54+00:00","when":"2022-08-03T16:53:48+00:00","text":"This issue has been fully resolved as of 2022-08-03 09:45 US/Pacific.\n1. Complete Usage data for all days in July are now available in the Billing console, and BigQuery Export.\n2. There was no impact to the Invoices for July, which were issued on 2022-08-01.\nThis is the final update on this issue.\nIf you experience any further issues with Cloud Billing usage reporting or BigQuery export for the month of July, please contact Cloud Support.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T16:42:39+00:00","modified":"2022-08-03T16:42:42+00:00","when":"2022-08-03T16:42:39+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n1. Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n2. Data for 2022-07-29 is in process and expected to be fully available by mid-day Wednesday, 2022-08-03 US/Pacific.\n3. There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Wednesday, 2022-08-03 10:45 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T03:54:59+00:00","modified":"2022-08-03T03:55:00+00:00","when":"2022-08-03T03:54:59+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n1. Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n2. Data for 2022-07-29 is in process and expected to be fully available by mid-day Wednesday, 2022-08-03 US/Pacific.\n3. There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Wednesday, 2022-08-03 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T03:52:26+00:00","modified":"2022-08-03T03:52:27+00:00","when":"2022-08-03T03:52:26+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\nComplete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\nData for 2022-07-29 is in process and expected to be fully available by mid-day Wednesday, 2022-08-03 US/Pacific.\nThere is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Wednesday, 2022-08-03 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T00:37:59+00:00","modified":"2022-08-03T00:38:00+00:00","when":"2022-08-03T00:37:59+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n- Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n- Data for 2022-07-29 is still under recovery and expected to be fully available by Tuesday, 2022-08-02 23:59 US/Pacific.\n- There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Tuesday, 2022-08-02 21:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T00:06:47+00:00","modified":"2022-08-03T00:06:48+00:00","when":"2022-08-03T00:06:47+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n- Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n- Data for 2022-07-29 is still under recovery and expected to be fully available by Tuesday, 2022-08-02 23:59 US/Pacific.\n- There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Tuesday, 2022-08-02 19:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T00:04:55+00:00","modified":"2022-08-03T00:04:57+00:00","when":"2022-08-03T00:04:55+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n- Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n- Data for 2022-07-29 is still under recovery and expected to be fully available by Tuesday, 2022-08-02 23:59 US/Pacific.\n- There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Tuesday, 2022-08-02 21:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-02T19:55:55+00:00","modified":"2022-08-02T19:55:56+00:00","when":"2022-08-02T19:55:55+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n- Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n- Data for 2022-07-29 is still under recovery and expected to be fully available by Tuesday, 2022-08-02 23:59 US/Pacific.\n- There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Tuesday, 2022-08-02 17:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-02T16:01:33+00:00","modified":"2022-08-02T16:01:36+00:00","when":"2022-08-02T16:01:33+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific.\n- Complete Usage data for all days, except 2022-07-29, are available, in the Billing console and Billing Export.\n- Data for 2022-07-29 is still under recovery and expected to be fully available by Tuesday, 2022-08-02 23:59 US/Pacific.\n- There is no impact to the Invoices for July, which were issued on 2022-08-01, and include accurate charge for 2022-07-29 as well.\nWe will provide more information by Tuesday, 2022-08-02 13:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-02T04:16:47+00:00","modified":"2022-08-02T04:16:49+00:00","when":"2022-08-02T04:16:47+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. Usage data for 2022-07-25, 2022-07-26, and 2022-07-27 US/Pacific is now available. Over the next day, users will start to see usage data for remaining days with full recovery by Tuesday, 2022-08-02 23:59 US/Pacific. Please note that the data in Big Query Export will continue to be populated with usage between 2022-07-25 and 2022-07-29 until the full recovery is completed.\nWe will provide more information by Tuesday, 2022-08-02 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-02T03:07:00+00:00","modified":"2022-08-02T03:07:01+00:00","when":"2022-08-02T03:07:00+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. Usage data for 2022-07-30 US/Pacific is now available. Over the next two days, users will start to see usage data from 2022-07-25 to 2022-07-29 become available with full recovery by Tuesday, 2022-08-02 23:59 US/Pacific. Please note that the data in Big Query Export will continue to be populated with usage between 2022-07-25 and 2022-07-29 until the full recovery is completed.\nWe will provide more information by Tuesday, 2022-08-02 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-02T00:01:04+00:00","modified":"2022-08-02T00:01:06+00:00","when":"2022-08-02T00:01:04+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. Usage data for 2022-07-30 US/Pacific is now available. Over the next two days, users will start to see usage data from 2022-07-25 to 2022-07-29 become available with full recovery by Tuesday, 2022-08-02 23:59 US/Pacific. Please note that the data in Big Query Export will continue to be populated with usage between 2022-07-25 and 2022-07-29 until the full recovery is completed.\nWe will provide more information by Monday, 2022-08-01 21:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T19:37:16+00:00","modified":"2022-08-01T19:37:18+00:00","when":"2022-08-01T19:37:16+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. Usage data for 2022-07-30 US/Pacific is now available. Over the next two days, users will start to see usage data from 2022-07-25 to 2022-07-29 become available with full recovery by Tuesday, 2022-08-02 23:59 US/Pacific. Please note that the data in Billing Export to Big Query will also change for usage between 2022-07-25 and 2022-07-29 until the full recovery is completed.\nWe will provide more information by Monday, 2022-08-01 17:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T15:46:06+00:00","modified":"2022-08-01T15:46:07+00:00","when":"2022-08-01T15:46:06+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. Usage data for 2022-07-30 US/Pacific is now available. Over the next two days, users will start to see usage data from 2022-07-25 to 2022-07-29 become available with full recovery by Tuesday, 2022-08-02 23:59 US/Pacific.\nWe will provide more information by Monday, 2022-08-01 13:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T04:03:50+00:00","modified":"2022-08-01T04:03:51+00:00","when":"2022-08-01T04:03:50+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. We expect to have complete usage data from 2022-07-25 to 2022-07-30 available by Tuesday, 2022-08-02 23:59 US/Pacific.\nWe will provide more information by Monday, 2022-08-01 09:30 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T03:45:01+00:00","modified":"2022-08-01T03:45:02+00:00","when":"2022-08-01T03:45:01+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. We expect to have complete usage data from 2022-07-25 to 2022-07-30 available by Tuesday, 2022-08-02 23:59 US/Pacific.\nWe will provide more information by Sunday, 2022-07-31 21:30 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T00:49:40+00:00","modified":"2022-08-01T00:49:50+00:00","when":"2022-08-01T00:49:40+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nCloud Billing reporting has resumed normal operations from 2022-07-31 US/Pacific. We expect to have complete usage data from 2022-07-25 to 2022-07-30 available by Tuesday, 2022-08-02 23:59 US/Pacific.\nWe will provide more information by Sunday, 2022-07-31 21:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-01T00:20:48+00:00","modified":"2022-08-01T00:20:58+00:00","when":"2022-08-01T00:20:48+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Sunday, 2022-07-31 19:30 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-31T21:55:03+00:00","modified":"2022-07-31T21:55:04+00:00","when":"2022-07-31T21:55:03+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Sunday, 2022-07-31 17:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-31T19:07:15+00:00","modified":"2022-07-31T19:07:17+00:00","when":"2022-07-31T19:07:15+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Sunday, 2022-07-31 15:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-31T15:54:54+00:00","modified":"2022-07-31T15:54:55+00:00","when":"2022-07-31T15:54:54+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Sunday, 2022-07-31 12:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-31T02:59:11+00:00","modified":"2022-07-31T02:59:18+00:00","when":"2022-07-31T02:59:11+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Sunday, 2022-07-31 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-30T22:14:07+00:00","modified":"2022-07-30T22:14:08+00:00","when":"2022-07-30T22:14:07+00:00","text":"Summary: Cloud Billing usage reporting is experiencing issues, and Cost Management experience may show incomplete data.\nDescription: We are experiencing an issue with Cloud Billing. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Saturday, 2022-07-30 20:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-30T16:01:14+00:00","modified":"2022-07-30T16:01:24+00:00","when":"2022-07-30T16:01:14+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Compute Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Compute Engine SKUs. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Saturday, 2022-07-30 14:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-30T03:55:25+00:00","modified":"2022-07-30T03:55:26+00:00","when":"2022-07-30T03:55:25+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Compute Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Compute Engine SKUs. The root cause has been identified, and the recovery process is still underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Saturday, 2022-07-30 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-30T00:20:39+00:00","modified":"2022-07-30T00:20:41+00:00","when":"2022-07-30T00:20:39+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Compute Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Compute Engine SKUs. The root cause has been identified, and the recovery process is already underway.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Friday, 2022-07-29 21:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-29T18:57:32+00:00","modified":"2022-07-29T18:57:34+00:00","when":"2022-07-29T18:57:32+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Compute Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Compute Engine SKUs. The root cause has been identified, and we have now initiated the recovery process.\nWe do not have an ETA at this point for when the full recovery will be complete.\nWe will provide more information by Friday, 2022-07-29 17:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-29T17:00:38+00:00","modified":"2022-07-29T17:00:45+00:00","when":"2022-07-29T17:00:38+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Compute Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Google Compute Engine SKUs.\nWe have identified the root cause and mitigation is currently underway by our engineering team. However, we do not have an ETA for mitigation and resolution at this point.\nWe will provide more information by Friday, 2022-07-29 12:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-29T15:29:17+00:00","modified":"2022-07-29T15:29:18+00:00","when":"2022-07-29T15:29:17+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Cloud Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing where billing has been paused for a subset of Compute Engine SKUs.\nWe have identified the root cause and mitigation is currently underway by our engineering team. However, we do not have an ETA for mitigation and resolution at this point.\nWe will provide more information by Friday, 2022-07-29 12:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-29T15:13:52+00:00","modified":"2022-07-29T15:13:58+00:00","when":"2022-07-29T15:13:52+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Cloud Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-07-29 09:30 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-29T02:40:24+00:00","modified":"2022-07-29T02:40:26+00:00","when":"2022-07-29T02:40:24+00:00","text":"Summary: Cloud Billing is experiencing issues with usage reporting for some Google Cloud Engine SKUs\nDescription: We are experiencing an issue with Cloud Billing\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-07-29 09:00 US/Pacific.\nDiagnosis: Users may experience delays in viewing real time Product usage information for some Google Compute Engine SKUs in the Cloud Billing Console\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-08-19T20:50:10+00:00","modified":"2022-08-19T20:50:10+00:00","when":"2022-08-19T20:50:10+00:00","text":"# Incident Report\n**Summary:**\nOn Monday, 25 July 2022, a problem with Google Cloud Billing resulted in incomplete reporting data in the Billing Console for a duration of 9 days, 9 hours and 5 minutes. Invoices were not impacted during the outage. To our customers whose operations were impacted during this outage, we sincerely apologize – this is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n**Root Cause:**\nGoogle periodically rolls out updates to its products to improve performance and reliability, and to add new functionality. On Monday, 25 July 2022 07:08 US/Pacific, a rollout to Google Compute Engine (GCE) resulted in a change to usage data which created a mismatch in customer billing information and eventually delayed reporting.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the delay in usage reporting through automated monitoring on Tuesday, 26 July 2022 at 01:10 US/Pacific and immediately started an investigation. Google engineers began rolling out a fix on Tuesday, 26 July 2022 at 20:29. However, during the mitigation engineers identified a second issue, which manifested as duplicated results and overbilled charges displayed for 25 July, 26 July, and 27 July.\nAt 15:27 on Wednesday, 27 July 2022, having found the root cause of the problem Google engineers suspended the relevant GCE rollout and developed a fix to correct the duplicated results. On Thursday, 28 July 2022, Google engineers continued to work on mitigation efforts and completed a comprehensive manual verification of the fix before pushing it to production. On Friday, 29 July 2022, engineers resumed the billing system to reprocess the customer usage data. In parallel, engineers observed a failure in billing reporting due to the large amount of queued corrections.\nThe incident was fully mitigated on Wednesday, 03 August 2022 09:47 US/Pacific, once the correction process completed across all systems.\nThere was no impact to July invoices, which were issued on Monday, 01 August 2022.\nGoogle is committed to preventing future issues like this and is completing the following actions to ensure there is not a recurrence:\n- Implement validation checks to detect the duplicated results that were passed to downstream systems, causing the second issue.\n- Implement end-to-end testing to cover critical user journeys across GCE, Billing, and Invoicing.\n- Implement a change detection program to identify backward incompatible events from GCE to Billing to prevent transient incorrect billing results.\n- Update the GCE rollout procedure to minimize impact when rolling out a new global billing capability for GCE.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact:**\n## Google Compute Engine (GCE), including Google Kubernetes Engine (GKE) and Google App Engine Flex (GAE):\n- 100% of GCE, GAE Flex, and GKE customers may have experienced delays in viewing real-time product usage information in the Cloud Billing Console or in BigQuery export, if used.\n- Cloud Billing usage reporting experienced issues and may have shown inaccurate or incomplete data. - Some customers may have seen up to double their instance usage being billed.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"},{"title":"Cloud Billing","id":"oLCqDYkE9NFWQVgctQTL"}],"uri":"incidents/NAU2p9yeFgrsj8iVU2Xh","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"cSLrA8wLeQF93qb8GFM4","number":"6130968339129840013","begin":"2022-07-25T13:23:36+00:00","created":"2022-07-25T13:36:15+00:00","end":"2022-07-25T13:47:00+00:00","modified":"2022-07-25T13:47:01+00:00","external_desc":"Reduced Pub/Sub availability in us-central1","updates":[{"created":"2022-07-25T13:46:53+00:00","modified":"2022-07-25T13:47:04+00:00","when":"2022-07-25T13:46:53+00:00","text":"The issue with Google Cloud Pub/Sub is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-25T13:36:07+00:00","modified":"2022-07-25T13:36:17+00:00","when":"2022-07-25T13:36:07+00:00","text":"Summary: Reduced Pub/Sub availability in us-central1\nDescription: We are experiencing an issue with Google Cloud Pub/Sub beginning on Monday, 2022-07-25 02:20 US/Pacific.\nOur engineering team is investigating the issue.\nWe will provide an update by Monday, 2022-07-25 07:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers amy see errors and experience higher latency for publish+subscribe operations in us-central1.\nWorkaround: Shifting traffic to a different region where possible.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-25T13:46:53+00:00","modified":"2022-07-25T13:47:04+00:00","when":"2022-07-25T13:46:53+00:00","text":"The issue with Google Cloud Pub/Sub is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"dFjdLh2v6zuES6t9ADCB","service_name":"Google Cloud Pub/Sub","affected_products":[{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"}],"uri":"incidents/cSLrA8wLeQF93qb8GFM4","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"gAJbQsuZv3kiuNbjQHvP","number":"6955968892207455274","begin":"2022-07-22T19:24:56+00:00","created":"2022-07-22T19:24:57+00:00","end":"2022-07-23T07:11:38+00:00","modified":"2022-07-23T07:11:38+00:00","external_desc":"Singapore: Cloud Storage for Firebase connectivity issues","updates":[{"created":"2022-07-23T07:11:30+00:00","modified":"2022-07-23T07:11:42+00:00","when":"2022-07-23T07:11:30+00:00","text":"The Cloud Storage for Firebase connectivity issue has been resolved for all affected users as of Saturday, 2022-07-23 00:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},{"created":"2022-07-22T19:24:57+00:00","modified":"2022-07-22T19:24:58+00:00","when":"2022-07-22T19:24:57+00:00","text":"Summary: Singapore: Cloud Storage for Firebase connectivity issues\nDescription: We are experiencing an issue with Cloud Storage for Firebase.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-07-23 13:00 US/Pacific with current details.\nDiagnosis: End users in Singapore of affected ISPs will be unable to access objects in Firebase Storage\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]}],"most_recent_update":{"created":"2022-07-23T07:11:30+00:00","modified":"2022-07-23T07:11:42+00:00","when":"2022-07-23T07:11:30+00:00","text":"The Cloud Storage for Firebase connectivity issue has been resolved for all affected users as of Saturday, 2022-07-23 00:10 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Cloud Storage for Firebase","id":"aY6Fbgy6TV4YWoutjhfe"}],"uri":"incidents/gAJbQsuZv3kiuNbjQHvP","currently_affected_locations":[],"previously_affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"}]},{"id":"gswAupd1mFy1zfq6zErG","number":"13373907050124657461","begin":"2022-07-22T16:25:54+00:00","created":"2022-07-22T16:25:55+00:00","end":"2022-07-22T16:30:33+00:00","modified":"2022-07-22T16:30:33+00:00","external_desc":"Cloud TPU V4 experiencing availability issues in us-central2-b","updates":[{"created":"2022-07-22T16:30:33+00:00","modified":"2022-07-22T16:30:34+00:00","when":"2022-07-22T16:30:33+00:00","text":"The issue with Cloud TPU V4 is less critical than initially indicated. Our Engineering Team is working on it.\nIf you've already opened a support case we will continue to provide updates there. If not and you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-22T16:25:55+00:00","modified":"2022-07-22T16:25:56+00:00","when":"2022-07-22T16:25:55+00:00","text":"Summary: Cloud TPU V4 experiencing availability issues in us-central2-b\nDescription: We are experiencing an issue with Cloud TPU instances beginning at Monday, 2022-07-11 09:07 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-22 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will be unable to schedule TPU V4 pod slices or may experiencing intermittent unavailability of running TPU V4 slices.\nOther TPU version are not affected by the issue.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-22T16:30:33+00:00","modified":"2022-07-22T16:30:34+00:00","when":"2022-07-22T16:30:33+00:00","text":"The issue with Cloud TPU V4 is less critical than initially indicated. Our Engineering Team is working on it.\nIf you've already opened a support case we will continue to provide updates there. If not and you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/gswAupd1mFy1zfq6zErG","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"mLBHeCxhRia17anXCSX1","number":"14970871909327597787","begin":"2022-07-19T14:17:00+00:00","created":"2022-07-20T13:39:01+00:00","end":"2022-07-19T15:47:00+00:00","modified":"2022-07-29T21:06:40+00:00","external_desc":"Secret Manager experienced service unavailability in europe-west2","updates":[{"created":"2022-07-29T21:06:40+00:00","modified":"2022-07-29T21:06:40+00:00","when":"2022-07-29T21:06:40+00:00","text":"For a full Incident Report, please refer to https://status.cloud.google.com/incidents/fmEL9i2fArADKawkZAa2","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T13:44:35+00:00","modified":"2022-07-20T13:44:36+00:00","when":"2022-07-20T13:44:35+00:00","text":"We experienced an issue with Secret Manager beginning at Tuesday, 2022-07-19 07:17 US/Pacific.\nSelf-diagnosis: Customers who had their secrets exclusively in europe-west2 or attempted to create a secret in europe-west2 were seeing UNAVAILABLE / 5xx errors\nThe issue has been resolved for all affected projects as of Tuesday, 2022-07-19 08:47 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T13:38:56+00:00","modified":"2022-07-20T13:39:02+00:00","when":"2022-07-20T13:38:56+00:00","text":"Summary: We are investigating a potential issue with Secret Manager.\nDescription: We are investigating a potential issue with Secret Manager.\nWe will provide more information by Wednesday, 2022-07-20 07:15 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]}],"most_recent_update":{"created":"2022-07-29T21:06:40+00:00","modified":"2022-07-29T21:06:40+00:00","when":"2022-07-29T21:06:40+00:00","text":"For a full Incident Report, please refer to https://status.cloud.google.com/incidents/fmEL9i2fArADKawkZAa2","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"kzGfErQK3HzkFhptoeHH","service_name":"Secret Manager","affected_products":[{"title":"Secret Manager","id":"kzGfErQK3HzkFhptoeHH"}],"uri":"incidents/mLBHeCxhRia17anXCSX1","currently_affected_locations":[],"previously_affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"id":"XVq5om2XEDSqLtJZUvcH","number":"5289378925036056618","begin":"2022-07-19T13:33:00+00:00","created":"2022-07-19T17:13:38+00:00","end":"2022-07-21T04:20:00+00:00","modified":"2022-07-29T21:05:41+00:00","external_desc":"Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2.","updates":[{"created":"2022-07-29T21:05:41+00:00","modified":"2022-07-29T21:05:41+00:00","when":"2022-07-29T21:05:41+00:00","text":"For a full Incident Report, please refer to https://status.cloud.google.com/incidents/fmEL9i2fArADKawkZAa2","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T19:06:31+00:00","modified":"2022-07-29T21:05:07+00:00","when":"2022-07-21T19:06:31+00:00","text":"For a preliminary Incident Report (Mini IR) , please refer to https://status.cloud.google.com/incidents/fmEL9i2fArADKawkZAa2","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T03:45:25+00:00","modified":"2022-07-20T03:45:26+00:00","when":"2022-07-20T03:45:25+00:00","text":"There was a cooling related failure in one of our buildings that hosts a portion of capacity for zone europe-west2-a for region europe-west2 that is now resolved. GCE, Persistent Disk and Autoscaling impacts have been addressed. Customers can launch VMs in all zones of europe-west2. A small number of HDD backed Persistent Disk volumes are still experiencing impact and will exhibit IO errors. If you are continuing to experience issues with these services, please contact Google Cloud Product Support and reference this message.\nThe issue has been resolved for all affected users as of Tuesday, 2022-07-19 20:43 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T22:29:06+00:00","modified":"2022-07-19T22:29:07+00:00","when":"2022-07-19T22:29:06+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nThere is a cooling related failure in one of our buildings that hosts a portion of capacity for zone europe-west2-a for region europe-west2 that is not yet completely resolved. GCE, Persistent Disk and Autoscaling impacts have been mitigated. Most customers can launch VMs in all zones of europe-west2. A minority of customers might continue to see failures in europe-west2-a. We continue to work on bringing back previously impacted capacity in europe-west2-a to fully restore GCE, Persistent Disk and Autoscaling. If you are continuing to experience issues with these services, please contact Google Cloud Product Support and reference this message.\nCustomers who launched new VMs in zones europe-west2-b and europe-west2-c and would like to delete their previously running VMs in europe-west2-a, can delete VMs via the console or GCE APIs. There might be a delay in processing the deletion and all deletions will be fully processed when all issues in europe-west2-a are resolved.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs.\nWorkaround: Customers who launched new VMs in zones europe-west2-b and europe-west2-c and would like to delete their previously running VMs in europe-west2-a, can delete VMs via the console or GCE APIs. There might be a delay in processing the deletion and all deletions will be fully processed when all issues in europe-west2-a are resolved.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T21:08:45+00:00","modified":"2022-07-19T21:16:34+00:00","when":"2022-07-19T21:08:45+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nThere is a cooling related failure in one of our buildings that hosts a portion of capacity for zone europe-west2-a for region europe-west2 that is not yet completely resolved.\nGCE, Persistent Disk and Autoscaling impacts have been mitigated. Most customers can launch VMs in all zones of europe-west2.\nA minority of customers might continue to see failures in europe-west2-a.\nWe continue to work on bringing back previously impacted capacity in europe-west2-a to fully restore GCE, Persistent Disk and Autoscaling. If you are continuing to experience issues with these services, please contact Google Cloud Product Support and reference this message.\nPlease refer to workaround section for additional information about VM deletion.\nWe will provide more information by Tuesday, 2022-07-19 16:00 US/Pacific.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs.\nWorkaround: Customers who launched new VMs in zones europe-west2-b and europe-west2-c and would like to delete their previously running VMs in europe-west2-a, can delete VMs via the console or GCE APIs. There might be a delay in processing the deletion and all deletions will be fully processed when all issues in europe-west2-a are resolved.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T19:29:11+00:00","modified":"2022-07-19T19:29:12+00:00","when":"2022-07-19T19:29:11+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. Europe-west2-b and europe-west2-c are not impacted for VMs. We have fixed the previously occurring issues when creating new Persistent Disk devices. Zonal autoscaling for europe-west2-a is impacted for customers who suffered VM terminations.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Tuesday, 2022-07-19 08:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nThere has been a cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. This caused a partial failure of capacity in that zone, leading to VM terminations and a loss of machines for a small set of our customers. We’re working hard to get the cooling back on-line and create capacity in that zone. We do not anticipate further impact in zone europe-west2-a and currently running VMs should not be impacted. A small percentage of replicated Persistent Disk devices are running in single redundant mode.\nIn order to prevent damage to machines and an extended outage, we have powered down part of the zone and are limiting GCE preemptible launches. We are working to restore redundancy for any remaining impacted replicated Persistent Disk devices.\nWe will provide an update by Tuesday, 2022-07-19 15:00 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs. We’re working on identifying and communicating with all affected customers.\nWorkaround: For customers who have experienced a VM failure in europe-west2-a, we recommend launching new instances in europe-west2-b and europe-west2-c. Customers who currently have running instances in europe-west2-a can continue to use Auto Scaling in europe-west2-a. Regional Auto Scaling continues to work.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T19:05:30+00:00","modified":"2022-07-19T19:05:31+00:00","when":"2022-07-19T19:05:30+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. Europe-west2-b and europe-west2-c are not impacted for VMs. We have fixed the previously occurring issues when creating new Persistent Disk devices. Zonal autoscaling for europe-west2-a is impacted.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Tuesday, 2022-07-19 08:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nThere has been a cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. This caused a partial failure of capacity in that zone, leading to VM terminations and a loss of machines for a small set of our customers. We’re working hard to get the cooling back on-line and create capacity in that zone. We do not anticipate further impact in zone europe-west2-a and currently running VMs should not be impacted. A small percentage of replicated Persistent Disk devices are running in single redundant mode.\nIn order to prevent damage to machines and an extended outage, we have powered down part of the zone and are limiting GCE preemptible launches. We are working to restore redundancy for any remaining impacted replicated Persistent Disk devices.\nWe will provide an update by Tuesday, 2022-07-19 14:00 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs. We’re working on identifying and communicating with all affected customers.\nWorkaround: For customers who have experienced a VM failure in europe-west2-a, we recommend launching new instances in europe-west2-b and europe-west2-c.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T18:36:45+00:00","modified":"2022-07-19T18:36:46+00:00","when":"2022-07-19T18:36:45+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. The other zones are not impacted for VMs. We are seeing regional impact for a small proportion of newly launched Persistent Disk volumes.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Tuesday, 2022-07-19 08:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nThere has been a cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. This caused a partial failure of capacity in that zone, leading to VM terminations and a loss of machines for a small set of our customers. We’re working hard to get the cooling back on-line and create capacity in that zone. We do not anticipate further impact in zone europe-west2-a and currently running VMs should not be impacted. A small percentage of replicated Persistent Disk devices are now running in single redundant mode.\nIn order to prevent damage to machines and an extended outage, we have powered down part of the zone and are limiting GCE preemptible launches. We are seeing regional impact for a small proportion of newly launched Persistent Disk volumes and are working to restore redundancy for the impacted replicated Persistent Disk devices.\nWe will provide an update by Tuesday, 2022-07-19 13:45 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs. We’re working on identifying and communicating with all affected customers.\nWorkaround: For customers who have experienced a VM failure in europe-west2-a, we recommend launching new instances in other zones of europe-west2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T17:41:40+00:00","modified":"2022-07-19T17:41:41+00:00","when":"2022-07-19T17:41:40+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. The other zones are not impacted for VMs. We are seeing regional impact for a small proportion of newly launched Persistent Disk volumes.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Tuesday, 2022-07-19 08:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nThere has been a cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. This caused a partial failure of capacity in that zone, leading to VM terminations and a loss of machines for a small set of our customers. We’re working hard to get the cooling back on-line and create capacity in that zone. We do not anticipate further impact in zone europe-west2-a and currently running VMs should not be impacted. A small percentage of replicated Persistent Disk devices are now running in single redundant mode.\nIn order to prevent damage to machines and an extended outage, we have powered down part of the zone and are limiting GCE preemptible launches. We are seeing regional impact for a small proportion of newly launched Persistent Disk volumes and are working to restore redundancy for the impacted replicated Persistent Disk devices.\nWe will provide an update by Tuesday, 2022-07-19 11:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs. We’re working on identifying and communicating with all affected customers.\nWorkaround: For customers who have experienced a VM failure in europe-west2-a, we recommend launching new instances in other zones of europe-west2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T17:13:37+00:00","modified":"2022-07-19T17:13:38+00:00","when":"2022-07-19T17:13:37+00:00","text":"Summary: Cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. The other zones are not impacted.\nDescription: We are experiencing an issue with Google Compute Engine beginning at Tuesday, 2022-07-19 08:10 US/Pacific.\nOur engineering team continues to investigate the issue.\nThere has been a cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2. This caused a partial failure of capacity in that zone, leading to VM terminations and a loss of machines for a small set of our customers. We’re working hard to get the cooling back on-line and create capacity in that zone. We do not anticipate further impact in zone europe-west2-a and currently running VMs should not be impacted. A small percentage of replicated Persistent Disk devices are now running in single redundant mode.\nIn order to prevent damage to machines and an extended outage, we have powered down part of the zone and are limiting GCE preemptible launches. We are also working to restore redundancy for the impacted replicated Persistent Disk devices.\nWe will provide an update by Tuesday, 2022-07-19 11:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue would have seen abnormal VM terminations for a small set of their VMs. We’re working on identifying and communicating with all affected customers.\nWorkaround: For customers who have experienced a VM failure in europe-west2-a, we recommend launching new instances in other zones of europe-west2.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]}],"most_recent_update":{"created":"2022-07-29T21:05:41+00:00","modified":"2022-07-29T21:05:41+00:00","when":"2022-07-29T21:05:41+00:00","text":"For a full Incident Report, please refer to https://status.cloud.google.com/incidents/fmEL9i2fArADKawkZAa2","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/XVq5om2XEDSqLtJZUvcH","currently_affected_locations":[],"previously_affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"id":"fmEL9i2fArADKawkZAa2","number":"17286000671883665526","begin":"2022-07-19T13:33:00+00:00","created":"2022-07-19T16:15:47+00:00","end":"2022-07-21T04:20:00+00:00","modified":"2022-07-29T21:13:17+00:00","external_desc":"Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2","updates":[{"created":"2022-07-29T21:00:05+00:00","modified":"2022-07-29T21:13:17+00:00","when":"2022-07-29T21:00:05+00:00","text":"## Incident Report\n**Summary:**\nOn Tuesday, 19 July 2022 at 06:33 US/Pacific, a simultaneous failure of multiple, redundant cooling systems in one of the data centers that hosts the zone europe-west2-a impacted multiple Google Cloud services. This resulted in some customers experiencing service unavailability for impacted products.\nTo our customers whose businesses were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps (detailed in the **Remediation \u0026 Prevention** section below) to improve the region's resilience.\n***Regional Impact***\nA number of regional Google Cloud services experienced impact during this incident, despite regional services being designed to survive the failure of a single zone. Upon investigation we have found two key contributing factors which led to these regional impacts: * At the start of the incident, we inadvertently modified traffic routing for internal services to avoid all three zones in the europe-west2 region, rather than just the impacted europe-west2-a zone. We corrected this on 19 July 2022 at 12:35 US/Pacific. * Our regional storage services, including GCS and BigQuery, replicate customer data across multiple zones. Due to the regional traffic routing change, they were unable to access any replica for a number of storage objects. This prevented customers from reading these objects until the traffic routing was corrected, at which point access was immediately restored.\n***Cooling System Impact Duration***\nGoogle engineers powered down the data center that hosted a portion of the impacted zone europe-west2-a on Tuesday, 19 July 2022 at 10:05 US/Pacific while the cooling system was repaired. The cooling system was repaired at 14:13 US/Pacific. The total duration of the cooling system failure impact was 4 hours, 8 minutes.\n***Cloud Service Restoration Duration***\nGoogle engineers began service restoration once the cooling system was repaired on Tuesday, 19 July 2022 at 14:13 US/Pacific. Cloud services were restored to operation by Wednesday, 20 July 2022 at 04:28 US/Pacific.\nThe duration of impact on Cloud services spans the window from 10:05 US/Pacific on Tuesday, 19 July 2022 (when a portion of europe-west2-a was powered down), to 04:28 US/Pacific on Wednesday, 20 July 2022, when Cloud services were restored; a total of 18 hours, 23 minutes.\n***Long Tail Duration***\nAfter the initial restoration of service to the zone, a small number of Google Compute Engine instances required additional work by our engineers to restore them to normal operations. This manifested as unavailable instances in GCE, and unavailable instances in products and services that rely on Google Compute Engine, such as Cloud SQL. This was fully mitigated on Wednesday, 20 July 2022 at 21:20 US/Pacific and the incident was closed with all services restored.\nFor the instances in this long tail, impact duration spans the window from the initial power down (at 10:05 US/Pacific on Tuesday, 19 July 2022) to the eventual full mitigation (at 21:20 US/Pacific on Wednesday, 20 July 2022); a total of 35 hours, 15 minutes.\nGoogle is conducting a detailed analysis of the systems and processes involved in both the cooling failure and the service recovery, with specific followup AIs identified below.\n**Root Cause:**\nOne of the data centers that hosts zone europe-west2-a could not maintain a safe operating temperature due to a simultaneous failure of multiple, redundant cooling systems combined with the extraordinarily high outside temperatures. We powered down this part of the zone to prevent an even longer outage or damage to machines. This caused a partial failure of capacity in that zone, leading to instance terminations, service degradation, and networking issues for a subset of customers.\n**Remediation and Prevention:**\nGoogle engineers were alerted to an issue affecting two cooling systems in one of the data centers that hosts europe-west2-a on Tuesday, 19 July 2022 at 06:33 US/Pacific and began an investigation. Engineers were engaged at 07:02 and began assessing viable mitigations. At 10:05, our engineers decided to power down servers in the impacted data center within europe-west2-a to prevent an even longer outage and further impact to infrastructure in the zone.\nThe cooling system was repaired at 14:13, and we restored our services by Wednesday, 20 July 2022, at 04:28 US/Pacific. A small subset of customers experienced residual effects which were fully mitigated by 21:20.\nGoogle is committed to preventing a future recurrence and improving recovery times by taking the following actions: * A small number of services experienced problems in zonal failover automation. We will repair and carefully re-test our failover automation to ensure stronger resilience in our failover protocols during large scale events such as this one. * We will investigate and develop more advanced methods to progressively decrease the thermal load within a single data center space, reducing the probability that a full shutdown is required. * Our initial recovery of impacted services once cooling was restored was 14 hours, 15 minutes. Additionally, the recovery of the long tail of impacted Google Compute Engine instances and related services was an additional 16 hours, 52 minutes. We are examining our procedures, tooling, and automated recovery systems for gaps to substantially improve our recovery times in the future. * Google engineers are actively conducting a detailed analysis of the cooling system failure that triggered this incident. * Google engineers will be conducting an audit of cooling system equipment and standards across the data centers that house Google Cloud globally.\n**Detailed Description of Impact:**\nOn Tuesday, 19 July 2022 from 06:33 to Wednesday, 20 July 2022 21:20 US/Pacific, some customers may have experienced high latency or errors in multiple Google Cloud services in the impacted location as detailed below:\n**Infrastructure Services**\n* **Google Compute Engine:** As data center temperatures started to increase, on Tuesday, 19 July 2022 at 08:06 US/Pacific Compute Engine terminated 42% of the Preemptible VMs (PVMs) across the europe-west2 region to reduce thermal load in zone europe-west2-a and ensure space for zonal failover activities in zones europe-west2-b and europe-west2-c. When we proceeded to power down the impacted data center to mitigate the cooling overload on Tuesday, 19 July 2022 at 10:07 US/Pacific, Compute Engine terminated all VMs in the impacted data center, representing approximately 35% of the VMs in the europe-west2-a zone. We were able to re-enable PVM launches in the running europe-west2-b and europe-west2-c zones at 13:50 US/Pacific. Power was restored on 19 July 2022 at 14:13 US/Pacific, at which point we began the recovery process for Compute Engine. To ensure a safe restoration, the team carefully sequenced the startup of the services powering Compute Engine. This process completed and the majority of VMs came back online starting at 20:18 US/Pacific. We enabled PVMs once the majority of the other VMs were running at 21:27 US/Pacific.The total impact duration was 12 hours, 12 minutes. A small number of VMs (approximately 0.6% of the europe-west2-a zone) encountered conflicts in our control plane state, requiring a manual reconciliation process. We completed this reconciliation for the “long tail” of all VMs on Thursday, 21 July 2022 at 02:32 US/Pacific. A small number of control plane requests to delete missing VMs during the incident required manual resolution, which was completed at 15:50 US/Pacific. ***Impact Mitigation time:*** Thursday, 21 July 2022 20:18 US/Pacific\n* **Persistent Disk (PD):** Approximately 38% of Persistent Disk volumes in zone europe-west2-a were unavailable from Tuesday, 19 July 2022 09:13 US/Pacific. Affected customers would observe unresponsive disks or I/O errors. In most cases, the GCE instances using these volumes were terminated shortly afterward, but about 1% of the unavailable Persistent Disk volumes in zone europe-west2-a were attached to instances that remained online throughout the incident. Approximately 96% of Persistent Disk volumes recovered automatically by 20:30 US/Pacific, but the remainder required additional work to recover, which completed on Wednesday, 20 July 2022 03:10 US/Pacific. Additionally, about 11% of Regional Persistent Disk volumes in the europe-west2 region experienced high disk latency at the beginning of the incident. Most of the Regional Persistent Disk volumes successfully detected the fault in zone europe-west2-a and switched to unreplicated mode, but about 8% of Regional Persistent Disk volumes in the europe-west2 region were unable to correctly detect the fault until the Persistent Disk team forced them into unreplicated mode, which completed around 11:50 US/Pacific. About 17% of Regional Persistent Disk customers in the europe-west2 region experienced errors performing control plane operations, including creating, deleting, attaching, detaching, and snapshotting Regional Persistent Disk volumes from 19 July 2022 07:18 US/Pacific to 13:40 US/Pacific as an unintended side effect of mitigation efforts. As a result of mitigation efforts, 38% of customers were unable to create new Persistent Disk volumes in zone europe-west2-a from Tuesday, 19 July 2022 11:16 US/Pacific to 20 July 2022 02:56 US/Pacific. Additionally, 48% of customers were unable to create new Persistent Disk volumes in zones europe-west2-b and europe-west2-c from Tuesday, 19 July 2022 10:23 US/Pacific to 11:36 US/Pacific. The Persistent Disk snapshot service was unavailable for 38% of customers in zone europe-west2-a from Tuesday, 19 July 2022 from 08:11 US/Pacific to 21:29 US/Pacific. During this time, affected customers could not create new Persistent Disk snapshots from disks located in zone europe-west2-a nor restore snapshots and disk images to disks in zone europe-west2-a. The total impact duration was 12 hours, 16 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 03:10 US/Pacific\n* **Google Cloud Storage:** On Tuesday, 19 July 2022 between 07:18 and 08:54 US/Pacific, ReadObject availability for buckets located in europe-west2 dropped to approximately 86%, and the entire region's availability to 96%. This impacted 24% of customer projects within this region. Customers would have received HTTP 500s when reading previously written data. All other operations, as well as read for new ingress, or data that was outside of the affected zones were not impacted. The total impact duration was 96 minutes. Google Cloud Storage (GCS) stores replicas in at least 2 independent colossus clusters. As a regional (not zonal) product, GCS leverages placement algorithms to ensure locations, network, and data center diversity when selecting colossus clusters [1]. There was a legacy placement algorithm isolated to just the europe-west2 region allowing for three colossus clusters in the region to be impacted by the same underlying issue relating to a single data center. In a small number of cases GCS had replicated regional data residing in two offline clusters, and subsequently some customers were unable to access and read some of their existing regional scoped data when the regional clusters were taken offline. Writes and other operations were not impacted. [1] - https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system ***Impact Mitigation time:*** Tuesday, 19 July 2022 08:54 US/Pacific.\n**Other Services**\n* **API Gateway:** ~47% of projects with traffic experienced an elevated number of spikes in 5xx responses in europe-west2 on Tuesday, 19 July 2022 from 07:20 to 14:00 US/Pacific. Affected customers observed 5xx responses from their API Gateways. The total impact duration was 6 hours, 40 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 14:00 US/Pacific.\n* **Cloud Bigtable:** ~70% of unreplicated Bigtable instances in europe-west2-a experienced 100% data plane unavailability from Tuesday, 19 July 2022 07:05 to Wednesday, 20 July 2022 02:20 US/Pacific. We observed failed control plane operations for 11% of instances that contained a replica in the europe-west2-a zone. Customers with replicated bigtables in europe-west2-a/b/c using Multi-Cluster routing may have seen increased latencies due to traffic failing over to other regions. The total impact duration was 19 hours, 15 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 02:20 US/Pacific\n* **Cloud Composer:** Cloud Composer environments (data-plane side) and operations (control-plane side) experienced degraded performance in europe-west2 on Tuesday, 19 July 2022 from 09:00 to 22:30 US/Pacific. Control plane operations experienced high failure rates (failure rate reached 100% at the peak). The number of Composer environments reporting a normal, operational state dropped by ~37%. Total capacity of all environments in the region (measured by the total number of tasks being executed in the whole region) was significantly reduced and the drop reached ~50% at the peak. The total impact duration was 13 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 22:30 US/Pacific\n* **Cloud Data Fusion:** ~20% of Data Fusion Instances in europe-west2 experienced service degradation, ranging from logs and metrics not being updated to complete loss of availability of their instance on Tuesday, 19 July 2022 10:15 to 21:30 US/Pacific. ~5% of instances were usable during the impact duration. The total impact duration was 11 hours, 15 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:30 US/Pacific\n* **Cloud Datastore:** Customers may have experienced timeouts and degraded service on approximately 1% of writes in the europe-west2 Datastore instance. The total impact duration was 9 hours, 25 minutes, on Tuesday, 19 July 2022 from approximately 12:30 to 19:30 US/Pacific. Approximately 40% of customers experienced significant latency increase on query operations from Tuesday, 19 July 2022 09:45 to 12:45 US/Pacific. ***Impact Mitigation time:*** Tuesday, 19 July 2022 19:30 US/Pacific\n* **Cloud Dataproc:** On Tuesday, 19 July 2022, from 08:00 US/Pacific to 22:00 US/Pacific, customers experienced increased error rates in creating and scaling up clusters in europe-west2. About 24% of CREATE operations and 13% of UPDATE operations were affected. Due to a backlog of queued requests requiring manual attention, error rates for old CREATE/DELETE requests remained elevated until Thursday, 21 July 2022 16:45 US/Pacific (this did not impact availability of already-running clusters). Some Dataproc clusters that were allocated in the impacted zone were unavailable during power down. Most of these came up by 19 July 2022 22:00 US/Pacific. By this time, CREATE operations in all zones began working. A few existing clusters were impacted by the long tail recovery in Google Compute Engine and were restored when that effort completed on Thursday, 21 July 2022 02:32 US/Pacific. Primary impact duration was approximately 14 hours. ***Impact Mitigation time:*** Tuesday, 19 July 2022 22:00 US/Pacific\n* **Cloud Firestore:** Firestore streaming (listen, write) requests via Webchannel were 100% unavailable in the europe-west2 instance on Tuesday, 19 July 2022 from 07:15 to 09:55 US/Pacific. The total impact duration was 2 hours, 40 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 09:55 US/Pacific\n* **Cloud Secret Manager** Cloud Secret Manager experienced an outage for secrets that were exclusively stored in europe-west2 from Tuesday, 19 July 2022 07:29 to 08:46 US/Pacific. Secret Manager is a global service that lets users define in which regions to store a given secret. The regional service instances for europe-west2 were deployed in the impacted data center. The total impact duration was 1 hour, 17 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 08:46 US/Pacific\n* **Cloud Spanner:** A more comprehensive investigation into our Cloud Spanner logs indicated no evidence of any customer impact. If you were impacted, please contact Google Cloud Support using https://cloud.google.com/support, and we will review your logs.\n* **Cloud SQL:** Customers experienced downtime on Tuesday, 19 July 2022 starting at 09:25 US/Pacific. 36% of zonal (non-HA) instances in europe-west2-a were affected. Additionally, 31% of regional (HA) instances whose primaries were located in europe-west2-a experienced extended downtime because they were unable to successfully fail over to another zone. Finally, customers experienced some failures during the incident for backup, instance creation, update, delete, restart, export, and Database Migration Service operations. The total impact duration was 17 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:00 US/Pacific\n* **Dataflow:** Approximately 8% of Dataflow streaming jobs running in europe-west2 were stuck from Tuesday, 19 July 2022 07:11 to 12:38 US/Pacific. There was limited impact to batch Dataflow jobs. Some new Dataflow jobs could not be initiated. The total impact duration was 5 hours, 27 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 12:38 US/Pacific\n* **Datastream:** Datastream streams experienced errors and processing lag in europe-west2-a as a result of impact on the data-plane infrastructure and services from Tuesday, 19 July 2002 09:05 to Wednesday, 20 July 2022 03:00 US/Pacific. Customers were advised to run their streams in another region. The total impact duration was 17 hours, 55 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 03:00 US/Pacific\n* **Google App Engine, Cloud Functions, and Cloud Run:** Customers may have experienced high error rates for Google App Engine, Cloud Functions and Cloud Run in europe-west2. Customers with a multi-region architecture could failover to another region. Traffic for ~72% of projects from Cloud Tasks, Cloud Scheduler, Eventarc, Cloud Pubsub to App Engine and Cloud Functions experienced up to 18% dropped requests/events on Tuesday, 19 July 2022 07:18 to 10:05 US/Pacific. Traffic from other sources (including end-users) to ~35% of App Engine, Cloud Functions, and Cloud Run projects experienced elevated latency in the same time period. Furthermore, ~5% of Cloud Run projects experienced elevated error rates (reaching peaks of 90% unavailability) caused by new instances failing to be created (some of which were due to a dependency on Google Cloud Secret Manager). The total impact duration was: * App Engine Flexible: 13 hours, 1 minute * App Engine Standard: 3 hours, 36 minutes * Cloud Functions: 3 hours, 36 minutes * Cloud Run: 3 hours, 36 minutes ***Impact Mitigation time:*** Tuesday, 19 July 2022 10:05 US/Pacific (App Engine Standard, Cloud Functions, Cloud Run) and Tuesday, 19 July 2022 20:30 US/Pacific (App Engine Flexible)\n* **Google BigQuery:** On Tuesday, 19 July 2022 between 04:40 US/Pacific and 13:43 US/Pacific, 12% of the projects in europe-west2 experienced errors and dataset unavailability. This was caused by mitigations and the power down of one of the data centers serving the europe-west2-a zone, which reduced the storage and compute capacity available to BigQuery. As a regional service, BigQuery was able to mitigate some of this capacity loss by shifting load to other data centers. However, BigQuery datasets which happened to be hosted solely in that data center were unavailable during the power down. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:43 US/Pacific\n* **Google Cloud Tasks:** Cloud Tasks automatically distributes projects across cloud zones within a region. 6% of projects in europe-west2 were loaded in the data center that was powered down on Tuesday, 19 July 2022 10:05 US/Pacific, and stopped delivering tasks until 13:24, after which delivery was resumed. No tasks were executed in any newly created queues in the region and in any existing queues in the impacted zone. However, as a regional service, Cloud Task was eventually able to mitigate all of the capacity loss by shifting load to other zones. The total impact duration was 3 hours, 19 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:24 US/Pacific\n* **Google Cloud Scheduler:** Cloud Scheduler automatically distributes projects across Cloud zones within a region. 6% of projects in europe-west2 were loaded in the datacenter that was powered down on Tuesday, 19 July 2022 10:05 US/Pacific and stopped executing jobs until 13:24, after which execution was resumed. As a regional service, Cloud Scheduler was eventually able to mitigate all of the capacity loss by shifting load to other zones. The total impact duration was 3 hours, 19 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:24 US/Pacific\n* **Cloud Filestore:** 45% of instances in europe-west2-a experienced service unavailability from Tuesday, 19 July 2022 10:05 US/Pacific to Wednesday, 20 July 2022 01:10 US/Pacific. This impact lasted until the mitigation time. At this point customers with working instances experienced no additional issues. 6.4% of impacted instances did not recover automatically and had to be recovered manually, which completed on Wednesday, 20 July 18:32 US/Pacific. The symptoms of these varied from unavailability to degraded availability. Customers were advised to fail over to another region, if possible. The total impact duration was 10 hours, 30 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 01:10 US/Pacific\n* **Google Kubernetes Engine:** 15% of zonal clusters in europe-west2-a and 57% of regional \u0026 zonal cluster nodes in europe-west2-a were fully unavailable from Tuesday, 19 July 2022 from 09:30 to 21:30 US/Pacific. Regional cluster control planes remained available, but overall cluster health may have been impacted by node unavailability. Customers were encouraged to move their workloads to other regions if possible. The approximate impact duration was 12 hours. However, a few clusters experienced lag through the next day due to underlying GCE impact. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:30 US/Pacific\n* **Looker:** Looker instances in europe-west2 were unavailable or experienced degraded performance starting Tuesday, July 19, 2022 09:33 through Wednesday, July 20, 2022 at 05:57 US/Pacific. Once temperatures inside the data center returned to safe levels, the Looker team restored file systems for impacted customers, and all Looker instances were back online on Wednesday, July 20, 2022 at 05:57 US/Pacific. The total impact duration was 20 hours, 24 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 05:57 US/Pacific\n* **Managed Service for Microsoft Active Directory:** 28.57% of the Managed Active Directory domains configured in the europe-west2 region were impacted during the incident. Starting July 19, 2022 09:20:00 US/Pacific, the impacted customers had one less domain controller (DC) serving incoming traffic. However, the domains continued to operate with reduced redundancy. Furthermore, periodic backups (12h frequency) were not performed for the impacted domains during the incident window. Subsequent backups were successful. The total impact duration was 12 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:50 US/Pacific\n* **Memorystore for Memcached:** 20.8% of instances in europe-west2 experienced degraded performance and availability issues resulting in a total cache flush. Impact start was Tuesday 19 July at 09:35 US/Pacific.All instances with VMs in europe-west2-a were unavailable or performed with degraded performance for the entire duration of the event. Instances that were only located in europe-west2-a were unavailable. Instances with some VMs in europe-west2-a lost their corresponding memcache availability (storage/access).All affected instances experienced a cache flush. DELETE, and RECREATE operations were unavailable for instances located in europe-west2-a. CREATE operations were not affected. UPDATE was not affected as there were no requests during that time but was theoretically unavailable. The total impact duration was 1 day, 5 hours, 27 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 15:02 US/Pacific\n* **Memorystore for Redis:** ~10% of instances in europe-west2 experienced timeouts with the management API (create, update, delete, etc) from Tuesday, 19 July 2022 09:24 to Wednesday, 20 July 2022 21:19 US/Pacific. Customers whose instances are located in the affected data center in the europe-west2-a zone were unable to access their instances. Additionally, all affected instances experienced a cache flush. In total, ~39% of basic-tier instances in europe-west2-a were affected. The total impact duration was 11 hours, 11 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 21:19 US/Pacific\n* **Vertex AI online prediction:** Vertex AI prediction showed an elevated error rate on Tuesday, 19 July 2022 from 10:00 to 15:11 US/Pacific for a total impact duration of 5 hours 11 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 15:11 US/Pacific\n* **Virtual Private Cloud (VPC):** Approximately 35% of the VMs in the europe-west2-a zone were unreachable from Tuesday, 19 July 2022 10:06 US/ Pacific to 20:32 US/ Pacific. This includes all Cloud traffic into and out of 1275 / 3509 VMs in europe-west2-a . Both the control plane and the data plane were impacted. The total impact duration was 10 hours, 26 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 20:32 US/Pacific\n-------------------------","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T19:12:00+00:00","modified":"2022-07-23T02:23:13+00:00","when":"2022-07-21T19:12:00+00:00","text":"This is a preliminary Incident Report (Mini-IR). A Full Incident Report with additional details is being prepared and will be posted at a later date.\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support .\n(All Times US/Pacific)\n**Incident Start:** 2022-07-19 06:33\n**Incident End:** 2022-07-20 21:20\n**Duration:** 1 day, 14 hours, 47 minutes\n**Regions/Zones:** europe-west2\n**Description:**\nOn Tuesday, 19 July 2022, a partial cooling failure in one of the buildings that hosts the zone europe-west2-a impacted multiple Google Cloud services. This resulted in some customers experiencing service unavailability for impacted products. The cooling system impairment began at 04:30 PDT, and was fully restored at 15:28 PDT. Google engineers were engaged at 06:40 PDT after a rise in temperature was noted by automated monitoring systems, and took a number of steps to reduce thermal load in the datacenter before ultimately turning down services and powering off servers in the affected zone at 09:04 PDT due to temperature excursions. Engineering teams worked in shifts around the clock to restore services once temperatures inside the datacenter returned to acceptable levels, and inital restoration began at 14:13 PDT. Many services in the affected zone were available again by 20:24 PDT on 19 July 2022, and service restoration was complete on 20 July 2022 at 04:28 PDT. A small number of customers experienced residual effects which were fully mitigated by 21:20 PDT on 20 July 2022. Preliminary root cause has been identified as two separate chiller unit failures, coupled with high ambient weather conditions, at one of the buildings that hosts the europe-west2-a zone.\nWe sincerely apologize to our customers who were impacted by this service disruption. Google and its suppliers are conducting a detailed analysis of the cooling system failure which triggered this incident, and Google engineers will subsequently conduct an audit of cooling system equipment and standards across the data centers which house Google cloud zones, to ensure that the lessons learned from this incident are applied consistently at all locations.\n**Customer Impact:**\n* **Google Cloud Storage:** Some customers with data replicated only in the impacted region experienced HTTP 500 errors. Customers with data replicated outside of the impacted region were not affected.\n* **Google BigQuery:** Some customers experienced dataset unavailability.\n* **Google App Engine and Cloud Functions:** Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2. Customers could failover to another region.\n* **Dataflow:** Some Dataflow streaming jobs running in the impacted area were stuck. Some new Dataflow jobs could not be initiated.\n* **Persistent Disk (PD):** Customers were unable to create PD devices in the impacted zone. Instances in the impacted zone were terminated, and therefore weren’t able to access their PD devices. A small number of Replicated PD volumes experienced delays in the failover to a healthy zone.\n* **API Gateway:** Customers saw an elevated number of clone exits and spikes in europe-west2.\n* **Cloud Spanner:** There was no impact for customers that were below our recommended CPU usage. Customers above the limit saw some latency impact. Some multi-region customers running in europe-west2 experienced increased latency.\n* **Google Cloud Tasks:** Customers experienced high latency for API requests. Some queues were not being loaded, impacting tasks. Customers may have also seen high delivery latency for their tasks, depending on which cell was serving their queues.\n* **Google Compute Engine:** Customers impacted by this issue would have experienced abnormal instance terminations for instances which were running in the impacted building. Affected customers who experienced an instance failure in europe-west2-a were advised to launch new instances in other zones of europe-west2.\n* **Vertex AI online prediction:** End-point Vertex AI prediction displayed time out errors for some customers.\n* **VPC (Traffic Virtnet):** VPCs in zone europe-west2-a were inaccessible. Customers also experienced 100% packet loss to zone europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* **Cloud Firestore:** Firestore streaming (listen, write) requests via Webchannel were affected.\n* **Cloud Datastore:** Customers may have experienced timeouts and degraded service.\n* **Looker:** Customers hosted in europe-west2 experienced significantly increased failed requests.\n* **Cloud Composer:** Cloud Composer running environments and operations experienced degraded performance in europe-west2. Resource creation experienced high failure rates.\n* **Cloud Data Fusion:** Data Fusion Instances in europe-west2 were unavailable, and pipelines configured to run in europe-west2 were failing. Customers in europe-west2 were not able to create new pipelines.\n* **Managed Service for Microsoft Active Directory:** Customers were unable to perform any operations on Managed Active Directory domains which were single region (europe-west2). Customers also experienced a degraded experience if one domain controller remained unavailable due to zonal impact.\n* **Cloud Dataproc:** Customers were not able to create or scale up clusters in europe-west2-a. Some customers in europe-west2-c experienced elevated error rates during cluster creation and scale up. Customers were able to choose a different zone to create clusters.\n* **Cloud Bigtable:** Some customers in europe-west2 experienced service unavailability and elevated latency. Customer workloads using replicated databases with impacted replicas in europe-west2, could be moved to the region close to the other replicas to reduce latency.\n* **Datastream:** Datastream streams experienced errors and processing lag as a result of impact on the data-plane infrastructure and services. Customers were advised to run their streams in another region.\n* **Google Kubernetes Engine:** A proportion of clusters in europe-west2-a were fully unavailable, and nodepools for some regional clusters in europe-west2 were disrupted. Customers were encouraged to move their workloads to other regions if possible.\n* **Cloud Filestore:** A small number of customers in europe-west2-a may have experienced service unavailability. Customers with working instances experienced no issues. Customers were advised to fail over to another region, if possible.\n* **MemoryStore for Memcached:** Some existing instances in europe-west2-a were unavailable. Additionally, customers may have experienced degraded performance in europe-west2. Instance creation was not affected.\n* **MemoryStore for Redis:** Customers experienced timeouts with the management API (create, update, delete ,etc) and cache flushes.\n* **Cloud SQL:** Customers experienced operation failures for backups, creates, Database Migration Service operations, updates, deletes, restarts and exports. Cloud SQL experienced instance unavailability for several zonal instances in europe-west2. A number of HA instances also experienced failover issues in europe-west2.","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T05:48:24+00:00","modified":"2022-07-21T05:48:25+00:00","when":"2022-07-21T05:48:24+00:00","text":"The issue with Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2 has been resolved for all affected users as of Wednesday, 2022-07-20 21:20 US/Pacific.\nServices Mitigated:\nGoogle Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Firestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached, MemoryStore for Redis, Cloud SQL.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T04:25:29+00:00","modified":"2022-07-21T04:25:30+00:00","when":"2022-07-21T04:25:29+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams have determined that further investigation is required to mitigate the issue. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 23:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T04:23:53+00:00","modified":"2022-07-21T04:23:54+00:00","when":"2022-07-21T04:23:53+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams have determined that further investigation is required to mitigate the issue. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 21:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T02:26:06+00:00","modified":"2022-07-21T02:26:08+00:00","when":"2022-07-21T02:26:06+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams have determined that further investigation is required to mitigate the issue. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 21:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T01:26:56+00:00","modified":"2022-07-21T01:27:02+00:00","when":"2022-07-21T01:26:56+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams have determined that further investigation is required to mitigate the issue. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 19:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-21T00:30:37+00:00","modified":"2022-07-21T00:30:38+00:00","when":"2022-07-21T00:30:37+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams have determined that further investigation is required to mitigate the issue. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 18:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T23:26:35+00:00","modified":"2022-07-20T23:26:42+00:00","when":"2022-07-20T23:26:35+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams continue to work on service restoration. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 17:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T22:24:14+00:00","modified":"2022-07-20T22:24:16+00:00","when":"2022-07-20T22:24:14+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore, MemoryStore for Memcached\n**Services Mitigation in progress:** MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n* Impact Mitigation: 07/20/22 15:00 US/Pacific\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 16:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T20:30:07+00:00","modified":"2022-07-20T20:30:08+00:00","when":"2022-07-20T20:30:07+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore,\n**Services Mitigation in progress:** MemoryStore for Memcached, MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 15:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T19:17:52+00:00","modified":"2022-07-20T19:17:54+00:00","when":"2022-07-20T19:17:52+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore,\n**Services Mitigation in progress:** MemoryStore for Memcached, MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 13:45 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T18:20:58+00:00","modified":"2022-07-20T18:20:59+00:00","when":"2022-07-20T18:20:58+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore,\n**Services Mitigation in progress:** MemoryStore for Memcached, MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 12:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T17:24:17+00:00","modified":"2022-07-20T17:24:21+00:00","when":"2022-07-20T17:24:17+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Services Mitigated:** Google Cloud Storage, Google BigQuery, Google App Engine and Cloud Functions, Dataflow, Persistent Disk (PD), API Gateway, Cloud Spanner, Google Cloud Tasks, Google Compute Engine, Vertex AI online prediction, VPC (Traffic Virtnet), Cloud Filestore, Cloud Datastore, Looker, Cloud Composer, Cloud Data Fusion, Managed Service for Microsoft Active Directory, Cloud Dataproc, Bigtable, Datastream, GKE, Cloud Filestore,\n**Services Mitigation in progress:** MemoryStore for Memcached, MemoryStore for Redis, Cloud SQL.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 11:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T16:31:30+00:00","modified":"2022-07-20T16:31:40+00:00","when":"2022-07-20T16:31:30+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation: 07/20/22 09:18 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 10:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T15:10:33+00:00","modified":"2022-07-20T15:10:46+00:00","when":"2022-07-20T15:10:33+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a could be unavailable.\n* Workaround: Customers were encouraged to move their workloads to other regions if possible.\n* Impact Mitigation time: 07/20/22 07:57 US/Pacific\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers were advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 09:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T14:11:17+00:00","modified":"2022-07-20T14:11:42+00:00","when":"2022-07-20T14:11:17+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 08:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T13:12:44+00:00","modified":"2022-07-20T13:12:51+00:00","when":"2022-07-20T13:12:44+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\n* Impact Mitigation time: 07/20/22 06:02 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n* Impact Mitigation time: 07/20/22 04:51 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up could experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n* Impact Mitigation time: 07/20/22 04:54 US/Pacific\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers were unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers could also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region could see elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers could experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area might have been stuck. New Dataflow jobs could not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Customers were unable to create any PD device in europe-west2. PD devices in europe-west2-a were unavailable\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:51 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers could experience elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers could not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 experienced significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers experienced high latency for all API requests. Some queues were not being loaded and they have stopped executing tasks. Customers could also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user could experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a were inaccessible. Customers could also experience a 100% packet loss to europe-west2-a. Customers were unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 07:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T12:16:39+00:00","modified":"2022-07-20T12:16:46+00:00","when":"2022-07-20T12:16:39+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region may have seen elevated errors when attempting to read objects.\n* Impact Mitigation time: 07/19/22 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 07/19/22 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 07/19/22 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may have been stuck. New Dataflow jobs may not start.\n* Impact Mitigation time: 07/19/22 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 07/19/22 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: All PDs should be healthy and back online\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c. From 07/20/22 04:18 US/Pacific all PDs should be healthy and back online.\n**API Gateway:**\n* Impact/Diagnosis: Customers may have experienced elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 07/19/22 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 07/19/22 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/20/22 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 07/19/22 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 07/19/22 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 07/19/22 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 07/19/22 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 06:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T11:13:45+00:00","modified":"2022-07-20T11:13:58+00:00","when":"2022-07-20T11:13:45+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency.\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\n**Cloud SQL:**\n* Impact/Diagnosis: 4 zonal instances are still impacted. Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 22:15 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n* Impact Mitigation time: 07/19/22 21:30 US/Pacific\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region may have seen elevated errors when attempting to read objects.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may have been stuck. New Dataflow jobs may not start.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 22:30 US/Pacific\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact Mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may have experienced elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n* Impact Mitigation time: 02:55 AM US/Pacific\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 19:30 US/Pacific\nWe will provide more information by Wednesday, 2022-07-20 05:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T10:00:26+00:00","modified":"2022-07-20T10:00:39+00:00","when":"2022-07-20T10:00:26+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region may have seen elevated errors when attempting to read objects.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may have been stuck. New Dataflow jobs may not start.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 22:30 US/Pacific\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Impact Mitigation time: 22:30 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may have experienced elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency..\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\nWe will provide more information by Wednesday, 2022-07-20 04:15 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T08:24:36+00:00","modified":"2022-07-20T08:24:39+00:00","when":"2022-07-20T08:24:36+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region may have seen elevated errors when attempting to read objects.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may have been stuck. New Dataflow jobs may not start.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations experienced downgraded performance in europe-west2.\n* Impact Mitigation time: 22:30 US/Pacific\n**Cloud Filestore:**\n* Impact/Diagnosis: A small number of customers in europe-west2-a may be experiencing service unavailability. No new issues are expected for customers with working instances.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Impact Mitigation time: 22:30 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may have experienced elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency..\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\nWe will provide more information by Wednesday, 2022-07-20 03:00 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T07:55:23+00:00","modified":"2022-07-20T07:55:26+00:00","when":"2022-07-20T07:55:23+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region may have seen elevated errors when attempting to read objects.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets were unavailable for the impacted locations.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may have experienced high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may have been stuck. New Dataflow jobs may not start.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Impact Mitigation time: 22:30 US/Pacific\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may have experienced elevated 5xx errors in europe-west2.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: Workloads using replicated databases with replicas in europe-west2, may be moved to the region close to the other replicas to reduce latency..\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming experienced Listen and Write outage starting around 07:15 US/Pacific.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service was degraded. Customers may have experienced timeouts.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\n**Datastream:**\n* Impact/Diagnosis: Datastream Streams in that region might experience errors and lags which eventually could lead to lost position\n* Workaround: Customers are advised to run their Streams in another region.\nWe will provide more information by Wednesday, 2022-07-20 01:00 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T06:28:55+00:00","modified":"2022-07-20T06:28:58+00:00","when":"2022-07-20T06:28:55+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects.\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2.\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific.\n* Workaround: None at this time.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service is degraded. Customers may experience timeouts.\n* Workaround: None at this time.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\nWe will provide more information by Wednesday, 2022-07-20 01:00 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T05:16:48+00:00","modified":"2022-07-20T05:16:52+00:00","when":"2022-07-20T05:16:48+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects.\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Most non-HA instances backed by europe-west2-a are working again in europe-west2-a. And most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigation time: From 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2.\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific.\n* Workaround: None at this time.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service is degraded. Customers may experience timeouts.\n* Workaround: None at this time.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\nWe will provide more information by Tuesday, 2022-07-19 23:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T04:11:49+00:00","modified":"2022-07-20T04:11:52+00:00","when":"2022-07-20T04:11:49+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription:\nA cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is impacting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects.\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region, if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**Dataflow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers.\n* Workaround: Customers are advised to fail over to another region, if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: 50% of non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. Most HA instances in europe-west2 are operational again as of 19:00 US/Pacific.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management API (create, update, delete, etc.), and cache flushes.\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk (PD):**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability. Most volumes in europe-west2-a are now available. There are a small number of HDD backed PD volumes that continue to experience impact that will result in IO errors.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2.\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region or 45% for Multi Region to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max. Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can choose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable.\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH.\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Impact Mitigation time: 20:22 US/Pacific\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n* Impact Mitigation time: 15:11 US/Pacific\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific.\n* Workaround: None at this time.\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Datastore:**\n* Impact/Diagnosis: Service is degraded. Customers may experience timeouts.\n* Workaround: None at this time.\n* Impact Mitigation time: 19:30 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b, europe-west2-c or other regions.\nWe will provide more information by Tuesday, 2022-07-19 22:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T02:45:53+00:00","modified":"2022-07-20T02:45:56+00:00","when":"2022-07-20T02:45:53+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is affecting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: 50% of non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. All but 13 HA instances in europe-west2 are operational again as of 19:00 PT.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n* Impact Mitigation time: 17:00 US/Pacific\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nWe will provide more information by Tuesday, 2022-07-19 21:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-20T02:06:09+00:00","modified":"2022-07-20T02:06:13+00:00","when":"2022-07-20T02:06:09+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is affecting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nWe will provide more information by Tuesday, 2022-07-19 20:30 US/Pacific.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T23:07:10+00:00","modified":"2022-07-19T23:07:14+00:00","when":"2022-07-19T23:07:10+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is affecting multiple Cloud services.\nCooling system restoration in europe-west2-a has been completed.\nGCP product teams are working on restoring their services. ETA to be determined.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:43 US/Pacific\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n* Impact Mitigation time: 12:38 US/Pacific\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n* Impact Mitigation time: 10:07 US/Pacific\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they have stopped executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n* Impact Mitigation time: 13:24 US/Pacific\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n* Impact Mitigation time: 12:49 US/Pacific\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T21:39:11+00:00","modified":"2022-07-19T21:39:14+00:00","when":"2022-07-19T21:39:11+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: A cooling related failure in one of our buildings that hosts zone europe-west2-a for region europe-west2 is affecting multiple Cloud services.\nOur engineering team is currently working to restore the cooling system in europe-west2-a.\nCooling system restoration in europe-west2-a is expected to be complete by Tuesday, 2022-07-19 16:30 US/Pacific.\nOnce the cooling system is restored, GCP product teams will work on restoring their services. ETA to be determined.\nWe will provide more information by Tuesday, 2022-07-19 16:30 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T21:18:21+00:00","modified":"2022-07-19T21:18:24+00:00","when":"2022-07-19T21:18:21+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 15:00 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**MemoryStore for Memcached**\n* Impact/Diagnosis: Existing instances in europe-west2-a may be unavailable. Additionally, customers may experience degraded performance in europe-west2. Instance creation is not affected.\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T21:08:30+00:00","modified":"2022-07-19T21:08:33+00:00","when":"2022-07-19T21:08:30+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 15:00 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Most Cloud Spanner customers will not see any impact, but customers should stay below our recommended CPU usage 65% for Single Region, 45% for Multi Region . to not experience any increased latency. https://cloud.google.com/spanner/docs/cpu-utilization#recommended-max . Multi Region clients running in europe-west2 will see added latency.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T20:40:01+00:00","modified":"2022-07-19T20:43:31+00:00","when":"2022-07-19T20:40:01+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 14:10 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: After further investigation by our Cloud Spanner Engineering, we confirmed that there is no known impact to external customers.\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T20:28:04+00:00","modified":"2022-07-19T20:28:07+00:00","when":"2022-07-19T20:28:04+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 14:00 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers. Failing ops include: backups, creates, DMS migrations, deletes, restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T20:11:46+00:00","modified":"2022-07-19T20:11:49+00:00","when":"2022-07-19T20:11:46+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 14:00 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. HA instances that were in europe-west2-a when the incident started, are down with stuck failovers. Failing ops include: backups, creates, DMS migrations, deletes, restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T19:43:40+00:00","modified":"2022-07-19T19:43:43+00:00","when":"2022-07-19T19:43:40+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-07-19 13:30 US/Pacific.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. Some HA instances are down in europe-west2-b/c (those with standby in europe-west2-a backed by europe-west2-a). Following operations are failing: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Service unavailability in europe-west2 for a very few customers.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a.\n* Workaround: Customers can choose a europe-west2-b , europe-west2-c or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T19:32:34+00:00","modified":"2022-07-19T19:32:37+00:00","when":"2022-07-19T19:32:34+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 13:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. Some HA instances are down in europe-west2-b/c (those with standby in europe-west2-a backed by europe-west2-a). Following operations are failing: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Customers in europe-west2 may see service disruption when they shut down europe-west2-a and may also see pipeline failures.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability and elevated latency for some customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-a and europe-west2-c.\n* Workaround: Customers can choose a europe-west2-b or other regions.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T19:21:39+00:00","modified":"2022-07-19T19:21:42+00:00","when":"2022-07-19T19:21:39+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact Mitigation time: 08:53 US/Pacific\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n* Impact Mitigation time: 11:05 US/Pacific\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances backed by europe-west2-a are hard-down in europe-west2-a. Some HA instances are down in europe-west2-b/c (those with standby in europe-west2-a backed by europe-west2-a). Following operations are failing: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Existing PD devices in europe-west2-a may be unavailable. Replicated PD devices in europe-west2 may see some replica unavailability.\n* Workaround: Create PD devices in a different region/zone.\n* Impact mitigated: Starting at 11:18 US/Pacific, customers should be able to create new PD devices in europe-west2-b and europe-west2-c.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop eeurope-west2-bcuting tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2europe-west2-bDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Customers in europe-west2 may see service disruption when they shut down europe-west2-a and may also see pipeline failures.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a. Customers are unable to make any control plane changes in europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability for very few customers in europe-west2.\n* Workaround: None at this time.\n**Cloud Firestore:** * Impact/Diagnosis: Webchannel use of Firestore streaming Listen and Write outage starting around 07:15 US/Pacific\n* Workaround: none\n* Impact Mitigation time: 09:55 US/Pacific\n**Cloud Dataproc:**\n* Impact/Diagnosis: Dataproc cluster creation and scale up may experience elevated error rate in europe-west2-c.\n* Workaround: Customers can choose a different zone.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T18:48:24+00:00","modified":"2022-07-19T18:48:28+00:00","when":"2022-07-19T18:48:24+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 12:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact mitigated at 08:53 US/Pacific for Google Cloud Storage\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances are hard-down in europe-west2-a. HA instances are down in europe-west2-a (pending zonal failover). Following ops are failing in all three zones, but mostly in europe-west2-a: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**MemoryStore for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Customers won't be able to create any PD device in europe-west2. PD devices in europe-west2-a may be unavailable.\n* Workaround: Create PD devices in a different region/zone.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Customers in europe-west2 may see service disruption when they shut down europe-west2-a and may also see pipeline failures.\n* Workaround: None at this time.\n**Managed Service for Microsoft Active Directory:**\n* Impact/Diagnosis: Customers will be unable to perform any operations on Managed Active Directory (AD) domains which are single region (europe-west2). Customers will also experience a degraded experience if one domain controller is unavailable due to zonal impact.\n* Workaround: None at this time.\n**Vertex AI online prediction**\n* Impact/Diagnosis: End user will experience timeouts\n* Workaround: None at this time.\n**VPC (Traffic Virtnet)**\n* Impact/Diagnosis: VPCs in europe-west2-a currently inaccessible. Customers will also experience 100% packet loss to europe-west2-a.\n* Workaround: None at this time.\n**Bigtable:**\n* Impact/Diagnosis: Service unavailability for very few customers in europe-west2.\n* Workaround: None at this time.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T18:05:23+00:00","modified":"2022-07-19T18:05:25+00:00","when":"2022-07-19T18:05:23+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 11:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact mitigated at 08:53 US/Pacific for Google Cloud Storage\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Customers are advised to fail over to another region if possible.\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Customers are advised to fail over to another region if possible.\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances are hard-down in europe-west2-a. HA instances are down in europe-west2-a (pending zonal failover). Following ops are failing in all three zones, but mostly in europe-west2-a: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**Memory Store for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Customers won't be able to create any PD device in europe-west2. PD devices in europe-west2-a may be unavailable.\n* Workaround: Create PD devices in a different region/zone.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\n**Google Compute Engine:**\n* Impact/Diagnosis: The impact details for GCE are externalized at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n* Workaround: Please refer to GCE posting at https://status.cloud.google.com/incidents/XVq5om2XEDSqLtJZUvcH\n**Cloud Data Fusion:**\n* Impact/Diagnosis : Customers in europe-west2 will not be able to create new pipelines\n* Workaround: None at this time.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T17:35:23+00:00","modified":"2022-07-19T17:35:26+00:00","when":"2022-07-19T17:35:23+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 11:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nProduct Impact:\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact mitigated at 08:53 Us/pacific for Google Cloud Storage\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n*Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Fail over to another region if your service supports it.\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Fail over to another region if your service supports it\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances are hard-down in europe-west2-a. HA instances are down in europe-west2-a (pending zonal failover). Following ops are failing in all three zones, but mostly in europe-west2-a: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**Memory Store for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Customers won't be able to create any PD device in europe-west2. PD devices in europe-west2-a are unavailable.\n* Workaround: Create PD devices in a different region/zone.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\n**GKE:**\n* Impact/Diagnosis: Certain portions of clusters with presence in europe-west2-a may be unavailable\n* Workaround: Customers are encouraged to move their workloads to other regions if possible.\n**Looker:**\n* Impact/Diagnosis: Customers hosted in europe-west2 will experience significantly increased failed requests.\n* Workaround: None at this time.\n**Google Cloud Tasks:**\n* Impact/Diagnosis: Customers will experience high latency for all API requests. Some queues are not being loaded and they stop executing tasks. Customers may also see high delivery latency for their tasks, depending on which cell is serving their queues.\n* Workaround: None at this time.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T17:07:06+00:00","modified":"2022-07-19T17:07:09+00:00","when":"2022-07-19T17:07:06+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates, latencies or service unavailability in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 10:40 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n* Impact mitigated at 08:53 Us/pacific for Google Cloud Storage\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted locations.\n* Workaround: None at this time.\n*Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Fail over to another region if your service supports it.\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:**\n* Impact/Diagnosis: All operations will experience downgraded performance in europe-west2.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Fail over to another region if your service supports it\n**Cloud SQL:**\n* Impact/Diagnosis: Non-HA instances are hard-down in europe-west2-a. HA instances are down in europe-west2-a (pending zonal failover). Following ops are failing in all three zones, but mostly in europe-west2-a: Backups, creates, DMS migrations, updates, deletes, recreates (internal), restarts, exports.\n* Workaround: None at this time.\n**Memory Store for Redis:**\n* Impact/Diagnosis: Customers will experience timeouts for management api (create,update,delete,etc), and cache flushes\n* Workaround: None at this time.\n**Persistent Disk:**\n* Impact/Diagnosis: Customers won't be able to create any PD device in europe-west2. PD devices in europe-west2-a are unavailable.\n* Workaround: Create PD devices in a different region/zone.\n**API Gateway:**\n* Impact/Diagnosis: Customers may see elevated 5xx errors in europe-west2\n* Workaround: None at this time.\n**Cloud Spanner**\n* Impact/Diagnosis: Customers that stay below our recommended CPU usage 65% SR, 45% MR should not see impact. Customers that are above the limit might see latency impact.\n* Workaround: For eur5 customers can chose to route to europe-west1, no workarounds needed for europe-west2\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T16:38:01+00:00","modified":"2022-07-19T16:38:03+00:00","when":"2022-07-19T16:38:01+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates in europe-west2\nDescription: We are experiencing an issue with multiple cloud products beginning on Tuesday, 2022-07-19 06:33 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 10:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\n**Product Impact:**\n**Google Cloud Storage:**\n* Impact/Diagnosis: Customers with data in the impacted region will see elevated errors when attempting to read objects\n* Workaround: None at this time.\n**Google BigQuery:**\n* Impact/Diagnosis: Datasets will be unavailable for the impacted cells.\n* Workaround: None at this time.\n**Cloud Filestore:**\n* Impact/Diagnosis: europe-west2-a is unavailable for all customers\n* Workaround: Fail over to another region if your service supports it\n**Google App Engine and Cloud Functions:**\n* Impact/Diagnosis: Customers may experience high error rates for Google App Engine and Cloud Functions in europe-west2 for requests coming through Cloud Pubsub, Eventarc, Cloud Tasks, and Cloud Scheduler. Pubsub, Eventarc, and Cloud Tasks traffic will be automatically retried once the outage is resolved. Cloud Scheduler requests will need to be resubmitted.\n* Workaround: Fail over to another region if your service supports it.\n**DataFlow:**\n* Impact/Diagnosis: Dataflow Streaming jobs already running in the impacted area may be stuck. New Dataflow jobs may not start.\n* Workaround: Customers are advised to run their jobs in another region.\n**Cloud Composer:** * Impact/Diagnosis: All operations will experience downgraded performance in europe-west2. * Workaround: None at this time.\nDiagnosis: Product specific symptoms are in the issue description.\nWorkaround: Product specific workaround are in the issue description.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"created":"2022-07-19T16:15:46+00:00","modified":"2022-07-19T16:15:48+00:00","when":"2022-07-19T16:15:46+00:00","text":"Summary: Multiple Cloud products experiencing elevated error rates in europe-west2\nDescription: We are experiencing an issue with Google Cloud Storage, Google BigQuery, Google App Engine, Google Cloud Functions, Google Cloud Dataflow beginning at Tuesday, 2022-07-19 06:33 US/Pacific .\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-19 09:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]}],"most_recent_update":{"created":"2022-07-29T21:00:05+00:00","modified":"2022-07-29T21:13:17+00:00","when":"2022-07-29T21:00:05+00:00","text":"## Incident Report\n**Summary:**\nOn Tuesday, 19 July 2022 at 06:33 US/Pacific, a simultaneous failure of multiple, redundant cooling systems in one of the data centers that hosts the zone europe-west2-a impacted multiple Google Cloud services. This resulted in some customers experiencing service unavailability for impacted products.\nTo our customers whose businesses were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps (detailed in the **Remediation \u0026 Prevention** section below) to improve the region's resilience.\n***Regional Impact***\nA number of regional Google Cloud services experienced impact during this incident, despite regional services being designed to survive the failure of a single zone. Upon investigation we have found two key contributing factors which led to these regional impacts: * At the start of the incident, we inadvertently modified traffic routing for internal services to avoid all three zones in the europe-west2 region, rather than just the impacted europe-west2-a zone. We corrected this on 19 July 2022 at 12:35 US/Pacific. * Our regional storage services, including GCS and BigQuery, replicate customer data across multiple zones. Due to the regional traffic routing change, they were unable to access any replica for a number of storage objects. This prevented customers from reading these objects until the traffic routing was corrected, at which point access was immediately restored.\n***Cooling System Impact Duration***\nGoogle engineers powered down the data center that hosted a portion of the impacted zone europe-west2-a on Tuesday, 19 July 2022 at 10:05 US/Pacific while the cooling system was repaired. The cooling system was repaired at 14:13 US/Pacific. The total duration of the cooling system failure impact was 4 hours, 8 minutes.\n***Cloud Service Restoration Duration***\nGoogle engineers began service restoration once the cooling system was repaired on Tuesday, 19 July 2022 at 14:13 US/Pacific. Cloud services were restored to operation by Wednesday, 20 July 2022 at 04:28 US/Pacific.\nThe duration of impact on Cloud services spans the window from 10:05 US/Pacific on Tuesday, 19 July 2022 (when a portion of europe-west2-a was powered down), to 04:28 US/Pacific on Wednesday, 20 July 2022, when Cloud services were restored; a total of 18 hours, 23 minutes.\n***Long Tail Duration***\nAfter the initial restoration of service to the zone, a small number of Google Compute Engine instances required additional work by our engineers to restore them to normal operations. This manifested as unavailable instances in GCE, and unavailable instances in products and services that rely on Google Compute Engine, such as Cloud SQL. This was fully mitigated on Wednesday, 20 July 2022 at 21:20 US/Pacific and the incident was closed with all services restored.\nFor the instances in this long tail, impact duration spans the window from the initial power down (at 10:05 US/Pacific on Tuesday, 19 July 2022) to the eventual full mitigation (at 21:20 US/Pacific on Wednesday, 20 July 2022); a total of 35 hours, 15 minutes.\nGoogle is conducting a detailed analysis of the systems and processes involved in both the cooling failure and the service recovery, with specific followup AIs identified below.\n**Root Cause:**\nOne of the data centers that hosts zone europe-west2-a could not maintain a safe operating temperature due to a simultaneous failure of multiple, redundant cooling systems combined with the extraordinarily high outside temperatures. We powered down this part of the zone to prevent an even longer outage or damage to machines. This caused a partial failure of capacity in that zone, leading to instance terminations, service degradation, and networking issues for a subset of customers.\n**Remediation and Prevention:**\nGoogle engineers were alerted to an issue affecting two cooling systems in one of the data centers that hosts europe-west2-a on Tuesday, 19 July 2022 at 06:33 US/Pacific and began an investigation. Engineers were engaged at 07:02 and began assessing viable mitigations. At 10:05, our engineers decided to power down servers in the impacted data center within europe-west2-a to prevent an even longer outage and further impact to infrastructure in the zone.\nThe cooling system was repaired at 14:13, and we restored our services by Wednesday, 20 July 2022, at 04:28 US/Pacific. A small subset of customers experienced residual effects which were fully mitigated by 21:20.\nGoogle is committed to preventing a future recurrence and improving recovery times by taking the following actions: * A small number of services experienced problems in zonal failover automation. We will repair and carefully re-test our failover automation to ensure stronger resilience in our failover protocols during large scale events such as this one. * We will investigate and develop more advanced methods to progressively decrease the thermal load within a single data center space, reducing the probability that a full shutdown is required. * Our initial recovery of impacted services once cooling was restored was 14 hours, 15 minutes. Additionally, the recovery of the long tail of impacted Google Compute Engine instances and related services was an additional 16 hours, 52 minutes. We are examining our procedures, tooling, and automated recovery systems for gaps to substantially improve our recovery times in the future. * Google engineers are actively conducting a detailed analysis of the cooling system failure that triggered this incident. * Google engineers will be conducting an audit of cooling system equipment and standards across the data centers that house Google Cloud globally.\n**Detailed Description of Impact:**\nOn Tuesday, 19 July 2022 from 06:33 to Wednesday, 20 July 2022 21:20 US/Pacific, some customers may have experienced high latency or errors in multiple Google Cloud services in the impacted location as detailed below:\n**Infrastructure Services**\n* **Google Compute Engine:** As data center temperatures started to increase, on Tuesday, 19 July 2022 at 08:06 US/Pacific Compute Engine terminated 42% of the Preemptible VMs (PVMs) across the europe-west2 region to reduce thermal load in zone europe-west2-a and ensure space for zonal failover activities in zones europe-west2-b and europe-west2-c. When we proceeded to power down the impacted data center to mitigate the cooling overload on Tuesday, 19 July 2022 at 10:07 US/Pacific, Compute Engine terminated all VMs in the impacted data center, representing approximately 35% of the VMs in the europe-west2-a zone. We were able to re-enable PVM launches in the running europe-west2-b and europe-west2-c zones at 13:50 US/Pacific. Power was restored on 19 July 2022 at 14:13 US/Pacific, at which point we began the recovery process for Compute Engine. To ensure a safe restoration, the team carefully sequenced the startup of the services powering Compute Engine. This process completed and the majority of VMs came back online starting at 20:18 US/Pacific. We enabled PVMs once the majority of the other VMs were running at 21:27 US/Pacific.The total impact duration was 12 hours, 12 minutes. A small number of VMs (approximately 0.6% of the europe-west2-a zone) encountered conflicts in our control plane state, requiring a manual reconciliation process. We completed this reconciliation for the “long tail” of all VMs on Thursday, 21 July 2022 at 02:32 US/Pacific. A small number of control plane requests to delete missing VMs during the incident required manual resolution, which was completed at 15:50 US/Pacific. ***Impact Mitigation time:*** Thursday, 21 July 2022 20:18 US/Pacific\n* **Persistent Disk (PD):** Approximately 38% of Persistent Disk volumes in zone europe-west2-a were unavailable from Tuesday, 19 July 2022 09:13 US/Pacific. Affected customers would observe unresponsive disks or I/O errors. In most cases, the GCE instances using these volumes were terminated shortly afterward, but about 1% of the unavailable Persistent Disk volumes in zone europe-west2-a were attached to instances that remained online throughout the incident. Approximately 96% of Persistent Disk volumes recovered automatically by 20:30 US/Pacific, but the remainder required additional work to recover, which completed on Wednesday, 20 July 2022 03:10 US/Pacific. Additionally, about 11% of Regional Persistent Disk volumes in the europe-west2 region experienced high disk latency at the beginning of the incident. Most of the Regional Persistent Disk volumes successfully detected the fault in zone europe-west2-a and switched to unreplicated mode, but about 8% of Regional Persistent Disk volumes in the europe-west2 region were unable to correctly detect the fault until the Persistent Disk team forced them into unreplicated mode, which completed around 11:50 US/Pacific. About 17% of Regional Persistent Disk customers in the europe-west2 region experienced errors performing control plane operations, including creating, deleting, attaching, detaching, and snapshotting Regional Persistent Disk volumes from 19 July 2022 07:18 US/Pacific to 13:40 US/Pacific as an unintended side effect of mitigation efforts. As a result of mitigation efforts, 38% of customers were unable to create new Persistent Disk volumes in zone europe-west2-a from Tuesday, 19 July 2022 11:16 US/Pacific to 20 July 2022 02:56 US/Pacific. Additionally, 48% of customers were unable to create new Persistent Disk volumes in zones europe-west2-b and europe-west2-c from Tuesday, 19 July 2022 10:23 US/Pacific to 11:36 US/Pacific. The Persistent Disk snapshot service was unavailable for 38% of customers in zone europe-west2-a from Tuesday, 19 July 2022 from 08:11 US/Pacific to 21:29 US/Pacific. During this time, affected customers could not create new Persistent Disk snapshots from disks located in zone europe-west2-a nor restore snapshots and disk images to disks in zone europe-west2-a. The total impact duration was 12 hours, 16 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 03:10 US/Pacific\n* **Google Cloud Storage:** On Tuesday, 19 July 2022 between 07:18 and 08:54 US/Pacific, ReadObject availability for buckets located in europe-west2 dropped to approximately 86%, and the entire region's availability to 96%. This impacted 24% of customer projects within this region. Customers would have received HTTP 500s when reading previously written data. All other operations, as well as read for new ingress, or data that was outside of the affected zones were not impacted. The total impact duration was 96 minutes. Google Cloud Storage (GCS) stores replicas in at least 2 independent colossus clusters. As a regional (not zonal) product, GCS leverages placement algorithms to ensure locations, network, and data center diversity when selecting colossus clusters [1]. There was a legacy placement algorithm isolated to just the europe-west2 region allowing for three colossus clusters in the region to be impacted by the same underlying issue relating to a single data center. In a small number of cases GCS had replicated regional data residing in two offline clusters, and subsequently some customers were unable to access and read some of their existing regional scoped data when the regional clusters were taken offline. Writes and other operations were not impacted. [1] - https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system ***Impact Mitigation time:*** Tuesday, 19 July 2022 08:54 US/Pacific.\n**Other Services**\n* **API Gateway:** ~47% of projects with traffic experienced an elevated number of spikes in 5xx responses in europe-west2 on Tuesday, 19 July 2022 from 07:20 to 14:00 US/Pacific. Affected customers observed 5xx responses from their API Gateways. The total impact duration was 6 hours, 40 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 14:00 US/Pacific.\n* **Cloud Bigtable:** ~70% of unreplicated Bigtable instances in europe-west2-a experienced 100% data plane unavailability from Tuesday, 19 July 2022 07:05 to Wednesday, 20 July 2022 02:20 US/Pacific. We observed failed control plane operations for 11% of instances that contained a replica in the europe-west2-a zone. Customers with replicated bigtables in europe-west2-a/b/c using Multi-Cluster routing may have seen increased latencies due to traffic failing over to other regions. The total impact duration was 19 hours, 15 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 02:20 US/Pacific\n* **Cloud Composer:** Cloud Composer environments (data-plane side) and operations (control-plane side) experienced degraded performance in europe-west2 on Tuesday, 19 July 2022 from 09:00 to 22:30 US/Pacific. Control plane operations experienced high failure rates (failure rate reached 100% at the peak). The number of Composer environments reporting a normal, operational state dropped by ~37%. Total capacity of all environments in the region (measured by the total number of tasks being executed in the whole region) was significantly reduced and the drop reached ~50% at the peak. The total impact duration was 13 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 22:30 US/Pacific\n* **Cloud Data Fusion:** ~20% of Data Fusion Instances in europe-west2 experienced service degradation, ranging from logs and metrics not being updated to complete loss of availability of their instance on Tuesday, 19 July 2022 10:15 to 21:30 US/Pacific. ~5% of instances were usable during the impact duration. The total impact duration was 11 hours, 15 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:30 US/Pacific\n* **Cloud Datastore:** Customers may have experienced timeouts and degraded service on approximately 1% of writes in the europe-west2 Datastore instance. The total impact duration was 9 hours, 25 minutes, on Tuesday, 19 July 2022 from approximately 12:30 to 19:30 US/Pacific. Approximately 40% of customers experienced significant latency increase on query operations from Tuesday, 19 July 2022 09:45 to 12:45 US/Pacific. ***Impact Mitigation time:*** Tuesday, 19 July 2022 19:30 US/Pacific\n* **Cloud Dataproc:** On Tuesday, 19 July 2022, from 08:00 US/Pacific to 22:00 US/Pacific, customers experienced increased error rates in creating and scaling up clusters in europe-west2. About 24% of CREATE operations and 13% of UPDATE operations were affected. Due to a backlog of queued requests requiring manual attention, error rates for old CREATE/DELETE requests remained elevated until Thursday, 21 July 2022 16:45 US/Pacific (this did not impact availability of already-running clusters). Some Dataproc clusters that were allocated in the impacted zone were unavailable during power down. Most of these came up by 19 July 2022 22:00 US/Pacific. By this time, CREATE operations in all zones began working. A few existing clusters were impacted by the long tail recovery in Google Compute Engine and were restored when that effort completed on Thursday, 21 July 2022 02:32 US/Pacific. Primary impact duration was approximately 14 hours. ***Impact Mitigation time:*** Tuesday, 19 July 2022 22:00 US/Pacific\n* **Cloud Firestore:** Firestore streaming (listen, write) requests via Webchannel were 100% unavailable in the europe-west2 instance on Tuesday, 19 July 2022 from 07:15 to 09:55 US/Pacific. The total impact duration was 2 hours, 40 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 09:55 US/Pacific\n* **Cloud Secret Manager** Cloud Secret Manager experienced an outage for secrets that were exclusively stored in europe-west2 from Tuesday, 19 July 2022 07:29 to 08:46 US/Pacific. Secret Manager is a global service that lets users define in which regions to store a given secret. The regional service instances for europe-west2 were deployed in the impacted data center. The total impact duration was 1 hour, 17 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 08:46 US/Pacific\n* **Cloud Spanner:** A more comprehensive investigation into our Cloud Spanner logs indicated no evidence of any customer impact. If you were impacted, please contact Google Cloud Support using https://cloud.google.com/support, and we will review your logs.\n* **Cloud SQL:** Customers experienced downtime on Tuesday, 19 July 2022 starting at 09:25 US/Pacific. 36% of zonal (non-HA) instances in europe-west2-a were affected. Additionally, 31% of regional (HA) instances whose primaries were located in europe-west2-a experienced extended downtime because they were unable to successfully fail over to another zone. Finally, customers experienced some failures during the incident for backup, instance creation, update, delete, restart, export, and Database Migration Service operations. The total impact duration was 17 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:00 US/Pacific\n* **Dataflow:** Approximately 8% of Dataflow streaming jobs running in europe-west2 were stuck from Tuesday, 19 July 2022 07:11 to 12:38 US/Pacific. There was limited impact to batch Dataflow jobs. Some new Dataflow jobs could not be initiated. The total impact duration was 5 hours, 27 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 12:38 US/Pacific\n* **Datastream:** Datastream streams experienced errors and processing lag in europe-west2-a as a result of impact on the data-plane infrastructure and services from Tuesday, 19 July 2002 09:05 to Wednesday, 20 July 2022 03:00 US/Pacific. Customers were advised to run their streams in another region. The total impact duration was 17 hours, 55 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 03:00 US/Pacific\n* **Google App Engine, Cloud Functions, and Cloud Run:** Customers may have experienced high error rates for Google App Engine, Cloud Functions and Cloud Run in europe-west2. Customers with a multi-region architecture could failover to another region. Traffic for ~72% of projects from Cloud Tasks, Cloud Scheduler, Eventarc, Cloud Pubsub to App Engine and Cloud Functions experienced up to 18% dropped requests/events on Tuesday, 19 July 2022 07:18 to 10:05 US/Pacific. Traffic from other sources (including end-users) to ~35% of App Engine, Cloud Functions, and Cloud Run projects experienced elevated latency in the same time period. Furthermore, ~5% of Cloud Run projects experienced elevated error rates (reaching peaks of 90% unavailability) caused by new instances failing to be created (some of which were due to a dependency on Google Cloud Secret Manager). The total impact duration was: * App Engine Flexible: 13 hours, 1 minute * App Engine Standard: 3 hours, 36 minutes * Cloud Functions: 3 hours, 36 minutes * Cloud Run: 3 hours, 36 minutes ***Impact Mitigation time:*** Tuesday, 19 July 2022 10:05 US/Pacific (App Engine Standard, Cloud Functions, Cloud Run) and Tuesday, 19 July 2022 20:30 US/Pacific (App Engine Flexible)\n* **Google BigQuery:** On Tuesday, 19 July 2022 between 04:40 US/Pacific and 13:43 US/Pacific, 12% of the projects in europe-west2 experienced errors and dataset unavailability. This was caused by mitigations and the power down of one of the data centers serving the europe-west2-a zone, which reduced the storage and compute capacity available to BigQuery. As a regional service, BigQuery was able to mitigate some of this capacity loss by shifting load to other data centers. However, BigQuery datasets which happened to be hosted solely in that data center were unavailable during the power down. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:43 US/Pacific\n* **Google Cloud Tasks:** Cloud Tasks automatically distributes projects across cloud zones within a region. 6% of projects in europe-west2 were loaded in the data center that was powered down on Tuesday, 19 July 2022 10:05 US/Pacific, and stopped delivering tasks until 13:24, after which delivery was resumed. No tasks were executed in any newly created queues in the region and in any existing queues in the impacted zone. However, as a regional service, Cloud Task was eventually able to mitigate all of the capacity loss by shifting load to other zones. The total impact duration was 3 hours, 19 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:24 US/Pacific\n* **Google Cloud Scheduler:** Cloud Scheduler automatically distributes projects across Cloud zones within a region. 6% of projects in europe-west2 were loaded in the datacenter that was powered down on Tuesday, 19 July 2022 10:05 US/Pacific and stopped executing jobs until 13:24, after which execution was resumed. As a regional service, Cloud Scheduler was eventually able to mitigate all of the capacity loss by shifting load to other zones. The total impact duration was 3 hours, 19 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 13:24 US/Pacific\n* **Cloud Filestore:** 45% of instances in europe-west2-a experienced service unavailability from Tuesday, 19 July 2022 10:05 US/Pacific to Wednesday, 20 July 2022 01:10 US/Pacific. This impact lasted until the mitigation time. At this point customers with working instances experienced no additional issues. 6.4% of impacted instances did not recover automatically and had to be recovered manually, which completed on Wednesday, 20 July 18:32 US/Pacific. The symptoms of these varied from unavailability to degraded availability. Customers were advised to fail over to another region, if possible. The total impact duration was 10 hours, 30 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 01:10 US/Pacific\n* **Google Kubernetes Engine:** 15% of zonal clusters in europe-west2-a and 57% of regional \u0026 zonal cluster nodes in europe-west2-a were fully unavailable from Tuesday, 19 July 2022 from 09:30 to 21:30 US/Pacific. Regional cluster control planes remained available, but overall cluster health may have been impacted by node unavailability. Customers were encouraged to move their workloads to other regions if possible. The approximate impact duration was 12 hours. However, a few clusters experienced lag through the next day due to underlying GCE impact. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:30 US/Pacific\n* **Looker:** Looker instances in europe-west2 were unavailable or experienced degraded performance starting Tuesday, July 19, 2022 09:33 through Wednesday, July 20, 2022 at 05:57 US/Pacific. Once temperatures inside the data center returned to safe levels, the Looker team restored file systems for impacted customers, and all Looker instances were back online on Wednesday, July 20, 2022 at 05:57 US/Pacific. The total impact duration was 20 hours, 24 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 05:57 US/Pacific\n* **Managed Service for Microsoft Active Directory:** 28.57% of the Managed Active Directory domains configured in the europe-west2 region were impacted during the incident. Starting July 19, 2022 09:20:00 US/Pacific, the impacted customers had one less domain controller (DC) serving incoming traffic. However, the domains continued to operate with reduced redundancy. Furthermore, periodic backups (12h frequency) were not performed for the impacted domains during the incident window. Subsequent backups were successful. The total impact duration was 12 hours, 30 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 21:50 US/Pacific\n* **Memorystore for Memcached:** 20.8% of instances in europe-west2 experienced degraded performance and availability issues resulting in a total cache flush. Impact start was Tuesday 19 July at 09:35 US/Pacific.All instances with VMs in europe-west2-a were unavailable or performed with degraded performance for the entire duration of the event. Instances that were only located in europe-west2-a were unavailable. Instances with some VMs in europe-west2-a lost their corresponding memcache availability (storage/access).All affected instances experienced a cache flush. DELETE, and RECREATE operations were unavailable for instances located in europe-west2-a. CREATE operations were not affected. UPDATE was not affected as there were no requests during that time but was theoretically unavailable. The total impact duration was 1 day, 5 hours, 27 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 15:02 US/Pacific\n* **Memorystore for Redis:** ~10% of instances in europe-west2 experienced timeouts with the management API (create, update, delete, etc) from Tuesday, 19 July 2022 09:24 to Wednesday, 20 July 2022 21:19 US/Pacific. Customers whose instances are located in the affected data center in the europe-west2-a zone were unable to access their instances. Additionally, all affected instances experienced a cache flush. In total, ~39% of basic-tier instances in europe-west2-a were affected. The total impact duration was 11 hours, 11 minutes. ***Impact Mitigation time:*** Wednesday, 20 July 2022 21:19 US/Pacific\n* **Vertex AI online prediction:** Vertex AI prediction showed an elevated error rate on Tuesday, 19 July 2022 from 10:00 to 15:11 US/Pacific for a total impact duration of 5 hours 11 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 15:11 US/Pacific\n* **Virtual Private Cloud (VPC):** Approximately 35% of the VMs in the europe-west2-a zone were unreachable from Tuesday, 19 July 2022 10:06 US/ Pacific to 20:32 US/ Pacific. This includes all Cloud traffic into and out of 1275 / 3509 VMs in europe-west2-a . Both the control plane and the data plane were impacted. The total impact duration was 10 hours, 26 minutes. ***Impact Mitigation time:*** Tuesday, 19 July 2022 20:32 US/Pacific\n-------------------------","status":"AVAILABLE","affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Memorystore","id":"LGPLu3M5pcUAKU1z6eP3"},{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"},{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"},{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"},{"title":"API Gateway","id":"VzyLPL7CtWQqJ9WeKAjp"},{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"},{"title":"Google Cloud Tasks","id":"tMWyzhyKK4rAzAf7x62h"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Vertex AI Online Prediction","id":"sdXM79fz1FS6ekNpu37K"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"},{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"},{"title":"Google Cloud Datastore","id":"MaS3dKoqp1oqkea4qB9U"},{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"},{"title":"Cloud Data Fusion","id":"rLKDHeeaBiXTeutF1air"},{"title":"Managed Service for Microsoft Active Directory (AD)","id":"m2BYeday5NQNxnEnY56V"},{"title":"Google Cloud Dataproc","id":"yjXrEg3Yvy26BauMwr69"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"},{"title":"Datastream","id":"ibJgP4CNKnFojHHw8L3s"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/fmEL9i2fArADKawkZAa2","currently_affected_locations":[],"previously_affected_locations":[{"title":"London (europe-west2)","id":"europe-west2"}]},{"id":"5fYoeLUgYW8TaNeGwkm5","number":"9185362715659142092","begin":"2022-07-18T15:30:00+00:00","created":"2022-07-18T16:27:28+00:00","end":"2022-07-18T21:00:00+00:00","modified":"2022-08-12T13:52:30+00:00","external_desc":"Google Cloud Support Systems File upload failure","updates":[{"created":"2022-08-11T20:34:27+00:00","modified":"2022-08-12T13:52:30+00:00","when":"2022-08-11T20:34:27+00:00","text":"# Incident Report\n**Summary:**\nOn Monday, 18 July 2022 at 08:30 US/Pacific, Google Cloud and Google Workspace Support customers were unable to attach files to new and existing support cases via the Cloud Console and Admin Console for a period of 5 hours and 30 minutes.\nTo our support customers who were impacted during this outage, we sincerely apologize, and we are taking immediate steps to improve the platform’s performance and availability.\n**Root Cause:**\nGoogle Cloud and Google Workspace Support customers have the ability to attach files to new or existing support cases. During the initial phase of the outage, some users experienced intermittent failures while uploading files.\nDuring a recent effort to improve the reliability of the Cloud Support backend service, a configuration change was made to our Global Service Load Balancer (GSLB), which resulted in unavailability of the file upload service. Part of this change included migrating the servers to new addresses; however, the server that handles file attachments was not ready for the migration. The configuration change inadvertently made the file upload service used by the backend service inaccessible, resulting in file uploads failing.\n**Remediation and Prevention:**\nOnce the nature and scope of the issue became clear, Google engineers quickly disabled the file attachment feature while they worked on mitigation efforts. The issue was fully mitigated on Monday, 18 July 2022 at 14:00 US/Pacific, once the GSLB configuration change was rolled back.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are committed to the following actions to prevent this from happening again:\n- Improve monitoring and alerting to detect file attachment errors.\n- Improve our load balancer emergency change procedures based on known best practices within Google to reduce mitigation time.\n- Improve automation testing to detect invalid configuration changes in staging environments.\n- Improve internal rollout procedure for load balancer changes in order to detect rollouts that have unanticipated impact and prevent them from proceeding.\nWe would like to apologize for the length and severity of this incident.\n**Detailed Description of Impact:**\n### Service(s) Affected:\n## Google Cloud Console ##\n- 100% of users could not upload files to new or existing support cases. Support case creation was not impacted.\n## Google Admin Console ##\n- 100% of users could not upload files to new or existing support cases. Support case creation was not impacted.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-08-03T21:42:29+00:00","modified":"2022-08-03T21:42:29+00:00","when":"2022-08-03T21:42:29+00:00","text":"**Mini-IR (Preliminary Incident Report)**\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support or to Google Workspace Support using help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 18 July 2022 08:30\n**Incident End:** 18 July 2022 14:00\n**Duration:** 5 hours, 30 minutes\n**Affected Services and Features:**\nGoogle Cloud Support - Cloud Console\nGoogle Workspace Support - Admin Console\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Support and Google Admin Console customers were unable to attach files to new and existing support cases for a period of 5 hours and 30 minutes. From preliminary analysis, the root cause of the issue was due to an inadvertent change to our Global Service Load Balancer (GSLB), which resulted in nonavailability of the upload service.\n**Customer Impact:** - Google Cloud Support: Customers were unable to attach files to new or existing support cases. - Google Workspace Support: Customers were unable to attach files to new or existing support cases.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T21:02:44+00:00","modified":"2022-07-18T21:02:45+00:00","when":"2022-07-18T21:02:44+00:00","text":"The issue with Google Cloud Support has been resolved for all affected users as of Monday, 2022-07-18 14:02 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T19:18:59+00:00","modified":"2022-07-18T19:19:00+00:00","when":"2022-07-18T19:18:59+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: The case attachment upload feature has been disabled for all Cloud Console users.\nEngineering team is currently working on a mitigation and will enable the feature once fully resolved.\nWe do not have a mitigation ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-07-18 14:30 US/Pacific.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature has been disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T19:12:15+00:00","modified":"2022-07-18T19:12:16+00:00","when":"2022-07-18T19:12:15+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: The case attachment upload feature has been disabled for all Cloud Console users.\nEngineering team is currently working on a mitigation and will enable the feature once fully resolved.\nWe do not have a mitigation ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-07-18 13:30 US/Pacific.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature has been disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T18:18:30+00:00","modified":"2022-07-18T18:18:32+00:00","when":"2022-07-18T18:18:30+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: The case attachment upload feature has been disabled for all Cloud Console users.\nEngineering team is investigating the root cause of the file upload feature and will enable it back once resolved.\nWe will provide an update by Monday, 2022-07-18 12:35 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature has been disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T17:59:44+00:00","modified":"2022-07-18T17:59:45+00:00","when":"2022-07-18T17:59:44+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: The case attachment upload feature has been disabled for all Cloud Console users.\nEngineering team is investigating the root cause of the file upload feature and will enable it back once resolved.\nWe will provide an update by Monday, 2022-07-18 11:35 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature has been disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-18T17:28:04+00:00","modified":"2022-07-18T17:28:06+00:00","when":"2022-07-18T17:28:04+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: The case attachment upload feature has been disabled for all Cloud Console users.\nEngineering team is investigating the root cause of the file upload feature and will enable it back once resolved.\nWe will provide an update by Monday, 2022-07-18 11:30 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature has been disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-18T17:03:09+00:00","modified":"2022-07-18T17:03:12+00:00","when":"2022-07-18T17:03:09+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: Engineering team is currently investigating the root cause of the issue.\nThe case attachments feature will be disabled for all Cloud Console users in the next 30 minutes. This mitigation step is being taken to enable the customer to utilize the Cloud support feature while the issue is being investigated.\nWe will provide an update by Monday, 2022-07-18 10:30 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads. The case attachment feature will be disabled until the issue is resolved.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-18T16:27:46+00:00","modified":"2022-07-18T16:27:52+00:00","when":"2022-07-18T16:27:46+00:00","text":"Summary: Google Cloud Support Systems File upload failure\nDescription: We are experiencing an issue with Google Cloud Support.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-18 10:12 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads\nWorkaround: None","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-18T16:27:22+00:00","modified":"2022-07-18T16:27:29+00:00","when":"2022-07-18T16:27:22+00:00","text":"Summary: Goggle Cloud Support Systems File upload failure\nDescription: We are experiencing an issue with Google Cloud Support.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-07-18 10:12 US/Pacific with current details.\nDiagnosis: Users experiencing failure with file uploads\nWorkaround: None","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-08-11T20:34:27+00:00","modified":"2022-08-12T13:52:30+00:00","when":"2022-08-11T20:34:27+00:00","text":"# Incident Report\n**Summary:**\nOn Monday, 18 July 2022 at 08:30 US/Pacific, Google Cloud and Google Workspace Support customers were unable to attach files to new and existing support cases via the Cloud Console and Admin Console for a period of 5 hours and 30 minutes.\nTo our support customers who were impacted during this outage, we sincerely apologize, and we are taking immediate steps to improve the platform’s performance and availability.\n**Root Cause:**\nGoogle Cloud and Google Workspace Support customers have the ability to attach files to new or existing support cases. During the initial phase of the outage, some users experienced intermittent failures while uploading files.\nDuring a recent effort to improve the reliability of the Cloud Support backend service, a configuration change was made to our Global Service Load Balancer (GSLB), which resulted in unavailability of the file upload service. Part of this change included migrating the servers to new addresses; however, the server that handles file attachments was not ready for the migration. The configuration change inadvertently made the file upload service used by the backend service inaccessible, resulting in file uploads failing.\n**Remediation and Prevention:**\nOnce the nature and scope of the issue became clear, Google engineers quickly disabled the file attachment feature while they worked on mitigation efforts. The issue was fully mitigated on Monday, 18 July 2022 at 14:00 US/Pacific, once the GSLB configuration change was rolled back.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are committed to the following actions to prevent this from happening again:\n- Improve monitoring and alerting to detect file attachment errors.\n- Improve our load balancer emergency change procedures based on known best practices within Google to reduce mitigation time.\n- Improve automation testing to detect invalid configuration changes in staging environments.\n- Improve internal rollout procedure for load balancer changes in order to detect rollouts that have unanticipated impact and prevent them from proceeding.\nWe would like to apologize for the length and severity of this incident.\n**Detailed Description of Impact:**\n### Service(s) Affected:\n## Google Cloud Console ##\n- 100% of users could not upload files to new or existing support cases. Support case creation was not impacted.\n## Google Admin Console ##\n- 100% of users could not upload files to new or existing support cases. Support case creation was not impacted.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"bGThzF7oEGP5jcuDdMuk","service_name":"Google Cloud Support","affected_products":[{"title":"Google Cloud Support","id":"bGThzF7oEGP5jcuDdMuk"}],"uri":"incidents/5fYoeLUgYW8TaNeGwkm5","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"o91gguo48MgGCXjGFFPe","number":"8950401021160007919","begin":"2022-07-15T18:42:51+00:00","created":"2022-07-15T20:41:26+00:00","end":"2022-07-15T21:29:21+00:00","modified":"2022-07-15T21:29:21+00:00","external_desc":"Customers may observe degraded read API throughput resulting in slow job runtimes in services (ODBC/JDBC, Dataproc, Dataflow) which read BigQuery data using the read API.","updates":[{"created":"2022-07-15T21:29:21+00:00","modified":"2022-07-15T21:29:22+00:00","when":"2022-07-15T21:29:21+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-07-15 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-15T20:41:25+00:00","modified":"2022-07-15T20:41:27+00:00","when":"2022-07-15T20:41:25+00:00","text":"Summary: Customers may observe degraded read API throughput resulting in slow job runtimes in services (ODBC/JDBC, Dataproc, Dataflow) which read BigQuery data using the read API.\nDescription: We are experiencing an issue with Google BigQuery beginning at Friday, 2022-07-15 04:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 15:00 US/Pacific with current details. We apologize to all who are affected by the disruption.\nDiagnosis: Customers may observe degraded read API throughput resulting in slow job runtimes in services (ODBC/JDBC, Dataproc, Dataflow) which read BigQuery data using the read API.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-15T21:29:21+00:00","modified":"2022-07-15T21:29:22+00:00","when":"2022-07-15T21:29:21+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-07-15 14:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/o91gguo48MgGCXjGFFPe","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"MYgsmwRt8h2E36MmjkQW","number":"15209462675513262658","begin":"2022-07-15T13:34:55+00:00","created":"2022-07-15T13:35:00+00:00","end":"2022-07-15T14:44:52+00:00","modified":"2022-07-15T14:44:52+00:00","external_desc":"Cloud Spanner may be experiencing issues Globally","updates":[{"created":"2022-07-15T14:44:46+00:00","modified":"2022-07-15T14:44:53+00:00","when":"2022-07-15T14:44:46+00:00","text":"After further investigation, our engineering did not see any issues with Cloud Spanner, Google Cloud Networking.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-15T14:34:24+00:00","modified":"2022-07-15T14:34:33+00:00","when":"2022-07-15T14:34:24+00:00","text":"Summary: Cloud Spanner may be experiencing issues Globally\nDescription: We are investigating a potential issue with Cloud Spanner\nWe will provide more information by Friday, 2022-07-15 08:10 US/Pacific.\nDiagnosis: Cloud Spanner may be experiencing some issue related to network traffic\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-15T14:01:12+00:00","modified":"2022-07-15T14:01:16+00:00","when":"2022-07-15T14:01:12+00:00","text":"Summary: We are experiencing an issue with Cloud Spanner globally\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-07-15 08:15 US/Pacific.\nWe will provide more information by Friday, 2022-07-15 08:15 US/Pacific.\nDiagnosis: Gmail and many other services are currently experiencing significant impact related to Spanner issues. Spanner in turn appears to be impacted by significant network instability\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-15T13:55:30+00:00","modified":"2022-07-15T13:55:34+00:00","when":"2022-07-15T13:55:30+00:00","text":"Summary: We are experiencing an issue with Cloud Spanner beginning at Friday, 2022-07-15 04:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 07:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-07-15 08:15 US/Pacific.\nWe will provide more information by Friday, 2022-07-15 08:15 US/Pacific.\nDiagnosis: Gmail and many other services are currently experiencing significant impact related to Spanner issues. Spanner in turn appears to be impacted by significant network instability\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-15T13:48:21+00:00","modified":"2022-07-15T13:48:30+00:00","when":"2022-07-15T13:48:21+00:00","text":"Summary: We are experiencing an issue with Cloud Spanner beginning at Friday, 2022-07-15 04:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 07:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-07-15 08:00 US/Pacific.\nWe will provide more information by Friday, 2022-07-15 08:00 US/Pacific.\nDiagnosis: Gmail and many other services are currently experiencing significant impact related to Spanner issues. Spanner in turn appears to be impacted by significant network instability\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-07-15T13:34:58+00:00","modified":"2022-07-15T13:35:03+00:00","when":"2022-07-15T13:34:58+00:00","text":"Summary: We are experiencing an issue with Cloud Spanner beginning at Friday, 2022-07-15 04:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 07:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDescription: We are experiencing an issue with Cloud Spanner beginning at Friday, 2022-07-15 04:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 07:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Gmail and many other services are currently experiencing significant impact related to Spanner issues. Spanner in turn appears to be impacted by significant network instability\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-15T14:44:46+00:00","modified":"2022-07-15T14:44:53+00:00","when":"2022-07-15T14:44:46+00:00","text":"After further investigation, our engineering did not see any issues with Cloud Spanner, Google Cloud Networking.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/MYgsmwRt8h2E36MmjkQW","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"hzxcQxLANyeavQXe3PpV","number":"10910203701421723325","begin":"2022-07-15T13:22:15+00:00","created":"2022-07-15T13:29:43+00:00","end":"2022-07-15T13:37:10+00:00","modified":"2022-07-15T13:37:10+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-07-15T13:37:02+00:00","modified":"2022-07-15T13:37:13+00:00","when":"2022-07-15T13:37:02+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-15T13:29:40+00:00","modified":"2022-07-15T13:29:46+00:00","when":"2022-07-15T13:29:40+00:00","text":"Summary: Mutliple services impacted - Spanner\nDescription: We are experiencing an issue with Cloud Spanner beginning at Friday, 2022-07-15 04:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 07:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Gmail and many other services are currently experiencing significant impact related to Spanner issues. Spanner in turn appears to be impacted by significant network instability\nWorkaround: None at this time","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-07-15T13:37:02+00:00","modified":"2022-07-15T13:37:13+00:00","when":"2022-07-15T13:37:02+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"EcNGGUgBtBLrtm4mWvqC","service_name":"Cloud Spanner","affected_products":[{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"}],"uri":"incidents/hzxcQxLANyeavQXe3PpV","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"PCibvK1LbstDfPKPGfRC","number":"10553856456157171095","begin":"2022-07-15T02:30:00+00:00","created":"2022-07-15T20:40:10+00:00","end":"2022-07-15T22:02:00+00:00","modified":"2022-07-28T15:09:25+00:00","external_desc":"BigQuery observing high import/export job latencies in several regions","updates":[{"created":"2022-07-28T00:46:02+00:00","modified":"2022-07-28T15:09:25+00:00","when":"2022-07-28T00:46:02+00:00","text":"INCIDENT REPORT\n**Summary:**\nGoogle Cloud Networking experienced reduced capacity for lower priority traffic such as batch, streaming and transfer operations from 19:30 US/Pacific on Thursday, 14 July 2022, through 15:02 US/Pacific on Friday, 15 July 2022. High-priority user-facing traffic was not affected. This service disruption resulted from an issue encountered during a combination of repair work and a routine network software upgrade rollout. Due to the nature of the disruption and resilience capabilities of Google Cloud products, the impacted regions and individual impact windows varied substantially. To our customers whose businesses were impacted during this disruption, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s availability.\n**Root Cause:**\nThe root cause was identified as an issue with a new control plane configuration rollout, causing low-priority classified traffic capacity reduction in Google’s internal backbone network connecting data centers. Mitigation efforts were slowed by the capacity reduction, and engineering teams required more than their usual time to safely undo the configuration change. During the period of the rollout and subsequent rollback, constrained traffic in certain cloud zones affected the performance of some Cloud services.\n**Remediation and Prevention:**\nAt approximately 02:00 US/Pacific on Friday, 15 July, as an in-progress rollout expanded to more regions, Google engineers observed performance degradation in Cloud Networking due to reduced capacity. The engineering team then started an investigation into the cause. At 03:50 US/Pacific, Google engineers pushed the first mitigation attempt to halt the ongoing rollout. While this effort succeeded in pausing any new actions, those already in progress continued, which further reduced network capacity.\nSubsequently, the engineering team shifted their mitigation efforts toward a global rollback of the problematic configuration. Their first attempt to mitigate using a configuration push was applied at 08:40 US/Pacific, but it was not successfully applied to all nodes, due in part to the reduced network performance. Google engineers worked through alternate mitigations, and by 12:40 US/Pacific, the configuration was updated correctly, and this mitigated the majority of impact.\nBy 15:02 US/Pacific on 15 July 2022, services for all customers had been restored. The Google Cloud Service Health Dashboard was updated to reflect this.\nGoogle is committed to preventing future recurrence, and we are taking the following\nactions:\nDetection:\n* Improve signals to detect significant changes in traffic for upgraded domains in the backbone network.\n* Improve dashboards that help debugging global- and domain-level control failures and configuration status.\nPrevention:\n* Improve the automated handling of disconnected local Software Defined Networking (SDN) controllers that will reduce overall impact and mitigation time. .\n* Improve the global safety systems that globally halt elective rollouts on Google’s wide area (WAN) networks, when global capacity is reduced.\n* Further isolate production network neighborhoods.\nMitigation:\n* Improve the API to push changes to global and local network controllers during a service disruption.\n* Improve failure domain configuration validation to reject unintended configuration.\n* Improve the feature and testing of emergency tools across different scenarios at regular intervals, and invest in test environments that enable us to do this without impact.\n**Detailed Description of Impact:**\n**Google Cloud Networking**\n* Google Cloud Networking experienced reduced capacity within the Google Cloud regions of us-east1, southamerica-west1, us-central1, and us-central2, starting from Friday 15 July 2022 02:24 US/Pacific. The most severe impact occurred from 03:58 to 12:40.\n* southamerica-west1 experienced reduced capacity between 14:40 and 15:02.\n* southamerica-west1 and southamerica-east1 both experienced egress packet loss between 20% and 30%.\n**Google Cloud Storage (GCS)**\n* Between Thursday, 14 July 2022 21:57 US/Pacific and Friday, 15 July 12:40 US/Pacific, GCS customers may have experienced elevated latency, delays, issues importing, exporting or querying data from GCS buckets, and HTTP 500 errors in the Google Cloud regions of us-east1, southamerica-west1, and us-central2, and for buckets located in us-central1, us-east1, and nam4.\n* This disruption affected 0.007% of GCS requests and impacted customers reading/writing data and metadata.\n**Google BigQuery**\n* Customer workloads running in impacted Google Cloud regions and using the BigQuery Storage Read and Write APIs to read from or write to BigQuery may have experienced elevated latency.\n**Note**\n* Additional services may have been impacted by this event but did not meet the thresholds to be included in this report.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-18T22:31:46+00:00","modified":"2022-07-21T20:43:24+00:00","when":"2022-07-18T22:31:46+00:00","text":"This is a preliminary Incident Report (Mini-IR). A Full Incident Report with additional details is being prepared and will be posted at a later date.\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 14 July 2022 19:30\n**Incident End:** 15 July 2022 15:02\n**Duration:** 19 hours, 32 minutes\n**Affected Services**\nGoogle Cloud Networking\nGoogle BigQuery\nGoogle Cloud Storage (GCS)\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced reduced availability globally for a period of 19 hours and 32 minutes. Because of the nature of the outage and resilience capabilities of GCP products, the impacted regions and individual impacted windows may vary inside of the network impact window. From preliminary analysis, the root cause was due to an issue with a new control plane configuration rollout.\n**Customer Impact:**\nGoogle Cloud Storage - Affected customers would have experienced elevated latencies or HTTP 500 errors in multiple regions, including us-east1, us-central1, and southamerica-west1. - Affected customers reading/writing data from GCS impacted regions or from buckets located in impacted regions would have observed high latency and/or errors. - Affected customers reading/writing metadata for buckets located in impacted regions would have observed high latency and/or errors.\nGoogle BigQuery - Affected customers performing cross-regional table copies would have observed increased latency and/or errors.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-15T21:17:57+00:00","modified":"2022-07-15T21:17:59+00:00","when":"2022-07-15T21:17:57+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-07-15 14:12 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-15T21:02:16+00:00","modified":"2022-07-15T21:02:17+00:00","when":"2022-07-15T21:02:16+00:00","text":"Summary: BigQuery observing high import/export job latencies in several regions\nDescription: We are experiencing an issue with Google BigQuery beginning at Friday, 2022-07-15 05:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 15:05 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: BigQuery is observing high import/export job latencies (slowness) in several regions, which may ultimately result in errors.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-07-15T20:40:10+00:00","modified":"2022-07-15T20:40:11+00:00","when":"2022-07-15T20:40:10+00:00","text":"Summary: BigQuery observing high import/export job latencies in several regions\nDescription: We are experiencing an issue with Google BigQuery beginning at Friday, 2022-07-15 05:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-15 15:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: BigQuery is observing high import/export job latencies (slowness) in several regions, which may ultimately result in errors.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-28T00:46:02+00:00","modified":"2022-07-28T15:09:25+00:00","when":"2022-07-28T00:46:02+00:00","text":"INCIDENT REPORT\n**Summary:**\nGoogle Cloud Networking experienced reduced capacity for lower priority traffic such as batch, streaming and transfer operations from 19:30 US/Pacific on Thursday, 14 July 2022, through 15:02 US/Pacific on Friday, 15 July 2022. High-priority user-facing traffic was not affected. This service disruption resulted from an issue encountered during a combination of repair work and a routine network software upgrade rollout. Due to the nature of the disruption and resilience capabilities of Google Cloud products, the impacted regions and individual impact windows varied substantially. To our customers whose businesses were impacted during this disruption, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s availability.\n**Root Cause:**\nThe root cause was identified as an issue with a new control plane configuration rollout, causing low-priority classified traffic capacity reduction in Google’s internal backbone network connecting data centers. Mitigation efforts were slowed by the capacity reduction, and engineering teams required more than their usual time to safely undo the configuration change. During the period of the rollout and subsequent rollback, constrained traffic in certain cloud zones affected the performance of some Cloud services.\n**Remediation and Prevention:**\nAt approximately 02:00 US/Pacific on Friday, 15 July, as an in-progress rollout expanded to more regions, Google engineers observed performance degradation in Cloud Networking due to reduced capacity. The engineering team then started an investigation into the cause. At 03:50 US/Pacific, Google engineers pushed the first mitigation attempt to halt the ongoing rollout. While this effort succeeded in pausing any new actions, those already in progress continued, which further reduced network capacity.\nSubsequently, the engineering team shifted their mitigation efforts toward a global rollback of the problematic configuration. Their first attempt to mitigate using a configuration push was applied at 08:40 US/Pacific, but it was not successfully applied to all nodes, due in part to the reduced network performance. Google engineers worked through alternate mitigations, and by 12:40 US/Pacific, the configuration was updated correctly, and this mitigated the majority of impact.\nBy 15:02 US/Pacific on 15 July 2022, services for all customers had been restored. The Google Cloud Service Health Dashboard was updated to reflect this.\nGoogle is committed to preventing future recurrence, and we are taking the following\nactions:\nDetection:\n* Improve signals to detect significant changes in traffic for upgraded domains in the backbone network.\n* Improve dashboards that help debugging global- and domain-level control failures and configuration status.\nPrevention:\n* Improve the automated handling of disconnected local Software Defined Networking (SDN) controllers that will reduce overall impact and mitigation time. .\n* Improve the global safety systems that globally halt elective rollouts on Google’s wide area (WAN) networks, when global capacity is reduced.\n* Further isolate production network neighborhoods.\nMitigation:\n* Improve the API to push changes to global and local network controllers during a service disruption.\n* Improve failure domain configuration validation to reject unintended configuration.\n* Improve the feature and testing of emergency tools across different scenarios at regular intervals, and invest in test environments that enable us to do this without impact.\n**Detailed Description of Impact:**\n**Google Cloud Networking**\n* Google Cloud Networking experienced reduced capacity within the Google Cloud regions of us-east1, southamerica-west1, us-central1, and us-central2, starting from Friday 15 July 2022 02:24 US/Pacific. The most severe impact occurred from 03:58 to 12:40.\n* southamerica-west1 experienced reduced capacity between 14:40 and 15:02.\n* southamerica-west1 and southamerica-east1 both experienced egress packet loss between 20% and 30%.\n**Google Cloud Storage (GCS)**\n* Between Thursday, 14 July 2022 21:57 US/Pacific and Friday, 15 July 12:40 US/Pacific, GCS customers may have experienced elevated latency, delays, issues importing, exporting or querying data from GCS buckets, and HTTP 500 errors in the Google Cloud regions of us-east1, southamerica-west1, and us-central2, and for buckets located in us-central1, us-east1, and nam4.\n* This disruption affected 0.007% of GCS requests and impacted customers reading/writing data and metadata.\n**Google BigQuery**\n* Customer workloads running in impacted Google Cloud regions and using the BigQuery Storage Read and Write APIs to read from or write to BigQuery may have experienced elevated latency.\n**Note**\n* Additional services may have been impacted by this event but did not meet the thresholds to be included in this report.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/PCibvK1LbstDfPKPGfRC","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"vLsxuKoRvykNHW3nnhsJ","number":"16828167276355000807","begin":"2022-07-15T02:30:00+00:00","created":"2022-07-15T19:58:02+00:00","end":"2022-07-15T22:02:00+00:00","modified":"2022-07-29T14:22:29+00:00","external_desc":"Google Cloud Storage is experiencing elevated latency in multiple regions.","updates":[{"created":"2022-07-28T00:47:21+00:00","modified":"2022-07-29T14:22:29+00:00","when":"2022-07-28T00:47:21+00:00","text":"## INCIDENT REPORT\n**Summary:**\nGoogle Cloud Networking experienced reduced capacity for lower priority traffic such as batch, streaming and transfer operations from 19:30 US/Pacific on Thursday, 14 July 2022, through 15:02 US/Pacific on Friday, 15 July 2022. High-priority user-facing traffic was not affected. This service disruption resulted from an issue encountered during a combination of repair work and a routine network software upgrade rollout. Due to the nature of the disruption and resilience capabilities of Google Cloud products, the impacted regions and individual impact windows varied substantially. To our customers whose businesses were impacted during this disruption, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s availability.\n**Root Cause:**\nThe root cause was identified as an issue with a new control plane configuration rollout, causing low-priority classified traffic capacity reduction in Google’s internal backbone network connecting data centers. Mitigation efforts were slowed by the capacity reduction, and engineering teams required more than their usual time to safely undo the configuration change. During the period of the rollout and subsequent rollback, constrained traffic in certain cloud zones affected the performance of some Cloud services.\n**Remediation and Prevention:**\nAt approximately 02:00 US/Pacific on Friday, 15 July, as an in-progress rollout expanded to more regions, Google engineers observed performance degradation in Cloud Networking due to reduced capacity. The engineering team then started an investigation into the cause. At 03:50 US/Pacific, Google engineers pushed the first mitigation attempt to halt the ongoing rollout. While this effort succeeded in pausing any new actions, those already in progress continued, which further reduced network capacity.\nSubsequently, the engineering team shifted their mitigation efforts toward a global rollback of the problematic configuration. Their first attempt to mitigate using a configuration push was applied at 08:40 US/Pacific, but it was not successfully applied to all nodes, due in part to the reduced network performance. Google engineers worked through alternate mitigations, and by 12:40 US/Pacific, the configuration was updated correctly, and this mitigated the majority of impact.\nBy 15:02 US/Pacific on 15 July 2022, services for all customers had been restored. The Google Cloud Service Health Dashboard was updated to reflect this.\nGoogle is committed to preventing future recurrence, and we are taking the following\nactions:\nDetection:\n* Improve signals to detect significant changes in traffic for upgraded domains in the backbone network.\n* Improve dashboards that help debugging global- and domain-level control failures and configuration status.\nPrevention:\n* Improve the automated handling of disconnected local Software Defined Networking (SDN) controllers that will reduce overall impact and mitigation time.\n* Improve the global safety systems that globally halt elective rollouts on Google’s wide area (WAN) networks, when global capacity is reduced.\n* Further isolate production network neighborhoods.\nMitigation:\n* Improve the API to push changes to global and local network controllers during a service disruption.\n* Improve failure domain configuration validation to reject unintended configuration.\n* Improve the feature and testing of emergency tools across different scenarios at regular intervals, and invest in test environments that enable us to do this without impact.\n**Detailed Description of Impact:**\n**Google Cloud Networking**\n* Google Cloud Networking experienced reduced capacity within the Google Cloud regions of us-east1, southamerica-west1, us-central1, and us-central2, starting from Friday 15 July 2022 02:24 US/Pacific. The most severe impact occurred from 03:58 to 12:40.\n* southamerica-west1 experienced reduced capacity between 14:40 and 15:02.\n* southamerica-west1 and southamerica-east1 both experienced egress packet loss between 20% and 30%.\n**Google Cloud Storage (GCS)**\n* Between Thursday, 14 July 2022 21:57 US/Pacific and Friday, 15 July 12:40 US/Pacific, GCS customers may have experienced elevated latency, delays, issues importing, exporting or querying data from GCS buckets, and HTTP 500 errors in the Google Cloud regions of us-east1, southamerica-west1, and us-central2, and for buckets located in us-central1, us-east1, and nam4.\n* This disruption affected 0.007% of GCS requests and impacted customers reading/writing data and metadata.\n**Google BigQuery**\n* Customer workloads running in impacted Google Cloud regions and using the BigQuery Storage Read and Write APIs to read from or write to BigQuery may have experienced elevated latency.\n**Note**\n* Additional services may have been impacted by this event but did not meet the thresholds to be included in this report.","status":"AVAILABLE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-07-18T22:28:26+00:00","modified":"2022-07-21T20:42:40+00:00","when":"2022-07-18T22:28:26+00:00","text":"This is a preliminary Incident Report (Mini-IR). A Full Incident Report with additional details is being prepared and will be posted at a later date.\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Cloud Support using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 14 July 2022 19:30\n**Incident End:** 15 July 2022 15:02\n**Duration:** 19 hours, 32 minutes\n**Affected Services**\nGoogle Cloud Networking\nGoogle BigQuery\nGoogle Cloud Storage (GCS)\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced reduced availability globally for a period of 19 hours and 32 minutes. Because of the nature of the outage and resilience capabilities of GCP products, the impacted regions and individual impacted windows may vary inside of the network impact window. From preliminary analysis, the root cause was due to an issue with a new control plane configuration rollout.\n**Customer Impact:**\nGoogle Cloud Storage - Affected customers would have experienced elevated latencies or HTTP 500 errors in multiple regions, including us-east1, us-central1, and southamerica-west1. - Affected customers reading/writing data from GCS impacted regions or from buckets located in impacted regions would have observed high latency and/or errors. - Affected customers reading/writing metadata for buckets located in impacted regions would have observed high latency and/or errors.\nGoogle BigQuery - Affected customers performing cross-regional table copies would have observed increased latency and/or errors.","status":"AVAILABLE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-07-15T22:27:07+00:00","modified":"2022-07-15T22:27:08+00:00","when":"2022-07-15T22:27:07+00:00","text":"The issue with Google Cloud Storage has been resolved for all affected users as of Friday, 2022-07-15 15:26 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-07-15T21:36:04+00:00","modified":"2022-07-15T21:36:06+00:00","when":"2022-07-15T21:36:04+00:00","text":"Summary: Google Cloud Storage is experiencing elevated latency in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-07-15 15:30 US/Pacific.\nWe will provide more information by Friday, 2022-07-15 15:40 US/Pacific.\nDiagnosis: Customers may see increase in latency (slowness) or HTTP 500 errors\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-07-15T20:32:09+00:00","modified":"2022-07-15T20:32:12+00:00","when":"2022-07-15T20:32:09+00:00","text":"Summary: Google Cloud Storage is experiencing elevated latency in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-07-15 14:37 US/Pacific.\nDiagnosis: Customers may see increase in latency (slowness) or HTTP 500 errors\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-07-15T19:57:55+00:00","modified":"2022-07-15T19:58:06+00:00","when":"2022-07-15T19:57:55+00:00","text":"Summary: Google Cloud Storage is experiencing elevated latency in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-07-15 13:37 US/Pacific.\nDiagnosis: Customers will see increase in latency or HTTP 500 errors\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-07-28T00:47:21+00:00","modified":"2022-07-29T14:22:29+00:00","when":"2022-07-28T00:47:21+00:00","text":"## INCIDENT REPORT\n**Summary:**\nGoogle Cloud Networking experienced reduced capacity for lower priority traffic such as batch, streaming and transfer operations from 19:30 US/Pacific on Thursday, 14 July 2022, through 15:02 US/Pacific on Friday, 15 July 2022. High-priority user-facing traffic was not affected. This service disruption resulted from an issue encountered during a combination of repair work and a routine network software upgrade rollout. Due to the nature of the disruption and resilience capabilities of Google Cloud products, the impacted regions and individual impact windows varied substantially. To our customers whose businesses were impacted during this disruption, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s availability.\n**Root Cause:**\nThe root cause was identified as an issue with a new control plane configuration rollout, causing low-priority classified traffic capacity reduction in Google’s internal backbone network connecting data centers. Mitigation efforts were slowed by the capacity reduction, and engineering teams required more than their usual time to safely undo the configuration change. During the period of the rollout and subsequent rollback, constrained traffic in certain cloud zones affected the performance of some Cloud services.\n**Remediation and Prevention:**\nAt approximately 02:00 US/Pacific on Friday, 15 July, as an in-progress rollout expanded to more regions, Google engineers observed performance degradation in Cloud Networking due to reduced capacity. The engineering team then started an investigation into the cause. At 03:50 US/Pacific, Google engineers pushed the first mitigation attempt to halt the ongoing rollout. While this effort succeeded in pausing any new actions, those already in progress continued, which further reduced network capacity.\nSubsequently, the engineering team shifted their mitigation efforts toward a global rollback of the problematic configuration. Their first attempt to mitigate using a configuration push was applied at 08:40 US/Pacific, but it was not successfully applied to all nodes, due in part to the reduced network performance. Google engineers worked through alternate mitigations, and by 12:40 US/Pacific, the configuration was updated correctly, and this mitigated the majority of impact.\nBy 15:02 US/Pacific on 15 July 2022, services for all customers had been restored. The Google Cloud Service Health Dashboard was updated to reflect this.\nGoogle is committed to preventing future recurrence, and we are taking the following\nactions:\nDetection:\n* Improve signals to detect significant changes in traffic for upgraded domains in the backbone network.\n* Improve dashboards that help debugging global- and domain-level control failures and configuration status.\nPrevention:\n* Improve the automated handling of disconnected local Software Defined Networking (SDN) controllers that will reduce overall impact and mitigation time.\n* Improve the global safety systems that globally halt elective rollouts on Google’s wide area (WAN) networks, when global capacity is reduced.\n* Further isolate production network neighborhoods.\nMitigation:\n* Improve the API to push changes to global and local network controllers during a service disruption.\n* Improve failure domain configuration validation to reject unintended configuration.\n* Improve the feature and testing of emergency tools across different scenarios at regular intervals, and invest in test environments that enable us to do this without impact.\n**Detailed Description of Impact:**\n**Google Cloud Networking**\n* Google Cloud Networking experienced reduced capacity within the Google Cloud regions of us-east1, southamerica-west1, us-central1, and us-central2, starting from Friday 15 July 2022 02:24 US/Pacific. The most severe impact occurred from 03:58 to 12:40.\n* southamerica-west1 experienced reduced capacity between 14:40 and 15:02.\n* southamerica-west1 and southamerica-east1 both experienced egress packet loss between 20% and 30%.\n**Google Cloud Storage (GCS)**\n* Between Thursday, 14 July 2022 21:57 US/Pacific and Friday, 15 July 12:40 US/Pacific, GCS customers may have experienced elevated latency, delays, issues importing, exporting or querying data from GCS buckets, and HTTP 500 errors in the Google Cloud regions of us-east1, southamerica-west1, and us-central2, and for buckets located in us-central1, us-east1, and nam4.\n* This disruption affected 0.007% of GCS requests and impacted customers reading/writing data and metadata.\n**Google BigQuery**\n* Customer workloads running in impacted Google Cloud regions and using the BigQuery Storage Read and Write APIs to read from or write to BigQuery may have experienced elevated latency.\n**Note**\n* Additional services may have been impacted by this event but did not meet the thresholds to be included in this report.","status":"AVAILABLE","affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"UwaYoXQ5bHYHG6EdiPB8","service_name":"Google Cloud Storage","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"}],"uri":"incidents/vLsxuKoRvykNHW3nnhsJ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"a9sMdFqr1mDB4vCB93M4","number":"7691610876520873903","begin":"2022-07-13T17:24:04+00:00","created":"2022-07-13T17:46:22+00:00","end":"2022-07-15T12:28:16+00:00","modified":"2022-07-15T12:28:17+00:00","external_desc":"Multi Region VMWare Engine - GCVE Firewall Status Failure","updates":[{"created":"2022-07-15T12:28:09+00:00","modified":"2022-07-15T12:28:21+00:00","when":"2022-07-15T12:28:09+00:00","text":"The issue with VMWare engine has been resolved for all affected projects as of Friday, 2022-07-15 05:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"created":"2022-07-13T19:53:45+00:00","modified":"2022-07-13T19:53:45+00:00","when":"2022-07-13T19:53:45+00:00","text":"Summary: Multi Region VMWare Engine - GCVE Firewall Status Failure\nDescription: Mitigation work is currently underway by our engineering team, a fix has been identified and is expected to be implemented Friday.\nWe will provide more information by Friday, 2022-07-15 08:00 US/Pacific.\nDiagnosis: When customers try to create or modify GCVE firewall, the operation will fail and will show firewall status as failed status after several minutes.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"created":"2022-07-13T18:14:53+00:00","modified":"2022-07-13T18:14:54+00:00","when":"2022-07-13T18:14:53+00:00","text":"Summary: Multi Region VMWare Engine - GCVE Firewall Status Failure\nDescription: We've received a report of an issue with VMWare engine as of Wednesday, 2022-07-13 10:24 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 13:00 US/Pacific.\nDiagnosis: When customers try to create or modify GCVE firewall, the operation will fail and will show firewall status as failed status after several minutes.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"created":"2022-07-13T18:14:34+00:00","modified":"2022-07-13T18:14:35+00:00","when":"2022-07-13T18:14:34+00:00","text":"Summary: Multi Region VMWare Engine - GCVE Firewall Status Failure\nDescription: We've received a report of an issue with VMWare engine as of Wednesday, 2022-07-13 10:24 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 13:00 US/Pacific.\nDiagnosis: When customers try to create or modify GCVE firewall, the operation will fail and will show firewall status as failed status after several minutes.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"created":"2022-07-13T17:48:12+00:00","modified":"2022-07-13T17:48:13+00:00","when":"2022-07-13T17:48:12+00:00","text":"Summary: Multi Region VMWare Engine - GCVE Firewall Status Failure\nDescription: We've received a report of an issue with VMWare engine as of Wednesday, 2022-07-13 10:24 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 13:00 US/Pacific.\nDiagnosis: When customers try to create or modify GCVE firewall, the operation will complete, however the firewall status will show as failed status after several minutes.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"created":"2022-07-13T17:46:16+00:00","modified":"2022-07-13T17:46:22+00:00","when":"2022-07-13T17:46:16+00:00","text":"Summary: Multi Region VMWare Engine - GVCE Firewall Status Failure\nDescription: We've received a report of an issue with VMWare engine as of Wednesday, 2022-07-13 10:24 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 13:00 US/Pacific.\nDiagnosis: When customers try to create or modify GCVE firewall, the operation will complete, however the firewall status will show as failed status after several minutes.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]}],"most_recent_update":{"created":"2022-07-15T12:28:09+00:00","modified":"2022-07-15T12:28:21+00:00","when":"2022-07-15T12:28:09+00:00","text":"The issue with VMWare engine has been resolved for all affected projects as of Friday, 2022-07-15 05:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"VMWare engine","id":"9H6gWUHvb2ZubeoxzQ1Y"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/a9sMdFqr1mDB4vCB93M4","currently_affected_locations":[],"previously_affected_locations":[{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"}]},{"id":"3GPGN5Vdj2bXGKm4ngpE","number":"13262905600359368227","begin":"2022-07-13T14:30:00+00:00","created":"2022-07-13T15:03:49+00:00","end":"2022-07-13T17:42:00+00:00","modified":"2022-09-26T22:09:26+00:00","external_desc":"Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1","updates":[{"created":"2022-07-13T20:36:26+00:00","modified":"2022-07-13T20:36:27+00:00","when":"2022-07-13T20:36:26+00:00","text":"The issue with Cloud Firestore has been resolved for all affected users as of Wednesday, 2022-07-13 13:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"created":"2022-07-13T18:30:43+00:00","modified":"2022-07-13T18:30:43+00:00","when":"2022-07-13T18:30:43+00:00","text":"Summary: Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-07-13 14:00 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 14:00 US/Pacific.\nDiagnosis: Customers may see increased rate of errors: \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential.\" in us-central1 and australia-southeast1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"created":"2022-07-13T16:18:24+00:00","modified":"2022-07-13T16:18:30+00:00","when":"2022-07-13T16:18:24+00:00","text":"Summary: Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-07-13 11:30 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 12:00 US/Pacific.\nDiagnosis: Customers may see increased rate of errors: \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential.\" in us-central1 and australia-southeast1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"created":"2022-07-13T15:23:28+00:00","modified":"2022-07-13T15:23:32+00:00","when":"2022-07-13T15:23:28+00:00","text":"Summary: Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-07-13 09:30 US/Pacific.\nWe will provide more information by Wednesday, 2022-07-13 09:22 US/Pacific.\nDiagnosis: Customers may see increased rate of errors: \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential.\" in us-central1 and australia-southeast1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"created":"2022-07-13T15:07:16+00:00","modified":"2022-07-13T15:07:26+00:00","when":"2022-07-13T15:07:16+00:00","text":"Summary: Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-07-13 09:30 US/Pacific.\nDiagnosis: Customers may see increased rate of errors: \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential.\" in us-central1 and australia-southeast1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"created":"2022-07-13T15:03:47+00:00","modified":"2022-07-13T15:03:51+00:00","when":"2022-07-13T15:03:47+00:00","text":"Summary: Cloud Firestore: authentication errors in Firestore API in us-central1 and australia-southeast1\nDescription: We are experiencing an issue with Cloud Firestore in us-central1 and australia-southeast1\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-07-13 09:00 US/Pacific with current details.\nDiagnosis: Customers may see increased rate of errors: \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential.\" in us-central1 and australia-southeast1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]}],"most_recent_update":{"created":"2022-07-13T20:36:26+00:00","modified":"2022-07-13T20:36:27+00:00","when":"2022-07-13T20:36:26+00:00","text":"The issue with Cloud Firestore has been resolved for all affected users as of Wednesday, 2022-07-13 13:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"CETSkT92V21G6A1x28me","service_name":"Cloud Firestore","affected_products":[{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/3GPGN5Vdj2bXGKm4ngpE","currently_affected_locations":[],"previously_affected_locations":[{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"}]},{"id":"AfU6Lhw8Sa3vfTk3oSK7","number":"6029436217795150449","begin":"2022-07-13T09:59:24+00:00","created":"2022-07-13T10:28:59+00:00","end":"2022-07-13T11:23:18+00:00","modified":"2022-07-13T11:23:18+00:00","external_desc":"Fabric programming rejected in us-central1.","updates":[{"created":"2022-07-13T11:23:10+00:00","modified":"2022-07-13T11:23:22+00:00","when":"2022-07-13T11:23:10+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Wednesday, 2022-07-13 04:22 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-07-13T11:12:27+00:00","modified":"2022-07-13T11:12:37+00:00","when":"2022-07-13T11:12:27+00:00","text":"Summary: Fabric programming rejected in us-central1.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-07-13 05:00 US/Pacific.\nDiagnosis: Changes to external IPs, such as new VMs with external IPs or changes to network load balances, in us-central1 are blocked or delayed for all customers in the region.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-07-13T10:28:51+00:00","modified":"2022-07-13T10:29:04+00:00","when":"2022-07-13T10:28:51+00:00","text":"Summary: Fabric programming rejected in us-central1.\nDescription: We are experiencing an issue with Google Cloud Networking.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-07-13 05:17 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Changes to external IPs, such as new VMs with external IPs or changes to network load balances, in us-central1 are blocked or delayed for all customers in the region.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-07-13T11:23:10+00:00","modified":"2022-07-13T11:23:22+00:00","when":"2022-07-13T11:23:10+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Wednesday, 2022-07-13 04:22 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/AfU6Lhw8Sa3vfTk3oSK7","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"ruHYNzJcn1TD2wSf3ncb","number":"9246742168398030682","begin":"2022-07-12T22:14:19+00:00","created":"2022-07-12T22:36:48+00:00","end":"2022-07-12T22:37:18+00:00","modified":"2022-07-12T22:37:18+00:00","external_desc":"Cloud Monitoring: Increased latency and errors","updates":[{"created":"2022-07-12T22:37:18+00:00","modified":"2022-07-12T22:37:18+00:00","when":"2022-07-12T22:37:18+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected projects as of Tuesday, 2022-07-12 14:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-12T22:36:43+00:00","modified":"2022-07-12T22:36:49+00:00","when":"2022-07-12T22:36:43+00:00","text":"Summary: Cloud Monitoring: Increased latency and errors\nDescription: We are experiencing an issue with Cloud Monitoring beginning at Tuesday, 2022-07-12 14:08 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-07-12 17:01 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may have experienced increased latency and errors for Cloud Monitoring services. Additionally, customers with write metric calls may see a gap in metrics for the impact period.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-07-12T22:37:18+00:00","modified":"2022-07-12T22:37:18+00:00","when":"2022-07-12T22:37:18+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected projects as of Tuesday, 2022-07-12 14:38 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"}],"uri":"incidents/ruHYNzJcn1TD2wSf3ncb","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"pNGXL7ecA1NEYTnSatj8","number":"15935317308708949851","begin":"2022-07-07T10:17:46+00:00","created":"2022-07-07T10:17:57+00:00","end":"2022-07-07T10:25:41+00:00","modified":"2022-07-07T10:25:41+00:00","external_desc":"Elevated TLS handshake latency in Google Cloud Networking","updates":[{"created":"2022-07-07T10:25:40+00:00","modified":"2022-07-07T10:25:44+00:00","when":"2022-07-07T10:25:40+00:00","text":"The issue with Google Cloud Networking is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-07T10:17:49+00:00","modified":"2022-07-07T10:18:00+00:00","when":"2022-07-07T10:17:49+00:00","text":"Summary: Elevated TLS handshake latency in Google Cloud Networking\nDescription: We are experiencing an issue with Google Cloud Networking.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-07 04:00 US/Pacific with current details.\nDiagnosis: Customers may experience elevated TLS handshake latency\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-07-07T10:25:40+00:00","modified":"2022-07-07T10:25:44+00:00","when":"2022-07-07T10:25:40+00:00","text":"The issue with Google Cloud Networking is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/pNGXL7ecA1NEYTnSatj8","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"tNca2hH1FeSKSvBTBDvq","number":"17839424974691831931","begin":"2022-07-07T10:01:11+00:00","created":"2022-07-07T10:14:17+00:00","end":"2022-07-07T10:18:22+00:00","modified":"2022-07-07T10:18:22+00:00","external_desc":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/pNGXL7ecA1NEYTnSatj8","updates":[{"created":"2022-07-07T10:18:13+00:00","modified":"2022-07-07T10:18:25+00:00","when":"2022-07-07T10:18:13+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/pNGXL7ecA1NEYTnSatj8","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-07-07T10:14:09+00:00","modified":"2022-07-07T10:14:19+00:00","when":"2022-07-07T10:14:09+00:00","text":"Summary: Elevated TLS handshake latency in Google Cloud Networking\nDescription: We are experiencing an issue with Google Cloud Networking.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-07-07 04:00 US/Pacific with current details.\nDiagnosis: Customers may experience elevated TLS handshake latency\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-07-07T10:18:13+00:00","modified":"2022-07-07T10:18:25+00:00","when":"2022-07-07T10:18:13+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/pNGXL7ecA1NEYTnSatj8","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/tNca2hH1FeSKSvBTBDvq","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"NLWrAcuy7i3T2ANQjFo3","number":"11303323485481356115","begin":"2022-07-06T20:37:15+00:00","created":"2022-07-06T20:50:54+00:00","end":"2022-07-06T21:03:30+00:00","modified":"2022-07-06T21:03:30+00:00","external_desc":"VMWare Engine portal unavailable.","updates":[{"created":"2022-07-06T21:03:29+00:00","modified":"2022-07-06T21:03:31+00:00","when":"2022-07-06T21:03:29+00:00","text":"The issue with VMWare engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-07-06T20:50:53+00:00","modified":"2022-07-06T20:50:55+00:00","when":"2022-07-06T20:50:53+00:00","text":"Summary: VMWare Engine portal unavailable.\nDescription: We are experiencing an issue with VMWare engine beginning at Wednesday, 2022-07-06 06:17 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-07-06 14:30 US/Pacific with current details.\nDiagnosis: Customers will not be able to access VMware Engine portal\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-07-06T21:03:29+00:00","modified":"2022-07-06T21:03:31+00:00","when":"2022-07-06T21:03:29+00:00","text":"The issue with VMWare engine is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"VMWare engine","id":"9H6gWUHvb2ZubeoxzQ1Y"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/NLWrAcuy7i3T2ANQjFo3","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"TaA75H7XA1DQyM2ReK2f","number":"15267780622191605299","begin":"2022-07-01T13:37:44+00:00","created":"2022-07-01T14:05:02+00:00","end":"2022-07-01T19:25:45+00:00","modified":"2022-07-01T19:25:45+00:00","external_desc":"[Google BigQuery] Lower throughput from the Read API","updates":[{"created":"2022-07-01T19:25:45+00:00","modified":"2022-07-01T19:25:46+00:00","when":"2022-07-01T19:25:45+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-07-01 12:23 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-01T17:48:07+00:00","modified":"2022-07-01T17:48:13+00:00","when":"2022-07-01T17:48:07+00:00","text":"Summary: [Google BigQuery] Lower throughput from the Read API\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2022-07-01 13:00 US/Pacific.\nDiagnosis: Customers may be observing lower throughput from the Read API\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-01T16:46:20+00:00","modified":"2022-07-01T16:46:21+00:00","when":"2022-07-01T16:46:20+00:00","text":"Summary: [Google BigQuery] Lower throughput from the Read API\nDescription: We believe our engineering team identified a potential fix and are working on rolling out the fix.\nWe do not have an ETA for mitigation at this point.\nWe will provide an update by Friday, 2022-07-01 11:00 US/Pacific with current details.\nDiagnosis: Customers may be observing lower throughput from the Read API\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-01T14:54:19+00:00","modified":"2022-07-01T14:54:24+00:00","when":"2022-07-01T14:54:19+00:00","text":"Summary: [Google BigQuery] Lower throughput from the Read API\nDescription: We believe our engineering team identified a potential fix and is currently testing it.\nWe do not have an ETA for test completion at this point.\nWe will provide an update by Friday, 2022-07-01 10:00 US/Pacific with current details.\nDiagnosis: Customers may be observing lower throughput from the Read API\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-07-01T14:04:53+00:00","modified":"2022-07-01T14:05:04+00:00","when":"2022-07-01T14:04:53+00:00","text":"Summary: [Google BigQuery] Lower throughput from the Read API\nDescription: We are experiencing an issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-07-01 07:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may be observing lower throughput from the Read API\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-07-01T19:25:45+00:00","modified":"2022-07-01T19:25:46+00:00","when":"2022-07-01T19:25:45+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-07-01 12:23 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/TaA75H7XA1DQyM2ReK2f","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"mDY7jN545et9XUV541MZ","number":"2463565635339146947","begin":"2022-06-30T18:12:00+00:00","created":"2022-06-30T18:45:06+00:00","end":"2022-07-01T02:15:28+00:00","modified":"2022-07-01T02:15:28+00:00","external_desc":"Intermittent Cloud Composer creation failures in select regions and elevated error rates during Cloud SQL instance creation.","updates":[{"created":"2022-07-01T02:15:28+00:00","modified":"2022-07-01T02:15:28+00:00","when":"2022-07-01T02:15:28+00:00","text":"We experienced an issue with Google Cloud Composer, Google Cloud SQL beginning at Thursday, 2022-06-28 09:00 US/Pacific.\nThe issue has been resolved for all affected users as of Thursday, 2022-06-30 19:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-07-01T00:50:56+00:00","modified":"2022-07-01T00:51:03+00:00","when":"2022-07-01T00:50:56+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions and elevated error rates during Cloud SQL instance creation.\nDescription: Mitigation work is underway by our engineering team.\nWe will provide more information by Thursday, 2022-06-30 20:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation. Customer may face errors stating \"databases already exist\" error upon retrying the creation of Composer.\nCustomer using Cloud SQL may see failures in calls shortly after database instance creation.\nWorkaround: Customers may retry the API calls for affected instances while using Cloud SQL.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-30T19:49:08+00:00","modified":"2022-06-30T19:49:10+00:00","when":"2022-06-30T19:49:08+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions and elevated error rates during Cloud SQL instance creation.\nDescription: Our engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Thursday, 2022-06-30 18:00 US/Pacific with current details.\nDiagnosis: Customers may experience latency and errors with Composer creation. Customer may face errors stating \"databases already exist\" error upon retrying the creation of Composer.\nCustomer using Cloud SQL may see failures in calls shortly after database instance creation.\nWorkaround: Customers may retry the API calls for affected instances while using Cloud SQL.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-30T19:04:16+00:00","modified":"2022-06-30T19:04:23+00:00","when":"2022-06-30T19:04:16+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions and elevated error rates during Cloud SQL instance creation.\nDescription: Mitigation work is still underway by our engineering team. We will provide more information by Thursday, 2022-06-30 13:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation. Customer may face errors stating \"databases already exist\" error upon retrying the creation of Composer.\nCustomer using Cloud SQL may see failures in calls shortly after database instance creation.\nWorkaround: Customers may retry the API calls for affected instances while using Cloud SQL.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-30T18:45:05+00:00","modified":"2022-06-30T18:45:08+00:00","when":"2022-06-30T18:45:05+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: Mitigation work is still underway by our engineering team. We will provide more information by Thursday, 2022-06-30 13:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-07-01T02:15:28+00:00","modified":"2022-07-01T02:15:28+00:00","when":"2022-07-01T02:15:28+00:00","text":"We experienced an issue with Google Cloud Composer, Google Cloud SQL beginning at Thursday, 2022-06-28 09:00 US/Pacific.\nThe issue has been resolved for all affected users as of Thursday, 2022-06-30 19:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"},{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/mDY7jN545et9XUV541MZ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"sPyYB214xAhqnoxNrrnW","number":"8795563426724731296","begin":"2022-06-29T20:54:00+00:00","created":"2022-06-29T22:14:46+00:00","end":"2022-06-29T22:59:00+00:00","modified":"2022-06-30T18:13:20+00:00","external_desc":"Global: Apigee X is experiencing issues with integrated portals and API Monitoring.","updates":[{"created":"2022-06-30T18:13:17+00:00","modified":"2022-06-30T18:13:17+00:00","when":"2022-06-30T18:13:17+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 29 June 2022 13:54\n**Incident End:** 29 June 2022 15:59\n**Duration:** 2 hours, 5 minutes\n**Affected Services and Features:**\nGoogle Cloud Apigee Integrated Portals\n**Regions/Zones:** Global/ All Regions\n**Description:**\nGoogle Cloud Apigee experienced intermittent errors while accessing Integrated Portals. From preliminary analysis, the root cause of the issue was an SSL certificate for an internal Apigee service not properly rotated.\n**Customer Impact:**\nIntermittent errors accessing Integrated Portals","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-29T23:11:51+00:00","modified":"2022-06-29T23:11:52+00:00","when":"2022-06-29T23:11:51+00:00","text":"The issue with Apigee has been resolved for all affected users as of Wednesday, 2022-06-29 16:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-29T22:33:21+00:00","modified":"2022-06-29T22:33:27+00:00","when":"2022-06-29T22:33:21+00:00","text":"Summary: Global: Apigee X is experiencing issues with integrated portals and API Monitoring.\nDescription: We are experiencing an issue with Apigee X beginning at Wednesday, 2022-06-29 13:54 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-06-29 16:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience intermittent failures when trying to access portal pages via the UI or APIs\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-29T22:14:41+00:00","modified":"2022-06-29T22:14:47+00:00","when":"2022-06-29T22:14:41+00:00","text":"Summary: Global: Apigee X is experiencing issues with integrated portals.\nDescription: We are experiencing an issue with Apigee X beginning at Wednesday, 2022-06-29 13:54 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-06-29 15:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience intermittent failures when trying to access portal pages\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-30T18:13:17+00:00","modified":"2022-06-30T18:13:17+00:00","when":"2022-06-30T18:13:17+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 29 June 2022 13:54\n**Incident End:** 29 June 2022 15:59\n**Duration:** 2 hours, 5 minutes\n**Affected Services and Features:**\nGoogle Cloud Apigee Integrated Portals\n**Regions/Zones:** Global/ All Regions\n**Description:**\nGoogle Cloud Apigee experienced intermittent errors while accessing Integrated Portals. From preliminary analysis, the root cause of the issue was an SSL certificate for an internal Apigee service not properly rotated.\n**Customer Impact:**\nIntermittent errors accessing Integrated Portals","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9Y13BNFy4fJydvjdsN3X","service_name":"Apigee","affected_products":[{"title":"Apigee","id":"9Y13BNFy4fJydvjdsN3X"}],"uri":"incidents/sPyYB214xAhqnoxNrrnW","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"V3AJNVDysYF1EXttKC3N","number":"6035749805300313659","begin":"2022-06-29T18:29:36+00:00","created":"2022-06-29T18:29:38+00:00","end":"2022-06-30T18:42:09+00:00","modified":"2022-06-30T18:42:09+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-06-30T18:42:09+00:00","modified":"2022-06-30T18:42:11+00:00","when":"2022-06-30T18:42:09+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-30T16:57:20+00:00","modified":"2022-06-30T16:57:28+00:00","when":"2022-06-30T16:57:20+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Thursday, 2022-06-30 13:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-30T13:22:58+00:00","modified":"2022-06-30T13:23:08+00:00","when":"2022-06-30T13:22:58+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Thursday, 2022-06-30 10:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-29T22:53:32+00:00","modified":"2022-06-29T22:53:33+00:00","when":"2022-06-29T22:53:32+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: Engineering has identified the root cause and mitigation work is currently underway.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-06-30 07:00 US/Pacific.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-29T22:43:04+00:00","modified":"2022-06-29T22:43:04+00:00","when":"2022-06-29T22:43:04+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: We are experiencing an intermittent issue with Google Cloud Composer creation failures due to latency for CloudSQL Database creations.\nOur engineering team continues to investigate the issue and root cause.\nWe will provide an update by Wednesday, 2022-06-29 19:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-29T20:53:26+00:00","modified":"2022-06-29T20:53:29+00:00","when":"2022-06-29T20:53:26+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: We are experiencing an intermittent issue with Google Cloud Composer creation failures due to latency for CloudSQL Database creations.\nOur engineering team continues to investigate the issue and root cause.\nWe will provide an update by Wednesday, 2022-06-29 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-29T18:47:44+00:00","modified":"2022-06-29T18:47:46+00:00","when":"2022-06-29T18:47:44+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: We are experiencing an intermittent issue with Google Cloud Composer creation failures due to latency for CloudSQL Database creations.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-06-29 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-29T18:29:37+00:00","modified":"2022-06-29T18:29:40+00:00","when":"2022-06-29T18:29:37+00:00","text":"Summary: Intermittent Cloud Composer creation failures in select regions\nDescription: We are experiencing an intermittent issue with Google Cloud Composer creation failures due to latency for CloudSQL Database creations.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Wednesday, 2022-06-29 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience latency and errors with Composer creation.\nWorkaround: Customers may retry the Composer creation operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-06-30T18:42:09+00:00","modified":"2022-06-30T18:42:11+00:00","when":"2022-06-30T18:42:09+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"YxkG5FfcC42cQmvBCk4j","service_name":"Google Cloud Composer","affected_products":[{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"}],"uri":"incidents/V3AJNVDysYF1EXttKC3N","currently_affected_locations":[],"previously_affected_locations":[{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"pXUM8jeE61fpp3VXz5sr","number":"14057655586445957884","begin":"2022-06-28T16:08:29+00:00","created":"2022-06-28T16:46:51+00:00","end":"2022-06-28T17:04:17+00:00","modified":"2022-06-28T17:04:18+00:00","external_desc":"Elevated packet loss in europe-north1","updates":[{"created":"2022-06-28T17:04:11+00:00","modified":"2022-06-28T17:04:19+00:00","when":"2022-06-28T17:04:11+00:00","text":"The issue with Google Cloud Networking, Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-28 09:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Finland (europe-north1)","id":"europe-north1"}]},{"created":"2022-06-28T16:46:45+00:00","modified":"2022-06-28T16:46:53+00:00","when":"2022-06-28T16:46:45+00:00","text":"Summary: Elevated packet loss in europe-north1\nDescription: We are experiencing an issue with Google Cloud Networking.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-28 10:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience packet loss.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Finland (europe-north1)","id":"europe-north1"}]}],"most_recent_update":{"created":"2022-06-28T17:04:11+00:00","modified":"2022-06-28T17:04:19+00:00","when":"2022-06-28T17:04:11+00:00","text":"The issue with Google Cloud Networking, Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-28 09:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Finland (europe-north1)","id":"europe-north1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/pXUM8jeE61fpp3VXz5sr","currently_affected_locations":[],"previously_affected_locations":[{"title":"Finland (europe-north1)","id":"europe-north1"}]},{"id":"mbtvSs2qKE3Nz6nxR6rY","number":"3478893343316437994","begin":"2022-06-28T09:55:31+00:00","created":"2022-06-28T10:20:33+00:00","end":"2022-06-28T10:25:35+00:00","modified":"2022-06-28T10:25:35+00:00","external_desc":"We are experiencing an issue with Hybrid Connectivity specifically in Geneva.","updates":[{"created":"2022-06-28T10:25:30+00:00","modified":"2022-06-28T10:25:35+00:00","when":"2022-06-28T10:25:30+00:00","text":"The issue with Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-28 03:02 US/Pacific. The impact was limited to Cloud Interconnect customers peering in Equinix GV2, Geneva West.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-06-28T10:20:32+00:00","modified":"2022-06-28T10:20:33+00:00","when":"2022-06-28T10:20:32+00:00","text":"Summary: We are experiencing an issue with Hybrid Connectivity specifically in Geneva\nDescription: We are experiencing an issue with Hybrid Connectivity beginning at Tuesday, 2022-06-28 02:31 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-28 04:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers might experience packet loss of 30-80%\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-06-28T10:25:30+00:00","modified":"2022-06-28T10:25:35+00:00","when":"2022-06-28T10:25:30+00:00","text":"The issue with Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-28 03:02 US/Pacific. The impact was limited to Cloud Interconnect customers peering in Equinix GV2, Geneva West.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/mbtvSs2qKE3Nz6nxR6rY","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"6ocKuGf4LTJTjaB84Ms4","number":"12615573420888182146","begin":"2022-06-27T22:33:40+00:00","created":"2022-06-27T22:54:59+00:00","end":"2022-06-28T14:04:37+00:00","modified":"2022-06-28T14:04:38+00:00","external_desc":"Cloud Function 2nd Generation deletes were erroring out in multiple regions.","updates":[{"created":"2022-06-28T14:04:35+00:00","modified":"2022-06-28T14:04:40+00:00","when":"2022-06-28T14:04:35+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Tuesday, 2022-06-28 01:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T10:30:11+00:00","modified":"2022-06-28T10:30:12+00:00","when":"2022-06-28T10:30:11+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-06-28 09:30 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T08:59:43+00:00","modified":"2022-06-28T08:59:43+00:00","when":"2022-06-28T08:59:43+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-06-28 04:30 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T04:36:01+00:00","modified":"2022-06-28T04:36:02+00:00","when":"2022-06-28T04:36:01+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-06-28 02:00 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T02:41:12+00:00","modified":"2022-06-28T02:41:13+00:00","when":"2022-06-28T02:41:12+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-06-27 22:00 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T02:16:35+00:00","modified":"2022-06-28T02:16:35+00:00","when":"2022-06-28T02:16:35+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-06-27 20:00 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-28T00:32:38+00:00","modified":"2022-06-28T00:32:39+00:00","when":"2022-06-28T00:32:38+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-06-27 19:17 US/Pacific.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-27T23:46:21+00:00","modified":"2022-06-27T23:46:22+00:00","when":"2022-06-27T23:46:21+00:00","text":"Summary: Cloud Function 2nd Generation deletes are erroring out in multiple regions.\nDescription: We are experiencing an issue impacting Google Cloud Functions 2nd Generation beginning at Thursday, 2022-06-23 18:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-06-27 17:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-27T23:26:49+00:00","modified":"2022-06-27T23:26:55+00:00","when":"2022-06-27T23:26:49+00:00","text":"Summary: Cloud Function deletes are erroring out in multiple regions.\nDescription: We are experiencing an issue with Google Cloud Functions beginning at Thursday, 2022-06-23 18:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-06-27 17:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-27T22:54:53+00:00","modified":"2022-06-27T22:55:00+00:00","when":"2022-06-27T22:54:53+00:00","text":"Summary: Cloud Function deletes are erroring out in multiple regions.\nDescription: We are experiencing an issue with Google Cloud Functions beginning at Thursday, 2022-06-23 18:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-06-27 16:33 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Delete function operations are erroring with following message although the corresponding resources are getting deleted and customers are able to reuse the function name\nError message:\nOperation Failed. Public Error Status: code: 5 message: Delete package operation for projects/[PROJECT_ID]/locations/[REGION]/repositories/gcf-artifacts/packages/[FUNCTION_ID]%2Fcustom-run has failed. Additional information: Requested entity was not found.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-06-28T14:04:35+00:00","modified":"2022-06-28T14:04:40+00:00","when":"2022-06-28T14:04:35+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Tuesday, 2022-06-28 01:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"oW4vJ7VNqyxTWNzSHopX","service_name":"Google Cloud Functions","affected_products":[{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/6ocKuGf4LTJTjaB84Ms4","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"fh6jfua8BdRbCkwTegBy","number":"8449268330911625257","begin":"2022-06-24T10:37:31+00:00","created":"2022-06-24T11:12:42+00:00","end":"2022-06-29T08:56:17+00:00","modified":"2022-06-29T08:56:17+00:00","external_desc":"Cloud Redis BASIC Tier Instances cannot proceed version upgrade after their maintenance or capacity update","updates":[{"created":"2022-06-29T08:56:12+00:00","modified":"2022-06-29T08:56:19+00:00","when":"2022-06-29T08:56:12+00:00","text":"We experienced an intermittent issue with Cloud Memorystore beginning at Wednesday, 2022-06-22 21:42 US/Pacific.\nThe issue has been resolved for all affected projects as of Wednesday, 2022-06-29 01:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-24T11:12:39+00:00","modified":"2022-06-24T11:12:45+00:00","when":"2022-06-24T11:12:39+00:00","text":"Summary: Cloud Redis BASIC Tier Instances cannot proceed version upgrade after their maintenance or capacity update\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-07-01 06:00 US/Pacific.\nWe will provide more information by Wednesday, 2022-06-29 06:00 US/Pacific.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Once the Basic Tier Instance went through a maintenance or a capacity update, it will fail all the version upgrade requests due to internal error (with code 13).\nVersion upgrade behavior can be found under: https://cloud.google.com/memorystore/docs/redis/version-upgrade-behavior\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-29T08:56:12+00:00","modified":"2022-06-29T08:56:19+00:00","when":"2022-06-29T08:56:12+00:00","text":"We experienced an intermittent issue with Cloud Memorystore beginning at Wednesday, 2022-06-22 21:42 US/Pacific.\nThe issue has been resolved for all affected projects as of Wednesday, 2022-06-29 01:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"LGPLu3M5pcUAKU1z6eP3","service_name":"Cloud Memorystore","affected_products":[{"title":"Cloud Memorystore","id":"LGPLu3M5pcUAKU1z6eP3"}],"uri":"incidents/fh6jfua8BdRbCkwTegBy","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"drLHg29pR5QHUvr5buDq","number":"17340949811212957340","begin":"2022-06-23T07:13:00+00:00","created":"2022-06-23T11:02:49+00:00","end":"2022-06-23T13:36:00+00:00","modified":"2022-06-24T21:44:18+00:00","external_desc":"vSphere vCenter and NSX may not have been available for a short period of time in us-central1","updates":[{"created":"2022-06-23T21:57:00+00:00","modified":"2022-06-23T21:57:00+00:00","when":"2022-06-23T21:57:00+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 23 June 2022 00:13 PT\n**Incident End:** 23 June 2022 06:36 PT\n**Duration:** 6 hours, 23 minutes\n**Affected Services and Features:**\nVMWare Engine\n**Regions/Zones:** us-central1a\n**Description:**\nGoogle Cloud customers using VMWare Engine experienced connectivity issues while using vSphere, vCenter and NSX in us-central1a zone for a duration of 6 hours, 23 minutes.\nFrom preliminary analysis, the issue was caused due to a network switch-over not working as expected during a planned maintenance window of ToR switches. The issue was mitigated by performing a file system recovery and restart of related services on the resources hosted by Google Cloud VMware Engine.\n**Customer Impact:**\n- Affected Customers may have observed issues with network partitions and accessing workload VMs.\n- Affected Customers may have experienced connectivity issues using vCenter, HCX, NSX Manager, and NSX-T Edge virtual machines.\n**Additional details:**\nGoogle engineers have paused the maintenance upgrade and also all redundant devices have been brought back to operational state. We are also working with the impacted customers to check the state of remaining workload VMs and shall assist in recovery if required.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-23T13:36:43+00:00","modified":"2022-06-23T13:36:57+00:00","when":"2022-06-23T13:36:43+00:00","text":"The issue with VMWare engine has been resolved for all affected projects as of Thursday, 2022-06-23 06:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-23T11:02:40+00:00","modified":"2022-06-23T11:02:52+00:00","when":"2022-06-23T11:02:40+00:00","text":"Summary: vSphere vCenter and NSX may not have been available for a short period of time in us-central1\nDescription: We are experiencing an issue with VMWare engine beginning at Thursday, 2022-06-23 07:13 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-23 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: vSphere vCenter and NSX may not have been available for a short period of time in us-central1, vCenter VMs has been recovered. Some of the Workload VMs might be still impacted.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-06-23T21:57:00+00:00","modified":"2022-06-23T21:57:00+00:00","when":"2022-06-23T21:57:00+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 23 June 2022 00:13 PT\n**Incident End:** 23 June 2022 06:36 PT\n**Duration:** 6 hours, 23 minutes\n**Affected Services and Features:**\nVMWare Engine\n**Regions/Zones:** us-central1a\n**Description:**\nGoogle Cloud customers using VMWare Engine experienced connectivity issues while using vSphere, vCenter and NSX in us-central1a zone for a duration of 6 hours, 23 minutes.\nFrom preliminary analysis, the issue was caused due to a network switch-over not working as expected during a planned maintenance window of ToR switches. The issue was mitigated by performing a file system recovery and restart of related services on the resources hosted by Google Cloud VMware Engine.\n**Customer Impact:**\n- Affected Customers may have observed issues with network partitions and accessing workload VMs.\n- Affected Customers may have experienced connectivity issues using vCenter, HCX, NSX Manager, and NSX-T Edge virtual machines.\n**Additional details:**\nGoogle engineers have paused the maintenance upgrade and also all redundant devices have been brought back to operational state. We are also working with the impacted customers to check the state of remaining workload VMs and shall assist in recovery if required.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"VMWare engine","id":"9H6gWUHvb2ZubeoxzQ1Y"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/drLHg29pR5QHUvr5buDq","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"58JrPVZpPTo1S6xJoiMj","number":"10942582489061747224","begin":"2022-06-21T10:22:58+00:00","created":"2022-06-21T12:21:50+00:00","end":"2022-06-21T15:05:39+00:00","modified":"2022-06-21T15:05:40+00:00","external_desc":"Cloud Router route priorities being wrong","updates":[{"created":"2022-06-21T15:05:37+00:00","modified":"2022-06-21T15:05:45+00:00","when":"2022-06-21T15:05:37+00:00","text":"The issue with Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-21 07:45 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-21T13:48:26+00:00","modified":"2022-06-21T13:48:33+00:00","when":"2022-06-21T13:48:26+00:00","text":"Summary: Cloud Router route priorities being wrong\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2022-06-21 09:00 US/Pacific.\nWe will provide more information by Tuesday, 2022-06-21 09:00 US/Pacific.\nDiagnosis: Route priorities between regions can differ between HA0 and HA1 attachments within GCP and thus traffic might flow in unexpected way\nWorkaround: Adjust route priorities or shutdown secondary paths","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-21T13:00:32+00:00","modified":"2022-06-21T13:00:43+00:00","when":"2022-06-21T13:00:32+00:00","text":"Summary: Cloud Router route priorities being wrong\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Tuesday, 2022-06-21 07:00 US/Pacific.\nDiagnosis: Route priorities between regions can differ between HA0 and HA1 attachments within GCP and thus traffic might flow in unexpected way\nWorkaround: Adjust route priorities or shutdown secondary paths","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-21T12:21:41+00:00","modified":"2022-06-21T12:21:52+00:00","when":"2022-06-21T12:21:41+00:00","text":"Summary: Cloud Router route priorities being wrong\nDescription: We are experiencing an issue with Hybrid Connectivity beginning at Friday, 2022-06-17 17:15 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-21 06:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Route priorities between regions can differ between HA0 and HA1 attachments within GCP and thus traffic might flow in unexpected way\nWorkaround: Adjust route priorities or shutdown secondary paths","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-21T15:05:37+00:00","modified":"2022-06-21T15:05:45+00:00","when":"2022-06-21T15:05:37+00:00","text":"The issue with Hybrid Connectivity has been resolved for all affected users as of Tuesday, 2022-06-21 07:45 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/58JrPVZpPTo1S6xJoiMj","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"DXiQQW2ipyeeNsq9RFxz","number":"11865608804010450284","begin":"2022-06-19T19:01:38+00:00","created":"2022-06-19T19:03:51+00:00","end":"2022-06-19T21:27:53+00:00","modified":"2022-06-20T11:52:17+00:00","external_desc":"Google engineer are currently investigating a issue with the cloud networking product","updates":[{"created":"2022-06-20T11:52:17+00:00","modified":"2022-06-20T11:52:17+00:00","when":"2022-06-20T11:52:17+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 19 June 2022 10:14\n**Incident End:** 19 June 2022 13:39\n**Duration:** 3 hours, 25 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking.\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced an issue with the Cloud Armour config changes that got stalled for a duration of 3 hours, 25 minutes. From preliminary analysis, the root cause of the issue is Google Cloud Armor Configuration Server experienced errors in writing configs to the config storage system.\n**Customer Impact:**\nCustomer configs propagation depending on the dos_cloud configs got delayed.\nSome impacted customers would not be able to make Cloud Armor config changes.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T21:27:52+00:00","modified":"2022-06-19T21:27:57+00:00","when":"2022-06-19T21:27:52+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected projects as of Sunday, 2022-06-19 14:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T20:31:14+00:00","modified":"2022-06-19T20:31:21+00:00","when":"2022-06-19T20:31:14+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Sunday, 2022-06-19 14:30 US/Pacific.\nDiagnosis: Customer configs propagation depending on the dos_cloud configs is delayed.\nCustomer will be able to make cloud armour config changes but expect higher latency for backlog to clear\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T20:30:47+00:00","modified":"2022-06-19T20:30:51+00:00","when":"2022-06-19T20:30:47+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Sunday, 2022-06-19 14:30 US/Pacific.\nDiagnosis: Customer configs propagation depending on the dos_cloud configs is delayed.\nCustomer will be able to make cloud armour config changes but expect higher latency for backlog to clear\nCustomer configs propagation depending on the dos_cloud configs is delayed.\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T20:00:08+00:00","modified":"2022-06-19T20:00:18+00:00","when":"2022-06-19T20:00:08+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Sunday, 2022-06-19 13:40 US/Pacific.\nDiagnosis: Customer are unable to make cloud armour config changes globally.\nCustomer configs propagation depending on the dos_cloud configs is delayed.\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T19:47:37+00:00","modified":"2022-06-19T19:47:50+00:00","when":"2022-06-19T19:47:37+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Sunday, 2022-06-19 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-19 13:35 US/Pacific with current details.\nDiagnosis: Customer are unable to make cloud armour config changes globally.\nCustomer configs propagation depending on the dos_cloud configs is delayed.\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T19:10:21+00:00","modified":"2022-06-19T19:10:26+00:00","when":"2022-06-19T19:10:21+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Sunday, 2022-06-19 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-19 13:35 US/Pacific with current details.\nDiagnosis: Customer are unable to make cloud armour config changes globally.\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-19T19:03:43+00:00","modified":"2022-06-19T19:03:55+00:00","when":"2022-06-19T19:03:43+00:00","text":"Summary: Google engineer are currently investigating a issue with the cloud networking product\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Sunday, 2022-06-19 00:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-19 13:35 US/Pacific with current details.\nDiagnosis: Customer are unable to make cloud amour config changes globally.\nWorkaround: n/a","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-20T11:52:17+00:00","modified":"2022-06-20T11:52:17+00:00","when":"2022-06-20T11:52:17+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 19 June 2022 10:14\n**Incident End:** 19 June 2022 13:39\n**Duration:** 3 hours, 25 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking.\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced an issue with the Cloud Armour config changes that got stalled for a duration of 3 hours, 25 minutes. From preliminary analysis, the root cause of the issue is Google Cloud Armor Configuration Server experienced errors in writing configs to the config storage system.\n**Customer Impact:**\nCustomer configs propagation depending on the dos_cloud configs got delayed.\nSome impacted customers would not be able to make Cloud Armor config changes.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/DXiQQW2ipyeeNsq9RFxz","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"sY4rnjxM4pSudhn6LZUA","number":"7149754702357146867","begin":"2022-06-16T18:14:59+00:00","created":"2022-06-16T18:26:23+00:00","end":"2022-06-16T23:25:47+00:00","modified":"2022-06-16T23:25:47+00:00","external_desc":"[Global] Cloud Spanner backups restore operations may be delayed.","updates":[{"created":"2022-06-16T23:25:47+00:00","modified":"2022-06-16T23:25:48+00:00","when":"2022-06-16T23:25:47+00:00","text":"The issue with Cloud Spanner latencies on backup restore operations has been resolved for all affected projects as of Thursday, 2022-06-16 15:40 US/Pacific.\nIf you have further questions, or need immediate assistance please open a case with the support team and we will work with you.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T19:51:43+00:00","modified":"2022-06-16T19:51:44+00:00","when":"2022-06-16T19:51:43+00:00","text":"Summary: [Global] Cloud Spanner backups restore operations may be delayed up to 3 Hours\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-06-16 17:00 US/Pacific.\nDiagnosis: Cloud Spanner Backups Restore Operations May Be Delayed Up to 3 Hours\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T19:50:48+00:00","modified":"2022-06-16T19:50:49+00:00","when":"2022-06-16T19:50:48+00:00","text":"Summary: [Global] Cloud Spanner backups restore operations may be delayed up to 3 Hours\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-06-16 15:00 US/Pacific.\nDiagnosis: Cloud Spanner Backups Restore Operations May Be Delayed Up to 3 Hours\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T18:26:22+00:00","modified":"2022-06-16T18:26:23+00:00","when":"2022-06-16T18:26:22+00:00","text":"Summary: [Global] Cloud Spanner backups restore operations may be delayed up to 3 Hours\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-06-16 13:00 US/Pacific.\nDiagnosis: Cloud Spanner Backups Restore Operations May Be Delayed Up to 3 Hours\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-16T23:25:47+00:00","modified":"2022-06-16T23:25:48+00:00","when":"2022-06-16T23:25:47+00:00","text":"The issue with Cloud Spanner latencies on backup restore operations has been resolved for all affected projects as of Thursday, 2022-06-16 15:40 US/Pacific.\nIf you have further questions, or need immediate assistance please open a case with the support team and we will work with you.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"EcNGGUgBtBLrtm4mWvqC","service_name":"Cloud Spanner","affected_products":[{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"}],"uri":"incidents/sY4rnjxM4pSudhn6LZUA","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"iAgVMxJUfE1J9et7j9KB","number":"13909014623288227313","begin":"2022-06-16T08:11:00+00:00","created":"2022-06-16T09:46:24+00:00","end":"2022-06-16T09:44:00+00:00","modified":"2022-06-17T00:10:46+00:00","external_desc":"Google Cloud Networking packet loss issue","updates":[{"created":"2022-06-17T00:10:38+00:00","modified":"2022-06-17T00:10:38+00:00","when":"2022-06-17T00:10:38+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 16 June 2022 01:11\n**Incident End:** 16 June 2022 02:44\n**Duration:** 1 hour, 33 minutes\n**Affected Services and Features:**\n- Google Cloud Networking\n- Cloud Monitoring\n- Cloud NAT\n- Hybrid Connectivity\n- Cloud Run\n- Cloud Interconnect\n- Virtual Private Cloud (VPC)\n- Gmail\n- Cloud Bigtable\n**Regions/Zones:** Europe and Asia\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss and latency with Google Cloud Services across Europe and Asia for a duration of 1 hour, 36 minutes. Any service that uses Cloud Networking may have observed impact. We have included available details of service specific impact below; however, this may not be a comprehensive accounting of all downstream networking impact.\nFrom preliminary analysis, the root cause of the issue was due to a large reconvergence event on our user facing backbone, which was triggered by a typical fiber cut in North America. The failure resulted in packet loss due to either some MPLS tunnels going down, or due to congestion on remaining tunnels that quickly grew to accommodate demand on next-best paths. Tunnels going down is not expected behavior of MPLS control plane in response to best-path capacity going down when adjacent capacity remains available and is being investigated with highest priority with the hardware vendor. Mitigation of the packet loss required Google engineers to manually intervene on the network control plane. The underlying Cloud Networking impact ended at 02:58, however, some Cloud Services may have taken longer to recover.\nDue to backbone control plane behavior during this event, network forwarding may have been suboptimal for some destinations resulting in higher network latency.\n**Customer Impact:**\n- **Google Cloud Networking** - Public IP traffic connectivity failed from 01:22 to 02:58 US/Pacific.\n- **Cloud Monitoring** - Affected customers observed metric data failing to publish in europe-north1.\n- **Cloud NAT** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Hybrid Connectivity** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Cloud Run** - Affected customers experienced packet loss in europe-north1.\n- **Cloud Interconnect** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Virtual Private Cloud (VPC)** - Affected customers experienced up to 100% packet loss with traffic between Europe and Asia over private and public IP.\n- **Cloud Bigtable** - Affected customers experienced elevated latency with read and write operations in europe-north1.\n- **Gmail** - Affected web client users experienced transient service unavailability.\n**Additional details:**\nFiber cuts on the Google network are quite common with no observable malfunction to the MPLS control plane. This incident surfaces a novel MPLS control plane behavior. We are committed to fully identifying the root cause and addressing it to prevent it with our partners.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Finland (europe-north1)","id":"europe-north1"}]},{"created":"2022-06-16T10:03:47+00:00","modified":"2022-06-16T10:03:57+00:00","when":"2022-06-16T10:03:47+00:00","text":"The issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) has been resolved for all affected projects as of Thursday, 2022-06-16 03:02 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Finland (europe-north1)","id":"europe-north1"}]},{"created":"2022-06-16T09:46:13+00:00","modified":"2022-06-16T09:46:26+00:00","when":"2022-06-16T09:46:13+00:00","text":"Summary: Google Cloud Networking packet loss issue\nDescription: We are experiencing an issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) beginning at Thursday, 2022-06-16 01:11 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-16 03:15 US/Pacific with current details.\nDiagnosis: The customers may experience persistent packet loss for some connection flows\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Finland (europe-north1)","id":"europe-north1"}]}],"most_recent_update":{"created":"2022-06-17T00:10:38+00:00","modified":"2022-06-17T00:10:38+00:00","when":"2022-06-17T00:10:38+00:00","text":"# MINI INCIDENT REPORT\nWe apologize for the inconvenience this service disruption/outage caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 16 June 2022 01:11\n**Incident End:** 16 June 2022 02:44\n**Duration:** 1 hour, 33 minutes\n**Affected Services and Features:**\n- Google Cloud Networking\n- Cloud Monitoring\n- Cloud NAT\n- Hybrid Connectivity\n- Cloud Run\n- Cloud Interconnect\n- Virtual Private Cloud (VPC)\n- Gmail\n- Cloud Bigtable\n**Regions/Zones:** Europe and Asia\n**Description:**\nGoogle Cloud Networking experienced elevated packet loss and latency with Google Cloud Services across Europe and Asia for a duration of 1 hour, 36 minutes. Any service that uses Cloud Networking may have observed impact. We have included available details of service specific impact below; however, this may not be a comprehensive accounting of all downstream networking impact.\nFrom preliminary analysis, the root cause of the issue was due to a large reconvergence event on our user facing backbone, which was triggered by a typical fiber cut in North America. The failure resulted in packet loss due to either some MPLS tunnels going down, or due to congestion on remaining tunnels that quickly grew to accommodate demand on next-best paths. Tunnels going down is not expected behavior of MPLS control plane in response to best-path capacity going down when adjacent capacity remains available and is being investigated with highest priority with the hardware vendor. Mitigation of the packet loss required Google engineers to manually intervene on the network control plane. The underlying Cloud Networking impact ended at 02:58, however, some Cloud Services may have taken longer to recover.\nDue to backbone control plane behavior during this event, network forwarding may have been suboptimal for some destinations resulting in higher network latency.\n**Customer Impact:**\n- **Google Cloud Networking** - Public IP traffic connectivity failed from 01:22 to 02:58 US/Pacific.\n- **Cloud Monitoring** - Affected customers observed metric data failing to publish in europe-north1.\n- **Cloud NAT** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Hybrid Connectivity** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Cloud Run** - Affected customers experienced packet loss in europe-north1.\n- **Cloud Interconnect** - Affected customers experienced packet loss on some flows between regions in Europe, South America, and North America.\n- **Virtual Private Cloud (VPC)** - Affected customers experienced up to 100% packet loss with traffic between Europe and Asia over private and public IP.\n- **Cloud Bigtable** - Affected customers experienced elevated latency with read and write operations in europe-north1.\n- **Gmail** - Affected web client users experienced transient service unavailability.\n**Additional details:**\nFiber cuts on the Google network are quite common with no observable malfunction to the MPLS control plane. This incident surfaces a novel MPLS control plane behavior. We are committed to fully identifying the root cause and addressing it to prevent it with our partners.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Finland (europe-north1)","id":"europe-north1"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud NAT","id":"hCNpnTQHkUCCGxJy35Yq"}],"uri":"incidents/iAgVMxJUfE1J9et7j9KB","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Finland (europe-north1)","id":"europe-north1"}]},{"id":"Lvd7FBrPJmL7oxhqrDwt","number":"15199014936264361317","begin":"2022-06-14T18:40:51+00:00","created":"2022-06-14T18:55:08+00:00","end":"2022-06-15T00:22:31+00:00","modified":"2022-06-15T00:22:31+00:00","external_desc":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/fc7GCA6kAgnBihezUAkx","updates":[{"created":"2022-06-15T00:22:30+00:00","modified":"2022-06-15T00:22:32+00:00","when":"2022-06-15T00:22:30+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/fc7GCA6kAgnBihezUAkx","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T21:38:08+00:00","modified":"2022-06-14T21:38:09+00:00","when":"2022-06-14T21:38:08+00:00","text":"Summary: Customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-06-14 08:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 18:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nWorkaround: Affected customers can create instances in another region.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T20:43:19+00:00","modified":"2022-06-14T20:43:20+00:00","when":"2022-06-14T20:43:19+00:00","text":"Summary: Customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-06-14 08:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 14:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nWorkaround: Affected customers can create instances in another region.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T19:44:29+00:00","modified":"2022-06-14T19:44:30+00:00","when":"2022-06-14T19:44:29+00:00","text":"Summary: Customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-06-14 08:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 13:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nWorkaround: Affected customers can create instances in another region.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T18:57:39+00:00","modified":"2022-06-14T18:57:40+00:00","when":"2022-06-14T18:57:39+00:00","text":"Summary: Customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-06-14 08:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 13:01 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nWorkaround: Affected customers can create instances in another region.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T18:55:02+00:00","modified":"2022-06-14T18:55:08+00:00","when":"2022-06-14T18:55:02+00:00","text":"Summary: Customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nDescription: We are experiencing an issue with Cloud Filestore beginning at Tuesday, 2022-06-14 08:02 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 13:01 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create Cloud Filestore High Scale and Enterprise instances in us-central1\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-06-15T00:22:30+00:00","modified":"2022-06-15T00:22:32+00:00","when":"2022-06-15T00:22:30+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/fc7GCA6kAgnBihezUAkx","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"jog4nyYkquiLeSK5s26q","service_name":"Cloud Filestore","affected_products":[{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/Lvd7FBrPJmL7oxhqrDwt","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"fc7GCA6kAgnBihezUAkx","number":"16466106385248773020","begin":"2022-06-14T13:56:00+00:00","created":"2022-06-15T00:09:03+00:00","end":"2022-06-15T00:43:00+00:00","modified":"2022-06-28T18:46:43+00:00","external_desc":"We are experiencing an issue with Google Cloud Networking at us-central1 across multiple products, beginning at Tuesday, 2022-06-14 06:00 US/Pacific.","updates":[{"created":"2022-06-28T18:27:16+00:00","modified":"2022-06-28T18:44:58+00:00","when":"2022-06-28T18:27:16+00:00","text":"# Incident Report\n**Summary:**\nOn Tuesday, 14 June 2022, at approximately 06:00 US/Pacific, Google Cloud Networking in us-central1 began experiencing increased delays in applying administrative operations, impacting several downstream services. Customers performing administrative actions on resources in us-central1 experienced delays, connectivity issues, and elevated rates of failure.\nTo our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**Background:**\nGoogle’s Cloud Load Balancer (GCLB) is a collection of software and services that load balances HTTP traffic across customer services. A key component of GCLB is the Google Front End (GFE), which load balances traffic over customer backend instances. GCLB also includes a health checking service to determine whether backends such as customer virtual machines, are responding to traffic as expected, or are unhealthy and should be removed from service.\n**Root Cause:**\nThe health checking service and GFE share a common resource pool. For a period of time, GCLB traffic was directed away from certain clusters, and, independently, during this time, health checking load in these clusters increased significantly.\nThe incident was triggered when Google engineers rerouted traffic to these clusters as part of a standard maintenance activity. This rerouted traffic increased load in those clusters, and this slowed the performance of the health checking service, resulting in an increasing rate of health check failures. This in turn led to a general networking control plane slowdown, as the service struggled to keep up with erroneous and rapid health status changes of load balancer backends. The slowdown in the networking control plane resulted in the impact on administrative operations for other resource types which involve network configuration. Customers may have experienced this as slowness or timeouts in administrative operations for the resource types listed in the Impact section, or delays in new resources (like VM instances) connecting to networks.\n**Remediation and Prevention:**\nOn Monday, 13 June 2022, at 16:30 US/Pacific, Google engineers rerouted traffic to additional compute resources in the us-central1 region as part of a standard maintenance activity.\nGoogle engineers were alerted to control plane slowness on Tuesday, 14 June 2022, at 09:17 and started an investigation. Initially, Google engineers were unable to determine the severity of the latency, due to insufficient monitoring. After attempts to mitigate by adding resources were unsuccessful, the incident was escalated at 15:50. A cross team effort of Google engineers was launched and at 17:39 mitigated the incident by removing the earlier reroute. This reduced the load on the health check system, and subsequently the networking control plane recovered at 17:43.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- Prevent similar incidents by improving the capacity modeling of our health checking service, and implementing improved resource isolation in our health checking service.\n- Detect similar incidents more rapidly by improving alerting related to the health checking process to notify responsible teams earlier and speed time to mitigate.\n- Add defense in depth: protect the downstream networking control plane from high rates of load balancing health reports, thus avoiding this type of incident in future.\n**Detailed Description of Impact:**\nOn 13 June 16:30 to 14 June 17:43 2022 US/Pacific:\n## Google Kubernetes Engine (GKE)\nAffected customers would have observed latency and up to ~40% elevated errors or timeouts during GKE Private Service Connect cluster operations including creation, deletion, and updates for a subset of clusters in us-central1. ## Google Cloud Load Balancing (GCLB)\nCustomers with resources in us-central1-c and us-central1-f would have observed increased latency or timeouts and connection errors from the Load Balancer service for resources in us-central1. Customers would have seen up to a 4.5% overall error rate, with up to 23% of requests timing out. ## Filestore\nAffected customers would have observed new instance creation failures for ~50% of the outage duration. In addition, existing instances would have been running at reduced capacity as some of their nodes may have been incorrectly marked down. ## Virtual Private Cloud (VPC)\nIncreased latency and timeouts for creating and updating networking resources in us-central1.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-15T05:58:48+00:00","modified":"2022-06-28T18:46:43+00:00","when":"2022-06-15T05:58:48+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 14 Jun 2022 06:56\n**Incident End:** 14 Jun 2022 17:43\n**Duration:** 10 hrs, 47 minutes\n**Affected Services and Features:**\nGoogle Compute Engine, Google Kubernetes Engine, Filestore, Google Cloud Load Balancers\n**Regions/Zones:** us-central1\n**Description:**\nDelays in creating Virtual machines or connecting to existing virtual machines for a period of 10 hrs 47 minutes. From preliminary analysis, the root cause of the issue is slow down in global health checking infrastructure check to an extent where flow cache in packet processing service was expiring.\n**Customer Impact:**\n**Google Compute Engine** - Users may have observed an error while creating new VMs or connecting VMs in use.\n**Google Kubernetes Engine** - Users observed latency and timeouts during GKE Cluster operations.\n**Google Cloud Load Balancers** - Customers may have observed errors from Load Balancer service for resources in us-central1.\n**Filestore** - Users may have observed an error while creating new VMs.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-15T01:15:01+00:00","modified":"2022-06-15T01:15:02+00:00","when":"2022-06-15T01:15:01+00:00","text":"The issue with Google Cloud Networking that impacted multiple products is fully mitigated as of 2022-06-14 17:43 US/Pacific. Our Engineering team is continuing to monitor the environment and working towards full resolution.\nIf you still have questions or are impacted, please open a case with the Support Team, and we will continue to work with you.\nWe thank you for your patience while we are working towards resolving this issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-15T00:47:02+00:00","modified":"2022-06-15T00:47:03+00:00","when":"2022-06-15T00:47:02+00:00","text":"Summary: We are experiencing an issue with Google Cloud Networking at us-central1 across multiple products, beginning at Tuesday, 2022-06-14 06:00 US/Pacific.\nDescription: We are experiencing an issue with Google Cloud Networking at us-central1, beginning at Tuesday, 2022-06-14 06:00 US/Pacific, with new VM creation errors, latencies, timeouts, and connection errors reported across multiple products.\n- Google Compute Engine\n- Google Kubernetes Engine\n- Google Cloud Load Balancers\n- Filestore\nMitigation work is currently underway by our engineering team. We do not have an ETA for mitigation at this point.\nWe will provide an update by Tuesday, 2022-06-14 18:20 US/Pacific with current details.\nDiagnosis: Customers may see new VM creation errors, latencies, timeouts, and connection errors reported across multiple products in us-central1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-15T00:15:30+00:00","modified":"2022-06-15T00:15:31+00:00","when":"2022-06-15T00:15:30+00:00","text":"Summary: We are experiencing an issue with Google Cloud Networking at us-central1 across multiple products, beginning at Tuesday, 2022-06-14 06:00 US/Pacific.\nDescription: We are experiencing an issue with Google Cloud Networking at us-central1 beginning at Tuesday, 2022-06-14 06:00 US/Pacific, with latencies across products.\n- Google Compute Engine.\n- Google Kubernetes Engine.\n- Google Cloud Load Balancers.\n- Filestore.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 17:45 US/Pacific with current details.\nDiagnosis: Services running from us-central1 may experience latency issues.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-15T00:09:02+00:00","modified":"2022-06-15T00:09:04+00:00","when":"2022-06-15T00:09:02+00:00","text":"Summary: We are experiencing an issue with Google Cloud Networking at us-central1 across multiple products, beginning at Tuesday, 2022-06-14 06:00 US/Pacific.\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Tuesday, 2022-06-14 06:00 US/Pacific with reports of possible latencies across products\n- Google Kubernetes Engine\n- Google Cloud Load Balancers\n- Filestore.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 17:45 US/Pacific with current details.\nDiagnosis: Services running from us-central1 may experience latency issues.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-06-28T18:27:16+00:00","modified":"2022-06-28T18:44:58+00:00","when":"2022-06-28T18:27:16+00:00","text":"# Incident Report\n**Summary:**\nOn Tuesday, 14 June 2022, at approximately 06:00 US/Pacific, Google Cloud Networking in us-central1 began experiencing increased delays in applying administrative operations, impacting several downstream services. Customers performing administrative actions on resources in us-central1 experienced delays, connectivity issues, and elevated rates of failure.\nTo our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**Background:**\nGoogle’s Cloud Load Balancer (GCLB) is a collection of software and services that load balances HTTP traffic across customer services. A key component of GCLB is the Google Front End (GFE), which load balances traffic over customer backend instances. GCLB also includes a health checking service to determine whether backends such as customer virtual machines, are responding to traffic as expected, or are unhealthy and should be removed from service.\n**Root Cause:**\nThe health checking service and GFE share a common resource pool. For a period of time, GCLB traffic was directed away from certain clusters, and, independently, during this time, health checking load in these clusters increased significantly.\nThe incident was triggered when Google engineers rerouted traffic to these clusters as part of a standard maintenance activity. This rerouted traffic increased load in those clusters, and this slowed the performance of the health checking service, resulting in an increasing rate of health check failures. This in turn led to a general networking control plane slowdown, as the service struggled to keep up with erroneous and rapid health status changes of load balancer backends. The slowdown in the networking control plane resulted in the impact on administrative operations for other resource types which involve network configuration. Customers may have experienced this as slowness or timeouts in administrative operations for the resource types listed in the Impact section, or delays in new resources (like VM instances) connecting to networks.\n**Remediation and Prevention:**\nOn Monday, 13 June 2022, at 16:30 US/Pacific, Google engineers rerouted traffic to additional compute resources in the us-central1 region as part of a standard maintenance activity.\nGoogle engineers were alerted to control plane slowness on Tuesday, 14 June 2022, at 09:17 and started an investigation. Initially, Google engineers were unable to determine the severity of the latency, due to insufficient monitoring. After attempts to mitigate by adding resources were unsuccessful, the incident was escalated at 15:50. A cross team effort of Google engineers was launched and at 17:39 mitigated the incident by removing the earlier reroute. This reduced the load on the health check system, and subsequently the networking control plane recovered at 17:43.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- Prevent similar incidents by improving the capacity modeling of our health checking service, and implementing improved resource isolation in our health checking service.\n- Detect similar incidents more rapidly by improving alerting related to the health checking process to notify responsible teams earlier and speed time to mitigate.\n- Add defense in depth: protect the downstream networking control plane from high rates of load balancing health reports, thus avoiding this type of incident in future.\n**Detailed Description of Impact:**\nOn 13 June 16:30 to 14 June 17:43 2022 US/Pacific:\n## Google Kubernetes Engine (GKE)\nAffected customers would have observed latency and up to ~40% elevated errors or timeouts during GKE Private Service Connect cluster operations including creation, deletion, and updates for a subset of clusters in us-central1. ## Google Cloud Load Balancing (GCLB)\nCustomers with resources in us-central1-c and us-central1-f would have observed increased latency or timeouts and connection errors from the Load Balancer service for resources in us-central1. Customers would have seen up to a 4.5% overall error rate, with up to 23% of requests timing out. ## Filestore\nAffected customers would have observed new instance creation failures for ~50% of the outage duration. In addition, existing instances would have been running at reduced capacity as some of their nodes may have been incorrectly marked down. ## Virtual Private Cloud (VPC)\nIncreased latency and timeouts for creating and updating networking resources in us-central1.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/fc7GCA6kAgnBihezUAkx","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"huJFgyiNYPPypbw8PX9Y","number":"9278202795851610263","begin":"2022-06-14T10:06:00+00:00","created":"2022-06-16T16:27:22+00:00","end":"2022-06-16T18:33:00+00:00","modified":"2022-06-30T14:51:46+00:00","external_desc":"Global: Some Google Cloud Console Customers are unable to create/edit GCE instances","updates":[{"created":"2022-06-24T21:47:40+00:00","modified":"2022-06-30T14:51:16+00:00","when":"2022-06-24T21:47:40+00:00","text":"**SUMMARY:**\nOn Tuesday, 14 June 2022, customers were unable to create or edit Google Compute Engine (GCE) instances via the Google Cloud Console for 2 days, 8 hours, 27 minutes. To our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**ROOT CAUSE:**\nCustomers can specify organization policies to limit what instances can use external IP addresses (compute.vmExternalIpAccess). Setting an IP address on an instance not allowed by policy will cause an operation failure.\nThe incident was triggered by a compute frontend UI release which made it impossible for certain users to modify instances due to interactions between org policies and a bug that forced an Ephemeral IP address while on either the edit or create page. Any user with the compute.vmExternalIpAccess policy could not create or edit instances without a public IP.\nA bug was identified where customers with a policy restricting external IP addresses were not able to select one during instance creation. An attempt to fix this bug created a regression where changing any field in the Edit instance page would change the IP address to ephemeral for instances that had no IP address selected. Because of the org policy blocks assigning the instance a public IP, the save operation would fail.The release containing this change included a fix to address the bug however, once in production several customers reported issues.\n**REMEDIATION AND PREVENTION:**\nGoogle engineers were alerted to the issue via customer support case on Thursday, 16 June 2022 at 04:15 and started an investigation. At 06:11, Google engineers were able to reproduce the issue and escalated the incident at 09:08. At 09:50, Google engineers initiated a bug of the release which was completed at 11:33 fully mitigating the issue.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- Improve unit testing for org policies to identify issues of this type.\n- Improve alerting to quickly detect configuration failures.\n**DETAILED DESCRIPTION OF IMPACT:**\nOn Tuesday, 14 June 2022 03:06 to Thursday 16 June 11:33 US/Pacific\n# Google Compute Engine\nAffected customers experienced failures creating or editing GCE instances via the Google Cloud Console and may have received an error “Constraint constraints/compute.vmExternalIpAccess violated for project [project ID].“\n**ADDITIONAL INFORMATION FOR CUSTOMERS:**\nAs a workaround, customers were still able to create or edit GCE instances via the gcloud CLI or via Google Cloud Console by disabling the constraints/compute.vmExternalIpAccess policy.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T23:54:30+00:00","modified":"2022-06-16T23:54:30+00:00","when":"2022-06-16T23:54:30+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 13 June 2022 14:55\n**Incident End:** 16 June 2022 11:26\n**Duration:** 2 days, 20 hours, 31 minutes\n**Affected Services and Features:**\nGoogle Cloud Console, Google Compute Engine\n**Regions/Zones:** Global\n**Description:**\nCustomers may have been unable to create or edit Google Compute Engine (GCE) instances via the Google Cloud Console for 2 days 20 hours 31 minutes. From preliminary analysis, the root cause of the issue was a recent update to the GCE frontend UI.\nGoogle engineers rolled back the GCE frontend UI update to mitigate the issue on 16 June 2022 11:33 US/Pacific.\n**Customer Impact:**\nCustomers attempting to create or edit GCE instances via the Google Cloud Console may have received an error “Constraint constraints/compute.vmExternalIpAccess violated for project [project ID].“\nAs a workaround, customers were still able to create or edit GCE instances via the gcloud CLI or via Google Cloud Console by disabling the constraints/compute.vmExternalIpAccess policy.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T18:55:37+00:00","modified":"2022-06-16T18:55:38+00:00","when":"2022-06-16T18:55:37+00:00","text":"The issue with Google Cloud Console, Google Compute Engine has been resolved for all affected projects as of Thursday, 2022-06-16 11:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T17:22:41+00:00","modified":"2022-06-16T17:22:42+00:00","when":"2022-06-16T17:22:41+00:00","text":"Summary: Global: Some Google Cloud Console Customers are unable to create/edit GCE instances\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-06-16 12:00 US/Pacific.\nDiagnosis: Affected customers are unable to create/edit GCE instances via Cloud Console.\nWorkaround: 1) Using gcloud CLI\n2) Disabling the policy of constraints/compute.vmExternalIpAccess","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T16:52:07+00:00","modified":"2022-06-16T16:52:08+00:00","when":"2022-06-16T16:52:07+00:00","text":"Summary: Global: Some Google Cloud Console Customers are unable to create/edit GCE instances\nDescription: We are experiencing an issue with Google Compute Engine, Google Cloud Console beginning at Thursday, 2022-06-16 09:08 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-16 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create/edit GCE instances via Cloud Console.\nWorkaround: 1) Using gcloud CLI\n2) Disabling the policy of constraints/compute.vmExternalIpAccess","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T16:44:46+00:00","modified":"2022-06-16T16:44:52+00:00","when":"2022-06-16T16:44:46+00:00","text":"Summary: Global: Some Google Cloud Console Customers are able to edit GCE instances\nDescription: We are experiencing an issue with Google Compute Engine, Google Cloud Console beginning at Thursday, 2022-06-16 09:08 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-16 09:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create/edit GCE instances via Cloud Console.\nWorkaround: 1) Using gcloud CLI\n2) Disabling the policy of constraints/compute.vmExternalIpAccess","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-16T16:27:16+00:00","modified":"2022-06-16T16:27:23+00:00","when":"2022-06-16T16:27:16+00:00","text":"Summary: Global: Some Google Cloud Console Customers are able to edit GCE instances\nDescription: We are experiencing an issue with Google Compute Engine, Google Cloud Console beginning at Thursday, 2022-06-16 09:08 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-16 09:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to edit any GCE instances via Cloud Console.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-24T21:47:40+00:00","modified":"2022-06-30T14:51:16+00:00","when":"2022-06-24T21:47:40+00:00","text":"**SUMMARY:**\nOn Tuesday, 14 June 2022, customers were unable to create or edit Google Compute Engine (GCE) instances via the Google Cloud Console for 2 days, 8 hours, 27 minutes. To our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**ROOT CAUSE:**\nCustomers can specify organization policies to limit what instances can use external IP addresses (compute.vmExternalIpAccess). Setting an IP address on an instance not allowed by policy will cause an operation failure.\nThe incident was triggered by a compute frontend UI release which made it impossible for certain users to modify instances due to interactions between org policies and a bug that forced an Ephemeral IP address while on either the edit or create page. Any user with the compute.vmExternalIpAccess policy could not create or edit instances without a public IP.\nA bug was identified where customers with a policy restricting external IP addresses were not able to select one during instance creation. An attempt to fix this bug created a regression where changing any field in the Edit instance page would change the IP address to ephemeral for instances that had no IP address selected. Because of the org policy blocks assigning the instance a public IP, the save operation would fail.The release containing this change included a fix to address the bug however, once in production several customers reported issues.\n**REMEDIATION AND PREVENTION:**\nGoogle engineers were alerted to the issue via customer support case on Thursday, 16 June 2022 at 04:15 and started an investigation. At 06:11, Google engineers were able to reproduce the issue and escalated the incident at 09:08. At 09:50, Google engineers initiated a bug of the release which was completed at 11:33 fully mitigating the issue.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- Improve unit testing for org policies to identify issues of this type.\n- Improve alerting to quickly detect configuration failures.\n**DETAILED DESCRIPTION OF IMPACT:**\nOn Tuesday, 14 June 2022 03:06 to Thursday 16 June 11:33 US/Pacific\n# Google Compute Engine\nAffected customers experienced failures creating or editing GCE instances via the Google Cloud Console and may have received an error “Constraint constraints/compute.vmExternalIpAccess violated for project [project ID].“\n**ADDITIONAL INFORMATION FOR CUSTOMERS:**\nAs a workaround, customers were still able to create or edit GCE instances via the gcloud CLI or via Google Cloud Console by disabling the constraints/compute.vmExternalIpAccess policy.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"}],"uri":"incidents/huJFgyiNYPPypbw8PX9Y","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Columbus (us-east5)","id":"us-east5"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"4Sie4sXFPougA2Ku24pT","number":"16190899427126199648","begin":"2022-06-14T10:03:00+00:00","created":"2022-06-14T11:00:36+00:00","end":"2022-06-14T13:22:00+00:00","modified":"2022-06-14T18:54:41+00:00","external_desc":"GKE API seeing high latency and errors in us-central1","updates":[{"created":"2022-06-14T18:54:05+00:00","modified":"2022-06-14T18:54:05+00:00","when":"2022-06-14T18:54:05+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 14 June 2022 03:03\n**Incident End:** 14 June 2022 06:22\n**Duration:** 3 hours, 19 minutes\n**Affected Services and Features:**\nGoogle Kubernetes Engine, Cloud Data Fusion, Cloud Logging\n**Regions/Zones:** us-central1\n**Description:**\nGoogle Kubernetes Engine (GKE) experienced increased latency and errors from the GKE API in us-central1 for 3 hours and 19 minutes. From preliminary analysis, the root cause of the issue was an unexpected increase in backend traffic that was compounded by clients retrying failed requests. The issue was mitigated by scaling up the GKE control plane to handle the increased traffic.\n**Customer Impact:**\n* **Google Kubernetes Engine (GKE)** customers may have experienced increased latency and errors for GKE API calls via gcloud and the Google Cloud Console UI. GKE cluster workloads continued to run; however customers may have been unable to perform operations such as confirm cluster status, trigger upgrades, view workloads, or create/delete clusters and node pools.\n* **Cloud Data Fusion** customers may have experienced instance creation and deletion failures in us-central1.\n* **Cloud Logging** customers may have experienced increased latency for suggested searches for GKE clusters in us-central1.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T13:26:34+00:00","modified":"2022-06-14T13:26:39+00:00","when":"2022-06-14T13:26:34+00:00","text":"The issue with Google Kubernetes Engine has been resolved for all affected users as of Tuesday, 2022-06-14 06:17 US/Pacific.\nIf customers are still experiencing issues, please raise the case via normal channels .\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T13:15:26+00:00","modified":"2022-06-14T13:15:31+00:00","when":"2022-06-14T13:15:26+00:00","text":"Summary: GKE API seeing high latency and errors in us-central1\nDescription: Mitigation work is still underway by our engineering team.\nCustomers who are able to use another region are advised to do so.\nWe will provide more information by Tuesday, 2022-06-14 06:35 US/Pacific.\nDiagnosis: Users will see high errors and latency from the GKE API in us-central1. Retries may be successful.\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T12:34:41+00:00","modified":"2022-06-14T12:34:46+00:00","when":"2022-06-14T12:34:41+00:00","text":"Summary: GKE API seeing high latency and errors in us-central1\nDescription: Mitigation work is still underway by our engineering team.\nCustomers who are able to use another region are advised to do so.\nWe will provide more information by Tuesday, 2022-06-14 06:10 US/Pacific.\nDiagnosis: Users will see high errors and latency from the GKE API in us-central1. Retries may be successful.\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T12:01:11+00:00","modified":"2022-06-14T12:01:18+00:00","when":"2022-06-14T12:01:11+00:00","text":"Summary: GKE API seeing high latency and errors in us-central1\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2022-06-14 05:30 US/Pacific.}\nWe will provide more information by Tuesday, 2022-06-14 05:31 US/Pacific.\nDiagnosis: Users will see high errors and latency from the GKE API in us-central1. Retries may be successful.\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T11:28:50+00:00","modified":"2022-06-14T11:28:55+00:00","when":"2022-06-14T11:28:50+00:00","text":"Summary: GKE API seeing high latency and errors in us-central1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-06-14 05:00 US/Pacific.\nDiagnosis: Users will see high errors and latency from the GKE API in us-central1. Retries may be successful.\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-06-14T11:00:28+00:00","modified":"2022-06-14T11:00:41+00:00","when":"2022-06-14T11:00:28+00:00","text":"Summary: GKE API seeing high latency and errors in us-central1\nDescription: We are experiencing an issue with Google Kubernetes Engine beginning at Tuesday, 2022-06-14 03:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-14 04:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users will see high errors and latency from the GKE API in us-central1. Retries may be successful.\nWorkaround: None at this time","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-06-14T18:54:05+00:00","modified":"2022-06-14T18:54:05+00:00","when":"2022-06-14T18:54:05+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 14 June 2022 03:03\n**Incident End:** 14 June 2022 06:22\n**Duration:** 3 hours, 19 minutes\n**Affected Services and Features:**\nGoogle Kubernetes Engine, Cloud Data Fusion, Cloud Logging\n**Regions/Zones:** us-central1\n**Description:**\nGoogle Kubernetes Engine (GKE) experienced increased latency and errors from the GKE API in us-central1 for 3 hours and 19 minutes. From preliminary analysis, the root cause of the issue was an unexpected increase in backend traffic that was compounded by clients retrying failed requests. The issue was mitigated by scaling up the GKE control plane to handle the increased traffic.\n**Customer Impact:**\n* **Google Kubernetes Engine (GKE)** customers may have experienced increased latency and errors for GKE API calls via gcloud and the Google Cloud Console UI. GKE cluster workloads continued to run; however customers may have been unable to perform operations such as confirm cluster status, trigger upgrades, view workloads, or create/delete clusters and node pools.\n* **Cloud Data Fusion** customers may have experienced instance creation and deletion failures in us-central1.\n* **Cloud Logging** customers may have experienced increased latency for suggested searches for GKE clusters in us-central1.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Cloud Logging","id":"PuCJ6W2ovoDhLcyvZ1xa"},{"title":"Cloud Data Fusion","id":"rLKDHeeaBiXTeutF1air"}],"uri":"incidents/4Sie4sXFPougA2Ku24pT","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"KPYTXQW4gRhXvTsZ1Fj9","number":"18213986659195085044","begin":"2022-06-11T12:16:00+00:00","created":"2022-06-11T13:46:24+00:00","end":"2022-06-11T14:45:00+00:00","modified":"2022-06-13T20:35:03+00:00","external_desc":"We are experiencing an issue with Cloud Armor control plane","updates":[{"created":"2022-06-13T20:33:50+00:00","modified":"2022-06-13T20:33:50+00:00","when":"2022-06-13T20:33:50+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 11 June 2022 05:16\n**Incident End:** 11 June 2022 07:45\n**Duration:** 2 hours, 29 minutes\n**Affected Services and Features:**\nGoogle Cloud Armour\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Armor control plane was not processing updates in the global locale for a duration of 2 hours and 29 minutes. From preliminary analysis, the root cause of the issue appears to be multiple Storage errors that caused the control plane writer to stop updating. The control plane processed no or minimal updates within 2022-06-11 05:16 - 07:45 PDT.\n**Customer Impact:**\nCustomers may have experienced Cloud Armor rule changes that were not applied since the control plane was not processing changes.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-11T15:44:17+00:00","modified":"2022-06-11T15:44:18+00:00","when":"2022-06-11T15:44:17+00:00","text":"The issue with Cloud Armor has been resolved for all affected users as of Saturday, 2022-06-11 07:45 US/Pacific.\nCustomers who made updates during the timeframe of 2022-06-11 05:16 - 07:45 PDT are not effective and will need to make a fresh update to their Cloud Armor config.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-11T14:22:25+00:00","modified":"2022-06-11T14:22:26+00:00","when":"2022-06-11T14:22:25+00:00","text":"Summary: We are experiencing an issue with Cloud Armor control plane\nDescription: We are experiencing an issue with Cloud Armor beginning at Saturday, 2022-06-11 05:27 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-06-11 08:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience that Cloud Armor control plane is stuck with no updates.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-11T13:46:24+00:00","modified":"2022-06-11T14:02:54+00:00","when":"2022-06-11T13:46:24+00:00","text":"Summary: We are experiencing an issue with Cloud Armor control plane\nDescription: We are experiencing an issue with Cloud Armor beginning at Saturday, 2022-06-11 05:27 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-06-11 07:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience that Cloud Armor control plane is stuck with no updates.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-06-13T20:33:50+00:00","modified":"2022-06-13T20:33:50+00:00","when":"2022-06-13T20:33:50+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 11 June 2022 05:16\n**Incident End:** 11 June 2022 07:45\n**Duration:** 2 hours, 29 minutes\n**Affected Services and Features:**\nGoogle Cloud Armour\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Armor control plane was not processing updates in the global locale for a duration of 2 hours and 29 minutes. From preliminary analysis, the root cause of the issue appears to be multiple Storage errors that caused the control plane writer to stop updating. The control plane processed no or minimal updates within 2022-06-11 05:16 - 07:45 PDT.\n**Customer Impact:**\nCustomers may have experienced Cloud Armor rule changes that were not applied since the control plane was not processing changes.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Armor","id":"Kakg69gTC3xFyeJCY2va"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/KPYTXQW4gRhXvTsZ1Fj9","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"HzDuJz8t92LzvER4pT3y","number":"5087447213217570600","begin":"2022-06-09T22:34:28+00:00","created":"2022-06-09T22:47:24+00:00","end":"2022-06-10T00:27:41+00:00","modified":"2022-06-10T00:27:41+00:00","external_desc":"[US Multiregion] Customers May Experience BigQuery Latency","updates":[{"created":"2022-06-10T00:27:40+00:00","modified":"2022-06-10T00:27:41+00:00","when":"2022-06-10T00:27:40+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2022-06-09 17:24 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-06-09T23:04:25+00:00","modified":"2022-06-09T23:04:25+00:00","when":"2022-06-09T23:04:25+00:00","text":"Summary: [US Multiregion] Customers May Experience BigQuery Latency\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-06-09 17:10 US/Pacific.\nWe will provide more information by Thursday, 2022-06-09 17:30 US/Pacific.\nDiagnosis: Affected customers may experience latencies with BigQuery in the US Multiregion\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-06-09T23:03:51+00:00","modified":"2022-06-09T23:03:52+00:00","when":"2022-06-09T23:03:51+00:00","text":"Summary: [US Multiregion] Customers May Experience BigQuery Latency\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-06-09 17:30 US/Pacific.\nWe will provide more information by Thursday, 2022-06-09 17:02 US/Pacific.\nDiagnosis: Affected customers may experience latencies with BigQuery in the US Multiregion\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-06-09T22:47:24+00:00","modified":"2022-06-09T22:47:25+00:00","when":"2022-06-09T22:47:24+00:00","text":"Summary: [US Multiregion] Customers May Experience BigQuery Latency\nDescription: We are experiencing a performance issue with Google BigQuery.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-09 16:05 US/Pacific with current details.\nDiagnosis: Affected customers may experience latencies with BigQuery in the US Multiregion\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-06-10T00:27:40+00:00","modified":"2022-06-10T00:27:41+00:00","when":"2022-06-10T00:27:40+00:00","text":"The issue with Google BigQuery has been resolved for all affected projects as of Thursday, 2022-06-09 17:24 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/HzDuJz8t92LzvER4pT3y","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"id":"Q9MUHCFVpqouJbGrzneJ","number":"13932012708372562392","begin":"2022-06-08T16:16:00+00:00","created":"2022-06-14T13:12:45+00:00","end":"2022-06-15T03:02:00+00:00","modified":"2022-06-15T09:39:27+00:00","external_desc":"[Global] Google App Engine - Customers using the Secrets Manager are experiencing increased errors.","updates":[{"created":"2022-06-15T09:38:38+00:00","modified":"2022-06-15T09:38:38+00:00","when":"2022-06-15T09:38:38+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 08 June 2022 09:16\n**Incident End:** 14 June 2022 20:02\n**Duration:** 6 day, 10 hours, 46 minutes\n**Affected Services and Features:**\nGoogle Cloud App Engine, Google Cloud Functions.\n**Regions/Zones:**\nGlobal\n**Description:**\nGoogle Cloud App Engine customers might have experienced elevated errors while using the Secrets Manager for a duration of 6 days, 10 hours and 46 minutes. From preliminary analysis, the root cause of the issue is, regression in a recent software release relating to Secret Manager functionality in Google Cloud App Engine.\n**Customer Impact:**\nCustomers might have experienced increased errors from apps or functions that use the Secrets Manager.\n**Additional details:**\nThe Secret Manager functionality related release updates are rolled back to mitigate the issue. During the impact customers were advised to mount each secret in a separate path as per https://cloud.google.com/functions/docs/configuring/secrets.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-15T04:03:22+00:00","modified":"2022-06-15T04:03:23+00:00","when":"2022-06-15T04:03:22+00:00","text":"The issue with Google App Engine has been resolved for all affected projects as of Tuesday, 2022-06-14 20:02 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-15T00:36:49+00:00","modified":"2022-06-15T00:36:57+00:00","when":"2022-06-15T00:36:49+00:00","text":"Summary: [Global] Google App Engine - Customers using the Secrets Manager are experiencing increased errors.\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Tuesday, 2022-06-14 22:00 US/Pacific.\nDiagnosis: Customers using the Secrets Manager are experiencing increased errors.\nWorkaround: A workaround is to mount each secret in a separate path. Please refer to https://cloud.google.com/functions/docs/configuring/secrets for information on Secret Manager.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-14T21:28:14+00:00","modified":"2022-06-14T21:28:15+00:00","when":"2022-06-14T21:28:14+00:00","text":"Summary: [Global] Google App Engine - Customers using the Secrets Manager are experiencing increased errors.\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Tuesday, 2022-06-14 18:00 US/Pacific.\nDiagnosis: Customers using the Secrets Manager are experiencing increased errors.\nWorkaround: A workaround is to mount each secret in a separate path. Please refer to https://cloud.google.com/functions/docs/configuring/secrets for information on Secret Manager.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-14T16:37:43+00:00","modified":"2022-06-14T16:37:53+00:00","when":"2022-06-14T16:37:43+00:00","text":"Summary: Increase in errors correlated with binary rollout\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is completed completed for europe-west3. The mitigation ETA for us-central1 is Tuesday, 2022-06-14 14:00 US/Pacific. ETA will be provided for other regions in a subsequent update.\nWe will provide more information by Tuesday, 2022-06-14 14:30 US/Pacific.\nDiagnosis: Customers using Secrets Manager are experiencing increased errors.\nWorkaround: A workaround is to mount each secret in a separate path. Please refer to https://cloud.google.com/functions/docs/configuring/secrets for information on Secret Manager.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-14T15:08:32+00:00","modified":"2022-06-14T15:08:39+00:00","when":"2022-06-14T15:08:32+00:00","text":"Summary: Increase in errors correlated with binary rollout\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to be completed for europe-west3 Tuesday, 2022-06-14 10:00 US/Pacific, and for us-central1 Tuesday, 2022-06-14 14:00 US/Pacific. ETA will be provided for other regions in a subsequent update.\nWe will provide more information by Tuesday, 2022-06-14 10:10 US/Pacific.\nDiagnosis: Customers using Secrets Manager are experiencing increased errors.\nWorkaround: A workaround is to mount each secret in a separate path. Please refer to https://cloud.google.com/functions/docs/configuring/secrets for information on Secret Manager.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-14T13:12:43+00:00","modified":"2022-06-14T13:12:48+00:00","when":"2022-06-14T13:12:43+00:00","text":"Summary: Increase in errors correlated with binary rollout\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to be completed for europe-west3 Tuesday, 2022-06-14 10:00 US/Pacific, and for us-central1 Tuesday, 2022-06-14 14:00 US/Pacific. ETA will be provided for other regions in a subsequent update.\nWe will provide more information by Tuesday, 2022-06-14 08:27 US/Pacific.\nDiagnosis: Customers are experiencing increased errors.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-15T09:38:38+00:00","modified":"2022-06-15T09:38:38+00:00","when":"2022-06-15T09:38:38+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 08 June 2022 09:16\n**Incident End:** 14 June 2022 20:02\n**Duration:** 6 day, 10 hours, 46 minutes\n**Affected Services and Features:**\nGoogle Cloud App Engine, Google Cloud Functions.\n**Regions/Zones:**\nGlobal\n**Description:**\nGoogle Cloud App Engine customers might have experienced elevated errors while using the Secrets Manager for a duration of 6 days, 10 hours and 46 minutes. From preliminary analysis, the root cause of the issue is, regression in a recent software release relating to Secret Manager functionality in Google Cloud App Engine.\n**Customer Impact:**\nCustomers might have experienced increased errors from apps or functions that use the Secrets Manager.\n**Additional details:**\nThe Secret Manager functionality related release updates are rolled back to mitigate the issue. During the impact customers were advised to mount each secret in a separate path as per https://cloud.google.com/functions/docs/configuring/secrets.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/Q9MUHCFVpqouJbGrzneJ","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"e383eLoLFGdSMeUQo7Ch","number":"13605570326637952215","begin":"2022-06-08T00:49:06+00:00","created":"2022-06-08T01:29:03+00:00","end":"2022-06-13T22:16:02+00:00","modified":"2022-06-13T22:16:02+00:00","external_desc":"Google Analytics Daily BigQuery exports for certain customers may experience delays","updates":[{"created":"2022-06-13T22:16:01+00:00","modified":"2022-06-13T22:16:02+00:00","when":"2022-06-13T22:16:01+00:00","text":"The issue with Google Analytics Daily BigQuery exports has been resolved for all affected users as of Monday, 2022-06-13 12:47 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-13T16:14:33+00:00","modified":"2022-06-13T16:14:35+00:00","when":"2022-06-13T16:14:33+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is still underway by our engineering team.\nWe will provide more information by Tuesday, 2022-06-14 09:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-13T14:55:31+00:00","modified":"2022-06-13T14:55:41+00:00","when":"2022-06-13T14:55:31+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Monday, 2022-06-13 09:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-10T20:04:29+00:00","modified":"2022-06-10T20:04:30+00:00","when":"2022-06-10T20:04:29+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Monday, 2022-06-13 08:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-10T17:57:27+00:00","modified":"2022-06-10T17:57:35+00:00","when":"2022-06-10T17:57:27+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Friday, 2022-06-10 14:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-10T03:37:40+00:00","modified":"2022-06-10T03:37:41+00:00","when":"2022-06-10T03:37:40+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Friday, 2022-06-10 11:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-09T23:08:28+00:00","modified":"2022-06-09T23:08:29+00:00","when":"2022-06-09T23:08:28+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: *Note 'This is not a problem with BigQuery, only Google Analytics BigQuery export is affected'\nMitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-06-09 11:59 US/Pacific.\nWe will provide more information by Friday, 2022-06-10 00:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T23:21:13+00:00","modified":"2022-06-08T23:21:14+00:00","when":"2022-06-08T23:21:13+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Our engineering team has determined that further investigation is required to mitigate the issue.\nWe will provide an update by Thursday, 2022-06-09 17:22 US/Pacific with current details.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T20:54:32+00:00","modified":"2022-06-08T20:54:38+00:00","when":"2022-06-08T20:54:32+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Wednesday, 2022-06-08 16:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T17:47:19+00:00","modified":"2022-06-08T17:47:20+00:00","when":"2022-06-08T17:47:19+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Wednesday, 2022-06-08 14:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T17:42:28+00:00","modified":"2022-06-08T17:42:34+00:00","when":"2022-06-08T17:42:28+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-06-08 10:00 US/Pacific.\nWe will provide more information by Wednesday, 2022-06-08 14:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T02:54:19+00:00","modified":"2022-06-08T02:54:20+00:00","when":"2022-06-08T02:54:19+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Wednesday, 2022-06-08 10:00 US/Pacific.\nWe will provide more information by Wednesday, 2022-06-08 10:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-08T01:28:57+00:00","modified":"2022-06-08T01:29:03+00:00","when":"2022-06-08T01:28:57+00:00","text":"Summary: Google Analytics Daily BigQuery exports for certain customers may experience delays\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-06-08 17:00 US/Pacific.\nDiagnosis: Affected customers may notice that their Google Analytics BigQuery Daily Export jobs are experiencing delays\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-13T22:16:01+00:00","modified":"2022-06-13T22:16:02+00:00","when":"2022-06-13T22:16:01+00:00","text":"The issue with Google Analytics Daily BigQuery exports has been resolved for all affected users as of Monday, 2022-06-13 12:47 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/e383eLoLFGdSMeUQo7Ch","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"YrjzRWPFBUZU5HJZ4mN7","number":"12112012328903018953","begin":"2022-06-07T12:50:00+00:00","created":"2022-06-07T14:01:19+00:00","end":"2022-06-07T16:02:00+00:00","modified":"2022-06-14T20:35:45+00:00","external_desc":"Google Cloud Networking experienced increased packet loss for egress traffic from Google to the Middle East, and elevated latency between our Europe and Asia Regions.","updates":[{"created":"2022-06-14T20:35:45+00:00","modified":"2022-06-14T20:35:45+00:00","when":"2022-06-14T20:35:45+00:00","text":"# INCIDENT REPORT\n**Summary:**\nOn Tuesday, 7 June 2022, Google Cloud Networking experienced increased packet loss for egress traffic from Google to users and customers in the Middle East and elevated latency between our Europe and Asia Regions for 3 hours and 12 minutes, affecting several Cloud Networking products.\nTo our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**Root Cause:**\nThe outage was triggered by two simultaneous fiber cuts within our Middle East network. This affected the end-to-end path for several submarine cables, reducing capacity for many telecom and technology companies, including Google.\nThe reduced capacity increased latency and caused packet loss between Google regions in Europe and regions in the Middle East and the rest of Asia.\n**Remediation and Prevention:**\nGoogle Engineers were alerted to the network bandwidth drop on Tuesday, 7 June 2022 at 06:00 US/Pacific. Google Engineers immediately started to redirect Internet egress demand away from the region. At 07:02, Europe-Asia traffic was redirected across backup circuits via America, trading increased latency for lower packet loss. Fiber engineers restored interim capacity by 08:26, ending packet loss between Europe and the Middle East. Once final stability was confirmed, Europe-Asia traffic was moved back to the direct path at 09:02.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- We are increasing the resilience of terrestrial network paths to provide more resilience to dual failures.\n- We are continuing with our planned programme of additional investments in the Europe-Middle East network to offer alternative network paths.\n- We are improving the effectiveness of tooling to reduce Internet egress demand during capacity shortfalls.\n**Detailed Description of Impact:**\nOn 07 June 2022 05:50 from 05:50 to 09:03 US/Pacific: ## Cloud Load Balancing\nCustomers using Cloud Load Balancing would have experienced increased packet loss up to 60% for egress traffic from Google to the Middle East and increased network latency between our Europe and Asia regions. ## Cloud Interconnect\nCloud Interconnect customers peering in the Middle East region would have experienced packet loss up to 80% during the incident. ## Virtual Private Cloud (VPC)\nCustomers using Virtual Private Cloud requiring cross-regional traffic between the following regions would have experienced packet loss of up to 50% between 05:47 and 07:03, then elevated network latency until 09:03:\n- asia-east1 to europe-southwest1, europe-west6, and europe-west8;\n- asia-east2 to all regions in Europe;\n- asia-south1 and asia-south2 to all regions in Europe, all northamerica-northeast and northamerica-southeast, and all us-east regions;\n- asia-southeast1 and asia-southeast2 to all regions in Europe;\n- australia-southeast2 to europe-west8.\n## Other Services\nWhile not specifically called out, all Google Cloud Services in the Middle East and our Europe and Asia regions could have been affected by the packet loss for egress traffic from Google to the Middle East, as well as increased latency between our Europe and Asia regions. We have listed the major services that our telemetry identified as causing customer impact.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T20:09:36+00:00","modified":"2022-06-07T20:09:36+00:00","when":"2022-06-07T20:09:36+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213. We will provide a full Incident Report with additional details.\n(All Times US/Pacific)\n**Incident Start:** 07 June 2022 05:50\n**Incident End:** 07 June 2022 09:02\n**Duration:** 3 hours, 12 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\nCloud NAT\nHybrid Connectivity\nVirtual Private Cloud (VPC)\nCloud Interconnect\nGoogle Kubernetes Engine (GKE)\n**Regions/Zones:** Packet Loss (Global to Middle East Internet Users), Latency (Between Asia and Europe regions)\n**Description:**\nGoogle Cloud Networking experienced increased packet loss for egress traffic from Google to the Middle East, and elevated latency between our Europe and Asia Regions as a result, for 3 hours and 12 minutes, affecting several related products including Cloud NAT, Hybrid Connectivity and Virtual Private Cloud (VPC). From preliminary analysis, the root cause of the issue was a capacity shortage following two simultaneous fiber-cuts.\n**Customer Impact:**\nAffected customers would have experienced increased packet loss and increased latency for the affected metros which would have caused delays and timeouts for the following services : - Cloud Load Balancing - Cloud Interconnect - Virtual Private Cloud (VPC) - Cloud NAT - Google Kubernetes Engine (GKE)","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T16:12:37+00:00","modified":"2022-06-07T16:12:39+00:00","when":"2022-06-07T16:12:37+00:00","text":"The issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) has been resolved for all affected users as of Tuesday, 2022-06-07 09:02 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T15:51:24+00:00","modified":"2022-06-07T15:51:28+00:00","when":"2022-06-07T15:51:24+00:00","text":"Summary: Packet loss observed from Internet in Middle East to Google\nDescription: We believe the issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) is partially resolved. Packet loss should be mitigated, but some traffic continues to have elevated latency.\nFull resolution is expected to complete by Tuesday, 2022-06-07 09:30 US/Pacific.\nWe will provide an update by Tuesday, 2022-06-07 09:30 US/Pacific with current details.\nDiagnosis: Increased packet loss for traffic traversing the affected metros.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T15:40:23+00:00","modified":"2022-06-07T15:40:26+00:00","when":"2022-06-07T15:40:23+00:00","text":"Summary: Packet loss observed from Internet in Middle East to Google\nDescription: Mitigation work is currently underway by our engineering team to redirect traffic and increase capacity.\nThe mitigation is expected to complete around Tuesday, 2022-06-07 09:00 US/Pacific.\nWe will provide more information by Tuesday, 2022-06-07 09:30 US/Pacific.\nDiagnosis: Increased packet loss for traffic traversing the affected metros.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T14:44:56+00:00","modified":"2022-06-07T14:45:02+00:00","when":"2022-06-07T14:44:56+00:00","text":"Summary: Packet loss observed from Internet in Middle East to Google\nDescription: We are experiencing an issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) beginning at Tuesday, 2022-06-07 06:00 US/Pacific.\nThere is a latency in connectivity between Europe and Asia.\nMitigation work is still underway by our engineering team.\nWe will provide more information by Tuesday, 2022-06-07 09:15 US/Pacific.\nDiagnosis: Increased packet loss for traffic traversing the affected metros.\nWorkaround: None.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-06-07T14:21:54+00:00","modified":"2022-06-07T14:40:49+00:00","when":"2022-06-07T14:21:54+00:00","text":"Summary: Major packet loss observed from Internet in Middle East to Google\nDescription: We are experiencing an issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) beginning at Tuesday, 2022-06-07 06:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-07 08:00 US/Pacific with current details.\nDiagnosis: Increased packet loss for traffic traversing the affected metros.\nWorkaround: None.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-07T14:01:08+00:00","modified":"2022-06-07T14:01:21+00:00","when":"2022-06-07T14:01:08+00:00","text":"Summary: Major packet loss observed between multiple regions - Europe and Asia\nDescription: We are experiencing an issue with Cloud NAT, Google Cloud Networking, Hybrid Connectivity, Virtual Private Cloud (VPC) beginning at Tuesday, 2022-06-07 06:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-06-07 08:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Increased packet loss for traffic traversing the affected metros.\nWorkaround: None.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-06-14T20:35:45+00:00","modified":"2022-06-14T20:35:45+00:00","when":"2022-06-14T20:35:45+00:00","text":"# INCIDENT REPORT\n**Summary:**\nOn Tuesday, 7 June 2022, Google Cloud Networking experienced increased packet loss for egress traffic from Google to users and customers in the Middle East and elevated latency between our Europe and Asia Regions for 3 hours and 12 minutes, affecting several Cloud Networking products.\nTo our customers that were impacted during this outage, we sincerely apologize. We are conducting an internal investigation and are taking steps to improve our service.\n**Root Cause:**\nThe outage was triggered by two simultaneous fiber cuts within our Middle East network. This affected the end-to-end path for several submarine cables, reducing capacity for many telecom and technology companies, including Google.\nThe reduced capacity increased latency and caused packet loss between Google regions in Europe and regions in the Middle East and the rest of Asia.\n**Remediation and Prevention:**\nGoogle Engineers were alerted to the network bandwidth drop on Tuesday, 7 June 2022 at 06:00 US/Pacific. Google Engineers immediately started to redirect Internet egress demand away from the region. At 07:02, Europe-Asia traffic was redirected across backup circuits via America, trading increased latency for lower packet loss. Fiber engineers restored interim capacity by 08:26, ending packet loss between Europe and the Middle East. Once final stability was confirmed, Europe-Asia traffic was moved back to the direct path at 09:02.\nGoogle is committed to improving our service in the future and will be completing the following actions:\n- We are increasing the resilience of terrestrial network paths to provide more resilience to dual failures.\n- We are continuing with our planned programme of additional investments in the Europe-Middle East network to offer alternative network paths.\n- We are improving the effectiveness of tooling to reduce Internet egress demand during capacity shortfalls.\n**Detailed Description of Impact:**\nOn 07 June 2022 05:50 from 05:50 to 09:03 US/Pacific: ## Cloud Load Balancing\nCustomers using Cloud Load Balancing would have experienced increased packet loss up to 60% for egress traffic from Google to the Middle East and increased network latency between our Europe and Asia regions. ## Cloud Interconnect\nCloud Interconnect customers peering in the Middle East region would have experienced packet loss up to 80% during the incident. ## Virtual Private Cloud (VPC)\nCustomers using Virtual Private Cloud requiring cross-regional traffic between the following regions would have experienced packet loss of up to 50% between 05:47 and 07:03, then elevated network latency until 09:03:\n- asia-east1 to europe-southwest1, europe-west6, and europe-west8;\n- asia-east2 to all regions in Europe;\n- asia-south1 and asia-south2 to all regions in Europe, all northamerica-northeast and northamerica-southeast, and all us-east regions;\n- asia-southeast1 and asia-southeast2 to all regions in Europe;\n- australia-southeast2 to europe-west8.\n## Other Services\nWhile not specifically called out, all Google Cloud Services in the Middle East and our Europe and Asia regions could have been affected by the packet loss for egress traffic from Google to the Middle East, as well as increased latency between our Europe and Asia regions. We have listed the major services that our telemetry identified as causing customer impact.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud NAT","id":"hCNpnTQHkUCCGxJy35Yq"}],"uri":"incidents/YrjzRWPFBUZU5HJZ4mN7","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"TujZ6j7u14hirgg5WqZ4","number":"9012572856388055433","begin":"2022-06-06T18:23:23+00:00","created":"2022-06-06T18:23:28+00:00","end":"2022-06-06T19:01:28+00:00","modified":"2022-06-06T19:01:28+00:00","external_desc":"US \u0026 EU Multiregions : Elevated errors with BigQuery streaming inserts","updates":[{"created":"2022-06-06T19:01:27+00:00","modified":"2022-06-06T19:01:30+00:00","when":"2022-06-06T19:01:27+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-06-06T18:23:27+00:00","modified":"2022-06-06T18:23:30+00:00","when":"2022-06-06T18:23:27+00:00","text":"Summary: US \u0026 Europe : Failure in BigQuery insert due to upsert Check\nDescription: We are experiencing an issue with Google BigQuery beginning at Monday, 2022-06-06 10:26 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-06-06 11:50 US/Pacific with current details.\nDiagnosis: Customers could see insert failures due to PK key check failures\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-06-06T19:01:27+00:00","modified":"2022-06-06T19:01:30+00:00","when":"2022-06-06T19:01:27+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of projects and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/TujZ6j7u14hirgg5WqZ4","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"id":"BnzamL7pXnge8zLHyjyK","number":"17344967214763707246","begin":"2022-06-05T19:17:00+00:00","created":"2022-06-05T21:49:14+00:00","end":"2022-06-05T23:14:00+00:00","modified":"2022-06-06T18:54:33+00:00","external_desc":"Global: Elevated delays in propagating changes to Cloud IAM policies and group memberships.","updates":[{"created":"2022-06-06T18:54:17+00:00","modified":"2022-06-06T18:54:17+00:00","when":"2022-06-06T18:54:17+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 05 June 2022 12:17\n**Incident End:** 05 June 2022 16:14\n**Duration:** 3 hours, 57 minutes\n**Affected Services and Features:**\nCloud IAM\n**Regions/Zones:** Global\n**Description:**\nCloud IAM experienced elevated delays in propagating changes to Cloud IAM policies due to an unexpected increase in deletion traffic.\n**Customer Impact:**\n- Affected customers would experience delays in processing Cloud IAM policy changes and the use of group membership changes in IAM policy evaluation.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-05T23:22:00+00:00","modified":"2022-06-05T23:22:01+00:00","when":"2022-06-05T23:22:00+00:00","text":"The issue with Identity and Access Management has been resolved for all affected projects as of Sunday, 2022-06-05 16:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-05T23:15:10+00:00","modified":"2022-06-05T23:15:16+00:00","when":"2022-06-05T23:15:10+00:00","text":"Summary: Global: Elevated delays in propagating changes to Cloud IAM policies and group memberships\nDescription: Mitigation work is still underway by our engineering team. We are seeing improvements in several regions globally.\nThe mitigation is expected to complete by Sunday, 2022-06-05 17:00 US/Pacific.\nWe will provide more information by Sunday, 2022-06-05 17:00 US/Pacific.\nDiagnosis: Affected customers when making IAM policy or group membership changes will experience increased delays before they take effect. Current delays are up to 45 minutes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-05T22:19:39+00:00","modified":"2022-06-05T22:19:40+00:00","when":"2022-06-05T22:19:39+00:00","text":"Summary: Global: Elevated delays in propagating changes to Cloud IAM policies and group memberships\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Sunday, 2022-06-05 17:00 US/Pacific.\nDiagnosis: Affected customers when making IAM policy or group membership changes will experience increased delays before they take effect. Current delays are up to 45 minutes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-05T22:06:48+00:00","modified":"2022-06-05T22:06:50+00:00","when":"2022-06-05T22:06:48+00:00","text":"Summary: Global: Elevated delays in propagating changes to Cloud IAM policies and group memberships\nDescription: We are experiencing an issue with Identity and Access Management.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-05 16:45 US/Pacific with current details.\nDiagnosis: Affected customers when making IAM policy or group membership changes will experience increased delays before they take effect. Current delays are up to 30 minutes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-06-05T22:04:02+00:00","modified":"2022-06-05T22:04:04+00:00","when":"2022-06-05T22:04:02+00:00","text":"Summary: Global: Elevated delays in propagating changes to Cloud IAM policies and group memberships\nDescription: We are experiencing an issue with Identity and Access Management.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-05 16:30 US/Pacific with current details.\nDiagnosis: Affected customers when making IAM policy or group membership changes will experience increased delays before they take effect. Current delays are up to 30 minutes.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-06-05T21:49:13+00:00","modified":"2022-06-05T21:49:16+00:00","when":"2022-06-05T21:49:13+00:00","text":"Summary: Global: Elevated delays in propagating changes to Cloud IAM Policies\nDescription: We are experiencing an issue with Identity and Access Management beginning at Sunday, 2022-06-05 09:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-06-05 16:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers when making IAM policies changes will experience increased delays before they take effect.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-06-06T18:54:17+00:00","modified":"2022-06-06T18:54:17+00:00","when":"2022-06-06T18:54:17+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 05 June 2022 12:17\n**Incident End:** 05 June 2022 16:14\n**Duration:** 3 hours, 57 minutes\n**Affected Services and Features:**\nCloud IAM\n**Regions/Zones:** Global\n**Description:**\nCloud IAM experienced elevated delays in propagating changes to Cloud IAM policies due to an unexpected increase in deletion traffic.\n**Customer Impact:**\n- Affected customers would experience delays in processing Cloud IAM policy changes and the use of group membership changes in IAM policy evaluation.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"adnGEDEt9zWzs8uF1oKA","service_name":"Identity and Access Management","affected_products":[{"title":"Identity and Access Management","id":"adnGEDEt9zWzs8uF1oKA"}],"uri":"incidents/BnzamL7pXnge8zLHyjyK","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"6sfxucMj6DuhVzmj9Xr8","number":"702824853392148085","begin":"2022-06-04T17:47:00+00:00","created":"2022-06-04T17:40:35+00:00","end":"2022-06-05T00:03:00+00:00","modified":"2022-07-12T17:52:34+00:00","external_desc":"us-east1: Elevated errors affecting multiple services.","updates":[{"created":"2022-06-06T09:14:00+00:00","modified":"2022-07-12T17:52:32+00:00","when":"2022-06-06T09:14:00+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case at https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 04 June 2022 10:47\n**Incident End:** 04 June 2022 17:03\n**Duration:** 6 hours 16 minutes\n**Affected Services and Features:**\nMultiple Google Cloud Services\n**Regions/Zones:** us-east1-c\n**Description:**\nDue to elevated latencies, several Google Cloud Products experienced increased error rates for a period of 3 hrs 04 minutes. The issues were triggered by high memory consumption on the file storage system in the Google Cloud distributed storage infrastructure [1] within us-east1-c. These issues were predominantly isolated to us-east1-c for zonal services, but some regional services experienced degradation until their traffic was redirected away from the impacted zone.\n[1] - https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system\n**Customer Impact:**\n- **BigQuery :** Customers would have experienced failures or slowness in their requests in the us-east1 region.\n- **Cloud Dataflow:** Customers would have experienced slow or stuck jobs in us-east1.\n- **App Engine:** Customers would have experienced brief periods of unavailability.\n- **Cloud Tasks:** Customers would have experienced elevated latencies with task delivery in us-east1.\n- **Cloud Pub/Sub:** Customers would have experienced elevated error rate for Pub/Sub operations in us-east1.\n- **Persistent Disk:** Customers would have experienced slow or stuck disk reads in the us-east1-c zone leading to unresponsive instances. A small number of Regional Persistent Disk volumes experienced slow disk reads in the us-east1 region.\n- **Cloud Bigtable:** Customers would have experienced elevated latency or errors in the us-east1-c zone.\n- **Cloud Run:** A small number of customers in us-east1 would have experienced brief periods of unavailability.\n- **Google Compute Engine:** Customers would have experienced elevated latencies during instance creation or deletion operations in us-east1 and us-east4.\n- **Google Cloud Networking:** Customers would have experienced delays in connecting to newly created instances or delays in propagation of new changes to firewall programming in us-east1. Network traffic for existing instances was not affected. Customers would have also experienced delays in Cloud Load Balancing creation or modification.\n- **Cloud Functions:** Customers would have experienced elevated availability issues in us-east1.\n- **Cloud Composer:** Customers would have experienced failure with new cloud composer creations in us-east1 and us-east4 . Existing cloud composer environments were not affected.\n- **Cloud Datastore:** Customers would have experienced elevated query latencies in us-east1.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-05T00:09:17+00:00","modified":"2022-06-05T00:09:19+00:00","when":"2022-06-05T00:09:17+00:00","text":"The issue with Apigee, Cloud Data Fusion, Cloud Filestore, Cloud Load Balancing, Cloud Run, Data Catalog, Datastream, Google App Engine, Google BigQuery, Google Cloud Bigtable, Google Cloud Composer, Google Cloud Dataflow, Google Cloud Datastore, Google Cloud Functions, Google Cloud Networking, Google Cloud Pub/Sub, Google Cloud SQL, Google Cloud Tasks, Google Compute Engine, Google Kubernetes Engine, Persistent Disk, Virtual Private Cloud (VPC) has been resolved for all affected users as of Saturday, 2022-06-04 17:03 US/Pacific.\nMost service impact was mitigated by 2022-06-04 13:20 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T23:43:24+00:00","modified":"2022-06-04T23:43:27+00:00","when":"2022-06-04T23:43:24+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: We believe the issue with Apigee, Cloud Data Fusion, Cloud Filestore, Cloud Load Balancing, Cloud Run, Data Catalog, Datastream, Google App Engine, Google BigQuery, Google Cloud Bigtable, Google Cloud Composer, Google Cloud Dataflow, Google Cloud Datastore, Google Cloud Functions, Google Cloud Networking, Google Cloud Pub/Sub, Google Cloud SQL, Google Cloud Tasks, Google Compute Engine, Google Kubernetes Engine, Persistent Disk, Virtual Private Cloud (VPC) is partially resolved.\nWe believe most service impact was mitigated by 2022-06-04 13:30 US/Pacific. We do not have an ETA for full resolution at this point.\nWe will provide an update by Saturday, 2022-06-04 18:00 US/Pacific with current details.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: [Mitigated] Elevated BigQuery latency and errors on Queries.\n- Dataflow: [Mitigated] Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: [Mitigated] Increased errors and/or latency.\n- Persistent Disk: [Mitigated] 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: [Mitigated] Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\n- Cloud Composer: [Mitigated] Creations fail because of errors creating App Engine apps, may be in additional regions.\n- Datastore: [Mitigated] Increased latency particular for queries.\n- Data Catalog: [Mitigated]\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T22:31:50+00:00","modified":"2022-06-04T22:31:50+00:00","when":"2022-06-04T22:31:50+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: We believe the issue with Apigee, Cloud Data Fusion, Cloud Filestore, Cloud Load Balancing, Cloud Run, Data Catalog, Datastream, Google App Engine, Google BigQuery, Google Cloud Bigtable, Google Cloud Composer, Google Cloud Dataflow, Google Cloud Datastore, Google Cloud Functions, Google Cloud Networking, Google Cloud Pub/Sub, Google Cloud SQL, Google Cloud Tasks, Google Compute Engine, Google Kubernetes Engine, Persistent Disk, Virtual Private Cloud (VPC) is partially resolved.\nWe believe most service impact was mitigated by 2022-06-04 13:30 US/Pacific. We do not have an ETA for full resolution at this point.\nWe will provide an update by Saturday, 2022-06-04 17:00 US/Pacific with current details.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: [Mitigated] Elevated BigQuery latency and errors on Queries.\n- Dataflow: [Mitigated] Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: [Mitigated] Increased errors and/or latency.\n- Persistent Disk: [Mitigated] 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: [Mitigated] Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\n- Cloud Composer: [Mitigated] Creations fail because of errors creating App Engine apps, may be in additional regions.\n- Datastore: [Mitigated] Increased latency particular for queries.\n- Data Catalog: [Mitigated]\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T21:21:43+00:00","modified":"2022-06-04T21:21:43+00:00","when":"2022-06-04T21:21:43+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: We believe the issue with Apigee, Cloud Data Fusion, Cloud Filestore, Cloud Load Balancing, Cloud Run, Data Catalog, Datastream, Google App Engine, Google BigQuery, Google Cloud Bigtable, Google Cloud Composer, Google Cloud Dataflow, Google Cloud Datastore, Google Cloud Functions, Google Cloud Networking, Google Cloud Pub/Sub, Google Cloud SQL, Google Cloud Tasks, Google Compute Engine, Google Kubernetes Engine, Persistent Disk, Virtual Private Cloud (VPC) is partially resolved.\nWe believe we have addressed the root cause and are seeing substantial improvements. Currently we are working to verify mitigation for each of the services. We do not have an ETA for full resolution at this point.\nWe will provide an update by Saturday, 2022-06-04 15:30 US/Pacific with current details.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: [Mitigated] Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: Increased errors and/or latency.\n- Persistent Disk: 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\n- Cloud Composer: Creations fail because of errors creating App Engine apps, may be in additional regions.\n- Datastore: [Mitigated] Increased latency particular for queries.\n- Data Catalog: [Mitigated]\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T20:57:54+00:00","modified":"2022-06-04T21:00:29+00:00","when":"2022-06-04T20:57:54+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Saturday, 2022-06-04 14:00 US/Pacific.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: [Mitigated] Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: Increased errors and/or latency.\n- Persistent Disk: 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\n- Cloud Composer: Creations fail because of errors creating App Engine apps, may be in additional regions.\n- Datastore: [Mitigated] Increased latency particular for queries.\n- Data Catalog: [Mitigated]\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T19:50:22+00:00","modified":"2022-06-04T21:00:35+00:00","when":"2022-06-04T19:50:22+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Saturday, 2022-06-04 14:00 US/Pacific.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: Increased errors and/or latency.\n- Persistent Disk: 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T19:01:36+00:00","modified":"2022-06-04T21:00:40+00:00","when":"2022-06-04T19:01:36+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Mitigation work is still underway by our engineering team.\nWe will provide more information by Saturday, 2022-06-04 13:00 US/Pacific.\nDiagnosis: Please see the additional details below for product specific impact where available:\n- BigQuery: Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: [Mitigated] Elevated unavailability.\n- Cloud Tasks: [Mitigated] Elevated unavailability.\n- Cloud Pub/Sub: Increased errors and/or latency.\n- Persistent Disk: 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\n- Cloud Run: [Mitigated] Elevated unavailability.\n- Compute Engine: No impact outside of side effects from underlying Persistent Disk impact.\n- Cloud Networking: Entire zone us-east1-c has delayed firewall programming for new changes to data plane, and delays launching or ssh'ing to instances. Existing programming should continue to work.\n- Cloud Functions: [Mitigated] Elevated unavailability.\nWorkaround: In general, retry failed requests or use an alternative region than us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible. Please see the additional details below for product specific workarounds where available:\n- Dataflow: If feasible, customers can consider restarting jobs again. They should be restarted in an unimpacted zone.\n- Persistent Disk: Use a different zone or PD-SSD disks.\n- Cloud Networking: If you are using load balancers or HA configuration, failover away from us-east1-c","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T18:43:38+00:00","modified":"2022-06-04T21:01:03+00:00","when":"2022-06-04T18:43:38+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-06-04 13:00 US/Pacific.\nDiagnosis:\nPlease see the additional details below for product specific impact where available:\n- BigQuery: Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: Elevated unavailability.\n- Cloud Tasks: Elevated unavailability.\n- Cloud Pub/Sub: Increased errors and/or latency.\n- Persistent Disk: 1% of PD-Standard (PD-HDD) disks in us-east1-c, and regional disks in us-east-1 are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\n- Cloud Bigtable: Elevated latency and errors in east1-c.\nWorkaround: Retry failed requests or use an alternative region that us-east1 for regional services, and an alternative zone than us-east1-c for zonal services where possible.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T18:22:38+00:00","modified":"2022-06-04T21:00:54+00:00","when":"2022-06-04T18:22:38+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Our engineering team continues to investigate the issue, which appears to be impacting multiple products in us-east1.\nWe will provide an update by Saturday, 2022-06-04 12:30 US/Pacific with current details.\nDiagnosis: Please see the following details for product specific impact:\n- BigQuery: Elevated BigQuery latency and errors on Queries.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\n- App Engine: Elevated unavailability.\n- Cloud Tasks: Elevated unavailability.\n- Cloud Pub/Sub: Elevated unavailability.\n- Persistent DIsk: Small number of PD-Standard (PD-HDD) disks in us-east1-c only are experiencing slow or stuck disk reads (operations hanging indefinitely), which may cause instances to become unresponsive.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T17:55:42+00:00","modified":"2022-06-04T21:00:49+00:00","when":"2022-06-04T17:55:42+00:00","text":"Summary: us-east1: Elevated errors affecting multiple services.\nDescription: Our engineering team continues to investigate the issue, which appears to be impacting multiple products in us-east1.\nWe will provide an update by Saturday, 2022-06-04 12:00 US/Pacific with current details.\nDiagnosis:\n- BigQuery: Elevated BigQuery errors.\n- Dataflow: Some customers will see stuckness or slowness in their Dataflow batch and streaming jobs.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-06-04T17:40:29+00:00","modified":"2022-06-04T17:40:37+00:00","when":"2022-06-04T17:40:29+00:00","text":"Summary: us-east1: Elevated BigQuery errors.\nDescription: We are experiencing an issue with Google BigQuery beginning at Saturday, 2022-06-04 10:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Saturday, 2022-06-04 11:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-06-06T09:14:00+00:00","modified":"2022-07-12T17:52:32+00:00","when":"2022-06-06T09:14:00+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case at https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 04 June 2022 10:47\n**Incident End:** 04 June 2022 17:03\n**Duration:** 6 hours 16 minutes\n**Affected Services and Features:**\nMultiple Google Cloud Services\n**Regions/Zones:** us-east1-c\n**Description:**\nDue to elevated latencies, several Google Cloud Products experienced increased error rates for a period of 3 hrs 04 minutes. The issues were triggered by high memory consumption on the file storage system in the Google Cloud distributed storage infrastructure [1] within us-east1-c. These issues were predominantly isolated to us-east1-c for zonal services, but some regional services experienced degradation until their traffic was redirected away from the impacted zone.\n[1] - https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system\n**Customer Impact:**\n- **BigQuery :** Customers would have experienced failures or slowness in their requests in the us-east1 region.\n- **Cloud Dataflow:** Customers would have experienced slow or stuck jobs in us-east1.\n- **App Engine:** Customers would have experienced brief periods of unavailability.\n- **Cloud Tasks:** Customers would have experienced elevated latencies with task delivery in us-east1.\n- **Cloud Pub/Sub:** Customers would have experienced elevated error rate for Pub/Sub operations in us-east1.\n- **Persistent Disk:** Customers would have experienced slow or stuck disk reads in the us-east1-c zone leading to unresponsive instances. A small number of Regional Persistent Disk volumes experienced slow disk reads in the us-east1 region.\n- **Cloud Bigtable:** Customers would have experienced elevated latency or errors in the us-east1-c zone.\n- **Cloud Run:** A small number of customers in us-east1 would have experienced brief periods of unavailability.\n- **Google Compute Engine:** Customers would have experienced elevated latencies during instance creation or deletion operations in us-east1 and us-east4.\n- **Google Cloud Networking:** Customers would have experienced delays in connecting to newly created instances or delays in propagation of new changes to firewall programming in us-east1. Network traffic for existing instances was not affected. Customers would have also experienced delays in Cloud Load Balancing creation or modification.\n- **Cloud Functions:** Customers would have experienced elevated availability issues in us-east1.\n- **Cloud Composer:** Customers would have experienced failure with new cloud composer creations in us-east1 and us-east4 . Existing cloud composer environments were not affected.\n- **Cloud Datastore:** Customers would have experienced elevated query latencies in us-east1.","status":"AVAILABLE","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"},{"title":"Apigee","id":"9Y13BNFy4fJydvjdsN3X"},{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"},{"title":"Data Catalog","id":"TFedVRYgKGRGMSJrUpup"},{"title":"Datastream","id":"ibJgP4CNKnFojHHw8L3s"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"},{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"},{"title":"Google Cloud Datastore","id":"MaS3dKoqp1oqkea4qB9U"},{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"},{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"},{"title":"Google Cloud Tasks","id":"tMWyzhyKK4rAzAf7x62h"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"},{"title":"Cloud Data Fusion","id":"rLKDHeeaBiXTeutF1air"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"}],"uri":"incidents/6sfxucMj6DuhVzmj9Xr8","currently_affected_locations":[],"previously_affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"XdQANahFJvMuxxkgA34K","number":"8853971020270422709","begin":"2022-06-02T17:10:00+00:00","created":"2022-06-02T20:58:28+00:00","end":"2022-06-02T21:30:00+00:00","modified":"2022-06-03T20:07:35+00:00","external_desc":"Global: Vertex AI Online Prediction Is Experiencing Increased Error Rates","updates":[{"created":"2022-06-03T20:06:43+00:00","modified":"2022-06-03T20:06:43+00:00","when":"2022-06-03T20:06:43+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 02 June 2022 10:10 US/Pacific\n**Incident End:** 02 June 2022 14:30 US/Pacific\n**Duration:** 4 hours, 20 minutes\n**Affected Services and Features:** Vertex AI Online Prediction\n**Regions/Zones:** Global\n**Description:**\nVertex AI Online Prediction experienced increased error rates from 30% up to 100% per region depending on user usage patterns for a duration of 4 hours, 20 minutes. From preliminary analysis, the root cause of the issue was that Vertex Prediction Endpoints were globally marked as deleted due to faulty resource cleanup process. The service fully recovered when the Vertex Prediction Endpoints were restored.\n**Customer Impact:**\nAffected customers may have experienced:\n- All pre-existing Vertex models undeployed on Vertex AI Endpoints\n- Empty responses when listing the deployed models\n- Runtime exceptions and general errors on Predict and Explain requests\n- Quota failure when trying to re-deploy models","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-02T22:24:14+00:00","modified":"2022-06-02T22:24:15+00:00","when":"2022-06-02T22:24:14+00:00","text":"The issue with Vertex AI Online Prediction has been resolved for all affected users as of Thursday, 2022-06-02 15:21 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-02T21:51:12+00:00","modified":"2022-06-02T21:51:12+00:00","when":"2022-06-02T21:51:12+00:00","text":"Summary: Global: Vertex AI Online Prediction Is Experiencing Increased Error Rates\nDescription: We believe the issue with Vertex AI Online Prediction is partially resolved.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Thursday, 2022-06-02 16:10 US/Pacific with current details.\nDiagnosis: For affected customers: When listing the deployed models in Endpoints, the list will be empty and Predict and Explain requests would fail.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-02T21:50:34+00:00","modified":"2022-06-02T21:50:35+00:00","when":"2022-06-02T21:50:34+00:00","text":"Summary: Global: Vertex AI Online Prediction Is Experiencing Increased Error Rates\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-06-02 15:07 US/Pacific.\nWe will provide more information by Thursday, 2022-06-02 15:07 US/Pacific.\nDiagnosis: For affected customers: When listing the deployed models in Endpoints, the list will be empty and Predict and Explain requests would fail.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-02T21:06:31+00:00","modified":"2022-06-02T21:06:32+00:00","when":"2022-06-02T21:06:31+00:00","text":"Summary: Global: Vertex AI Online Prediction Is Experiencing Increased Error Rates\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-06-02 15:07 US/Pacific.\nWe will provide more information by Thursday, 2022-06-02 15:07 US/Pacific.\nDiagnosis: Customers will experiences increased error rates.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"created":"2022-06-02T20:58:27+00:00","modified":"2022-06-02T20:58:28+00:00","when":"2022-06-02T20:58:27+00:00","text":"Summary: Global: Vertex AI Online Prediction Is Experiencing Increased Error Rates\nDescription: We are experiencing an issue with Vertex AI Online Prediction beginning at Thursday, 2022-06-02 10:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-06-02 14:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will experiences errors\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]}],"most_recent_update":{"created":"2022-06-03T20:06:43+00:00","modified":"2022-06-03T20:06:43+00:00","when":"2022-06-03T20:06:43+00:00","text":"# Mini Incident Report\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 02 June 2022 10:10 US/Pacific\n**Incident End:** 02 June 2022 14:30 US/Pacific\n**Duration:** 4 hours, 20 minutes\n**Affected Services and Features:** Vertex AI Online Prediction\n**Regions/Zones:** Global\n**Description:**\nVertex AI Online Prediction experienced increased error rates from 30% up to 100% per region depending on user usage patterns for a duration of 4 hours, 20 minutes. From preliminary analysis, the root cause of the issue was that Vertex Prediction Endpoints were globally marked as deleted due to faulty resource cleanup process. The service fully recovered when the Vertex Prediction Endpoints were restored.\n**Customer Impact:**\nAffected customers may have experienced:\n- All pre-existing Vertex models undeployed on Vertex AI Endpoints\n- Empty responses when listing the deployed models\n- Runtime exceptions and general errors on Predict and Explain requests\n- Quota failure when trying to re-deploy models","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Vertex AI Online Prediction","id":"sdXM79fz1FS6ekNpu37K"},{"title":"Cloud Machine Learning","id":"z9PfKanGZYvYNUbnKzRJ"}],"uri":"incidents/XdQANahFJvMuxxkgA34K","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"}]},{"id":"YkkPCVAzdyuNJJFS54kM","number":"666965533070443831","begin":"2022-05-31T19:32:50+00:00","created":"2022-05-31T19:50:19+00:00","end":"2022-05-31T20:56:11+00:00","modified":"2022-05-31T20:56:11+00:00","external_desc":"Cloud Build ListBuild HTTP calls having increased latency and timeouts","updates":[{"created":"2022-05-31T20:56:10+00:00","modified":"2022-05-31T20:56:11+00:00","when":"2022-05-31T20:56:10+00:00","text":"The issue with Cloud Build has been resolved for all affected users as of Tuesday, 2022-05-31 13:44 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-05-31T19:51:25+00:00","modified":"2022-05-31T19:51:25+00:00","when":"2022-05-31T19:51:25+00:00","text":"Summary: Cloud Build ListBuild HTTP calls having increased latency and timeouts\nDescription: We are experiencing an issue with Cloud Build beginning at Tuesday, 2022-05-31 11:04 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-05-31 13:59 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers making google.devtools.cloudbuild.v1.CloudBuild.ListBuilds HTTP calls may see elevated latency or timeouts.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-05-31T19:50:19+00:00","modified":"2022-05-31T19:50:20+00:00","when":"2022-05-31T19:50:19+00:00","text":"Summary: Cloud Build ListBuild HTTP calls having increased latency and timeouts\nDescription: We are experiencing an issue with Cloud Build beginning at Tuesday, 2022-05-31 11:04 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-05-31 13:59 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud Build ListBuild HTTP calls having increased latency and timeouts\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-31T20:56:10+00:00","modified":"2022-05-31T20:56:11+00:00","when":"2022-05-31T20:56:10+00:00","text":"The issue with Cloud Build has been resolved for all affected users as of Tuesday, 2022-05-31 13:44 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Developer Tools","id":"BGJQ6jbGK4kUuBTQFZ1G"},{"title":"Cloud Build","id":"fw8GzBdZdqy4THau7e1y"}],"uri":"incidents/YkkPCVAzdyuNJJFS54kM","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"haJamsyevGnru71kfZRM","number":"7009434990327813350","begin":"2022-05-31T15:14:32+00:00","created":"2022-05-31T15:14:50+00:00","end":"2022-05-31T17:39:45+00:00","modified":"2022-05-31T17:39:45+00:00","external_desc":"Networking metrics in Cloud Monitoring partially unavailable in europe-west4, us-central*","updates":[{"created":"2022-05-31T17:39:45+00:00","modified":"2022-05-31T17:39:45+00:00","when":"2022-05-31T17:39:45+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected users as of Tuesday, 2022-05-31 10:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-31T17:32:56+00:00","modified":"2022-05-31T17:32:58+00:00","when":"2022-05-31T17:32:56+00:00","text":"Summary: Networking metrics in Cloud Monitoring partially unavailable in europe-west4, us-central*\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-05-31 12:00 US/Pacific.\nDiagnosis: Customers will see unavailable Cloud Networking metrics in affected regions (in europe-west4, us-central*)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-05-31T15:57:46+00:00","modified":"2022-05-31T15:57:47+00:00","when":"2022-05-31T15:57:46+00:00","text":"Summary: Networking metrics in Cloud Monitoring partially unavailable in europe-west4, us-central*\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-05-31 10:34 US/Pacific.\nDiagnosis: Customers will see unavailable Cloud Networking metrics in affected regions (in europe-west4, us-central*)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]},{"created":"2022-05-31T15:14:40+00:00","modified":"2022-05-31T15:14:52+00:00","when":"2022-05-31T15:14:40+00:00","text":"Summary: Networking metrics in Cloud Monitoring partially unavailable in europe-west4, us-central*\nDescription: We are experiencing an intermittent issue with Cloud Monitoring beginning at Tuesday, 2022-05-31 00:00 US/Pacific beginning at Tuesday, 2022-05-31 06:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-05-31 09:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see unavailable Cloud Networking metrics in affected regions (in europe-west4, us-central*)\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-31T17:39:45+00:00","modified":"2022-05-31T17:39:45+00:00","when":"2022-05-31T17:39:45+00:00","text":"The issue with Cloud Monitoring has been resolved for all affected users as of Tuesday, 2022-05-31 10:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"}],"uri":"incidents/haJamsyevGnru71kfZRM","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"ipisoukd9hNno6SbpWWE","number":"13688798534542981487","begin":"2022-05-27T20:56:06+00:00","created":"2022-05-27T20:56:18+00:00","end":"2022-05-27T21:04:41+00:00","modified":"2022-05-27T21:04:41+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-05-27T21:04:40+00:00","modified":"2022-05-27T21:04:42+00:00","when":"2022-05-27T21:04:40+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-27T20:56:10+00:00","modified":"2022-05-27T20:56:20+00:00","when":"2022-05-27T20:56:10+00:00","text":"Summary: Europe : Eventarc GCS trigger mutations failing sporadically in Europe\nDescription: We are experiencing an intermittent issue with Eventarc beginning at Friday, 2022-05-26 20:56 US/Pacific. Users may receive an internal error when manipulating GCS triggers.\nOur engineering team continues to investigate the issue. Users can retry manipulating the trigger.\nWe will provide an update by Friday, 2022-05-27 14:20 US/Pacific with current details.\nDiagnosis: Eventarc users may receive an internal error when manipulating GCS triggers\nWorkaround: Users can retry manipulating the trigger","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-27T21:04:40+00:00","modified":"2022-05-27T21:04:42+00:00","when":"2022-05-27T21:04:40+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"YaFawoMaXnqgY4keUBnW","service_name":"Eventarc","affected_products":[{"title":"Eventarc","id":"YaFawoMaXnqgY4keUBnW"}],"uri":"incidents/ipisoukd9hNno6SbpWWE","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"eMrkQFQCj1Xmf3trQRNt","number":"9948110675578981301","begin":"2022-05-27T20:42:25+00:00","created":"2022-05-27T21:26:15+00:00","end":"2022-05-27T22:12:21+00:00","modified":"2022-05-27T22:12:22+00:00","external_desc":"Europe: Customers may experience elevated errors with Google Cloud Storage API operation.","updates":[{"created":"2022-05-27T22:12:16+00:00","modified":"2022-05-27T22:12:22+00:00","when":"2022-05-27T22:12:16+00:00","text":"The issue with Eventarc, Google Cloud Storage has been resolved for all affected projects as of Friday, 2022-05-27 15:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-27T21:50:05+00:00","modified":"2022-05-27T21:50:07+00:00","when":"2022-05-27T21:50:05+00:00","text":"Summary: Europe: Customers may experience elevated errors with Google Cloud Storage API operation.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-05-27 18:00 US/Pacific.\nWe will provide more information by Friday, 2022-05-27 18:00 US/Pacific.\nDiagnosis: Customers may experience elevated CLOUD_IAM_SERVICE_ERROR with GetProjectServiceAccount calls to GCS.\nEventarc users creating, updating, or deleting GCS triggers in European regions may get an internal error.\nWorkaround: Eventarc users can retry the create/update/delete operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Multi-region: eu","id":"eu"}]},{"created":"2022-05-27T21:26:14+00:00","modified":"2022-05-27T21:26:16+00:00","when":"2022-05-27T21:26:14+00:00","text":"Summary: Europe: Customers may experience elevated errors with Google Cloud Storage API operation.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-05-27 17:30 US/Pacific.\nWe will provide more information by Friday, 2022-05-27 18:00 US/Pacific.\nDiagnosis: Customers may experience elevated CLOUD_IAM_SERVICE_ERROR with GetProjectServiceAccount calls to GCS.\nEventarc users creating, updating, or deleting GCS triggers in European regions may get an internal error.\nWorkaround: Eventarc users can retry the create/update/delete operation.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-05-27T22:12:16+00:00","modified":"2022-05-27T22:12:22+00:00","when":"2022-05-27T22:12:16+00:00","text":"The issue with Eventarc, Google Cloud Storage has been resolved for all affected projects as of Friday, 2022-05-27 15:11 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Eventarc","id":"YaFawoMaXnqgY4keUBnW"}],"uri":"incidents/eMrkQFQCj1Xmf3trQRNt","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Multi-region: eu","id":"eu"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Madrid (europe-southwest1)","id":"europe-southwest1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Milan (europe-west8)","id":"europe-west8"},{"title":"Paris (europe-west9)","id":"europe-west9"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"qD5T5M49jVJvj4NXvYjK","number":"11614801264955688536","begin":"2022-05-27T19:59:44+00:00","created":"2022-05-27T20:22:44+00:00","end":"2022-05-27T20:33:58+00:00","modified":"2022-05-27T20:33:58+00:00","external_desc":"us-east4: Cloud Interconnects are experiencing latency spikes and packet loss.","updates":[{"created":"2022-05-27T20:33:58+00:00","modified":"2022-05-27T20:34:00+00:00","when":"2022-05-27T20:33:58+00:00","text":"The issue with Google Cloud Networking is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"created":"2022-05-27T20:22:43+00:00","modified":"2022-05-27T20:22:46+00:00","when":"2022-05-27T20:22:43+00:00","text":"Summary: us-east4: Cloud Interconnects are experiencing latency spikes and packet loss.\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Friday, 2022-05-27 11:03 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-27 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers with Cloud Interconnects in us-east4 may experience latency spikes and packet loss.\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-27T20:33:58+00:00","modified":"2022-05-27T20:34:00+00:00","when":"2022-05-27T20:33:58+00:00","text":"The issue with Google Cloud Networking is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nNo further updates will be provided here.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/qD5T5M49jVJvj4NXvYjK","currently_affected_locations":[],"previously_affected_locations":[{"title":"Northern Virginia (us-east4)","id":"us-east4"}]},{"id":"2uFuNdeK9xXSwY9w7cCj","number":"7247953702549949059","begin":"2022-05-26T12:14:30+00:00","created":"2022-05-26T13:52:30+00:00","end":"2022-05-26T15:49:34+00:00","modified":"2022-05-26T15:49:34+00:00","external_desc":"Google Cloud python libraries incompatible with 4.21.0 protobuf library release","updates":[{"created":"2022-05-26T15:49:33+00:00","modified":"2022-05-26T15:49:35+00:00","when":"2022-05-26T15:49:33+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Thursday, 2022-05-26 08:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-26T15:18:35+00:00","modified":"2022-05-26T15:18:40+00:00","when":"2022-05-26T15:18:35+00:00","text":"Summary: Google Cloud python libraries incompatible with 4.21.0 protobuf library release\nDescription: We are experiencing an issue with the python Google Cloud Client libraries beginning on Wednesday, 2022-05-25 18:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-05-26 08:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Impacted customers will see applications failing to initialize with a \"TypeError: Descriptors cannot not be created directly.\" error.\nWorkaround: None at this time","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-26T14:48:27+00:00","modified":"2022-05-26T14:48:32+00:00","when":"2022-05-26T14:48:27+00:00","text":"Summary: Google Cloud python libraries incompatible with 4.21.0 protobuf library release\nDescription: We are experiencing an issue with the python Google Cloud Client libraries beginning on Wednesday, 2022-05-25 18:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-05-26 08:20 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Impacted customers will see applications failing to initialize with a \"TypeError: Descriptors cannot not be created directly.\" error.\nWorkaround: None at this time","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-26T13:52:28+00:00","modified":"2022-05-26T13:52:34+00:00","when":"2022-05-26T13:52:28+00:00","text":"Summary: Google Cloud python libraries incompatible with 4.21.0 protobuf library release\nDescription: We are experiencing an issue with Google Cloud Functions beginning on Wednesday, 2022-05-25 18:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-05-26 07:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected Cloud Functions create and update function operations will fail\nWorkaround: Downgrade the protobuf package to 3.20.x by adding protobuf==3.20.1 to requirements.txt then retry the create/update function operation","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-05-26T15:49:33+00:00","modified":"2022-05-26T15:49:35+00:00","when":"2022-05-26T15:49:33+00:00","text":"The issue with Google Cloud Functions has been resolved for all affected users as of Thursday, 2022-05-26 08:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"oW4vJ7VNqyxTWNzSHopX","service_name":"Google Cloud Functions","affected_products":[{"title":"Google Cloud Functions","id":"oW4vJ7VNqyxTWNzSHopX"}],"uri":"incidents/2uFuNdeK9xXSwY9w7cCj","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"Gt6njQyniuxXViQULV2T","number":"18110704032802855247","begin":"2022-05-25T01:04:00+00:00","created":"2022-05-25T07:29:52+00:00","end":"2022-05-25T17:34:00+00:00","modified":"2022-06-02T17:21:24+00:00","external_desc":"Global: BigQuery may experience elevated query latencies or failures.","updates":[{"created":"2022-06-02T17:20:00+00:00","modified":"2022-06-02T17:21:19+00:00","when":"2022-06-02T17:20:00+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 24 May 2022 from 18:04 to 25 May 2022 10:34 Google BigQuery experienced elevated query latencies and job failures in four regions (US multiregion, europe-west1, asia-east1, and asia-east2) for a duration of 16 hours, 30 minutes. A product change roll out was identified as the root cause. The issue was mitigated by rolling back the changes. The rollback was performed in phases to prevent additional impact on the service, which caused some regions to recover earlier than others. Affected customers experienced elevated latencies or failures for QUERY, IMPORT and EXPORT jobs in BigQuery.\n**Root Cause:**\nOn 11 May 2022, BigQuery began a software rollout to improve audit logging for data that is imported from, queried, or exported to Google Cloud Storage (GCS). This rollout inadvertently contained a memory leak that gradually and incrementally manifested whenever these code paths were executed. This memory leak gradually consumed memory on BigQuery’s compute nodes until they were unable to accept new work to execute jobs, including queries, loads, and exports. The software rollout was deployed to all regions before the issue was detected and rolled back. Given the nature of the root cause, significant user load and time were required for the issue to manifest, meaning that the issue was not observed in internal testing, or in most of BigQuery's production regions.\n**Remediation and Prevention:**\nBigQuery will take the following actions to mitigate against such issues happening in the future: - In the short-term, enable comprehensive memory error detector coverage for the affected code path to detect possible memory leaks ahead of time. - In the long-term, ensure such analysis is enabled for all BigQuery code paths.\nIntroduce additional internal monitoring to detect memory pressure scenarios.\n**Detailed Description of Impact**\nIn affected regions, a portion of BigQuery compute nodes were unable to service incoming jobs due to insufficient memory. As a result customer jobs - including queries, loads, and exports - experienced elevated latencies and failures while waiting for nodes with sufficient memory to become available.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T21:54:12+00:00","modified":"2022-05-25T21:54:12+00:00","when":"2022-05-25T21:54:12+00:00","text":"**Mini Incident-Report:**\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 24 May 2022 18:04\n**Incident End:** 25 May 2022 12:19\n**Duration:** 18 hours, 15 minutes\n**Affected Services and Features:**\n* Google BigQuery\n**Regions/Zones:** Global\n**Description:**\nGoogle BigQuery experienced elevated query latencies and job failures globally for a duration of 18 hours, 15 minutes. From preliminary analysis, the root cause of the issue is a product change which had been rolled out globally. The issue was mitigated by rolling back the changes. The rollback was performed in a phased manner to prevent additional impact on the service and some regions would have recovered earlier than others.\n**Customer Impact:**\n* Affected customers would have experienced elevated query latencies or in some cases query failures.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T19:32:23+00:00","modified":"2022-05-25T19:32:25+00:00","when":"2022-05-25T19:32:23+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of customers and our Engineering Team continues to work on mitigation across all regions.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T19:30:58+00:00","modified":"2022-05-25T19:31:00+00:00","when":"2022-05-25T19:30:58+00:00","text":"The issue with Google BigQuery is believed to be affecting a very small number of customers and our Engineering Team continues to work on mitigation across all regions.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T19:00:40+00:00","modified":"2022-05-25T19:00:42+00:00","when":"2022-05-25T19:00:40+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: us multi-region, europe-west1, asia-east1, and asia-east2 regions have recovered and our engineering team continue to monitor the situation for full recovery.\nWe will provide more information by Wednesday, 2022-05-25 13:00 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T16:55:14+00:00","modified":"2022-05-25T16:55:22+00:00","when":"2022-05-25T16:55:14+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: us multi-region, europe-west1, asia-east1, and asia-east2 regions have recovered and our engineering team is currently monitoring the situation for full recovery.\nWe will provide more information by Wednesday, 2022-05-25 12:00 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T15:51:15+00:00","modified":"2022-05-25T15:51:17+00:00","when":"2022-05-25T15:51:15+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: The US multi- region is nearly completely recovered and the europe-west1, asia-east1, and asia-east2 regions have fully recovered. Other regions are currently not affected but precautionary actions are being taking globally by our engineering team.\nWe will provide more information by Wednesday, 2022-05-25 10:00 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Multi-region: eu","id":"eu"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T15:26:27+00:00","modified":"2022-05-25T15:26:33+00:00","when":"2022-05-25T15:26:27+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: All Global locations including multi-region locations for BigQuery are impacted.\nEurope-west1 and Asia-east2 are currently mitigated\nMitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 09:00 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T14:40:41+00:00","modified":"2022-05-25T14:40:48+00:00","when":"2022-05-25T14:40:41+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: All Global locations including multi-region locations for BigQuery are impacted.\nEurope-west1 is currently mitigated\nMitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 08:45 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T13:44:08+00:00","modified":"2022-05-25T13:44:12+00:00","when":"2022-05-25T13:44:08+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures.\nDescription: All Global locations including multi-region locations for BigQuery are impacted.\nEurope-west1 is currently mitigated\nMitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 07:30 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Multi-region: eu","id":"eu"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T13:25:02+00:00","modified":"2022-05-25T13:25:09+00:00","when":"2022-05-25T13:25:02+00:00","text":"Summary: Global: BigQuery may experience elevated query latencies or failures\nDescription: Europe-west1 is currently mitigated\nMitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 07:30 US/Pacific.\nDiagnosis: Customers will experience Increased Query latency and possible job failures.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-25T12:00:07+00:00","modified":"2022-05-25T12:00:18+00:00","when":"2022-05-25T12:00:07+00:00","text":"Summary: BigQuery degraded in us-multiregion, europe-west1, asia-northeast1, asia-southeast1, asia-southeast2, eu-canary, europe-west2, europe-west6, europe-west9, us-central1, us-west4. Customers will experience Increased Query latency and possible job failures.\nDescription: Europe-west1 is currently mitigated and mitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 06:30 US/Pacific.\nDiagnosis: Increased Query latency and possible job failures\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-05-25T10:49:00+00:00","modified":"2022-05-25T10:49:06+00:00","when":"2022-05-25T10:49:00+00:00","text":"Summary: BigQuery degraded in us-multiregion and europe-west1. Customers will experience Increased Query latency and possible job failures.\nDescription: Europe-west1 is currently mitigated and mitigation work is currently underway for the remaining impacted regions by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 05:00 US/Pacific.\nDiagnosis: Increased Query latency and possible job failures\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-05-25T08:11:47+00:00","modified":"2022-05-25T08:11:48+00:00","when":"2022-05-25T08:11:47+00:00","text":"Summary: BigQuery degraded in us-multiregion and europe-west1. Customers will experience Increased Query latency and possible job failures.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 03:36 US/Pacific.\nDiagnosis: Increased Query latency and possible job failures\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-05-25T07:29:52+00:00","modified":"2022-05-25T07:29:54+00:00","when":"2022-05-25T07:29:52+00:00","text":"Summary: BigQuery degraded in multiple regions. Customers will experience Increased Query latency and possible job failures\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-05-25 01:36 US/Pacific.\nDiagnosis: Increased Query latency and possible job failures\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-06-02T17:20:00+00:00","modified":"2022-06-02T17:21:19+00:00","when":"2022-06-02T17:20:00+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 24 May 2022 from 18:04 to 25 May 2022 10:34 Google BigQuery experienced elevated query latencies and job failures in four regions (US multiregion, europe-west1, asia-east1, and asia-east2) for a duration of 16 hours, 30 minutes. A product change roll out was identified as the root cause. The issue was mitigated by rolling back the changes. The rollback was performed in phases to prevent additional impact on the service, which caused some regions to recover earlier than others. Affected customers experienced elevated latencies or failures for QUERY, IMPORT and EXPORT jobs in BigQuery.\n**Root Cause:**\nOn 11 May 2022, BigQuery began a software rollout to improve audit logging for data that is imported from, queried, or exported to Google Cloud Storage (GCS). This rollout inadvertently contained a memory leak that gradually and incrementally manifested whenever these code paths were executed. This memory leak gradually consumed memory on BigQuery’s compute nodes until they were unable to accept new work to execute jobs, including queries, loads, and exports. The software rollout was deployed to all regions before the issue was detected and rolled back. Given the nature of the root cause, significant user load and time were required for the issue to manifest, meaning that the issue was not observed in internal testing, or in most of BigQuery's production regions.\n**Remediation and Prevention:**\nBigQuery will take the following actions to mitigate against such issues happening in the future: - In the short-term, enable comprehensive memory error detector coverage for the affected code path to detect possible memory leaks ahead of time. - In the long-term, ensure such analysis is enabled for all BigQuery code paths.\nIntroduce additional internal monitoring to detect memory pressure scenarios.\n**Detailed Description of Impact**\nIn affected regions, a portion of BigQuery compute nodes were unable to service incoming jobs due to insufficient memory. As a result customer jobs - including queries, loads, and exports - experienced elevated latencies and failures while waiting for nodes with sufficient memory to become available.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/Gt6njQyniuxXViQULV2T","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Multi-region: eu","id":"eu"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Multi-region: us","id":"us"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"rrmfPRaESXcrpfxPo5y6","number":"17140268093845218737","begin":"2022-05-24T14:01:00+00:00","created":"2022-05-24T14:51:27+00:00","end":"2022-05-24T14:50:00+00:00","modified":"2022-05-24T18:52:35+00:00","external_desc":"Degraded serving for Google App Engine and Cloud Functions users in us-central1","updates":[{"created":"2022-05-24T18:36:18+00:00","modified":"2022-05-24T18:52:35+00:00","when":"2022-05-24T18:36:18+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 24 May 2022 07:01\n**Incident End:** 24 May 2022 07:50\n**Duration:** 49 minutes\n**Affected Services and Features:**\n* App Engine\n* Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Cloud Functions experienced elevated request latencies for a duration of 49 minutes. From preliminary analysis, the root cause of the issue is an unexpected surge in traffic which increased resource usage. The issue was mitigated by implementing safeguards to prevent resource starvation.\nWe continue to investigate the nature of the traffic surge and we will identify additional safeguards to prevent recurrence of the issue.\n**Customer Impact:**\n* Affected customers would have experienced elevated latencies for App Engine app serving and Cloud Function executions.\n* Less than 1% of the customers in us-central1 would have seen App Engine and Cloud Function requests failing with errors.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-24T15:03:45+00:00","modified":"2022-05-24T15:03:52+00:00","when":"2022-05-24T15:03:45+00:00","text":"The issue with Google App Engine has been resolved for all affected users as of Tuesday, 2022-05-24 07:50 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-24T14:51:18+00:00","modified":"2022-05-24T14:51:30+00:00","when":"2022-05-24T14:51:18+00:00","text":"Summary: Degraded serving for Google App Engine and Cloud Functions users in us-central1\nDescription: We are experiencing an issue with Google App Engine beginning at Tuesday, 2022-05-24 07:01 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-05-24 08:15 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers are seeing a high serving latency and request failures\nWorkaround: None at this time","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-05-24T18:36:18+00:00","modified":"2022-05-24T18:52:35+00:00","when":"2022-05-24T18:36:18+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 24 May 2022 07:01\n**Incident End:** 24 May 2022 07:50\n**Duration:** 49 minutes\n**Affected Services and Features:**\n* App Engine\n* Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Cloud Functions experienced elevated request latencies for a duration of 49 minutes. From preliminary analysis, the root cause of the issue is an unexpected surge in traffic which increased resource usage. The issue was mitigated by implementing safeguards to prevent resource starvation.\nWe continue to investigate the nature of the traffic surge and we will identify additional safeguards to prevent recurrence of the issue.\n**Customer Impact:**\n* Affected customers would have experienced elevated latencies for App Engine app serving and Cloud Function executions.\n* Less than 1% of the customers in us-central1 would have seen App Engine and Cloud Function requests failing with errors.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/rrmfPRaESXcrpfxPo5y6","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"JqefFhK5oa22EzFGhtg3","number":"419743856759571945","begin":"2022-05-23T08:26:00+00:00","created":"2022-05-23T16:01:37+00:00","end":"2022-05-23T16:30:00+00:00","modified":"2022-05-23T21:55:04+00:00","external_desc":"Some customer VMs may be unreachable in us-central1-b.","updates":[{"created":"2022-05-23T21:55:03+00:00","modified":"2022-05-23T21:55:03+00:00","when":"2022-05-23T21:55:03+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 23 May 2021 01:26\n**Incident End:** 23 May 2021 09:30\n**Duration:** 8 hours, 4 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:** us-central1-b\n**Description:**\nGoogle Cloud Networking experienced issues causing Google Compute Engine instances to be unreachable in us-central1-b for a duration of 8 hours, 4 minutes. From preliminary analysis, the root cause is a roll out in us-central1-b. The issue was mitigated by rolling back the changes.\n**Customer Impact:**\nAffected customers would have experienced issues with network traffic between Google Compute Engine instances within us-central1-b of the same VPC.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-23T16:35:56+00:00","modified":"2022-05-23T16:35:58+00:00","when":"2022-05-23T16:35:56+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Monday, 2022-05-23 09:29 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-23T16:05:11+00:00","modified":"2022-05-23T16:05:13+00:00","when":"2022-05-23T16:05:11+00:00","text":"Summary: Some customer VMs may be unreachable in us-central1-b.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-05-23 10:00 US/Pacific.\nWe will provide more information by Monday, 2022-05-23 10:30 US/Pacific.\nDiagnosis: VMs may be unreachable in us-central1-b.\nWorkaround: Customer can try migrating VMs to another cluster in us-central1-b.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-23T16:01:35+00:00","modified":"2022-05-23T16:01:39+00:00","when":"2022-05-23T16:01:35+00:00","text":"Summary: Some customer VMs may be unreachable in us-central1-b.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-05-23 10:00 US/Pacific.\nWe will provide more information by Monday, 2022-05-23 10:00 US/Pacific.\nDiagnosis: VMs may be unreachable in us-central1-b.\nWorkaround: Customer can try migrating VMs to another cluster in us-central1-b.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-23T21:55:03+00:00","modified":"2022-05-23T21:55:03+00:00","when":"2022-05-23T21:55:03+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 23 May 2021 01:26\n**Incident End:** 23 May 2021 09:30\n**Duration:** 8 hours, 4 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:** us-central1-b\n**Description:**\nGoogle Cloud Networking experienced issues causing Google Compute Engine instances to be unreachable in us-central1-b for a duration of 8 hours, 4 minutes. From preliminary analysis, the root cause is a roll out in us-central1-b. The issue was mitigated by rolling back the changes.\n**Customer Impact:**\nAffected customers would have experienced issues with network traffic between Google Compute Engine instances within us-central1-b of the same VPC.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/JqefFhK5oa22EzFGhtg3","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"eo76pxZiDgWVz4z3kmUv","number":"14038663271156697675","begin":"2022-05-20T20:47:00+00:00","created":"2022-05-20T21:44:17+00:00","end":"2022-05-20T21:07:00+00:00","modified":"2022-06-02T19:11:24+00:00","external_desc":"Global : Cloud Networking faced severe packet loss","updates":[{"created":"2022-06-02T19:11:24+00:00","modified":"2022-06-02T19:11:24+00:00","when":"2022-06-02T19:11:24+00:00","text":"**INCIDENT REPORT**\n**SUMMARY:**\nOn Friday, 20 May 2022 at 13:47 US/Pacific, Google Cloud Networking experienced intermittent packet loss for traffic between multiple cloud regions for a duration of 20 minutes. The issue was identified and mitigated automatically by 14:07 US/Pacific.\nWe understand this issue has affected our valued customers and users, and we apologize to those who were affected.\n**ROOT CAUSE:**\nGoogle’s production backbone is a global network that enables connectivity for all user-facing traffic via Points of Presence (POPs) or internet exchanges.\nA failure of a component on a fiber path from one of the central US gateway campuses in Google’s production backbone led to a decrease in available network bandwidth between the gateway and multiple edge locations, causing packet loss while the backbone automatically moved traffic onto remaining paths.\nThe network topology in this region is being augmented, and the second-best path has not completed its augmentation. This meant some traffic needed to reroute onto the third-best path, which led to an extended traffic migration period. This disruption was more severe than we had anticipated, and is the subject of remediation actions below.\n**REMEDIATION AND PREVENTION:**\nGoogle’s automated repair mechanisms detected the decrease in available network bandwidth on Friday, 20 May 2022 at 13:47 US/Pacific and automatically routed the traffic through alternate links. The traffic rerouting completed on Friday, 20 May 2022 at 14:06 US/Pacific, mitigating the issue.\nWhile our automated mechanisms worked as intended and recovered the traffic without manual intervention, we understand that the scope of impact caused by this event affected our customers.\nWe have been working on optimizing our global network to minimize the time spent automatically reconfiguring around failures like this (known as \"convergence time\"). While we have made progress, efforts to improve are ongoing. We continue to ensure that the current technology is optimally configured to minimize the frequency and severity of these issues.\nIn this network region, we intend to complete the augmentation by 11 July 2022, which will return the network to the intended topology where any single fiber path failure can be rerouted quickly onto the second-best path.\nWe will also build automatic analysis to ensure that the network topology during augmentation always supports fast convergence.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**DETAILED DESCRIPTION OF IMPACT:**\n- Google Cloud Networking - Affected customers would have observed packet loss for ingress and egress traffic to and from US Central Cloud regions from 13:47 to 14:07 US/Pacific.\n- Cloud VPN - Affected customers would have experienced latency and errors for cross region VPN with global routing from 13:47 to 14:07 US/Pacific. Intra-region traffic for Classic and HA VPN would not have been affected.\n- Cloud Router - Affected customers would have observed delays in global routing propagation from 13:47 to 14:07 US/Pacific.\n- Cloud Interconnect - Affected customers would have experienced latency and errors from 13:47 to 14:07 US/Pacific.\n- Google Cloud Storage - Affected customers would have experienced elevated latency, HTTP 500 errors, or transient API errors from 13:47 to 14:17 US/Pacific.\n- Cloud SQL - Affected customers would have experienced failures for Export, Update, and Delete operations as well as delayed data replication in us-west1 from 13:53 to 14:13 US/Pacific.\n- Messages - Affected customers would have experienced service availability issues from 13:49 to 14:05 US/Pacific.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-23T21:33:36+00:00","modified":"2022-05-23T21:33:36+00:00","when":"2022-05-23T21:33:36+00:00","text":"**Mini Incident Report**\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 20 May 2022 13:47\n**Incident End:** 20 May 2022 14:07\n**Duration:** 20 minutes\n**Affected Services and Features:**\n* Google Cloud Networking\n* Cloud VPN\n* Cloud Router\n* Cloud Interconnect\n* Google Cloud Storage\n* Cloud SQL\n* Messages\n**Regions/Zones:** Multiple regions\n**Description:**\nGoogle Cloud Networking experienced intermittent packet loss for some transit traffic affecting inter-region connectivity for multiple cloud regions, which lasted 20 minutes. From preliminary analysis, the root cause is a hardware issue on an optical (amplification) component affecting Google's user facing backbone. The issue was identified and mitigated by our automated repair mechanism without manual intervention.\n**Customer Impact:** * Google Cloud Networking - Affected customers would have observed packet loss for Ingress and egress traffic to and from central US cloud regions. * Cloud VPN - Affected customers would have experienced latency and errors for cross region VPN with global routing. Intra-region traffic for Classic and HA VPN would not have been affected.\n* Cloud Router - Affected customers would have observed delays in global routing propagation.\n* Cloud Interconnect - Affected customers would have experienced latency and errors.\n* Google Cloud Storage - Affected customers would have experienced elevated latency, HTTP 500 errors, or transient API errors. * Cloud SQL - Affected customers would have experienced failures for Export, Update, and Delete operations as well as delayed data replication in us-west1.\n* Messages - Affected customers would have experienced service availability issues.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-20T21:52:20+00:00","modified":"2022-05-20T21:52:27+00:00","when":"2022-05-20T21:52:20+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Friday, 2022-05-20 14:07 US/Pacific.\nAffected customers would have experienced high latency, timeouts and errors.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-20T21:44:16+00:00","modified":"2022-05-20T21:44:20+00:00","when":"2022-05-20T21:44:16+00:00","text":"Summary: Global : Cloud Networking faced severe packet loss\nDescription: We've received a report of an issue with Google Cloud Networking as of Friday, 2022-05-20 13:47 US/Pacific.\nWe will provide more information by Friday, 2022-05-20 14:45 US/Pacific.\nDiagnosis: Customers may have encountered elevated latency errors\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-06-02T19:11:24+00:00","modified":"2022-06-02T19:11:24+00:00","when":"2022-06-02T19:11:24+00:00","text":"**INCIDENT REPORT**\n**SUMMARY:**\nOn Friday, 20 May 2022 at 13:47 US/Pacific, Google Cloud Networking experienced intermittent packet loss for traffic between multiple cloud regions for a duration of 20 minutes. The issue was identified and mitigated automatically by 14:07 US/Pacific.\nWe understand this issue has affected our valued customers and users, and we apologize to those who were affected.\n**ROOT CAUSE:**\nGoogle’s production backbone is a global network that enables connectivity for all user-facing traffic via Points of Presence (POPs) or internet exchanges.\nA failure of a component on a fiber path from one of the central US gateway campuses in Google’s production backbone led to a decrease in available network bandwidth between the gateway and multiple edge locations, causing packet loss while the backbone automatically moved traffic onto remaining paths.\nThe network topology in this region is being augmented, and the second-best path has not completed its augmentation. This meant some traffic needed to reroute onto the third-best path, which led to an extended traffic migration period. This disruption was more severe than we had anticipated, and is the subject of remediation actions below.\n**REMEDIATION AND PREVENTION:**\nGoogle’s automated repair mechanisms detected the decrease in available network bandwidth on Friday, 20 May 2022 at 13:47 US/Pacific and automatically routed the traffic through alternate links. The traffic rerouting completed on Friday, 20 May 2022 at 14:06 US/Pacific, mitigating the issue.\nWhile our automated mechanisms worked as intended and recovered the traffic without manual intervention, we understand that the scope of impact caused by this event affected our customers.\nWe have been working on optimizing our global network to minimize the time spent automatically reconfiguring around failures like this (known as \"convergence time\"). While we have made progress, efforts to improve are ongoing. We continue to ensure that the current technology is optimally configured to minimize the frequency and severity of these issues.\nIn this network region, we intend to complete the augmentation by 11 July 2022, which will return the network to the intended topology where any single fiber path failure can be rerouted quickly onto the second-best path.\nWe will also build automatic analysis to ensure that the network topology during augmentation always supports fast convergence.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**DETAILED DESCRIPTION OF IMPACT:**\n- Google Cloud Networking - Affected customers would have observed packet loss for ingress and egress traffic to and from US Central Cloud regions from 13:47 to 14:07 US/Pacific.\n- Cloud VPN - Affected customers would have experienced latency and errors for cross region VPN with global routing from 13:47 to 14:07 US/Pacific. Intra-region traffic for Classic and HA VPN would not have been affected.\n- Cloud Router - Affected customers would have observed delays in global routing propagation from 13:47 to 14:07 US/Pacific.\n- Cloud Interconnect - Affected customers would have experienced latency and errors from 13:47 to 14:07 US/Pacific.\n- Google Cloud Storage - Affected customers would have experienced elevated latency, HTTP 500 errors, or transient API errors from 13:47 to 14:17 US/Pacific.\n- Cloud SQL - Affected customers would have experienced failures for Export, Update, and Delete operations as well as delayed data replication in us-west1 from 13:53 to 14:13 US/Pacific.\n- Messages - Affected customers would have experienced service availability issues from 13:49 to 14:05 US/Pacific.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"}],"uri":"incidents/eo76pxZiDgWVz4z3kmUv","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"3NTkKG1x382cHtxQGM76","number":"11053303972152724257","begin":"2022-05-09T08:47:55+00:00","created":"2022-05-09T08:48:00+00:00","end":"2022-05-09T08:48:33+00:00","modified":"2022-05-09T08:48:33+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-05-09T08:48:32+00:00","modified":"2022-05-09T08:48:33+00:00","when":"2022-05-09T08:48:32+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-05-09T08:48:00+00:00","modified":"2022-05-09T08:48:01+00:00","when":"2022-05-09T08:48:00+00:00","text":"Summary: Google Infrastructure Configuration Server operation requests failing\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Sunday, 2022-05-08 23:24 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 03:00 US/Pacific with current details\nDiagnosis: Google Infrastructure Configuration Server operation requests failing for multiple actions to create, set or\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-05-09T08:48:32+00:00","modified":"2022-05-09T08:48:33+00:00","when":"2022-05-09T08:48:32+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/3NTkKG1x382cHtxQGM76","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"jmCkyGvzEvbgUuhdYTTW","number":"10151776288952327323","begin":"2022-05-09T08:18:39+00:00","created":"2022-05-09T08:18:44+00:00","end":"2022-05-09T08:42:41+00:00","modified":"2022-05-09T08:42:41+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-05-09T08:42:40+00:00","modified":"2022-05-09T08:42:41+00:00","when":"2022-05-09T08:42:40+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-09T08:18:44+00:00","modified":"2022-05-09T08:18:45+00:00","when":"2022-05-09T08:18:44+00:00","text":"Summary: Google App Engine Flex failing deployments in multiple regions with DEADLINE_EXCEEDED\nDescription: We are experiencing an intermittent issue with Google App Engine beginning at Monday, 2022-05-08 23:38 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 01:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users may observe error, DEADLINE_EXCEEDED - \"Timed out waiting for the app infrastructure to become healthy.\"\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-05-09T08:42:40+00:00","modified":"2022-05-09T08:42:41+00:00","when":"2022-05-09T08:42:40+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/jmCkyGvzEvbgUuhdYTTW","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"SmJPisFk1m1KH7UTJrM5","number":"1736553551166578884","begin":"2022-05-09T08:05:00+00:00","created":"2022-05-09T08:28:59+00:00","end":"2022-05-09T08:31:30+00:00","modified":"2022-05-09T08:31:30+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-05-09T08:31:30+00:00","modified":"2022-05-09T08:31:31+00:00","when":"2022-05-09T08:31:30+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-09T08:28:58+00:00","modified":"2022-05-09T08:28:59+00:00","when":"2022-05-09T08:28:58+00:00","text":"Summary: Composer creations fail in multiple regions\nDescription: We are experiencing an issue with Google Cloud Composer beginning at Monday, 2022-05-09 00:39 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 02:10 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users are unable to create Composer environments with Private IP.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-05-09T08:31:30+00:00","modified":"2022-05-09T08:31:31+00:00","when":"2022-05-09T08:31:30+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"YxkG5FfcC42cQmvBCk4j","service_name":"Google Cloud Composer","affected_products":[{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"}],"uri":"incidents/SmJPisFk1m1KH7UTJrM5","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"GVJPxjAqPSvxFMh3CmjQ","number":"18030607443765012729","begin":"2022-05-09T06:59:24+00:00","created":"2022-05-09T07:30:41+00:00","end":"2022-05-09T08:37:22+00:00","modified":"2022-05-09T08:37:22+00:00","external_desc":"We've received a report of an issue with Persistent Disk.","updates":[{"created":"2022-05-09T08:37:22+00:00","modified":"2022-05-09T08:37:23+00:00","when":"2022-05-09T08:37:22+00:00","text":"The issue with Persistent Disk is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-09T07:30:35+00:00","modified":"2022-05-09T07:30:41+00:00","when":"2022-05-09T07:30:35+00:00","text":"Summary: We've received a report of an issue with Persistent Disk.\nDescription: We are experiencing an issue with Persistent Disk.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 01:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-09T08:37:22+00:00","modified":"2022-05-09T08:37:23+00:00","when":"2022-05-09T08:37:22+00:00","text":"The issue with Persistent Disk is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"}],"uri":"incidents/GVJPxjAqPSvxFMh3CmjQ","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"2Hd52dn3PqYGTD5zdp7v","number":"12687481699252051222","begin":"2022-05-09T06:55:00+00:00","created":"2022-05-09T08:37:29+00:00","end":"2022-05-09T08:42:00+00:00","modified":"2022-05-26T19:57:20+00:00","external_desc":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/eWat683pNnkMT7orVDBV","updates":[{"created":"2022-05-09T08:42:39+00:00","modified":"2022-05-09T08:42:40+00:00","when":"2022-05-09T08:42:39+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/eWat683pNnkMT7orVDBV","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-09T08:42:31+00:00","modified":"2022-05-09T08:42:31+00:00","when":"2022-05-09T08:42:31+00:00","text":"Summary: Google Infrastructure Configuration Server operation requests failing\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Sunday, 2022-05-08 23:24 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 03:00 US/Pacific with current details\nDiagnosis: Diagnosis: Customer's might experience following:\n1) External HTTP/S Load Balancing, Cloud CDN - config changes will be accepted \u0026 fail to propagate\n2) Cloud Armor rules may also be affected\n3) Appengine flex customers may see apps fail to deploy\n4) Traffic Director may see configs fail to propagate\n5) VM instance group healthchecks \u0026 functionality like autoscaling/autohealing may be affected\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-05-09T08:37:29+00:00","modified":"2022-05-09T08:37:30+00:00","when":"2022-05-09T08:37:29+00:00","text":"Summary: Google Infrastructure Configuration Server operation requests failing\nDescription: We are experiencing an issue with Google Cloud DNS, Service Directory beginning at Sunday, 2022-05-08 23:24 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 03:00 US/Pacific with current details\nDiagnosis: Diagnosis: Customer's might experience following:\n1) External HTTP/S Load Balancing, Cloud CDN - config changes will be accepted \u0026 fail to propagate\n2) Cloud Armor rules may also be affected\n3) Appengine flex customers may see apps fail to deploy\n4) Traffic Director may see configs fail to propagate\n5) VM instance group healthchecks \u0026 functionality like autoscaling/autohealing may be affected\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-09T08:42:39+00:00","modified":"2022-05-09T08:42:40+00:00","when":"2022-05-09T08:42:39+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/eWat683pNnkMT7orVDBV","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud DNS","id":"TUZUsWSJUVJGW97Jq2sH"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Service Directory","id":"vmq8TsEZwitKYM6V9BaM"},{"title":"Cloud CDN","id":"ckSRJf2vQwQy188ULGy3"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Cloud Armor","id":"Kakg69gTC3xFyeJCY2va"},{"title":"Access Approval","id":"duAxoF9U3MBmoAihC67y"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Anthos Service Mesh","id":"D6ayar99EiNLHhwcn77V"}],"uri":"incidents/2Hd52dn3PqYGTD5zdp7v","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"eWat683pNnkMT7orVDBV","number":"6487971899846239496","begin":"2022-05-09T06:24:00+00:00","created":"2022-05-09T08:28:43+00:00","end":"2022-05-09T09:42:00+00:00","modified":"2022-05-10T22:40:46+00:00","external_desc":"Google Cloud Infrastructure is failing to push cloud configs","updates":[{"created":"2022-05-10T22:40:22+00:00","modified":"2022-05-10T22:40:22+00:00","when":"2022-05-10T22:40:22+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 08 May 2022 23:24\n**Incident End:** 09 May 2022 02:42\n**Duration:** 3 hours, 18 minutes\n**Affected Services and Features:**\n* Google Cloud Networking\n* Google App Engine\n* Google Cloud Composer\n**Regions/Zones:** Global\n**Description:**\nMultiple Google Cloud services experienced issues from 8 May 2022 23:24 to 9 May 2022 02:42 US/Pacific. From preliminary analysis, the root cause of the issue was network issues that caused tests to fail which led the configuration management system to treat the config as a bad config and prevented propagating configuration changes to Google Cloud infrastructure backend servers.\n**Customer Impact:**\n* Google Cloud Networking - Customers modifying backend configuration for load balanced products or health check configuration may have seen their configuration accepted but not propagate, or fail after a timeout\n* Google App Engine - Customers may have observed the error, DEADLINE_EXCEEDED - “Timed out waiting for the app infrastructure to become healthy” when attempting to deploy updates.\n* Google Cloud Composer - Customers would have been unable to create Composer 1 and some Composer 2 \"Private IP\" environments (only those using VPC peering, environments using Private Service Connect were unaffected).","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-05-09T09:49:51+00:00","modified":"2022-05-09T09:49:52+00:00","when":"2022-05-09T09:49:51+00:00","text":"The issue with Google App Engine, Google Cloud Composer, Google Cloud DNS, Google Cloud Networking, Google Compute Engine, Service Directory has been resolved for all affected users as of Monday, 2022-05-09 02:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-05-09T09:27:45+00:00","modified":"2022-05-09T09:27:46+00:00","when":"2022-05-09T09:27:45+00:00","text":"Summary: Google Cloud Infrastructure is failing to push cloud configs\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-05-09 04:00 US/Pacific.\nDiagnosis: Customers may experience the following: 1) External HTTP/S Load Balancing, Cloud CDN - config changes will be accepted but fail to propagate 2) Cloud Armor rules may also be affected 3) App Engine Flex customers may see apps fail to deploy 4) Traffic Director may see configs fail to propagate 5) VM instance group health checks \u0026 functionality like autoscaling/autohealing may be affected.\nProduct Impact:\nGoogle App Engine Flex:\nImpact/Diagnosis: Users may observe error, DEADLINE_EXCEEDED. “Timed out waiting for the app infrastructure to become healthy”. This occurs when attempting to deploy major version updates.\nWorkaround: None.\nGoogle Cloud Networking\nImpact/Diagnosis: Cloud customers modifying backend configuration for load balanced products, or health check configuration, may see their configuration accepted but not propagate, or fail after a timeout.\nWorkaround: None\nCloud Composer:\nImpact: Users are unable to create Composer 1 and Composer 2 \"Private IP\" environments.\nWorkaround: No workaround is available for Composer 1. For Composer 2 “Private IP” the workaround is to create environments with Private Service Connect. Composer 2 “Public IP” environment creations should be successful.\nWorkaround: None","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-05-09T08:28:42+00:00","modified":"2022-05-09T08:28:43+00:00","when":"2022-05-09T08:28:42+00:00","text":"Summary: GICS is failing to push cloud configs\nDescription: We are experiencing an issue with Google Cloud DNS, Service Directory beginning at Sunday, 2022-05-08 23:24 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-05-09 03:00 US/Pacific with current details.\nDiagnosis: Customer's might experience following:\n1) External HTTP/S Load Balancing, Cloud CDN - config changes will be accepted \u0026 fail to propagate\n2) Cloud Armor rules may also be affected\n3) Appengine flex customers may see apps fail to deploy\n4) Traffic Director may see configs fail to propagate\n5) VM instance group healthchecks \u0026 functionality like autoscaling/autohealing may be affected\nWorkaround: None","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-05-10T22:40:22+00:00","modified":"2022-05-10T22:40:22+00:00","when":"2022-05-10T22:40:22+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 08 May 2022 23:24\n**Incident End:** 09 May 2022 02:42\n**Duration:** 3 hours, 18 minutes\n**Affected Services and Features:**\n* Google Cloud Networking\n* Google App Engine\n* Google Cloud Composer\n**Regions/Zones:** Global\n**Description:**\nMultiple Google Cloud services experienced issues from 8 May 2022 23:24 to 9 May 2022 02:42 US/Pacific. From preliminary analysis, the root cause of the issue was network issues that caused tests to fail which led the configuration management system to treat the config as a bad config and prevented propagating configuration changes to Google Cloud infrastructure backend servers.\n**Customer Impact:**\n* Google Cloud Networking - Customers modifying backend configuration for load balanced products or health check configuration may have seen their configuration accepted but not propagate, or fail after a timeout\n* Google App Engine - Customers may have observed the error, DEADLINE_EXCEEDED - “Timed out waiting for the app infrastructure to become healthy” when attempting to deploy updates.\n* Google Cloud Composer - Customers would have been unable to create Composer 1 and some Composer 2 \"Private IP\" environments (only those using VPC peering, environments using Private Service Connect were unaffected).","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud DNS","id":"TUZUsWSJUVJGW97Jq2sH"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google Cloud Composer","id":"YxkG5FfcC42cQmvBCk4j"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Service Directory","id":"vmq8TsEZwitKYM6V9BaM"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Cloud CDN","id":"ckSRJf2vQwQy188ULGy3"},{"title":"Traffic Director","id":"NroZwL2UMMionesUGP87"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"}],"uri":"incidents/eWat683pNnkMT7orVDBV","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"x7sHBZr8vu8tyJoq8Ahq","number":"1062169737220912229","begin":"2022-05-06T18:01:01+00:00","created":"2022-05-06T18:01:06+00:00","end":"2022-05-06T22:30:25+00:00","modified":"2022-05-09T18:38:58+00:00","external_desc":"Customers may experience elevated latency for inter-region in multiple asia regions.","updates":[{"created":"2022-05-06T22:30:25+00:00","modified":"2022-05-06T22:30:26+00:00","when":"2022-05-06T22:30:25+00:00","text":"The issue with Cloud Memorystore, Google Cloud Networking, Google Cloud SQL, Google Compute Engine, Google Kubernetes Engine has been resolved for all affected projects as of Friday, 2022-05-06 15:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]},{"created":"2022-05-06T22:20:50+00:00","modified":"2022-05-09T18:38:36+00:00","when":"2022-05-06T22:20:50+00:00","text":"Summary: Customers may experience elevated latency for inter-region in multiple asia regions.\nDescription: We believe the issue with Cloud Memorystore, Google Cloud Networking, Google Cloud SQL, Google Compute Engine, Google Kubernetes Engine is partially resolved.\nFull resolution is expected to complete by Friday, 2022-05-06 16:30 US/Pacific.\nWe will provide an update by Friday, 2022-05-06 16:45 US/Pacific with current details.\nDiagnosis: Customers may experience elevated inter-region latency between following regions\n* Traffic between asia-east1 and asia-northeast3\n* Traffic between asia-east2 and asia-east1\n* Traffic between asia-east2 and asia-northeast3\n* Traffic between asia-southeast1 and asia-east1\n* Traffic between asia-southeast2 and asia-east1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]},{"created":"2022-05-06T18:22:34+00:00","modified":"2022-05-09T18:38:48+00:00","when":"2022-05-06T18:22:34+00:00","text":"Summary: Customers may experience elevated latency for inter-region in multiple asia regions.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Friday, 2022-05-06 16:00 US/Pacific.\nWe will provide more information by Friday, 2022-05-06 16:15 US/Pacific.\nDiagnosis: Customers may experience elevated inter-region latency between following regions\n* Traffic between asia-east1 and asia-northeast3\n* Traffic between asia-east2 and asia-east1\n* Traffic between asia-east2 and asia-northeast3\n* Traffic between asia-southeast1 and asia-east1\n* Traffic between asia-southeast2 and asia-east1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]},{"created":"2022-05-06T18:01:05+00:00","modified":"2022-05-09T18:38:58+00:00","when":"2022-05-06T18:01:05+00:00","text":"Summary: Customers may experience elevated latency for inter-region in multiple asia regions.\nDescription: We are experiencing an issue with Google Cloud Networking, Google Kubernetes Engine, Google Compute Engine, Google Cloud SQL, Cloud Memorystore beginning at Friday, 2022-05-06 10:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-06 11:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience elevated inter-region latency between following regions\n* Traffic between asia-east1 and asia-northeast3\n* Traffic between asia-east2 and asia-east1\n* Traffic between asia-east2 and asia-northeast3\n* Traffic between asia-southeast1 and asia-east1\n* Traffic between asia-southeast2 and asia-east1\nWorkaround: None at this time.","status":"SERVICE_INFORMATION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]}],"most_recent_update":{"created":"2022-05-06T22:30:25+00:00","modified":"2022-05-06T22:30:26+00:00","when":"2022-05-06T22:30:25+00:00","text":"The issue with Cloud Memorystore, Google Cloud Networking, Google Cloud SQL, Google Compute Engine, Google Kubernetes Engine has been resolved for all affected projects as of Friday, 2022-05-06 15:25 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]},"status_impact":"SERVICE_INFORMATION","severity":"low","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Cloud Memorystore","id":"LGPLu3M5pcUAKU1z6eP3"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/x7sHBZr8vu8tyJoq8Ahq","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"}]},{"id":"6nV9kudxEmgDnwAG1uJY","number":"16191319608876327775","begin":"2022-05-06T13:24:37+00:00","created":"2022-05-06T13:24:42+00:00","end":"2022-05-06T13:25:18+00:00","modified":"2022-05-06T13:25:18+00:00","external_desc":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","updates":[{"created":"2022-05-06T13:25:17+00:00","modified":"2022-05-06T13:25:18+00:00","when":"2022-05-06T13:25:17+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-06T13:24:42+00:00","modified":"2022-05-06T13:24:42+00:00","when":"2022-05-06T13:24:42+00:00","text":"Summary: Users can't connect to their instance in us-central1-b through proxy-server\nDescription: We are experiencing an issue with Google Cloud SQL beginning at Friday, 2022-05-06 02:00 US/Pacific US/Pacific.\nOur engineering team continues to investigate the issue.\nFor regular status updates, please follow: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV where we will provide the next update.\nDiagnosis: None at this time.Users can't connect to their instance in us-central1-b through proxy-server. Other connectivity ways seem to be unaffected.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-05-06T13:25:17+00:00","modified":"2022-05-06T13:25:18+00:00","when":"2022-05-06T13:25:17+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/6nV9kudxEmgDnwAG1uJY","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"1YzVoQe8tR83ubvbAnDd","number":"4016492199676528941","begin":"2022-05-06T11:00:01+00:00","created":"2022-05-06T12:18:46+00:00","end":"2022-05-06T13:13:16+00:00","modified":"2022-05-06T13:13:16+00:00","external_desc":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","updates":[{"created":"2022-05-06T13:13:15+00:00","modified":"2022-05-06T13:13:16+00:00","when":"2022-05-06T13:13:15+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[]},{"created":"2022-05-06T12:18:38+00:00","modified":"2022-05-06T12:18:49+00:00","when":"2022-05-06T12:18:38+00:00","text":"Summary: Hung tasks in Cloud Filestore in us-central1-b. Investigation ongoing\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1.\nOur engineering team continues to investigate the issue.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Slow and possible hung NFS\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-05-06T13:13:15+00:00","modified":"2022-05-06T13:13:16+00:00","when":"2022-05-06T13:13:15+00:00","text":"This incident is being merged with an existing incident. All future updates will be provided there: https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"jog4nyYkquiLeSK5s26q","service_name":"Cloud Filestore","affected_products":[{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"}],"uri":"incidents/1YzVoQe8tR83ubvbAnDd","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"YUJH3JbojVM5WE4jxyrc","number":"10598063297897699427","begin":"2022-05-06T09:15:37+00:00","created":"2022-05-06T11:35:38+00:00","end":"2022-05-06T12:45:00+00:00","modified":"2022-05-06T12:45:01+00:00","external_desc":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","updates":[{"created":"2022-05-06T12:44:54+00:00","modified":"2022-05-06T12:45:02+00:00","when":"2022-05-06T12:44:54+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T11:35:33+00:00","modified":"2022-05-06T11:35:39+00:00","when":"2022-05-06T11:35:33+00:00","text":"Summary: Elevated tail latencies on Persistent Disk standard devices\nDescription: We are experiencing an issue with Persistent Disk beginning at Friday, 2022-05-06 01:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-06 05:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some I/O operations in Persistent Disk Standard devices are stuck for a long time (\u003e1 min)\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-05-06T12:44:54+00:00","modified":"2022-05-06T12:45:02+00:00","when":"2022-05-06T12:44:54+00:00","text":"This issue is believed to be affecting a very small number of projects and our Engineering Team is working on it. If you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved. No further updates will be provided here. We thank you for your patience while we are working on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"}],"uri":"incidents/YUJH3JbojVM5WE4jxyrc","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"4Qvmd4q81VnA9RirCMqV","number":"2022535118131364015","begin":"2022-05-06T08:30:00+00:00","created":"2022-05-06T12:01:47+00:00","end":"2022-05-06T19:06:00+00:00","modified":"2022-05-16T23:13:40+00:00","external_desc":"We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b","updates":[{"created":"2022-05-16T23:12:31+00:00","modified":"2022-05-16T23:12:31+00:00","when":"2022-05-16T23:12:31+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 6 May 2022 at 01:30 US/Pacific, multiple Google Cloud services experienced issues in the us-central1 region. These issues mostly were isolated to us-central1-b for zonal services, but some regional services experienced degradation until their traffic could be shifted away from the impacted zone. Most Google Cloud services recovered automatically, after the underlying problem was resolved.\nWe sincerely apologize for the impact to your service or application. We completed an internal investigation and are taking immediate steps to improve the quality and reliability of our services. If you believe that your services experienced an SLA violation as a result of this incident, please [contact us](https://support.google.com/cloud/contact/cloud_platform_sla).\n**Root Cause:**\nGoogle Cloud systems are built on a zonal distributed storage system called [Colossus](https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system), which replicates data across a large number of individual storage servers called D Servers. In this incident, a background job responsible for repacking storage objects began to retry those repack operations more aggressively as part of its normal operations. This subsequently increased the load on the Colossus system in the zone, including the number of open connections to the D Servers.\nThe sudden increase in connection load to D Servers caused a small number of servers to unexpectedly crash due to high memory pressure. This led our automated management systems to remove them from the serving fleet for Colossus. This further reduced the number of D Servers available to handle the rising traffic loads and increased the traffic latency within the Colossus system in the impacted zone.\nThis significant increase in latency subsequently impacted our customers’ performance across a range of Google Cloud services that are built atop Colossus, including Persistent Disk, BigQuery, and many others.\nThis zonal incident impacted some regional services due to the specific failure mode. When a Colossus cluster is marked down, the regional services receive proactive notification and automatically shift traffic away from the cluster. Since this cluster was still up, but with variable latency for some operations, the regional services received no proactive notification and were unable to automatically shift traffic away from the cluster. Therefore, the impact to a number of regional services was extended as they had to manually remove the impacted cluster from serving.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue on Friday, 6 May, 2022 at 01:54 US/Pacific and immediately started an investigation.\nGoogle engineers stopped the background traffic. To increase traffic capacity, Google engineers re-added the impacted D Servers to the serving fleet, mitigating the issue at 12:06 US/Pacific.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are taking the following steps to prevent this or similar issues from happening again:\n* Investigate and add additional protections in the D Servers to decrease memory pressure during high network traffic load periods.\n* Improve the retry logic for the storage object repacking job to ensure that it cannot overload the Colossus system within a zone.\n* Extend the automated D Server management systems to better handle crash loop conditions and quickly restore D Servers to production once they become healthy.\n* Google's regional services are designed to tolerate zonal failure while staying within their service level objectives. The nature of this failure was not properly handled by some regional services. We are committed to investigating the behavior of each regional service impacted in this outage to ensure that fault tolerance gaps are properly addressed.\n**Detailed Description of Impact:**\nSome customers may have experienced high latency or errors in multiple Google Cloud services in the impacted region.\n* **BigQuery [us-central1 and US multi-region]:** Customers saw increased query, import, and export latencies and errors. The overall duration of impact was 6 hours 5 minutes in us-central1 and 4 hours 34 minutes in US multi-region.\n* **Cloud Bigtable [us-central1-b zone]:** A small number of Customers in us-central1-b experienced elevated latency and errors as well as replication delays for a duration of 10 hours, 36 minutes. A very minor percentage of the affected customers for Cloud Bigtable had residual impact for additional 6 hours, 40 minutes.\n* **Cloud Pub/Sub [us-central1 region]:** Customers may have seen missing backlog stats metrics for subscriptions against topics with messages published to us-central1 for a duration of 2 hours, 41 minutes. Since the impact was based on the message publish region, the subscribers could have been in regions other than us-central1.\n* **Google Cloud Load Balancer (GCLB) [us-central1-b zone]:** New load balancer creations and modifications or deletions of existing components with backends in us-central1-b may have been delayed or not taken effect until the outage was resolved. The total impact duration for GCLB is 4 hours, 46 minutes.\n* **Google Compute Engine (GCE) [us-central1-b zone]:** Customers may have seen issues with instance availability in us-central1-b due to some input/output (I/O) operations in Persistent Disk Standard disks being stuck for over one minute. Additionally, Regional Persistent Disk Standard disks with a replica in us-central1-b may have been briefly affected due to delays in failover. A small number of instances may have experienced brief loss of network connectivity to other Google Cloud services following live migration events. The total impact duration for GCE is around 5 hours, 25 minutes.\n* **Cloud Datastream [us-central1 region]:** Customers may have seen streams enter into \"Failed\" state on the Datastream UI, noticed no new data ingested by Datastream into Google Cloud Storage buckets, had duplicate data loaded into Google Cloud Storage, or metrics not being reported. This impacted a whole region for a duration of 7 hours 40 minutes, because the cluster over provisioning was not at a high enough level, and losing one zone on the underlying Kafka cluster caused the cluster to be at 100% utilization, until it was able to fully copy the data to a new zone.\n* **Cloud Filestore [us-central1-b zone]:** Many Filestore instance creation operations failed. Additionally, a small number of instances were unresponsive for the duration of the incident. Some instances suffered performance impact.\n* **Cloud Memorystore [us-central1-b zone]:** Redis nodes in us-central1-b may have been unavailable for a duration of 3 hours, 54 minutes.\n* **Cloud SQL [us-central1-b zone]:** Customers may not have been able to connect to their instance in us-central1-b through the Cloud SQL Auth proxy for a duration of 3 hours, 5 minutes.\n* **Google Kubernetes Engine (GKE) [us-central1-b zone]:** Customers may have experienced issues interacting with their clusters' control planes. New workloads may not have been scheduled. Auto scaling may not have been operational.The total impact duration for GKE is 7 hours, 11 minutes.\n* **Apigee [us-central1 region]:** Customers may have seen errors for their API traffic with Datastore Errors. Apigee is internally redundant across zones within the region, but due to the high latency failure mode in us-central1-b, the engineers were not able to remove the impacted zone from the regional cluster. The total impact duration for Apigee is 2 hours, 55 minutes.\n* **Dataflow [us-central1 region]:** New Dataflow jobs may have failed to start in us-central1-b. Jobs already running in us-central1-b may have been stuck or delayed, but restarting the jobs would have automatically routed them to a healthy zone starting at 05:00 US/Pacific if the customer was using auto zone placement. The total impact duration for dataflow is 2 hours, 55 minutes.\n* **Cloud Data Fusion (CDF) [us-central1 region]:** Customers may have experienced DataFusion instance creation failures, instance availability issues and higher data processing pipeline failures. This was because Persistent Disk (PD) issues caused DataFusion backend services to become unhealthy and the total impact duration was about 7 hours.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T23:12:13+00:00","modified":"2022-05-16T23:13:40+00:00","when":"2022-05-06T23:12:13+00:00","text":"**Mini Incident Report**\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 06 May 2022 01:30\n**Incident End:** 06 May 2022 12:06\n**Duration:** 10 hours, 36 minutes\n**Affected Services and Features:** * BigQuery * Cloud Pub/Sub * Google Cloud Load Balancer (GCLB) * Google Compute Engine (GCE) * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Apigee * Cloud Dataflow * Cloud Data Fusion (CDF) * Cloud Bigtable * Google Kubernetes Engine (GKE)\n**Regions/Zones:** us-central1-b\n**Description:**\nMultiple Google Cloud services experienced issues in the us-central1 region beginning Friday, 6 May 2022 at 01:30 PT. These issues were predominantly isolated to us-central1-b for zonal services, but some regional services experienced degradation until their traffic could be shifted away from the impacted zone. Most services recovered automatically after the underlying problem was resolved.\nThe issues were triggered by an unexpected increase in normally occurring background traffic in the Google Cloud distributed storage infrastructure[1] within the us-central1-b zone. The system automatically directed load away from backend file servers that were impacted by this load increase. This subsequently reduced the overall traffic capacity in the zone. Google engineers mitigated the issue by stopping the background traffic and marking the impacted file servers as available in order to increase capacity.\n**Customer Impact:**\n**How Customers Experienced the Issue:** Some customers may have experienced high latency or errors in multiple Google Cloud services in the impacted region.\n* **BigQuery:** Customers may have seen increased query delays and/or failures.\n* **Cloud Bigtable:** Customers may have experienced elevated latency and errors.\n* **Cloud Pub/Sub:** Customers may have seen missing metrics for backlog statistics.\n* **Google Cloud Load Balancer (GCLB):** New load balancer creations, as well as modifications or deletions of existing components, with backends in us-central1-b may have been delayed or not taken effect until the outage was resolved.\n* **Google Compute Engine (GCE):** Customers may have seen issues with instance availability in us-central1-b due to some input/output (I/O) operations in Persistent Disk being stuck for over one minute. A small number of instances may have experienced brief loss of network reachability to other Google Cloud services following live migration events.\n* **Datastream:** Customers may have seen streams enter into \"Failed\" state on the Datastream UI, noticed no new data ingested by Datastream into Google Cloud Storage bucket, or metrics not being reported.\n* **Cloud Filestore:** Customers may have experienced hung tasks in Filestore instances.\n* **Cloud Memorystore:** Redis nodes in us-central1-b may have been unavailable.\n* **Cloud SQL:** Customers may not have been able to connect to their instance in us-central1-b through the proxy-server.\n* **Google Kubernetes Engine (GKE):** Customers may have experienced issues interacting with the control plane. New workloads may not have been scheduled. Auto scaling may not have been operational.\n* **Apigee:** Customers may have seen errors for their API traffic with Datastore Errors.\n* **Dataflow:** Some Dataflow batch and streaming jobs in us-central1 may have been stuck or delayed.\n* **Cloud Data Fusion (CDF):** CDF operations, like instance creation and pipeline launch, may have failed in the us-central1 region due to an issue on Compute Engine.\n[1] https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T19:09:51+00:00","modified":"2022-05-06T19:09:53+00:00","when":"2022-05-06T19:09:51+00:00","text":"The issue with Cloud Data Fusion, Cloud Filestore, Cloud Memorystore, Google BigQuery, Google Cloud Dataflow, Google Cloud Networking, Google Cloud Pub/Sub, Google Cloud SQL, Google Kubernetes Engine, Persistent Disk, Apigee has been resolved for all affected projects as of Friday, 2022-05-06 12:06 US/Pacific.\nProducts with Narrow Impact: * Google Cloud Bigtable: Outage is currently affecting less than 2% of customers us-central1-b. Mitigation is ongoing and support will continue to work with the affected customers through resolution.\nWe will publish an Incident Report once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T18:16:49+00:00","modified":"2022-05-06T18:16:53+00:00","when":"2022-05-06T18:16:49+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with multiple cloud services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed, and most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 12:30 US/Pacific.\nProducts Recovered: * BigQuery Engine * Cloud Pub/Sub * Cloud Networking * Compute Engine * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Cloud Data Fusion * Apigee * Dataflow * GKE\nProducts Still Recovering: * Google Cloud Bigtable: Mitigation is ongoing for a small number of customers who are experiencing elevated latency and errors.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T17:57:45+00:00","modified":"2022-05-06T17:57:46+00:00","when":"2022-05-06T17:57:45+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with multiple cloud services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed, and most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 11:30 US/Pacific.\nProducts Recovered: * BigQuery Engine * Cloud Pub/Sub * Cloud Networking * Compute Engine * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Cloud Data Fusion * Apigee * Dataflow * GKE\nProducts Still Recovering: * Google Cloud Bigtable: Mitigation is ongoing for a small number of customers who are experiencing elevated latency and errors.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T17:28:20+00:00","modified":"2022-05-06T17:28:22+00:00","when":"2022-05-06T17:28:20+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 11:00 US/Pacific.\nProducts Recovered: * BigQuery Engine * Cloud Pub/Sub * Cloud Networking * Compute Engine * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Cloud Data Fusion * Apigee * Dataflow * GKE\nProducts Still Recovering: * Google Cloud Bigtable: A small number of customers may still be experiencing elevated latency and errors.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T16:55:11+00:00","modified":"2022-05-06T16:55:12+00:00","when":"2022-05-06T16:55:11+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 10:30 US/Pacific.\nProducts Recovered: * BigQuery Engine:Cloud Pub/Sub * Cloud Networking * Compute Engine * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Cloud Data Fusion * Apigee * Dataflow * GKE\nProducts Still Recovering: * Google Cloud Bigtable: Customers may be experiencing elevated latency and errors.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T16:26:48+00:00","modified":"2022-05-06T16:26:49+00:00","when":"2022-05-06T16:26:48+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 10:00 US/Pacific.\nProducts Recovered: * BigQuery Engine:Cloud Pub/Sub * Cloud Networking * Compute Engine * Datastream * Cloud Filestore * Cloud Memorystore * Cloud SQL * Apigee * Dataflow\nProducts Still Recovering: * Google Cloud Bigtable: Customers may be experiencing elevated latency and errors. * Google Kubernetes Engine: Customers may experience issues interacting with the control plane. New workloads won’t be scheduled. Auto scaling may not be operational. * Cloud Data Fusion: CDF operations like instance creation, pipeline launch might fail in us-central1 region due to a Compute Engine issue.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T15:56:44+00:00","modified":"2022-05-06T15:56:46+00:00","when":"2022-05-06T15:56:44+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and we see that most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 09:30 US/Pacific.\nProducts Recovered:\n- BigQuery Engine:Cloud Pub/Sub, Cloud Networking, Compute Engine, Datastream, Cloud Filestore, Cloud Memorystore, Cloud SQL, Apigee, Dataflow\nProducts Still Recovering:\n- Google Cloud BigTable: Customers may be experiencing elevated latency and errors.\n- Google Kubernetes Engine: Customers may experience issues interacting with the control plane. New workloads won’t be scheduled. Auto scaling may not be operational.\n- Cloud Data Fusion: CDF operations like instance creation, pipeline launch might fail in us-central1 region due to an issue on Compute Engine.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T15:27:58+00:00","modified":"2022-05-06T15:27:59+00:00","when":"2022-05-06T15:27:58+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and we see that most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 09:00 US/Pacific.\nProducts Recovered:\nBigQuery Engine:Cloud Pub/Sub, Cloud Networking, Compute Engine, Datastream, Cloud Filestore, Cloud Memorystore, Cloud SQL, Apigee, Dataflow\nProducts Still Recovering:\n- Google Cloud BigTable: Customers may be experiencing issues.\n- Google Kubernetes Engine: Customers may experience issues interacting with the control plane. New workloads won’t be scheduled. Auto scaling may not be operational.\n- Cloud Data Fusion: CDF operations like instance creation, pipeline launch might fail in us-central1 region due to an issue on Compute Engine.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T15:01:50+00:00","modified":"2022-05-06T15:01:51+00:00","when":"2022-05-06T15:01:50+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, Google Kubernetes Engine (GKE), Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion (CDF) beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and we see that most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 08:30 US/Pacific.\nProducts Recovered:\nBigQuery Engine:Cloud Pub/Sub, Cloud Networking, Compute Engine, Datastream, Cloud Filestore, Cloud Memorystore, Cloud SQL, Apigee, Dataflow\nProducts Still Recovering:\n- Google Kubernetes Engine: Customers may experience issues interacting with the control plane. New workloads won’t be scheduled. Auto scaling may not be operational.\n- Cloud Data Fusion: CDF operations like instance creation, pipeline launch might fail in us-central1 region due to an issue on Compute Engine.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T14:25:49+00:00","modified":"2022-05-06T14:25:50+00:00","when":"2022-05-06T14:25:49+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, GKE, Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services, Cloud Data Fusion beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation is completed and we see that most of the affected services have recovered.\nWe will provide more information by Friday, 2022-05-06 08:00 US/Pacific.\nProduct Impact:\n- BigQuery Engine: Customers may see increased query latencies and/or failures.\n- Cloud Pub/Sub: Customer may see missing metrics for backlog statistics.\n- Cloud Networking: Customers may see connectivity issues.\n- Compute Engine: Customers may see issues with VM availability in us-central1-b.\n- Datastream: Customers may see streams enter into \"Failed\" state on the Datastream UI, notice no new data ingested by Datastream into GCS bucket or metrics not being reported.\n- Cloud Filestore: Customers may experience many hung tasks in filestore VMs.\n- Cloud Memorystore: Redis nodes in us-central1-b may be unavailable.\n- Cloud SQL: Customers may not be able to connect to their instance in us-central1-b through proxy-server.\n- Apigee: Customers may see 5XX errors for their API traffic with Datastore Errors.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T13:54:30+00:00","modified":"2022-05-06T13:54:32+00:00","when":"2022-05-06T13:54:30+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, GKE, Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation work is currently underway by our engineering team. We see partial recovery for some services.\nWe will provide more information by Friday, 2022-05-06 07:30 US/Pacific.\nProduct Impact:\n- BigQuery Engine: Customers may see increased query latencies and/or failures.\n- Cloud Pub/Sub: Customer may see missing metrics for backlog statistics\n- Cloud Networking : Customers may see connectivity issues.\n- Compute Engine : Customers may see issues with VM availability in us-central1-b\n- Datastream: Customers may see streams enter into \"Failed\" state on the Datastream UI, notice no new data ingested by Datastream into GCS bucket or metrics not being reported.\n- Cloud Filestore : Customers may experience many hung tasks in filestore VMs.\n- Cloud Memorystore: Redis nodes in us-central1-b may be unavailable\n- Cloud SQL: Customers may not be able to connect to their instance in us-central1-b through proxy-server.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T13:20:50+00:00","modified":"2022-05-06T13:20:51+00:00","when":"2022-05-06T13:20:50+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including BigQuery, Cloud Networking, Cloud SQL, GKE Control Plane, Cloud Filestore, Cloud Bigtable, Cloud Memorystore, Apigee, Cloud Dataflow services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Friday, 2022-05-06 07:00 US/Pacific.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T13:04:08+00:00","modified":"2022-05-06T13:04:09+00:00","when":"2022-05-06T13:04:08+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services including Bigquery, Cloud Networking, Cloud SQL, GKE beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1-b.\nMitigation work is currently underway by our engineering team.\nWe will provide more information by Friday, 2022-05-06 06:30 US/Pacific.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T12:58:39+00:00","modified":"2022-05-06T12:58:40+00:00","when":"2022-05-06T12:58:39+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1-b\nDescription: Mitigation work is currently underway by our engineering team.\nWe will provide more information by Friday, 2022-05-06 06:30 US/Pacific.\nDiagnosis: Customers might see connectivity issues in us-central1-b\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T12:45:08+00:00","modified":"2022-05-06T12:45:09+00:00","when":"2022-05-06T12:45:08+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1. Our engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-06 06:30 US/Pacific with current details. with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some I/O operations in Persistent Disk Standard devices are stuck for a long time (\u003e1 min)\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T12:01:47+00:00","modified":"2022-05-06T12:01:48+00:00","when":"2022-05-06T12:01:47+00:00","text":"Summary: We are experiencing an issue with Persistent Disk affecting multiple services in us-central1\nDescription: We are experiencing an issue with Persistent Disk affecting multiple services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-06 06:30 US/Pacific with current details. with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Some I/O operations in Persistent Disk Standard devices are stuck for a long time (\u003e1 min)\nWorkaround: Move the workloads to a different zone if possible","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-05-16T23:12:31+00:00","modified":"2022-05-16T23:12:31+00:00","when":"2022-05-16T23:12:31+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 6 May 2022 at 01:30 US/Pacific, multiple Google Cloud services experienced issues in the us-central1 region. These issues mostly were isolated to us-central1-b for zonal services, but some regional services experienced degradation until their traffic could be shifted away from the impacted zone. Most Google Cloud services recovered automatically, after the underlying problem was resolved.\nWe sincerely apologize for the impact to your service or application. We completed an internal investigation and are taking immediate steps to improve the quality and reliability of our services. If you believe that your services experienced an SLA violation as a result of this incident, please [contact us](https://support.google.com/cloud/contact/cloud_platform_sla).\n**Root Cause:**\nGoogle Cloud systems are built on a zonal distributed storage system called [Colossus](https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system), which replicates data across a large number of individual storage servers called D Servers. In this incident, a background job responsible for repacking storage objects began to retry those repack operations more aggressively as part of its normal operations. This subsequently increased the load on the Colossus system in the zone, including the number of open connections to the D Servers.\nThe sudden increase in connection load to D Servers caused a small number of servers to unexpectedly crash due to high memory pressure. This led our automated management systems to remove them from the serving fleet for Colossus. This further reduced the number of D Servers available to handle the rising traffic loads and increased the traffic latency within the Colossus system in the impacted zone.\nThis significant increase in latency subsequently impacted our customers’ performance across a range of Google Cloud services that are built atop Colossus, including Persistent Disk, BigQuery, and many others.\nThis zonal incident impacted some regional services due to the specific failure mode. When a Colossus cluster is marked down, the regional services receive proactive notification and automatically shift traffic away from the cluster. Since this cluster was still up, but with variable latency for some operations, the regional services received no proactive notification and were unable to automatically shift traffic away from the cluster. Therefore, the impact to a number of regional services was extended as they had to manually remove the impacted cluster from serving.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue on Friday, 6 May, 2022 at 01:54 US/Pacific and immediately started an investigation.\nGoogle engineers stopped the background traffic. To increase traffic capacity, Google engineers re-added the impacted D Servers to the serving fleet, mitigating the issue at 12:06 US/Pacific.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are taking the following steps to prevent this or similar issues from happening again:\n* Investigate and add additional protections in the D Servers to decrease memory pressure during high network traffic load periods.\n* Improve the retry logic for the storage object repacking job to ensure that it cannot overload the Colossus system within a zone.\n* Extend the automated D Server management systems to better handle crash loop conditions and quickly restore D Servers to production once they become healthy.\n* Google's regional services are designed to tolerate zonal failure while staying within their service level objectives. The nature of this failure was not properly handled by some regional services. We are committed to investigating the behavior of each regional service impacted in this outage to ensure that fault tolerance gaps are properly addressed.\n**Detailed Description of Impact:**\nSome customers may have experienced high latency or errors in multiple Google Cloud services in the impacted region.\n* **BigQuery [us-central1 and US multi-region]:** Customers saw increased query, import, and export latencies and errors. The overall duration of impact was 6 hours 5 minutes in us-central1 and 4 hours 34 minutes in US multi-region.\n* **Cloud Bigtable [us-central1-b zone]:** A small number of Customers in us-central1-b experienced elevated latency and errors as well as replication delays for a duration of 10 hours, 36 minutes. A very minor percentage of the affected customers for Cloud Bigtable had residual impact for additional 6 hours, 40 minutes.\n* **Cloud Pub/Sub [us-central1 region]:** Customers may have seen missing backlog stats metrics for subscriptions against topics with messages published to us-central1 for a duration of 2 hours, 41 minutes. Since the impact was based on the message publish region, the subscribers could have been in regions other than us-central1.\n* **Google Cloud Load Balancer (GCLB) [us-central1-b zone]:** New load balancer creations and modifications or deletions of existing components with backends in us-central1-b may have been delayed or not taken effect until the outage was resolved. The total impact duration for GCLB is 4 hours, 46 minutes.\n* **Google Compute Engine (GCE) [us-central1-b zone]:** Customers may have seen issues with instance availability in us-central1-b due to some input/output (I/O) operations in Persistent Disk Standard disks being stuck for over one minute. Additionally, Regional Persistent Disk Standard disks with a replica in us-central1-b may have been briefly affected due to delays in failover. A small number of instances may have experienced brief loss of network connectivity to other Google Cloud services following live migration events. The total impact duration for GCE is around 5 hours, 25 minutes.\n* **Cloud Datastream [us-central1 region]:** Customers may have seen streams enter into \"Failed\" state on the Datastream UI, noticed no new data ingested by Datastream into Google Cloud Storage buckets, had duplicate data loaded into Google Cloud Storage, or metrics not being reported. This impacted a whole region for a duration of 7 hours 40 minutes, because the cluster over provisioning was not at a high enough level, and losing one zone on the underlying Kafka cluster caused the cluster to be at 100% utilization, until it was able to fully copy the data to a new zone.\n* **Cloud Filestore [us-central1-b zone]:** Many Filestore instance creation operations failed. Additionally, a small number of instances were unresponsive for the duration of the incident. Some instances suffered performance impact.\n* **Cloud Memorystore [us-central1-b zone]:** Redis nodes in us-central1-b may have been unavailable for a duration of 3 hours, 54 minutes.\n* **Cloud SQL [us-central1-b zone]:** Customers may not have been able to connect to their instance in us-central1-b through the Cloud SQL Auth proxy for a duration of 3 hours, 5 minutes.\n* **Google Kubernetes Engine (GKE) [us-central1-b zone]:** Customers may have experienced issues interacting with their clusters' control planes. New workloads may not have been scheduled. Auto scaling may not have been operational.The total impact duration for GKE is 7 hours, 11 minutes.\n* **Apigee [us-central1 region]:** Customers may have seen errors for their API traffic with Datastore Errors. Apigee is internally redundant across zones within the region, but due to the high latency failure mode in us-central1-b, the engineers were not able to remove the impacted zone from the regional cluster. The total impact duration for Apigee is 2 hours, 55 minutes.\n* **Dataflow [us-central1 region]:** New Dataflow jobs may have failed to start in us-central1-b. Jobs already running in us-central1-b may have been stuck or delayed, but restarting the jobs would have automatically routed them to a healthy zone starting at 05:00 US/Pacific if the customer was using auto zone placement. The total impact duration for dataflow is 2 hours, 55 minutes.\n* **Cloud Data Fusion (CDF) [us-central1 region]:** Customers may have experienced DataFusion instance creation failures, instance availability issues and higher data processing pipeline failures. This was because Persistent Disk (PD) issues caused DataFusion backend services to become unhealthy and the total impact duration was about 7 hours.","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"},{"title":"Apigee","id":"9Y13BNFy4fJydvjdsN3X"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Kubernetes Engine","id":"LCSbT57h59oR4W98NHuz"},{"title":"Cloud Memorystore","id":"LGPLu3M5pcUAKU1z6eP3"},{"title":"Google Cloud Bigtable","id":"LfZSuE3xdQU46YMFV5fy"},{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"},{"title":"Google Cloud Dataflow","id":"T9bFoXPqG8w8g1YbWTKY"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"},{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"},{"title":"Cloud Filestore","id":"jog4nyYkquiLeSK5s26q"},{"title":"Cloud Data Fusion","id":"rLKDHeeaBiXTeutF1air"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/4Qvmd4q81VnA9RirCMqV","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"pQohCqBLfFapHrkjY5Mh","number":"10148657515826785856","begin":"2022-05-06T08:20:00+00:00","created":"2022-05-06T10:49:53+00:00","end":"2022-05-06T19:09:00+00:00","modified":"2022-05-06T19:36:48+00:00","external_desc":"Elevated tail latencies on Persistent Disk standard devices","updates":[{"created":"2022-05-06T19:36:42+00:00","modified":"2022-05-06T19:36:42+00:00","when":"2022-05-06T19:36:42+00:00","text":"The issue with Persistent Disk has been resolved for all affected projects as of Friday, 2022-05-06 12:09 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.\nFor additional details, please refer to https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T12:47:42+00:00","modified":"2022-05-06T12:47:53+00:00","when":"2022-05-06T12:47:42+00:00","text":"We are experiencing an issue with Persistent Disk affecting multiple services beginning at Friday, 2022-05-06 01:20 US/Pacific in us-central1.\nFor further information please refer to https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"created":"2022-05-06T10:49:54+00:00","modified":"2022-05-06T10:49:54+00:00","when":"2022-05-06T10:49:54+00:00","text":"We are experiencing an issue with Persistent Disk beginning at Friday, 2022-05-06 01:20 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Friday, 2022-05-06 04:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nCUSTOMER SYMPTOMS\nSome I/O operations in Persistent Disk Standard devices are stuck for a long time (\u003e1 min)\nWORKAROUND\nMove the workloads to a different zone if possible","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]}],"most_recent_update":{"created":"2022-05-06T19:36:42+00:00","modified":"2022-05-06T19:36:42+00:00","when":"2022-05-06T19:36:42+00:00","text":"The issue with Persistent Disk has been resolved for all affected projects as of Friday, 2022-05-06 12:09 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.\nFor additional details, please refer to https://status.cloud.google.com/incidents/4Qvmd4q81VnA9RirCMqV","status":"AVAILABLE","affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"SzESm2Ux129pjDGKWD68","service_name":"Persistent Disk","affected_products":[{"title":"Persistent Disk","id":"SzESm2Ux129pjDGKWD68"}],"uri":"incidents/pQohCqBLfFapHrkjY5Mh","currently_affected_locations":[],"previously_affected_locations":[{"title":"Iowa (us-central1)","id":"us-central1"}]},{"id":"TFyk1uenaojF2iJAnAAL","number":"901619274871354280","begin":"2022-04-28T14:27:00+00:00","created":"2022-04-28T15:18:18+00:00","end":"2022-04-28T15:51:00+00:00","modified":"2022-05-05T16:47:59+00:00","external_desc":"Google Cloud Support experiencing issues with case creation, case viewing and case search","updates":[{"created":"2022-05-05T16:47:59+00:00","modified":"2022-05-05T16:47:59+00:00","when":"2022-05-05T16:47:59+00:00","text":"The Incident Report is now available on the Google Cloud Status Dashboard:\nhttps://status.cloud.google.com/incidents/mvpNTsgUmf2LL7PdgmyF","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-29T01:22:08+00:00","modified":"2022-04-29T01:22:08+00:00","when":"2022-04-29T01:22:08+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 28 April 2022 07:27\n**Incident End:** 28 April 2022 08:51\n**Duration:** 1 hour, 24 minutes\n**Affected Services and Features:**\nGoogle Cloud Support - Cloud Console\n**Regions/Zones:** Global\n**Description:**\n- Google Cloud Support was unavailable via the Cloud Console and Admin Console for a duration of 1 hour, 24 minutes. From preliminary analysis, the root cause of the issue was due to elevated errors and latency from several backend component modules which failed to start in Google App Engine, due to an overload in the Google App Engine infrastructure.\n**Customer Impact:**\n- Google Cloud Support - customers were unable to create, view or search support cases in Google Cloud Support Center.\n**Additional details:**\nThe issue was fully resolved once the root cause change was rolled back from the Google App Engine infrastructure and request levels returned to normal, allowing the affected backend component modules to start.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-28T16:04:26+00:00","modified":"2022-04-28T16:04:27+00:00","when":"2022-04-28T16:04:26+00:00","text":"The issue with Google Cloud Support has been resolved for all affected users as of Thursday, 2022-04-28 09:04 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-28T15:40:14+00:00","modified":"2022-04-28T15:40:14+00:00","when":"2022-04-28T15:40:14+00:00","text":"Summary: Google Cloud Support experiencing issues with case creation, case viewing and case search\nDescription: We are experiencing an issue with Google Cloud Support beginning at Thursday, 2022-04-28 07:27 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-04-28 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create, view and search cases using Cloud Console or Google Cloud Support Center.\nWorkaround: Google Cloud customers can use https://support.google.com/cloud/contact/prod_issue to open the cases","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-28T15:18:17+00:00","modified":"2022-04-28T15:18:19+00:00","when":"2022-04-28T15:18:17+00:00","text":"Summary: Google Cloud Support experiencing issues with case creation, case viewing and case search\nDescription: We are experiencing an issue with Google Cloud Support beginning at Thursday, 2022-04-28 07:27 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-04-28 08:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are unable to create, view and search cases using Cloud Console or Google Cloud Support Center.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-05-05T16:47:59+00:00","modified":"2022-05-05T16:47:59+00:00","when":"2022-05-05T16:47:59+00:00","text":"The Incident Report is now available on the Google Cloud Status Dashboard:\nhttps://status.cloud.google.com/incidents/mvpNTsgUmf2LL7PdgmyF","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"bGThzF7oEGP5jcuDdMuk","service_name":"Google Cloud Support","affected_products":[{"title":"Google Cloud Support","id":"bGThzF7oEGP5jcuDdMuk"}],"uri":"incidents/TFyk1uenaojF2iJAnAAL","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"mvpNTsgUmf2LL7PdgmyF","number":"9101450190999181209","begin":"2022-04-28T14:00:00+00:00","created":"2022-04-28T15:37:05+00:00","end":"2022-04-28T15:32:00+00:00","modified":"2022-05-05T15:26:36+00:00","external_desc":"Google App Engine Increased Latency in us-central1","updates":[{"created":"2022-05-05T15:26:36+00:00","modified":"2022-05-05T15:26:36+00:00","when":"2022-05-05T15:26:36+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 28 April 2022, from 07:00 to 08:32 US/Pacific, Google App Engine and Google Cloud Functions experienced increased latency and reduced availability for a duration of 1 hour and 32 minutes in one zone in the us-central1 region. Additionally, customers were unable to create, view, or search support cases in the Google Cloud Support Center and Google Admin Console for 1 hour and 24 minutes. We sincerely apologize for the impact to your service or application. We have completed an internal investigation and are taking immediate steps to improve our service’s quality and reliability.\n**Root Cause:**\nThe Serverless stack relies on a file serving service for container images. The issue was triggered when the file serving component of the Serverless stack experienced a sudden increase in traffic. A bug, introduced in a recent configuration change to the file serving service, was surfaced by the sudden increase in traffic, causing many threads to get stuck. This led to resource exhaustion on the affected file servers, causing some tasks to crash and preventing new requests from completing.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue on Thursday, 28 April 2022, at 07:11 US/Pacific and immediately started an investigation. Once the affected component was identified, engineers added additional capacity to the component in the zone that was experiencing the degradation. This mitigated the resource exhaustion, and the service recovered at 08:20 US/Pacific.\nTo prevent recurrence of the issue, engineers rolled back the configuration change to the previous stable version and implemented an automated release block to prevent any unintended release of a version that included the bug.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are taking the following steps to prevent this or similar issues from happening again:\nTo improve resolution time for future issues of this type, we are calibrating our alerting system to give us an earlier and more precise notification which will allow us to diagnose the issue more quickly.\nWe are also evaluating what kinds of load/stress tests could deterministically detect this kind of issue in the future, so that such regressions are caught automatically before they are deployed to production.\n**Detailed Description of Impact:**\nOn 28th April 2022 from 7:00 PT to 8:32 PT\n**Google App Engine**\nGoogle App Engine experienced increased latency and reduced availability in one zone in us-central1 for a period of 1 hour and 32 minutes. Customers may have experienced increased latency or higher error rate for App Engine projects.\n**Google Cloud Functions**\nGoogle Cloud Functions experienced increased latency and reduced availability in one zone in us-central1 for a period of 1 hour and 32 minutes. “Google Cloud Functions” customers updating their functions (e.g. deploying a new version) may have experienced increased latency or failures, notably failing health checks.\n**Google Cloud Support and Google Workspace Support**\nCustomers were unable to create, view, or search support cases in the Google Cloud Support Center or Google Admin Console for 1 hour and 24 minutes. In addition, a small number of customers had degraded access to phone support, being redirected to a queue requiring additional manual authentication with the support agent.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-04-29T06:05:46+00:00","modified":"2022-04-29T06:05:46+00:00","when":"2022-04-29T06:05:46+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 28 April 2022 07:00\n**Incident End:** 28 April 2022 08:32\n**Duration:** 1 hours, 32 minutes\n**Affected Services and Features:**\nGoogle App Engine\nGoogle Cloud Functions\n**Regions/Zones:** us-central1\n**Description:**\nGoogle App Engine and Google Cloud Functions experienced increased latency and reduced availability in us-central1 for a period of 1 hour and 32 minutes. From the preliminary investigation root cause is related to a bug that caused one component of App Engine to crash under heavy load in us-central1.\n**Customer Impact:**\nGoogle App Engine\nCustomers may have experienced increased latency or higher error rate for App Engine projects.\nGoogle Cloud Functions\nCustomers updating their functions (e.g. deploying a new version) may have experienced increased latency or failures, notably failing health checks.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-04-28T15:52:32+00:00","modified":"2022-04-28T15:52:32+00:00","when":"2022-04-28T15:52:32+00:00","text":"The issue with Google App Engine has been resolved for all affected projects as of Thursday, 2022-04-28 08:52 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-04-28T15:43:41+00:00","modified":"2022-04-28T15:43:41+00:00","when":"2022-04-28T15:43:41+00:00","text":"Summary: Google App Engine Increased Latency in us-central1\nDescription: We are experiencing an issue with Google App Engine beginning at Thursday, 2022-04-28 07:00 US/Pacific.\nOur engineers believe the issue is mitigated and are validating.\nWe will provide an update by Thursday, 2022-04-28 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may have experienced increased latency for App Engine projects in us-central1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-04-28T15:37:04+00:00","modified":"2022-04-28T15:37:06+00:00","when":"2022-04-28T15:37:04+00:00","text":"Summary: Google App Engine Increased Latency in us-central1\nDescription: We are experiencing an issue with Google App Engine beginning at Thursday, 2022-04-28 07:00 US/Pacific.\nOur engineers believe the issue is mitigated and are validating.\nWe will provide an update by Thursday, 2022-04-28 09:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may have experienced increased latency for App Engine projects in uc-central1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-05-05T15:26:36+00:00","modified":"2022-05-05T15:26:36+00:00","when":"2022-05-05T15:26:36+00:00","text":"**INCIDENT REPORT**\n**Summary:**\nOn 28 April 2022, from 07:00 to 08:32 US/Pacific, Google App Engine and Google Cloud Functions experienced increased latency and reduced availability for a duration of 1 hour and 32 minutes in one zone in the us-central1 region. Additionally, customers were unable to create, view, or search support cases in the Google Cloud Support Center and Google Admin Console for 1 hour and 24 minutes. We sincerely apologize for the impact to your service or application. We have completed an internal investigation and are taking immediate steps to improve our service’s quality and reliability.\n**Root Cause:**\nThe Serverless stack relies on a file serving service for container images. The issue was triggered when the file serving component of the Serverless stack experienced a sudden increase in traffic. A bug, introduced in a recent configuration change to the file serving service, was surfaced by the sudden increase in traffic, causing many threads to get stuck. This led to resource exhaustion on the affected file servers, causing some tasks to crash and preventing new requests from completing.\n**Remediation and Prevention:**\nGoogle engineers were alerted to the issue on Thursday, 28 April 2022, at 07:11 US/Pacific and immediately started an investigation. Once the affected component was identified, engineers added additional capacity to the component in the zone that was experiencing the degradation. This mitigated the resource exhaustion, and the service recovered at 08:20 US/Pacific.\nTo prevent recurrence of the issue, engineers rolled back the configuration change to the previous stable version and implemented an automated release block to prevent any unintended release of a version that included the bug.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We are taking the following steps to prevent this or similar issues from happening again:\nTo improve resolution time for future issues of this type, we are calibrating our alerting system to give us an earlier and more precise notification which will allow us to diagnose the issue more quickly.\nWe are also evaluating what kinds of load/stress tests could deterministically detect this kind of issue in the future, so that such regressions are caught automatically before they are deployed to production.\n**Detailed Description of Impact:**\nOn 28th April 2022 from 7:00 PT to 8:32 PT\n**Google App Engine**\nGoogle App Engine experienced increased latency and reduced availability in one zone in us-central1 for a period of 1 hour and 32 minutes. Customers may have experienced increased latency or higher error rate for App Engine projects.\n**Google Cloud Functions**\nGoogle Cloud Functions experienced increased latency and reduced availability in one zone in us-central1 for a period of 1 hour and 32 minutes. “Google Cloud Functions” customers updating their functions (e.g. deploying a new version) may have experienced increased latency or failures, notably failing health checks.\n**Google Cloud Support and Google Workspace Support**\nCustomers were unable to create, view, or search support cases in the Google Cloud Support Center or Google Admin Console for 1 hour and 24 minutes. In addition, a small number of customers had degraded access to phone support, being redirected to a queue requiring additional manual authentication with the support agent.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"kchyUtnkMHJWaAva8aYc","service_name":"Google App Engine","affected_products":[{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"}],"uri":"incidents/mvpNTsgUmf2LL7PdgmyF","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"HoppX9SAc7jshpz6H52u","number":"15296038728160858841","begin":"2022-04-26T08:47:00+00:00","created":"2022-04-26T09:32:28+00:00","end":"2022-04-26T09:40:00+00:00","modified":"2022-04-26T17:23:37+00:00","external_desc":"We are experiencing Cloud Networking Control Plane issues","updates":[{"created":"2022-04-26T17:23:07+00:00","modified":"2022-04-26T17:23:07+00:00","when":"2022-04-26T17:23:07+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 26 April 2022 01:47\n**Incident End:** 26 April 2022 02:40\n**Duration:** 53 minutes\n**Affected Services and Features:** Google Cloud Networking\n**Regions/Zones:** Global/All regions\n**Description:**\nGoogle Cloud Networking control plane experienced elevated latency. All Google Cloud Load Balancer config to Google Front End stalled globally for a duration of 53 minutes.From the preliminary analysis, the root cause of the issue seems to be a race condition where unprocessed configuration deletes caused conflicts with newer configuration changes, leading to the configuration pipeline stall.\n**Customer Impact:**\nCustomers might have experienced issues while creating new forwarding rules for Global Layer 7 External load balancer or edit or delete existing ones.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-04-26T09:52:04+00:00","modified":"2022-04-26T09:52:10+00:00","when":"2022-04-26T09:52:04+00:00","text":"The issue with Google Cloud Networking has been resolved for all affected users as of Tuesday, 2022-04-26 02:40 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-04-26T09:32:22+00:00","modified":"2022-04-26T09:41:56+00:00","when":"2022-04-26T09:32:22+00:00","text":"Summary: We are experiencing Cloud Networking Control Plane issues\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Tuesday, 2022-04-26 02:06 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-04-26 03:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-04-26T17:23:07+00:00","modified":"2022-04-26T17:23:07+00:00","when":"2022-04-26T17:23:07+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 26 April 2022 01:47\n**Incident End:** 26 April 2022 02:40\n**Duration:** 53 minutes\n**Affected Services and Features:** Google Cloud Networking\n**Regions/Zones:** Global/All regions\n**Description:**\nGoogle Cloud Networking control plane experienced elevated latency. All Google Cloud Load Balancer config to Google Front End stalled globally for a duration of 53 minutes.From the preliminary analysis, the root cause of the issue seems to be a race condition where unprocessed configuration deletes caused conflicts with newer configuration changes, leading to the configuration pipeline stall.\n**Customer Impact:**\nCustomers might have experienced issues while creating new forwarding rules for Global Layer 7 External load balancer or edit or delete existing ones.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/HoppX9SAc7jshpz6H52u","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Delhi (asia-south2)","id":"asia-south2"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"yatPQDmQ5uXqb6PzwanU","number":"13941430952028707728","begin":"2022-04-23T02:10:00+00:00","created":"2022-04-23T16:27:43+00:00","end":"2022-04-23T17:21:00+00:00","modified":"2022-04-25T20:06:04+00:00","external_desc":"Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub","updates":[{"created":"2022-04-25T20:05:32+00:00","modified":"2022-04-25T20:05:32+00:00","when":"2022-04-25T20:05:32+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 22 April 2022 19:10 PT\n**Incident End:** 23 April 2022 10:21 PT\n**Duration:** 15 hours,11 minutes\n**Affected Services and Features:**\nGoogle Cloud Pub/Sub - Google Cloud Monitoring\n**Regions/Zones:** Global Locale\n**Description:**\nGoogle Cloud Pub/Sub customers experienced issues with metrics in Google Cloud Monitoring for a duration of 15 hours, 11 minutes. The issue was caused by a configuration change to the backend for Cloud Monitoring that affected Cloud Pub/Sub metric recording. The issue was mitigated by reverting this change.\n**Customer Impact:** - Cloud Pub/Sub metrics in Cloud Monitoring for times during the incident may be missing or underreported. - The metric values lost in this timeframe will not be recoverable. - Any alerting based on these metrics might have fired erroneously or not fired when they should have during the time of the incident. - Any auto-scaling of Google Kubernetes Engine (GKE) based on these metrics may not have functioned as expected during the time of the incident. - Cloud Pub/Sub administrative, publish, and subscribe operations were not affected by the incident.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-23T17:40:46+00:00","modified":"2022-04-23T17:40:48+00:00","when":"2022-04-23T17:40:46+00:00","text":"The issue with Google Cloud Pub/Sub monitoring has been resolved for all affected projects as of Saturday, 2022-04-23 10:21 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-23T17:27:03+00:00","modified":"2022-04-23T17:27:05+00:00","when":"2022-04-23T17:27:03+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We believe the issue with Google Cloud Pub/Sub monitoring was partially resolved as of 10:20 US/Pacific and are continuing to monitor the recovery of the service.\nWe do not have an ETA for full resolution at this point.\nWe will provide more information by Saturday, 2022-04-23 11:30 US/Pacific.\nDiagnosis: Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values. Any alerting based on these metrics may fire erroneously.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-23T16:53:35+00:00","modified":"2022-04-23T16:53:38+00:00","when":"2022-04-23T16:53:35+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Google Cloud Pub/Sub beginning on Friday, 2022-04-22 19:10 US/Pacific.\nThere is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Saturday, 2022-04-23 10:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values. Any alerting based on these metrics may fire erroneously.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-23T16:27:43+00:00","modified":"2022-04-23T16:27:46+00:00","when":"2022-04-23T16:27:43+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Google Cloud Pub/Sub beginning on Friday, 2022-04-22 19:10 US/Pacific.\nThere is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Saturday, 2022-04-23 10:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values. Any alerting based on these metrics may fire erroneously.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\ninstance/cpu/utilization\ninstance/network/received_bytes_count\ninstance/network/sent_bytes_count","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-04-25T20:05:32+00:00","modified":"2022-04-25T20:05:32+00:00","when":"2022-04-25T20:05:32+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 22 April 2022 19:10 PT\n**Incident End:** 23 April 2022 10:21 PT\n**Duration:** 15 hours,11 minutes\n**Affected Services and Features:**\nGoogle Cloud Pub/Sub - Google Cloud Monitoring\n**Regions/Zones:** Global Locale\n**Description:**\nGoogle Cloud Pub/Sub customers experienced issues with metrics in Google Cloud Monitoring for a duration of 15 hours, 11 minutes. The issue was caused by a configuration change to the backend for Cloud Monitoring that affected Cloud Pub/Sub metric recording. The issue was mitigated by reverting this change.\n**Customer Impact:** - Cloud Pub/Sub metrics in Cloud Monitoring for times during the incident may be missing or underreported. - The metric values lost in this timeframe will not be recoverable. - Any alerting based on these metrics might have fired erroneously or not fired when they should have during the time of the incident. - Any auto-scaling of Google Kubernetes Engine (GKE) based on these metrics may not have functioned as expected during the time of the incident. - Cloud Pub/Sub administrative, publish, and subscribe operations were not affected by the incident.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"dFjdLh2v6zuES6t9ADCB","service_name":"Google Cloud Pub/Sub","affected_products":[{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"}],"uri":"incidents/yatPQDmQ5uXqb6PzwanU","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"BNZwWJfvtjg3HxKA3bjY","number":"11838922764773661140","begin":"2022-04-21T00:59:00+00:00","created":"2022-04-21T17:44:44+00:00","end":"2022-04-21T05:18:00+00:00","modified":"2022-04-22T00:51:31+00:00","external_desc":"We are experiencing a decrease in availability of Cloud ML Vision, increase in latency.","updates":[{"created":"2022-04-22T00:51:20+00:00","modified":"2022-04-22T00:51:20+00:00","when":"2022-04-22T00:51:20+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 20 April 2021 17:59\n**Incident End:** 20 April 2021 22:18\n**Duration:** 4 hours, 19 minutes\n**Affected Services and Features:**\nCloud Vision - Vision API\n**Regions/Zones:** Global\n**Description:**\nCloud Vision API experienced increased latency and decreased availability for Cloud ML Vision text detection features for a duration of 4 hours, 19 minutes.\nFrom preliminary analysis, the root cause of the issue was due to a recent update in the Optical Character Recognition [OCR] Model [1] which resulted in performance issues on Cloud Vision API.\n[1] - https://cloud.google.com/vision/docs/ocr\nThe issue was resolved on Wednesday, 20 April 22:18 once a rollback of the change was completed.\n**Customer Impact:**\n- Affected customers may have experienced increased latency and elevated errors.\n- Some features of Cloud Vision API were temporarily unavailable.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-21T17:46:53+00:00","modified":"2022-04-21T17:46:53+00:00","when":"2022-04-21T17:46:53+00:00","text":"The issue with Cloud Vision has been resolved for all affected users as of Wednesday, 2022-04-20 22:17:21 US/Pacific. We thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-21T17:44:45+00:00","modified":"2022-04-21T17:44:45+00:00","when":"2022-04-21T17:44:45+00:00","text":"We are experiencing an issue with Cloud Vision beginning at Wednesday, 2022-04-20 17:59 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-04-21 00:35 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-04-22T00:51:20+00:00","modified":"2022-04-22T00:51:20+00:00","when":"2022-04-22T00:51:20+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case https://cloud.google.com/support\n(All Times US/Pacific)\n**Incident Start:** 20 April 2021 17:59\n**Incident End:** 20 April 2021 22:18\n**Duration:** 4 hours, 19 minutes\n**Affected Services and Features:**\nCloud Vision - Vision API\n**Regions/Zones:** Global\n**Description:**\nCloud Vision API experienced increased latency and decreased availability for Cloud ML Vision text detection features for a duration of 4 hours, 19 minutes.\nFrom preliminary analysis, the root cause of the issue was due to a recent update in the Optical Character Recognition [OCR] Model [1] which resulted in performance issues on Cloud Vision API.\n[1] - https://cloud.google.com/vision/docs/ocr\nThe issue was resolved on Wednesday, 20 April 22:18 once a rollback of the change was completed.\n**Customer Impact:**\n- Affected customers may have experienced increased latency and elevated errors.\n- Some features of Cloud Vision API were temporarily unavailable.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"pDkm4vkHrT54mm7iSVHm","service_name":"Cloud Vision","affected_products":[{"title":"Cloud Vision","id":"pDkm4vkHrT54mm7iSVHm"}],"uri":"incidents/BNZwWJfvtjg3HxKA3bjY","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"waYi5P1JfEPrJh5tPNQU","number":"6524406606269626845","begin":"2022-04-18T03:52:00+00:00","created":"2022-04-18T16:49:41+00:00","end":"2022-04-19T00:33:00+00:00","modified":"2022-04-20T14:32:50+00:00","external_desc":"Cloud Logging is experiencing elevated latencies for log querying. Customers using global storage buckets or storage buckets in us-central1 to store their logs may see latencies on queries run against Cloud Logging. - Issue Resolved.","updates":[{"created":"2022-04-20T14:32:33+00:00","modified":"2022-04-20T14:32:33+00:00","when":"2022-04-20T14:32:33+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 17 April 2022 20:52\n**Incident End:** 18 April 2022 17:33\n**Duration:** 20 hours, 41 minutes\n**Affected Services and Features:**\nGoogle Cloud Logging\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Logging experienced elevated error rates and high latency in log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not have been able to see their recently written logs for a duration of 20 hours, 41 minutes.\nFrom preliminary analysis, an unexpected increase in uncached NOT_FOUND errors while validating log bucket configurations caused a large increase in the overall volume of configuration reads. This in turn caused latency of configuration reads and therefore validations to increase, leading to an ingestion backlog and a delay in log ingestion to the storage layer of our query backend.\nThe issue was resolved at 17:33 US/Pacific once the ingestion backlog cleared.\n**Customer Impact:**\n- Customers using global storage buckets or storage buckets in us-central1 to store their logs may not have been able to see their recently written logs for most of the duration of the event.\n- Customers may have experienced high latency or failures up to 90% on reads from Google Cloud Logging and other query requests.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-19T00:43:20+00:00","modified":"2022-04-19T00:43:20+00:00","when":"2022-04-19T00:43:20+00:00","text":"The issue on Cloud Logging Ingestion and querying has been resolved for all affected projects as of Monday, 2022-04-18 17:33 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T23:55:47+00:00","modified":"2022-04-18T23:55:48+00:00","when":"2022-04-18T23:55:47+00:00","text":"Summary: Cloud Logging is experiencing elevated latencies for log querying. Customers using global storage buckets or storage buckets in us-central1 to store their logs may see latencies on queries run against Cloud Logging.\nDescription: Our engineering team continues to investigate the issue with Log Querying on Cloud Logging. Log ingestion backlogs have cleared but customers may experience issues with querying logs.\nWe will provide an update by Monday, 2022-04-18 18:00 US/Pacific with current details.\nDiagnosis: Customers may experience high latency or failures when listing log entries and for other query requests.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T22:47:30+00:00","modified":"2022-04-18T22:47:31+00:00","when":"2022-04-18T22:47:30+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Our engineering team has determined that further investigation is required to mitigate the issue with log querying.\nLog ingestion backlog has cleared but customers may experience issues with querying the logs.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-04-18 17:00 US/Pacific.\nDiagnosis:\n* Customers may experience high latency or failures when listing log entries and for other query requests\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T21:48:41+00:00","modified":"2022-04-18T21:48:44+00:00","when":"2022-04-18T21:48:41+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Following the fix roll out, log ingestion backlog has cleared but customers may experience issue with querying the logs.\nMitigation work is currently underway by our engineering team for the issue with log querying.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Monday, 2022-04-18 16:00 US/Pacific.\nDiagnosis:\n* Customers may experience high latency or failures when listing log entries and for other query requests\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T20:51:48+00:00","modified":"2022-04-18T20:51:49+00:00","when":"2022-04-18T20:51:48+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Following the fix roll out, log ingestion backlog has cleared but customers may experience issue with querying the logs.\nOur engineering team is working to fix the log querying issue.\nWe will provide more information by Monday, 2022-04-18 15:00 US/Pacific.\nDiagnosis:\n* Customers may experience high latency or failures when listing log entries and for other query requests\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T19:53:12+00:00","modified":"2022-04-18T19:53:13+00:00","when":"2022-04-18T19:53:12+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Following the fix roll out, log ingestion backlog has cleared but customers may experience issue with querying the logs.\nOur engineering team is working to fix the log querying issue.\nWe will provide more information by Monday, 2022-04-18 14:00 US/Pacific.\nDiagnosis:\n* Log ingestion backlog has cleared but customers may experience issue with querying the logs.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T18:56:02+00:00","modified":"2022-04-18T18:56:03+00:00","when":"2022-04-18T18:56:02+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: A fix roll out is completed and customers may still experience delays while the log ingestion backlog is being cleared.\nThe backlog is expected to clear by Monday, 2022-04-18 15:00 US/Pacific.\nWe will provide more information by Monday, 2022-04-18 13:00 US/Pacific.\nDiagnosis:\n* There is a high latency in log ingestion with median latency of around 2 hours and 99% latency of 4.5 hours.\n* Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T17:53:53+00:00","modified":"2022-04-18T17:53:54+00:00","when":"2022-04-18T17:53:53+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-04-18 12:00 US/Pacific.\nWe will provide more information by Monday, 2022-04-18 12:00 US/Pacific.\nDiagnosis: * There is a high latency in log ingestion with median latency of around 2 hours and 99% latency of 4.5 hours.\n* Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-18T16:49:40+00:00","modified":"2022-04-18T16:49:42+00:00","when":"2022-04-18T16:49:40+00:00","text":"Summary: Cloud Logging is experiencing elevated latency for log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Monday, 2022-04-18 12:00 US/Pacific.\nWe will provide more information by Monday, 2022-04-18 11:00 US/Pacific.\nDiagnosis: * There is a high latency in log ingestion in our backends with median latency of around 2 hours and 99% latency of 4.5 hours.\n* Customers using global storage buckets or storage buckets in us-central1 to store their logs may not be able to see their recently written logs for a few hours.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-04-20T14:32:33+00:00","modified":"2022-04-20T14:32:33+00:00","when":"2022-04-20T14:32:33+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 17 April 2022 20:52\n**Incident End:** 18 April 2022 17:33\n**Duration:** 20 hours, 41 minutes\n**Affected Services and Features:**\nGoogle Cloud Logging\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Logging experienced elevated error rates and high latency in log ingestion. Customers using global storage buckets or storage buckets in us-central1 to store their logs may not have been able to see their recently written logs for a duration of 20 hours, 41 minutes.\nFrom preliminary analysis, an unexpected increase in uncached NOT_FOUND errors while validating log bucket configurations caused a large increase in the overall volume of configuration reads. This in turn caused latency of configuration reads and therefore validations to increase, leading to an ingestion backlog and a delay in log ingestion to the storage layer of our query backend.\nThe issue was resolved at 17:33 US/Pacific once the ingestion backlog cleared.\n**Customer Impact:**\n- Customers using global storage buckets or storage buckets in us-central1 to store their logs may not have been able to see their recently written logs for most of the duration of the event.\n- Customers may have experienced high latency or failures up to 90% on reads from Google Cloud Logging and other query requests.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Cloud Logging","id":"PuCJ6W2ovoDhLcyvZ1xa"}],"uri":"incidents/waYi5P1JfEPrJh5tPNQU","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"ukkfXQc8CEeFZbSTYQi7","number":"14166479295409213890","begin":"2022-03-31T19:15:00+00:00","created":"2022-03-31T21:17:41+00:00","end":"2022-03-31T22:13:00+00:00","modified":"2022-04-01T18:49:41+00:00","external_desc":"us multiregion: Elevated errors on Cloud KMS requests.","updates":[{"created":"2022-04-01T18:49:24+00:00","modified":"2022-04-01T18:49:24+00:00","when":"2022-04-01T18:49:24+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 2022-03-31 12:15\n**Incident End:** 2022-03-31 15:13\n**Duration:** 2 hours, 58 minutes\n**Affected Services and Features:**\nGoogle Cloud Key Management Service (KMS)\nGoogle Cloud Storage (GCS)\n**Regions/Zones:** Multiregional US\n**Description:**\nA Cloud Key Management Service (KMS) job experienced multiple errors due to task crashes in one metro of the US multiregion for 2 Hours 58 Minutes. From the preliminary analysis, the root cause of was identified as a map-reduce-style batch job with a huge fast ramp-up of ReadObjects to Google Cloud Storage (GCS), which overloaded the KMS jobs (that are a dependency of GCS).\n**Customer Impact:**\n- The affected customers observed errors in Google Cloud Storage for one project.\n- Multiple tasks failed with Memory-Exceed Error.\n- There were a tiny non-zero amount of errors for some projects.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-03-31T22:14:05+00:00","modified":"2022-03-31T22:14:07+00:00","when":"2022-03-31T22:14:05+00:00","text":"The issue with Cloud Key Management Service has been resolved for all affected users as of Thursday, 2022-03-31 15:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-03-31T21:58:09+00:00","modified":"2022-03-31T21:58:10+00:00","when":"2022-03-31T21:58:09+00:00","text":"Summary: us multiregion: Elevated errors on Cloud KMS requests.\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-03-31 16:30 US/Pacific.\nDiagnosis: Affected customers are seeing elevated errors on Cloud KMS requests in the us multiregion.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"created":"2022-03-31T21:17:40+00:00","modified":"2022-03-31T21:17:43+00:00","when":"2022-03-31T21:17:40+00:00","text":"Summary: us multiregion: Elevated errors on Cloud KMS requests.\nDescription: We are experiencing an issue with Cloud Key Management Service beginning at Thursday, 2022-03-31 12:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are seeing elevated errors on Cloud KMS requests in the us multiregion.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Multi-region: us","id":"us"}]}],"most_recent_update":{"created":"2022-04-01T18:49:24+00:00","modified":"2022-04-01T18:49:24+00:00","when":"2022-04-01T18:49:24+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 2022-03-31 12:15\n**Incident End:** 2022-03-31 15:13\n**Duration:** 2 hours, 58 minutes\n**Affected Services and Features:**\nGoogle Cloud Key Management Service (KMS)\nGoogle Cloud Storage (GCS)\n**Regions/Zones:** Multiregional US\n**Description:**\nA Cloud Key Management Service (KMS) job experienced multiple errors due to task crashes in one metro of the US multiregion for 2 Hours 58 Minutes. From the preliminary analysis, the root cause of was identified as a map-reduce-style batch job with a huge fast ramp-up of ReadObjects to Google Cloud Storage (GCS), which overloaded the KMS jobs (that are a dependency of GCS).\n**Customer Impact:**\n- The affected customers observed errors in Google Cloud Storage for one project.\n- Multiple tasks failed with Memory-Exceed Error.\n- There were a tiny non-zero amount of errors for some projects.","status":"AVAILABLE","affected_locations":[{"title":"Multi-region: us","id":"us"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"67cSySTL7dwJZo9JWUGU","service_name":"Cloud Key Management Service","affected_products":[{"title":"Cloud Key Management Service","id":"67cSySTL7dwJZo9JWUGU"}],"uri":"incidents/ukkfXQc8CEeFZbSTYQi7","currently_affected_locations":[],"previously_affected_locations":[{"title":"Multi-region: us","id":"us"}]},{"id":"RmPhfQT9RDGwWLCXS2sC","number":"3617221773064871579","begin":"2022-03-31T18:07:00+00:00","created":"2022-03-31T18:41:46+00:00","end":"2022-03-31T22:13:00+00:00","modified":"2022-04-01T19:27:03+00:00","external_desc":"Global: Delays creating or modifying load balancer configurations","updates":[{"created":"2022-04-01T19:26:50+00:00","modified":"2022-04-01T19:26:50+00:00","when":"2022-04-01T19:26:50+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 31 March 2022 11:07\n**Incident End:** 31 March 2022 15:13\n**Duration:** 4 hours, 6 minutes,\n**Affected Services and Features:**\n* Global External HTTP/S load balancing\n* Cloud CDN\n* Cloud Armor\n* Appengine flex\n**Regions/Zones:** Global Locale\n**Description:**\nCloud Load Balancers experienced delays creating or modifying configurations for 4 hours 6 minutes. From the preliminary analysis, the root cause of the issue is a rollout on the configuration management system that manages and pushes configuration for multiple Google infrastructure systems. The roll out caused an increase in the task counts which overloaded the configuration management system as all tasks pulled the configuration at the same time.\n**Customer Impact:**\n* Affected customers would have experienced delays in creating or modifying the configuration of Global External HTTP(S) load balancers, Cloud Armor and Cloud CDN.\n* App Engine Flexible apps might have failed to deploy.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-31T21:56:04+00:00","modified":"2022-03-31T21:56:06+00:00","when":"2022-03-31T21:56:04+00:00","text":"The issue with Cloud Armor, Google App Engine, Google Cloud Networking has been resolved for all affected users as of Thursday, 2022-03-31 14:55 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-31T20:17:13+00:00","modified":"2022-03-31T20:17:15+00:00","when":"2022-03-31T20:17:13+00:00","text":"Summary: Global: Delays creating or modifying load balancer configurations\nDescription: Mitigation efforts are reducing the backlog of delayed configuration changes, which are slowly being processed.\nWe will provide more information by Thursday, 2022-03-31 15:15 US/Pacific.\nDiagnosis: Affected customers will see delays in creating or modifying the configuration of Global External HTTP(S) load balancers, Cloud Armor and Cloud CDN. App Engine Flexible apps may fail to deploy. Configuration changes will be accepted, but not take effect until the issue is resolved. Existing configurations and deployments are not impacted.\nWorkaround: Configuration changes will eventually take effect. Failed App Engine Flexible deployments can be retried.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-31T19:43:10+00:00","modified":"2022-03-31T19:43:13+00:00","when":"2022-03-31T19:43:10+00:00","text":"Summary: Global: Delays creating or modifying load balancer configurations\nDescription: Our engineering team is exploring multiple mitigations options currently.\nWe will provide more information by Thursday, 2022-03-31 15:00 US/Pacific.\nDiagnosis: Affected customers will see delays in creating or modifying the configuration of Global External HTTP(S) load balancers, Cloud Armor and Cloud CDN. App Engine Flexible apps may fail to deploy. Configuration changes will be accepted, but not take effect until the issue is resolved. Existing configurations and deployments are not impacted.\nWorkaround: Configuration changes will eventually take effect. Failed App Engine Flexible deployments can be retried.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-31T19:11:56+00:00","modified":"2022-03-31T19:12:03+00:00","when":"2022-03-31T19:11:56+00:00","text":"Summary: Global: Unable to create or modify some Cloud Networking configurations\nDescription: Mitigation work is still underway by our engineering team.\nCurrent data indicates that approximately 15% of projects globally are affected by this issue.\nWe will provide more information by Thursday, 2022-03-31 14:00 US/Pacific.\nDiagnosis: Affected customers are not able to create or change External HTTP(S) load balancers. Cloud Armor and Cloud CDN have similar symptoms. App Engine Flexible apps may fail to deploy. In general, config change will be accepted, but will not take effect. Existing configurations are not impacted.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T18:51:39+00:00","modified":"2022-03-31T18:51:42+00:00","when":"2022-03-31T18:51:39+00:00","text":"Summary: Global: Unable to create or modify some Cloud Networking configurations\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-03-31 13:00 US/Pacific.\nDiagnosis: Affected customers are not able to create or change External HTTP(S) load balancers. Cloud Armor and Cloud CDN have similar symptoms. App Engine Flexible apps may fail to deploy. In general, config change will be accepted, but will not take effect. Existing configurations are not impacted.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T18:41:39+00:00","modified":"2022-03-31T18:41:50+00:00","when":"2022-03-31T18:41:39+00:00","text":"Summary: Global: Unable to create or modify regional external HTTP(S) load balancers\nDescription: We are experiencing an issue with Google Cloud Networking beginning at Thursday, 2022-03-31 11:07 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 12:45 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers are not able to create or change Regional external HTTP(S) load balancer balancers. Existing balancers are not impacted.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-04-01T19:26:50+00:00","modified":"2022-04-01T19:26:50+00:00","when":"2022-04-01T19:26:50+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 31 March 2022 11:07\n**Incident End:** 31 March 2022 15:13\n**Duration:** 4 hours, 6 minutes,\n**Affected Services and Features:**\n* Global External HTTP/S load balancing\n* Cloud CDN\n* Cloud Armor\n* Appengine flex\n**Regions/Zones:** Global Locale\n**Description:**\nCloud Load Balancers experienced delays creating or modifying configurations for 4 hours 6 minutes. From the preliminary analysis, the root cause of the issue is a rollout on the configuration management system that manages and pushes configuration for multiple Google infrastructure systems. The roll out caused an increase in the task counts which overloaded the configuration management system as all tasks pulled the configuration at the same time.\n**Customer Impact:**\n* Affected customers would have experienced delays in creating or modifying the configuration of Global External HTTP(S) load balancers, Cloud Armor and Cloud CDN.\n* App Engine Flexible apps might have failed to deploy.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Armor","id":"Kakg69gTC3xFyeJCY2va"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Cloud CDN","id":"ckSRJf2vQwQy188ULGy3"}],"uri":"incidents/RmPhfQT9RDGwWLCXS2sC","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Global","id":"global"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"B1hD4KAtcxiyAWkcANfV","number":"17742360388109155603","begin":"2022-03-31T15:30:00+00:00","created":"2022-03-31T18:40:18+00:00","end":"2022-03-31T22:54:00+00:00","modified":"2022-04-18T20:16:50+00:00","external_desc":"Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub","updates":[{"created":"2022-04-18T20:16:50+00:00","modified":"2022-04-18T20:16:50+00:00","when":"2022-04-18T20:16:50+00:00","text":"**Summary**\nOn Thursday March 31st, starting at 08:30 PT, Cloud Pub/Sub metrics were missing or were underreported in Cloud Monitoring for some Cloud Pub/Sub customers for a duration of 7 hours, 24 minutes. Google apologizes to customers who were affected by this outage and is taking steps to ensure that this type of outage does not reoccur.\n**Root Cause**\nOur investigation found the cause was a backend configuration change to our Cloud Monitoring service. This configuration changed the computation of some metrics not directly related to, but shared by, Cloud Pub/Sub. This configuration change progressively rolled out across all Google Cloud regions over two hours.\nThis configuration change increased the latency of requests to record metrics sent from Cloud Pub/Sub to Cloud Monitoring and, in some cases, resulted in failures due to write operations timing out.\n**Remediation and Prevention**\nEngineers were able to mitigate the issue by reverting the change that caused the issue, restoring services for all customers at 15:54 US/Pacific.\nWe are taking the following actions to ensure this does not happen again:\n- Improving the monitoring of Cloud Pub/Sub metrics reporting to allow for quicker error detection.\n- Making Cloud Pub/Sub metrics reporting operations more resilient to high latency.\n- Improving internal visibility and vetting of Cloud Monitoring backend configuration changes.\n**Detailed Description of Impact**\nOn Thursday March 31st, between 08:30 and 15:54 US/Pacific time:\n**Cloud Pub/Sub Metrics in Cloud Reporting**\n- The metric values lost during this timeframe are not recoverable.\n- Any alerting based on these metrics might have fired erroneously or not fired when it should have.\n- Auto scaling of Google Kubernetes Engine (GKE) based on these metrics may not have functioned as expected.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-04-01T20:13:25+00:00","modified":"2022-04-01T20:13:25+00:00","when":"2022-04-01T20:13:25+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support or help article https://support.google.com/a/answer/1047213.\n(All Times US/Pacific)\n**Incident Start:** 31 March 2022 08:30\n**Incident End:** 31 March 2022 15:54\n**Duration:** 7 hours, 24 minutes\n**Affected Services and Features:**\nGoogle Cloud Pub/Sub, Google Cloud Monitoring\n**Regions/Zones:** Global Locale\n**Description:**\nGoogle Cloud Pub/Sub customers experienced issues with metrics in Google Cloud Monitoring for a duration of 7 hours, 24 minutes. The issue was caused by a configuration change to the backend for Cloud Monitoring that affected Cloud Pub/Sub metric recording. The issue was mitigated by reverting this change.\n**Customer Impact:**\n- Cloud Pub/Sub metrics in Cloud Monitoring for times during the incident may be missing or underreported. - The metric values lost in this timeframe will not be recoverable.\n- Any alerting based on these metrics might have fired erroneously or not fired when they should have during the time of the incident.\n- Any auto scaling of Google Kubernetes Engine (GKE) based on these metrics may not have functioned as expected during the time of the incident.\n- Cloud Pub/Sub administrative, publish, and subscribe operations were not affected by the incident.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T23:11:12+00:00","modified":"2022-03-31T23:11:14+00:00","when":"2022-03-31T23:11:12+00:00","text":"The issue with Google Cloud Pub/Sub monitoring has been resolved for all affected projects as of Thursday, 2022-03-31 15:54 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T22:23:34+00:00","modified":"2022-03-31T22:23:36+00:00","when":"2022-03-31T22:23:34+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: ​​We believe the issue with Google Cloud Pub/Sub monitoring was partially resolved as of 14:57, and are continuing to monitor the recovery of the service.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Thursday, 2022-03-31 16:30 US/Pacific with current details.\nDiagnosis: - Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values.\n- Any alerting based on these metrics may fire erroneously.\n- Any auto scaling of GKE based on these metrics may not function as expected due to lack of or underreported values.\nPublish and subscribe metrics are currently affected for publishers and subscribers in following regions:\n- asia-east1\n- europe-north1\n- europe-west4\n- us-central1\n- us-central2\n- us-east1\n- us-east4\n- us-east7\n- us-west1\n- us-west4\nBacklog metrics for subscriptions and snapshot metrics in all regions are no longer affected in any region.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T21:49:14+00:00","modified":"2022-03-31T21:49:15+00:00","when":"2022-03-31T21:49:14+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring metrics for Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 15:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: - Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values.\n- Any alerting based on these metrics may fire erroneously.\n- Any auto scaling of GKE based on these metrics may not function as expected due to lack of or underreported values.\nPublish and subscribe metrics are currently affected for publishers and subscribers in following regions:\n- asia-east1\n- europe-north1\n- europe-west4\n- us-central1\n- us-central2\n- us-east1\n- us-east4\n- us-east7\n- us-west1\n- us-west4\nBacklog metrics for subscriptions and snapshot metrics in all regions are no longer affected in any region.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T21:20:01+00:00","modified":"2022-03-31T21:20:01+00:00","when":"2022-03-31T21:20:01+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring metrics for Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 14:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: - Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values.\n- Any alerting based on these metrics may fire erroneously.\n- Any auto scaling of GKE based on these metrics may not function as expected due to lack of or underreported values.\nPublish and subscribe metrics are currently affected for publishers and subscribers in following regions:\n- asia-east1\n- europe-north1\n- europe-west4\n- us-central1\n- us-central2\n- us-east1\n- us-east4\n- us-east7\n- us-west1\n- us-west4\nBacklog metrics for subscriptions and snapshot metrics in all regions are currently affected.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T20:49:56+00:00","modified":"2022-03-31T20:49:57+00:00","when":"2022-03-31T20:49:56+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring metrics for Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 14:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: - Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values.\n- Any alerting based on these metrics may fire erroneously.\n- Any auto scaling of GKE based on these metrics may not function as expected due to lack of or underreported values.\nPublish and subscribe metrics are currently affected for publishers and subscribers in following regions:\n- asia-east1\n- europe-north1\n- europe-west4\n- us-central1\n- us-central2\n- us-east1\n- us-east4\n- us-east7\n- us-west1\n- us-west4\nBacklog metrics for subscriptions and snapshot metrics in all regions are currently affected.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T20:18:51+00:00","modified":"2022-03-31T20:18:52+00:00","when":"2022-03-31T20:18:51+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring and Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 13:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: - Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values.\n- Any alerting based on these metrics may fire erroneously.\n- Any auto scaling of GKE based on these metrics may not function as expected due to lack of or underreported values.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T19:52:27+00:00","modified":"2022-03-31T19:52:33+00:00","when":"2022-03-31T19:52:27+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring and Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 13:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values. Any alerting based on these metrics may fire erroneously.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T19:23:08+00:00","modified":"2022-03-31T19:23:09+00:00","when":"2022-03-31T19:23:08+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable or underreported for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring and Cloud Pub/Sub beginning Thursday, 2022-03-31 09:30 US/Pacific. There is no known impact on Cloud Pub/Sub administrative, publish, or subscribe operations at this time.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 12:55 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers impacted by this issue may see Cloud Monitoring metrics for Cloud Pub/Sub that show no or underreported values. Any alerting based on these metrics may fire erroneously.\nWorkaround: Non-Cloud-Pub/Sub metrics and logs on publish and subscriber clients can be used as a proxy to ensure that publishing and subscribing is still behaving as expected. For example, metrics available for clients running on GCE include:\n- instance/cpu/utilization\n- instance/network/received_bytes_count\n- instance/network/sent_bytes_count","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T18:58:09+00:00","modified":"2022-03-31T18:58:10+00:00","when":"2022-03-31T18:58:09+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable for Cloud Pub/Sub\nDescription: We are experiencing an issue with Cloud Monitoring and Cloud Pub/Sub beginning at Thursday, 2022-03-31 09:30 US/Pacific.\nEngineering is continuing to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 12:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience unavailable Metrics in Cloud Monitoring for Cloud Pub/Sub\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-31T18:40:17+00:00","modified":"2022-03-31T18:40:19+00:00","when":"2022-03-31T18:40:17+00:00","text":"Summary: Global: Cloud Monitoring Metrics may be unavailable\nDescription: We are experiencing an issue with Cloud Monitoring beginning at Thursday, 2022-03-31 09:30 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-03-31 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience unavailable Metrics in Cloud Monitoring\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-04-18T20:16:50+00:00","modified":"2022-04-18T20:16:50+00:00","when":"2022-04-18T20:16:50+00:00","text":"**Summary**\nOn Thursday March 31st, starting at 08:30 PT, Cloud Pub/Sub metrics were missing or were underreported in Cloud Monitoring for some Cloud Pub/Sub customers for a duration of 7 hours, 24 minutes. Google apologizes to customers who were affected by this outage and is taking steps to ensure that this type of outage does not reoccur.\n**Root Cause**\nOur investigation found the cause was a backend configuration change to our Cloud Monitoring service. This configuration changed the computation of some metrics not directly related to, but shared by, Cloud Pub/Sub. This configuration change progressively rolled out across all Google Cloud regions over two hours.\nThis configuration change increased the latency of requests to record metrics sent from Cloud Pub/Sub to Cloud Monitoring and, in some cases, resulted in failures due to write operations timing out.\n**Remediation and Prevention**\nEngineers were able to mitigate the issue by reverting the change that caused the issue, restoring services for all customers at 15:54 US/Pacific.\nWe are taking the following actions to ensure this does not happen again:\n- Improving the monitoring of Cloud Pub/Sub metrics reporting to allow for quicker error detection.\n- Making Cloud Pub/Sub metrics reporting operations more resilient to high latency.\n- Improving internal visibility and vetting of Cloud Monitoring backend configuration changes.\n**Detailed Description of Impact**\nOn Thursday March 31st, between 08:30 and 15:54 US/Pacific time:\n**Cloud Pub/Sub Metrics in Cloud Reporting**\n- The metric values lost during this timeframe are not recoverable.\n- Any alerting based on these metrics might have fired erroneously or not fired when it should have.\n- Auto scaling of Google Kubernetes Engine (GKE) based on these metrics may not have functioned as expected.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Monitoring","id":"3zaaDb7antc73BM1UAVT"},{"title":"Operations","id":"DixAowEQm45KgqXKP5tR"},{"title":"Google Cloud Pub/Sub","id":"dFjdLh2v6zuES6t9ADCB"}],"uri":"incidents/B1hD4KAtcxiyAWkcANfV","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"4rRjbE16mteQwUeXPZwi","number":"8134027662519725646","begin":"2022-03-29T21:00:00+00:00","created":"2022-03-30T01:14:53+00:00","end":"2022-03-29T22:27:00+00:00","modified":"2022-03-30T17:30:12+00:00","external_desc":"We've received a report of an issue with Cloud Talent Solution - SearchJobs API queries.","updates":[{"created":"2022-03-30T17:30:12+00:00","modified":"2022-03-30T17:30:12+00:00","when":"2022-03-30T17:30:12+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case\nusing https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 29 March 2022 14:00\n**Incident End:** 29 March 2022 15:27\n**Duration:** 1 hour, 27 minutes\n**Affected Services and Features:**\nCloud Talent Solution - Job Search\n**Regions/Zones:** Global Locale\n**Description:**\nCloud Talent Solution Job Search experienced elevated error rate for a duration of 1 hour, 27 minutes. From preliminary analysis, the root cause of the issue is reduced availability on a dependency component that is responsible for enhancing search results.\n**Customer Impact:**\nAffected customers would have experienced deadline exceeded 504 or service unavailable 503 errors when performing Job search.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-30T01:23:02+00:00","modified":"2022-03-30T01:23:02+00:00","when":"2022-03-30T01:23:02+00:00","text":"We experienced an issue with Cloud Talent Solution - SearchJobs API, beginning at Tuesday, 2022-03-29 14:00 US/Pacific.\nCustomers may have experienced 504 - Deadline exceeded errors, on SearchJobs API queries.\nThe issue has been resolved for all affected projects as of Tuesday, 2022-03-29 15:27 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},{"created":"2022-03-30T01:16:59+00:00","modified":"2022-03-30T01:44:33+00:00","when":"2022-03-30T01:16:59+00:00","text":"Summary: We've received a report of an issue with Cloud Talent Solution - SearchJobs API queries.\nDescription: This is a retrospective update for a reported issue with Cloud Talent Solution - SearchJobs API queries, reported between 2022-03-29 14:00 - 15:27, US/Pacific.\nWe will provide more information by Tuesday, 2022-03-29 18:30 US/Pacific.\nDiagnosis: Customers may have experienced 504 - Deadline exceeded errors, on SearchJobs API queries.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Global","id":"global"}]}],"most_recent_update":{"created":"2022-03-30T17:30:12+00:00","modified":"2022-03-30T17:30:12+00:00","when":"2022-03-30T17:30:12+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case\nusing https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 29 March 2022 14:00\n**Incident End:** 29 March 2022 15:27\n**Duration:** 1 hour, 27 minutes\n**Affected Services and Features:**\nCloud Talent Solution - Job Search\n**Regions/Zones:** Global Locale\n**Description:**\nCloud Talent Solution Job Search experienced elevated error rate for a duration of 1 hour, 27 minutes. From preliminary analysis, the root cause of the issue is reduced availability on a dependency component that is responsible for enhancing search results.\n**Customer Impact:**\nAffected customers would have experienced deadline exceeded 504 or service unavailable 503 errors when performing Job search.","status":"AVAILABLE","affected_locations":[{"title":"Global","id":"global"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Talent Solution - Job Search","id":"VXydUfMqEtvZxXJFm56a"},{"title":"Cloud Machine Learning","id":"z9PfKanGZYvYNUbnKzRJ"}],"uri":"incidents/4rRjbE16mteQwUeXPZwi","currently_affected_locations":[],"previously_affected_locations":[{"title":"Global","id":"global"}]},{"id":"2j8xsJMSyDhmgfJriGeR","number":"5259740469836333814","begin":"2022-03-28T22:30:00+00:00","created":"2022-03-29T04:53:00+00:00","end":"2022-03-29T09:58:00+00:00","modified":"2022-03-29T23:36:25+00:00","external_desc":"Cloud Spanner instance creation failure","updates":[{"created":"2022-03-29T23:36:23+00:00","modified":"2022-03-29T23:36:23+00:00","when":"2022-03-29T23:36:23+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case\nusing https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 28 March 2022 15:30\n**Incident End:** 29 March 2022 2:58\n**Duration:** 11 hours, 28 minutes\n**Affected Services and Features:**\nCloud Spanner - Creation of new instance , Scaling existing instances.\n**Regions/Zones:** us-east1, europe-central2, multi-region location nam6\n**Description:**\nCloud Spanner experienced delays in creation and scaling of instances in us-east1, europe-central2, and multi-region location nam6 [1] for a duration of 11 hours, 28 minutes. The cause of this was a rollout of a new feature that affected the ability to create or modify instance compute capacity (via instance scaling or new instance creation). This issue was discovered internally and mitigation was performed via updating the configuration back to the previous settings.\n[1] https://cloud.google.com/spanner/docs/instance-configurations#available-configurations-multi-region\n**Customer Impact:**\nAffected customers would have experienced the following operations being stuck or failing with a timeout:\n* Creation of new Cloud Spanner instances\n* Scaling existing Cloud Spanner instances","status":"AVAILABLE","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T10:46:17+00:00","modified":"2022-03-29T10:46:24+00:00","when":"2022-03-29T10:46:17+00:00","text":"The issue with Cloud Spanner has been resolved for all affected users as of Tuesday, 2022-03-29 03:13 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T09:56:46+00:00","modified":"2022-03-29T09:56:56+00:00","when":"2022-03-29T09:56:46+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2022-03-29 04:30 US/Pacific.\nWe will provide more information by Tuesday, 2022-03-29 04:30 US/Pacific.\nDiagnosis: The impacted users might experience timeout failures while:\n1) Creating a new Cloud Spanner instance\n2) Scaling existing Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new cloud spanner instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T09:06:41+00:00","modified":"2022-03-29T09:06:42+00:00","when":"2022-03-29T09:06:41+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2022-03-29 03:30 US/Pacific.\nWe will provide more information by Tuesday, 2022-03-29 03:30 US/Pacific.\nDiagnosis: The impacted users might experience timeout failures while:\n1) Creating a new Cloud Spanner instance\n2) Scaling existing Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new cloud spanner instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T07:15:48+00:00","modified":"2022-03-29T07:15:54+00:00","when":"2022-03-29T07:15:48+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: We are experiencing an issue with Cloud Spanner beginning at Monday, 2022-03-28 15:30 US/Pacific. Updating and creating a new Cloud Spanner instance in us-east1 and europe-central2 might fail with the timeout errors.\nOur engineering team continues to investigate the issue and working towards the mitigation.\nWe will provide an update by Tuesday, 2022-03-29 05:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The impacted users might experience timeout failures while:\n1) Creating a new Cloud Spanner instance\n2) Scaling existing Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new cloud spanner instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T05:48:39+00:00","modified":"2022-03-29T05:48:40+00:00","when":"2022-03-29T05:48:39+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: We are experiencing an issue with Cloud Spanner beginning at Monday, 2022-03-28 15:30 US/Pacific. Updating and creating a new Cloud Spanner instance in us-east1 might be failing with timeout errors.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-03-29 01:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The impacted users might experience timeout failures while:\n1) Creating a new Cloud Spanner instance\n2) Scaling existing Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new cloud spanner instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T05:29:01+00:00","modified":"2022-03-29T05:29:07+00:00","when":"2022-03-29T05:29:01+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: We are experiencing an issue with Cloud Spanner beginning at Monday, 2022-03-28 15:30 US/Pacific. A new Cloud Spanner instance creation in us-east1 might be failing with timeout errors.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-03-29 01:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The impacted users might experience timeout failures while creating a new Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new cloud spanner instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"created":"2022-03-29T04:52:54+00:00","modified":"2022-03-29T04:53:00+00:00","when":"2022-03-29T04:52:54+00:00","text":"Summary: Cloud Spanner instance creation failure\nDescription: We are experiencing an issue with Cloud Spanner beginning at Monday, 2022-03-28 19:00 US/Pacific. A new Cloud Spanner instance creation in us-east1 might be failing with timeout errors.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2022-03-28 23:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: The impacted users might experience timeout failures while creating a new Cloud Spanner instance\nWorkaround: As a workaround, users may try to create new instance in a different region","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"South Carolina (us-east1)","id":"us-east1"}]}],"most_recent_update":{"created":"2022-03-29T23:36:23+00:00","modified":"2022-03-29T23:36:23+00:00","when":"2022-03-29T23:36:23+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case\nusing https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 28 March 2022 15:30\n**Incident End:** 29 March 2022 2:58\n**Duration:** 11 hours, 28 minutes\n**Affected Services and Features:**\nCloud Spanner - Creation of new instance , Scaling existing instances.\n**Regions/Zones:** us-east1, europe-central2, multi-region location nam6\n**Description:**\nCloud Spanner experienced delays in creation and scaling of instances in us-east1, europe-central2, and multi-region location nam6 [1] for a duration of 11 hours, 28 minutes. The cause of this was a rollout of a new feature that affected the ability to create or modify instance compute capacity (via instance scaling or new instance creation). This issue was discovered internally and mitigation was performed via updating the configuration back to the previous settings.\n[1] https://cloud.google.com/spanner/docs/instance-configurations#available-configurations-multi-region\n**Customer Impact:**\nAffected customers would have experienced the following operations being stuck or failing with a timeout:\n* Creation of new Cloud Spanner instances\n* Scaling existing Cloud Spanner instances","status":"AVAILABLE","affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"EcNGGUgBtBLrtm4mWvqC","service_name":"Cloud Spanner","affected_products":[{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"}],"uri":"incidents/2j8xsJMSyDhmgfJriGeR","currently_affected_locations":[],"previously_affected_locations":[{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"South Carolina (us-east1)","id":"us-east1"}]},{"id":"MtMwhU6SXrpBeg5peXqY","number":"17330021626924647123","begin":"2022-03-25T07:00:00+00:00","created":"2022-03-25T08:22:51+00:00","end":"2022-03-25T07:16:00+00:00","modified":"2022-03-25T19:59:34+00:00","external_desc":"Global: We experienced Google Cloud Networking issues.","updates":[{"created":"2022-03-25T19:59:31+00:00","modified":"2022-03-25T19:59:31+00:00","when":"2022-03-25T19:59:31+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 25 March 2022 00:00\n**Incident End:** 25 March 2022 00:16\n**Duration:** 16 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:** Multiple regions\n**Description:**\nGoogle Cloud Networking experienced packet loss due to transient failures on several fiber paths between two metro locations in the US northwest region and US central region. This packet loss led to disruption of traffic between multiple cloud regions globally. Most of the transient failures were cleared by 25 March 2022, 00:08 US/Pacific mitigating the issue for global regions.\nAn unrelated transient fiber failure in the Asia region caused an additional minor disruption that was limited only to the APAC region between 25 March 2022 00:10 US/Pacific and 25 March 2022 00:16 US/Pacific.\n**Customer Impact:**\nCustomers may have experienced issues with transit traffic between multiple Google Cloud regions. Following are the cloud regions which were affected the most:\n* Traffic FROM us-east2 TO asia-east1\n* Traffic FROM all europe regions TO us-west1, asia-east1and asia-south2\n* Traffic FROM us-east1, us-east2, us-east4 TO us-west1, asia-east1and asia-south2\n* Traffic FROM us-central1 TO us-west1, asia-east1and asia-south2","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-25T08:38:09+00:00","modified":"2022-03-25T08:38:09+00:00","when":"2022-03-25T08:38:09+00:00","text":"We experienced an issue with Google Cloud Networking beginning at 2022-03-25 00:00 US/Pacific to 2022-03-25 00:08 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"created":"2022-03-25T08:22:51+00:00","modified":"2022-03-25T08:22:52+00:00","when":"2022-03-25T08:22:51+00:00","text":"Summary: Global: We experienced Google Cloud Networking issues.\nDescription: We experienced an issue with Google Cloud Networking , beginning at Friday, 2022-03-25 00:00 US/Pacific to 2022-03-25 00:08.\nOur engineering team continues to monitor the issue.\nWe will provide an update by Friday, 2022-03-25 02:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]}],"most_recent_update":{"created":"2022-03-25T19:59:31+00:00","modified":"2022-03-25T19:59:31+00:00","when":"2022-03-25T19:59:31+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 25 March 2022 00:00\n**Incident End:** 25 March 2022 00:16\n**Duration:** 16 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:** Multiple regions\n**Description:**\nGoogle Cloud Networking experienced packet loss due to transient failures on several fiber paths between two metro locations in the US northwest region and US central region. This packet loss led to disruption of traffic between multiple cloud regions globally. Most of the transient failures were cleared by 25 March 2022, 00:08 US/Pacific mitigating the issue for global regions.\nAn unrelated transient fiber failure in the Asia region caused an additional minor disruption that was limited only to the APAC region between 25 March 2022 00:10 US/Pacific and 25 March 2022 00:16 US/Pacific.\n**Customer Impact:**\nCustomers may have experienced issues with transit traffic between multiple Google Cloud regions. Following are the cloud regions which were affected the most:\n* Traffic FROM us-east2 TO asia-east1\n* Traffic FROM all europe regions TO us-west1, asia-east1and asia-south2\n* Traffic FROM us-east1, us-east2, us-east4 TO us-west1, asia-east1and asia-south2\n* Traffic FROM us-central1 TO us-west1, asia-east1and asia-south2","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/MtMwhU6SXrpBeg5peXqY","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Hong Kong (asia-east2)","id":"asia-east2"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Mumbai (asia-south1)","id":"asia-south1"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Toronto (northamerica-northeast2)","id":"northamerica-northeast2"},{"title":"São Paulo (southamerica-east1)","id":"southamerica-east1"},{"title":"Santiago (southamerica-west1)","id":"southamerica-west1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"},{"title":"Los Angeles (us-west2)","id":"us-west2"},{"title":"Salt Lake City (us-west3)","id":"us-west3"},{"title":"Las Vegas (us-west4)","id":"us-west4"}]},{"id":"R9vAbtGnhzo6n48SnqTj","number":"2948654908633925955","begin":"2022-03-22T22:30:00+00:00","created":"2022-03-23T00:14:43+00:00","end":"2022-03-23T00:15:00+00:00","modified":"2022-03-28T15:30:50+00:00","external_desc":"Customers connecting from Mexico and Central America may experience issues with accessing GCP services","updates":[{"created":"2022-03-28T15:30:50+00:00","modified":"2022-03-28T15:30:50+00:00","when":"2022-03-28T15:30:50+00:00","text":"**Summary**\nOn Tuesday, 22 March 2022, Google Cloud Networking experienced congestion on network infrastructure to and from the network edge locations [1] in Queretaro, Mexico, for a duration of 1 hour and 45 minutes, following multiple fiber cuts between the United States and Mexico. Affected customers may have experienced high latency, high retransmits and elevated errors.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n[1] - https://cloud.google.com/vpc/docs/edge-locations\n**Root Cause**\nGoogle’s wide-area network is primarily comprised of infrastructure owned and operated by Google, although some physical links use fiber infrastructure which is owned and operated by third parties. Google has multiple resilient fiber paths and network points of presence serving users in Mexico.\nMultiple simultaneous fiber cuts on diversely-routed paths, at the same time as a planned maintenance event on another diversely-routed path, resulted in a capacity shortfall in Google’s wide-area network between Queretaro, Mexico and the United States. This multiple failure event represents a rare case in which the resulting capacity shortfall was visible to Google's users.\nTraffic was subsequently redirected to alternate links; however, there was insufficient capacity to serve all the redirected traffic, resulting in packet loss for user-facing network traffic to Google from users in Mexico.\n**Remediation and Prevention**\nGoogle’s automated repair mechanism detected the congestion on Tuesday, 22 March 2022, at 15:42 US/Pacific and redirected the traffic through alternate edge locations. However, the alternate link did not have sufficient capacity to serve all the redirected traffic, resulting in packet loss. The congestion was cleared when traffic was manually routed around the failed links on Tuesday, 22 March 2022, at 17:15 US/Pacific.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. However, this incident was the result of multiple concurrent failures on links which are designed to provide resilience; such failures, whilst very rare, are expected at a low frequency. We are taking the following steps to ensure we respond quickly to similar events in the future:\n* Improving the reliability of tooling that manually reroutes traffic in extreme multiple-failure scenarios.\n* Improving the diagnostic systems that help Google's Cloud Networking teams decide how to deal with extreme multiple-failure scenarios.\nWe appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact**\nOn Tuesday, 22 March 2022 from 15:30 to 17:15 US/Pacific, customers reaching Google services from Mexico may have experienced network slowness and packet loss, and errors returned from our services. This may have resulted in customers not being able to access services running on Google Cloud and Workspace services including:\n* Google Meet\n* Gmail\n* Google Drive","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-23T17:25:19+00:00","modified":"2022-03-23T17:25:19+00:00","when":"2022-03-23T17:25:19+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 22 March 2022 15:30\n**Incident End:** 22 March 2022 17:15\n**Duration:** 1 hour, 45 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking - Cloud VPN, Cloud Interconnect, Cloud Load Balancers\nWorkspace Products - Gmail, Meet, Drive and Other Workspace products\n**Regions/Zones:** Mexico\n**Description:**\nGoogle Cloud Networking experienced congestion on network infrastructure to and from the network edge locations in Queretaro, Mexico, for a duration of 1 hour and 45 minutes, following a fiber cut between the United States \u0026 Mexico.\nGoogle’s automated repair mechanism detected the congestion and redirected the traffic through alternate edge locations. However, the alternate link did not have sufficient capacity to serve all the redirected traffic, resulting in packet loss for user-facing network traffic to Google. When traffic was manually routed to take other paths, the congestion was cleared.\n**Customer Impact:**\nCustomers reaching Google services, including GCP and Workspace, from Mexico may have experienced high latency, high packet loss, high retransmits, and errors returned from our services, resulting in customers not being able to access those services.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-23T01:28:48+00:00","modified":"2022-03-23T01:28:49+00:00","when":"2022-03-23T01:28:48+00:00","text":"The issue with Cloud Interconnect, Cloud Load Balancing, Cloud NAT, Cloud Networking, Cloud Router, Cloud VPN has been resolved for all affected users as of Tuesday, 2022-03-22 17:15 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-23T00:49:12+00:00","modified":"2022-03-23T00:49:12+00:00","when":"2022-03-23T00:49:12+00:00","text":"Summary: Customers connecting from Mexico and Central America may experience issues with accessing GCP services\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-03-22 18:30 US/Pacific.\nDiagnosis: Customers may experience delays in accessing GCP services from Mexico and Central America.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-03-23T00:15:29+00:00","modified":"2022-03-23T00:15:30+00:00","when":"2022-03-23T00:15:29+00:00","text":"Summary: Customers connecting from South-Central America may experience issues with accessing GCP services\nDescription: We are experiencing an issue with Cloud Interconnect, Cloud Load Balancing, Cloud NAT, Cloud Networking, Cloud Router, Cloud VPN beginning at Tuesday, 2022-03-22 16:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-03-22 17:50 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience delays in accessing GCP services from South-Central America.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-03-23T00:14:37+00:00","modified":"2022-03-23T00:14:43+00:00","when":"2022-03-23T00:14:37+00:00","text":"Summary: Customers connecting from South-Central America may experience issues with accessing GCP services\nDescription: We are experiencing an issue with Cloud Interconnect, Cloud Load Balancing, Cloud NAT, Cloud Networking, Cloud Router, Cloud VPN beginning at Tuesday, 2022-03-22 16:15 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-03-22 20:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers may experience delays in accessing GCP services from South-Central America.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-03-28T15:30:50+00:00","modified":"2022-03-28T15:30:50+00:00","when":"2022-03-28T15:30:50+00:00","text":"**Summary**\nOn Tuesday, 22 March 2022, Google Cloud Networking experienced congestion on network infrastructure to and from the network edge locations [1] in Queretaro, Mexico, for a duration of 1 hour and 45 minutes, following multiple fiber cuts between the United States and Mexico. Affected customers may have experienced high latency, high retransmits and elevated errors.\nWe would like to apologize for the length and severity of this incident. We are taking immediate steps to prevent a recurrence and improve reliability in the future.\n[1] - https://cloud.google.com/vpc/docs/edge-locations\n**Root Cause**\nGoogle’s wide-area network is primarily comprised of infrastructure owned and operated by Google, although some physical links use fiber infrastructure which is owned and operated by third parties. Google has multiple resilient fiber paths and network points of presence serving users in Mexico.\nMultiple simultaneous fiber cuts on diversely-routed paths, at the same time as a planned maintenance event on another diversely-routed path, resulted in a capacity shortfall in Google’s wide-area network between Queretaro, Mexico and the United States. This multiple failure event represents a rare case in which the resulting capacity shortfall was visible to Google's users.\nTraffic was subsequently redirected to alternate links; however, there was insufficient capacity to serve all the redirected traffic, resulting in packet loss for user-facing network traffic to Google from users in Mexico.\n**Remediation and Prevention**\nGoogle’s automated repair mechanism detected the congestion on Tuesday, 22 March 2022, at 15:42 US/Pacific and redirected the traffic through alternate edge locations. However, the alternate link did not have sufficient capacity to serve all the redirected traffic, resulting in packet loss. The congestion was cleared when traffic was manually routed around the failed links on Tuesday, 22 March 2022, at 17:15 US/Pacific.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. However, this incident was the result of multiple concurrent failures on links which are designed to provide resilience; such failures, whilst very rare, are expected at a low frequency. We are taking the following steps to ensure we respond quickly to similar events in the future:\n* Improving the reliability of tooling that manually reroutes traffic in extreme multiple-failure scenarios.\n* Improving the diagnostic systems that help Google's Cloud Networking teams decide how to deal with extreme multiple-failure scenarios.\nWe appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact**\nOn Tuesday, 22 March 2022 from 15:30 to 17:15 US/Pacific, customers reaching Google services from Mexico may have experienced network slowness and packet loss, and errors returned from our services. This may have resulted in customers not being able to access services running on Google Cloud and Workspace services including:\n* Google Meet\n* Gmail\n* Google Drive","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"},{"title":"Cloud NAT","id":"hCNpnTQHkUCCGxJy35Yq"}],"uri":"incidents/R9vAbtGnhzo6n48SnqTj","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"aA3kbJm5nwvVTKnYbrWM","number":"551739384385711524","begin":"2022-03-18T22:20:00+00:00","created":"2022-03-18T23:53:02+00:00","end":"2022-03-18T22:28:00+00:00","modified":"2022-03-29T03:49:06+00:00","external_desc":"Cloud Networking: Up to 40% packet loss between affected zones","updates":[{"created":"2022-03-29T03:49:06+00:00","modified":"2022-03-29T03:49:06+00:00","when":"2022-03-29T03:49:06+00:00","text":"**Summary**\nOn Friday, 18 March 2022 at 15:20 US/Pacific, Google Cloud Networking experienced intermittent packet loss for traffic between multiple cloud regions for a duration of 8 minutes. The issue was identified and mitigated automatically by 15:28 US/Pacific.\nWe understand this issue has affected our valued customers and users, and we apologize to those who were affected.\n**Root Cause**\nGoogle’s production backbone is a global network that enables connectivity for all user-facing traffic via Points of Presence (POPs) or internet exchanges.\nA rare hardware failure of a component on the fiber paths from one of the transpacific gateway campuses in Google’s production backbone led to a decrease in available network bandwidth between the gateway and multiple edge locations, causing packet loss.\n**Remediation and Prevention**\nGoogle’s automated repair mechanisms detected the decrease in available network bandwidth on Friday, 18 March 2022 at 15:20 US/Pacific and automatically routed the traffic through alternate links. The traffic rerouting completed on Friday, 18 March 2022 at 15:28 US/Pacific, mitigating the issue.\nWhile our automated mechanisms worked as intended and recovered the traffic without manual intervention, we understand that the scope of impact caused by this rare event affected our customers. We have been working on optimizing our global network to minimize the time spent automatically reconfiguring around failures like this (known as \"convergence time\"). While we have made progress, efforts to improve still further remain ongoing. We continue to ensure that the current technology is optimally configured to minimize the frequency and severity of these issues.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact**\nCustomers may have observed packet loss for traffic routed via transpacific links on Google's backbone. This could include traffic from or to any of the following cloud regions:\n* asia-east1\n* asia-northeast1\n* asia-northeast2\n* asia-northeast3\n* asia-southeast1\n* asia-southeast2\n* australia-southeast1\n* australia-southeast2\n* us-west1\n* us-central1\n* us-east1\n* us-east4\n* northamerica-northeast1\n* europe-west1\n* europe-west2\n* europe-west3\n* europe-west4\n* europe-west6\n* europe-west8\n* europe-west9\n* europe-central2\n* europe-north1","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-03-21T17:36:33+00:00","modified":"2022-03-23T16:13:24+00:00","when":"2022-03-21T17:36:33+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 18 March 2022 15:20\n**Incident End:** 18 March 2022 15:28\n**Duration:** 8 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking\n**Regions/Zones:**\nasia-east1, asia-northeast1, asia-northeast2, asia-northeast3, asia-southeast1, asia-southeast2,\naustrailia-southeast1, austrailia-southeast2\nus-west1, us-central1, us-east1, us-east4, northamerica-northeast1,\neurope-west1, europe-west2, europe-west3, europe-west4, europe-west6, europe-west8, europe-west9, europe-central2, europe-north1\n**Description:**\nGoogle Cloud Networking experienced intermittent packet loss for transit traffic in multiple cloud regions for 8 minutes. From preliminary analysis, the root cause is a hardware issue on a component of Google Cloud’s networking equipment. The issue was identified and mitigated automatically.\n**Customer Impact:**\nCustomers may have observed packet loss for transit traffic in the above mentioned cloud regions.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-03-19T00:01:18+00:00","modified":"2022-03-23T16:13:04+00:00","when":"2022-03-19T00:01:18+00:00","text":"We experienced an issue with Cloud Networking beginning at Friday, 2022-03-18 15:20 US/Pacific.\nSelf-diagnosis:\nCustomers may have experienced up to 40% packet loss between VMs in the following affected regions:\nasia-east1 asia-northeast1 asia-northeast2 asia-northeast3 asia-southeast1 asia-southeast2 austrailia-southeast1 austrailia-southeast2 us-west1 us-central1 us-east1 us-east4 northamerica-northeast1 europe-west1 europe-west2 europe-west3 europe-west4 europe-west6 europe-west8 europe-west9 europe-southwest1 europe-central2 europe-north1\nThe issue has been resolved for all affected projects as of Friday, 2022-03-18 15:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"created":"2022-03-18T23:53:02+00:00","modified":"2022-03-21T18:42:22+00:00","when":"2022-03-18T23:53:02+00:00","text":"Summary: Cloud Networking: Up to 40% packet loss between affected zones\nDescription: We are investigating a potential issue with Cloud Networking.\nWe will provide more information by Friday, 2022-03-18 17:25 US/Pacific.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"}]}],"most_recent_update":{"created":"2022-03-29T03:49:06+00:00","modified":"2022-03-29T03:49:06+00:00","when":"2022-03-29T03:49:06+00:00","text":"**Summary**\nOn Friday, 18 March 2022 at 15:20 US/Pacific, Google Cloud Networking experienced intermittent packet loss for traffic between multiple cloud regions for a duration of 8 minutes. The issue was identified and mitigated automatically by 15:28 US/Pacific.\nWe understand this issue has affected our valued customers and users, and we apologize to those who were affected.\n**Root Cause**\nGoogle’s production backbone is a global network that enables connectivity for all user-facing traffic via Points of Presence (POPs) or internet exchanges.\nA rare hardware failure of a component on the fiber paths from one of the transpacific gateway campuses in Google’s production backbone led to a decrease in available network bandwidth between the gateway and multiple edge locations, causing packet loss.\n**Remediation and Prevention**\nGoogle’s automated repair mechanisms detected the decrease in available network bandwidth on Friday, 18 March 2022 at 15:20 US/Pacific and automatically routed the traffic through alternate links. The traffic rerouting completed on Friday, 18 March 2022 at 15:28 US/Pacific, mitigating the issue.\nWhile our automated mechanisms worked as intended and recovered the traffic without manual intervention, we understand that the scope of impact caused by this rare event affected our customers. We have been working on optimizing our global network to minimize the time spent automatically reconfiguring around failures like this (known as \"convergence time\"). While we have made progress, efforts to improve still further remain ongoing. We continue to ensure that the current technology is optimally configured to minimize the frequency and severity of these issues.\nGoogle is committed to quickly and continually improving our technology and operations to prevent service disruptions. We appreciate your patience and apologize again for the impact to your organization. We thank you for your business.\n**Detailed Description of Impact**\nCustomers may have observed packet loss for traffic routed via transpacific links on Google's backbone. This could include traffic from or to any of the following cloud regions:\n* asia-east1\n* asia-northeast1\n* asia-northeast2\n* asia-northeast3\n* asia-southeast1\n* asia-southeast2\n* australia-southeast1\n* australia-southeast2\n* us-west1\n* us-central1\n* us-east1\n* us-east4\n* northamerica-northeast1\n* europe-west1\n* europe-west2\n* europe-west3\n* europe-west4\n* europe-west6\n* europe-west8\n* europe-west9\n* europe-central2\n* europe-north1","status":"AVAILABLE","affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"VNJxzcH58QmTt5H6pnT6","service_name":"Google Cloud Networking","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"}],"uri":"incidents/aA3kbJm5nwvVTKnYbrWM","currently_affected_locations":[],"previously_affected_locations":[{"title":"Taiwan (asia-east1)","id":"asia-east1"},{"title":"Tokyo (asia-northeast1)","id":"asia-northeast1"},{"title":"Osaka (asia-northeast2)","id":"asia-northeast2"},{"title":"Seoul (asia-northeast3)","id":"asia-northeast3"},{"title":"Singapore (asia-southeast1)","id":"asia-southeast1"},{"title":"Jakarta (asia-southeast2)","id":"asia-southeast2"},{"title":"Sydney (australia-southeast1)","id":"australia-southeast1"},{"title":"Melbourne (australia-southeast2)","id":"australia-southeast2"},{"title":"Warsaw (europe-central2)","id":"europe-central2"},{"title":"Finland (europe-north1)","id":"europe-north1"},{"title":"Belgium (europe-west1)","id":"europe-west1"},{"title":"London (europe-west2)","id":"europe-west2"},{"title":"Frankfurt (europe-west3)","id":"europe-west3"},{"title":"Netherlands (europe-west4)","id":"europe-west4"},{"title":"Zurich (europe-west6)","id":"europe-west6"},{"title":"Montréal (northamerica-northeast1)","id":"northamerica-northeast1"},{"title":"Iowa (us-central1)","id":"us-central1"},{"title":"South Carolina (us-east1)","id":"us-east1"},{"title":"Northern Virginia (us-east4)","id":"us-east4"},{"title":"Oregon (us-west1)","id":"us-west1"}]},{"id":"LuGcJVjNTeC5Sb9pSJ9o","number":"5384612291846020564","begin":"2022-03-08T18:07:00+00:00","created":"2022-03-08T20:36:16+00:00","end":"2022-03-08T20:42:00+00:00","modified":"2022-03-15T23:23:16+00:00","external_desc":"global: Elevated HTTP 500s errors for a small number of customers with load balancers on Traffic Director-managed backends","updates":[{"created":"2022-03-15T23:23:16+00:00","modified":"2022-03-15T23:23:16+00:00","when":"2022-03-15T23:23:16+00:00","text":"**INCIDENT REPORT**\n**Summary**\nOn Tuesday, 8 March 2022, Traffic Director users, who had service mesh with Traffic Director-managed backends, experienced elevated service errors for 2 hours and 35 minutes. To our Traffic Director customers who were impacted during this service disruption, we sincerely apologize. We have conducted an internal investigation and are taking steps to improve our service.\n**Root Cause**\nTraffic Director has a configuration pipeline that distributes customer configurations to Traffic Director infrastructure globally. The configuration pipeline has been undergoing a multi-stage, multi-year architectural rewrite to address a number of limitations in the previous architecture. One step to move to the new architecture has been to migrate existing Traffic Director configurations to a different format. This data migration has been ongoing since November 2021. The Traffic Director code was updated to handle both old and new formats of the configuration.\nThe data format migration was not fully completed; it encountered sporadic failures that were believed to only affect test configurations of new unreleased features. These failures masked the true completion state for full migration of all customer data. As a result, some customer data was an inconsistent state of old and new formats.\nOn 8 March 2022 at 10:05 PT, a change to the Traffic Director code that processes the configuration was updated. The code change assumed that the configuration data format migration was fully completed. In fact, the data migration had not completed. The failures were believed to only affect test configurations of new unreleased features, but they also affected a certain set of customer configurations that met all of the following criteria:\n1. The project was part of a Shared VPC.\n2. The project had at least one configuration migrated to the new format, which would be true if: a. The customer modified the project configuration after 12 November 2021; or b. The internal migration tool successfully processed the configuration.\n3. The project had at least one configuration that was not migrated to the new format: a. The customer had not modified the project since 12 November 2021; or b.The internal migration tool failed to process the configuration.\n4. The hostname of interest was part of the migrated configuration or the data plane requested configuration from the Traffic Director based on the migrated configuration.\nIt would inadvertently delete the configurations which caused the downstream clients to lose their programming and deconfigure the data plane.\nThe change was rolled back, the configurations were recovered, and service was restored for all users.\n**Remediation and Prevention**\nGoogle engineers were alerted to the issue through a customer support case on 8 March 2022 at 10:24 US/Pacific and immediately started an investigation.\nOnce the nature and scope of the issue became clear, Google engineers rolled back the Traffic Director configuration rollout to prevent additional customer impact.\nAt 12:42 US/Pacific, engineers forced a reprogramming of configurations, which mitigated the issue.\nWe sincerely apologize for the length and severity of this incident. Our team at Google is taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact**\nOn Tuesday, 8 March 2022 from 10:07 to 12:42 US/Pacific, customers using Traffic Director-managed backends experienced elevated service errors. Affected customers would have seen their Traffic Director managed clients deprogrammed as the configuration was removed. The effect of the deprogramming for users behind Google Cloud Load Balancers (GCLB) would have been visible as 500 errors. Some affected customers were able to mitigate the issue for themselves through the workaround of moving to backends that were not Traffic Director managed.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-09T17:25:35+00:00","modified":"2022-03-11T00:21:25+00:00","when":"2022-03-09T17:25:35+00:00","text":"Mini Incident Report (Full Incident Report To Follow)\nWe apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 08 March 2022 10:07\n**Incident End:** 08 March 2022 12:42\n**Duration:** 2 hours, 35 minutes\n**Affected Services and Features:**\nTraffic Director\n**Regions/Zones:** Global\n**Description:**\nTraffic Director customers who used shared Virtual Private Cloud (VPC) experienced elevated service errors for 2 hours and 35 minutes, due to local proxies, gRPC clients, and other services being unable to retrieve their xDS configurations. From preliminary analysis, the root cause of the issue was related to a bug introduced in a recent Traffic Director programming pipeline rollout.\n**Customer Impact:**\nAffected customers would have seen their Traffic Director-managed clients deprogrammed as the configuration was removed. The effect of the deprogramming for users behind GCLB would have been visible as 500 errors. Some affected customers were able to mitigate the issue for themselves through the workaround of moving to backends that were not Traffic Director-managed.\n**Additional details:**\nOur engineers rolled back the Traffic Director configuration rollout and forced a reprogramming of configurations, which mitigated the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-08T22:23:50+00:00","modified":"2022-03-08T22:23:57+00:00","when":"2022-03-08T22:23:50+00:00","text":"The issue with Traffic Director has been confirmed to be caused by a recent release; the release has been rolled back and customers can now start using Traffic Director. We have identified a probable root cause and will be publishing an Incident Report within the next several days.\nThe issue with Cloud Load Balancing, Cloud Networking, Traffic Director has been resolved for all affected projects as of Tuesday, 2022-03-08 12:42 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-03-08T21:21:27+00:00","modified":"2022-03-08T21:21:31+00:00","when":"2022-03-08T21:21:27+00:00","text":"Summary: global: Elevated HTTP 500s errors for a small number of customers with load balancers on Traffic Director-managed backends\nDescription: We believe the issue with Traffic Director is mitigated. We do not have an ETA for full resolution at this point. Customers should leave the workaround in place, as the issue could reoccur until the root cause has been determined.\nWe believe the issue is limited to Traffic Director users and does not affect all of Cloud Load Balancing or Cloud Networking.\nWe will provide an update by Tuesday, 2022-03-08 14:30 US/Pacific with current details.\nDiagnosis: Affected customers will see elevated HTTP 500s errors on load balancers with Traffic Director managed customer-run backends. Thus far, impact has only been observed in us-east1, but customers with multi-regional Traffic Director deployments could be impacted in more regions.\nWorkaround: Customers with Traffic Director managed backends should consider moving to backends that are not Traffic Director-managed.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-03-08T20:41:41+00:00","modified":"2022-03-08T20:41:44+00:00","when":"2022-03-08T20:41:41+00:00","text":"Summary: global: Elevated HTTP 500s errors for a small number of customers with load balancers on Traffic Director-managed Envoy backends\nDescription: We are experiencing an intermittent issue with Cloud Load Balancing, Cloud Networking, Traffic Director beginning at Tuesday, 2022-03-08 10:07:51 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-03-08 14:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers will see elevated HTTP 500s errors on load balancers with Traffic Director managed customer-run Envoy backends. Thus far, impact has only been observed in us-east1, but customers with multi-regional Traffic Director deployments could be impacted in more regions.\nWorkaround: Customers with Traffic Director managing their envoys should consider moving to backends that are not Traffic Director-managed.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-03-08T20:36:14+00:00","modified":"2022-03-08T20:36:18+00:00","when":"2022-03-08T20:36:14+00:00","text":"Summary: global: Elevated HTTP 500s errors for a small number of customers with load balancers on Traffic Director-managed Envoy backends\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point, but a customer self-mitigation is available.\nWe will provide more information by Tuesday, 2022-03-08 14:00 US/Pacific.\nDiagnosis: Affected customers will see elevated HTTP 500s errors on load balancers with Traffic Director managed customer-run Envoy backends. Thus far, impact has only been observed in us-east1, but customers with multi-regional Traffic Director deployments could be impacted in more regions.\nWorkaround: Customers with Traffic Director managing their envoys should consider moving to backends that are not Traffic Director-managed.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-03-15T23:23:16+00:00","modified":"2022-03-15T23:23:16+00:00","when":"2022-03-15T23:23:16+00:00","text":"**INCIDENT REPORT**\n**Summary**\nOn Tuesday, 8 March 2022, Traffic Director users, who had service mesh with Traffic Director-managed backends, experienced elevated service errors for 2 hours and 35 minutes. To our Traffic Director customers who were impacted during this service disruption, we sincerely apologize. We have conducted an internal investigation and are taking steps to improve our service.\n**Root Cause**\nTraffic Director has a configuration pipeline that distributes customer configurations to Traffic Director infrastructure globally. The configuration pipeline has been undergoing a multi-stage, multi-year architectural rewrite to address a number of limitations in the previous architecture. One step to move to the new architecture has been to migrate existing Traffic Director configurations to a different format. This data migration has been ongoing since November 2021. The Traffic Director code was updated to handle both old and new formats of the configuration.\nThe data format migration was not fully completed; it encountered sporadic failures that were believed to only affect test configurations of new unreleased features. These failures masked the true completion state for full migration of all customer data. As a result, some customer data was an inconsistent state of old and new formats.\nOn 8 March 2022 at 10:05 PT, a change to the Traffic Director code that processes the configuration was updated. The code change assumed that the configuration data format migration was fully completed. In fact, the data migration had not completed. The failures were believed to only affect test configurations of new unreleased features, but they also affected a certain set of customer configurations that met all of the following criteria:\n1. The project was part of a Shared VPC.\n2. The project had at least one configuration migrated to the new format, which would be true if: a. The customer modified the project configuration after 12 November 2021; or b. The internal migration tool successfully processed the configuration.\n3. The project had at least one configuration that was not migrated to the new format: a. The customer had not modified the project since 12 November 2021; or b.The internal migration tool failed to process the configuration.\n4. The hostname of interest was part of the migrated configuration or the data plane requested configuration from the Traffic Director based on the migrated configuration.\nIt would inadvertently delete the configurations which caused the downstream clients to lose their programming and deconfigure the data plane.\nThe change was rolled back, the configurations were recovered, and service was restored for all users.\n**Remediation and Prevention**\nGoogle engineers were alerted to the issue through a customer support case on 8 March 2022 at 10:24 US/Pacific and immediately started an investigation.\nOnce the nature and scope of the issue became clear, Google engineers rolled back the Traffic Director configuration rollout to prevent additional customer impact.\nAt 12:42 US/Pacific, engineers forced a reprogramming of configurations, which mitigated the issue.\nWe sincerely apologize for the length and severity of this incident. Our team at Google is taking immediate steps to prevent a recurrence and improve reliability in the future.\n**Detailed Description of Impact**\nOn Tuesday, 8 March 2022 from 10:07 to 12:42 US/Pacific, customers using Traffic Director-managed backends experienced elevated service errors. Affected customers would have seen their Traffic Director managed clients deprogrammed as the configuration was removed. The effect of the deprogramming for users behind Google Cloud Load Balancers (GCLB) would have been visible as 500 errors. Some affected customers were able to mitigate the issue for themselves through the workaround of moving to backends that were not Traffic Director managed.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Traffic Director","id":"NroZwL2UMMionesUGP87"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"}],"uri":"incidents/LuGcJVjNTeC5Sb9pSJ9o","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"Hko5cWSXxGSsxfiSpg4n","number":"6491961050454270833","begin":"2022-02-22T05:45:00+00:00","created":"2022-02-25T17:57:41+00:00","end":"2022-02-25T20:22:00+00:00","modified":"2022-02-25T23:21:04+00:00","external_desc":"BigQuery S3 Data Transfer Service experiencing issues in us-multiregion, asia-noutheast1 and asia-southeast1","updates":[{"created":"2022-02-25T23:20:38+00:00","modified":"2022-02-25T23:20:38+00:00","when":"2022-02-25T23:20:38+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 21 February 2022 21:45\n**Incident End:** 25 February 2022 12:22\n**Duration:** 3 days, 14 hours, 37 minutes\n**Affected Services and Features:**\nGoogle BigQuery - Data Transfer Service\n**Regions/Zones:** Global\n**Description:**\nGoogle BigQuery S3 Data Transfer Service experienced table validation failures globally, with the majority of impact observed in us-multiregion, asia-northeast1, and asia-southeast1. From preliminary analysis, the root cause of the issue was a rollout that started on 21 February 2022 at 01:00 US/Pacific. A rollback was initiated on 25 February 2022 at 08:29 to mitigate the issue in the most heavily affected regions (us-multiregion, asia-northeast1, and asia-southeast1) which was completed on 25 February 2022 12:01.\n**Customer Impact:**\n* Transfer Runs for Google BigQuery S3 Data Transfer Service [1] will fail with an INVALID_ARGUMENT error if the following conditions are met: * The destination table in the Transfer Configuration contains a runtime parameter\n[2]. * The rollback has not completed in the given region. Regions where we identified impact have been prioritized and rolled back already.\n[1] - https://cloud.google.com/bigquery-transfer/docs/s3-transfer-intro\n[2] - https://cloud.google.com/bigquery-transfer/docs/s3-transfer-parameters\n**Additional Details:**\n* The rollback should complete across all regions by 01 March 2022.\n* Once the rollback completes, affected customers can retry the failed Transfer Runs to load any missed files.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-25T20:04:03+00:00","modified":"2022-02-25T20:04:05+00:00","when":"2022-02-25T20:04:03+00:00","text":"The issue with Google BigQuery has been resolved for all affected users as of Friday, 2022-02-25 12:03 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-25T17:57:41+00:00","modified":"2022-02-25T17:57:41+00:00","when":"2022-02-25T17:57:41+00:00","text":"Summary: BigQuery S3 Data Transfer Service experiencing issues in us-multiregion, asia-noutheast1 and asia-southeast1\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by the following dates/times:\nUS-Multiregion - Friday, 2022-02-25 12:00 US/Pacific.\nAsia-southeast1 and Asia-northeast1 - Friday, 2022-02-25 14:00 US/Pacific.\nOther regions potentially impacted - Tuesday, 2022-03-01 EOB US/Pacific.\nWe will provide more information by Friday, 2022-02-25 12:00 US/Pacific.\nDiagnosis: S3 transfers may fail table validation when table name contains template argument (e.g., \"{run_time}\")\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-25T23:20:38+00:00","modified":"2022-02-25T23:20:38+00:00","when":"2022-02-25T23:20:38+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 21 February 2022 21:45\n**Incident End:** 25 February 2022 12:22\n**Duration:** 3 days, 14 hours, 37 minutes\n**Affected Services and Features:**\nGoogle BigQuery - Data Transfer Service\n**Regions/Zones:** Global\n**Description:**\nGoogle BigQuery S3 Data Transfer Service experienced table validation failures globally, with the majority of impact observed in us-multiregion, asia-northeast1, and asia-southeast1. From preliminary analysis, the root cause of the issue was a rollout that started on 21 February 2022 at 01:00 US/Pacific. A rollback was initiated on 25 February 2022 at 08:29 to mitigate the issue in the most heavily affected regions (us-multiregion, asia-northeast1, and asia-southeast1) which was completed on 25 February 2022 12:01.\n**Customer Impact:**\n* Transfer Runs for Google BigQuery S3 Data Transfer Service [1] will fail with an INVALID_ARGUMENT error if the following conditions are met: * The destination table in the Transfer Configuration contains a runtime parameter\n[2]. * The rollback has not completed in the given region. Regions where we identified impact have been prioritized and rolled back already.\n[1] - https://cloud.google.com/bigquery-transfer/docs/s3-transfer-intro\n[2] - https://cloud.google.com/bigquery-transfer/docs/s3-transfer-parameters\n**Additional Details:**\n* The rollback should complete across all regions by 01 March 2022.\n* Once the rollback completes, affected customers can retry the failed Transfer Runs to load any missed files.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/Hko5cWSXxGSsxfiSpg4n","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"qfgJm8m4WPn2Ej2Z7vc2","number":"714206970471699851","begin":"2022-02-19T17:01:00+00:00","created":"2022-02-23T19:18:53+00:00","end":"2022-02-25T05:00:00+00:00","modified":"2022-02-25T18:42:09+00:00","external_desc":"Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used","updates":[{"created":"2022-02-25T18:41:39+00:00","modified":"2022-02-25T18:41:39+00:00","when":"2022-02-25T18:41:39+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 19 February 2022 09:01\n**Incident End:** 24 February 2022 20:48\n**Duration:** 5 days, 11 hours, 47 minutes\n**Affected Services and Features:**\nGoogle Cloud Run - .NET application failures using HTTP/2 or gRPC\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Run services using .NET HTTP/2 or gRPC experienced elevated errors. From preliminary analysis, the root cause of the issue is a change triggered by a recent rollout.\n**Customer Impact:**\nAffected .Net services observed \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request was made using HTTP/2 or gRPC.\n**Additional Details:**\nThe ability to disable \"preserve_downstream_scheme\" was removed upstream in Envoy proxy [1] which led to an unintentional breaking change in Cloud Run. The breaking change introduces an incompatibility with .NET default enforcement between incoming transport-layer security and “:scheme” header (see details [2] ). The Cloud Run and Envoy teams at Google were able to mitigate the issue once identified, and have taken steps to limit and better manage such changes in the future.\nThe issue was fully resolved on 24 February 2022 at 20:48 US/Pacific once a rollback of the change was completed.\n* [1] - https://www.envoyproxy.io/docs/envoy/latest/version_history/current#removed-config-or-runtime\n* [2] - https://github.com/dotnet/aspnetcore/issues/30532","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-25T05:00:47+00:00","modified":"2022-02-25T05:00:47+00:00","when":"2022-02-25T05:00:47+00:00","text":"The issue with Cloud Run has been resolved for all affected users as of Thursday, 2022-02-24 20:57 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-25T02:58:15+00:00","modified":"2022-02-25T02:58:16+00:00","when":"2022-02-25T02:58:15+00:00","text":"Summary: Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-02-24 US/Pacific.\nWe will provide more information by Thursday, 2022-02-24 22:30 US/Pacific.\nDiagnosis: Affected customers will see \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request is made using HTTP/2 or gRPC.\nWorkaround: If using .NET 6, settings KestrelServerOptions.AllowAlternateSchemes to true will avoid the issue:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.server.kestrel.core.kestrelserveroptions.allowalternateschemes?view=aspnetcore-6.0","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-25T00:56:56+00:00","modified":"2022-02-25T00:56:57+00:00","when":"2022-02-25T00:56:56+00:00","text":"Summary: Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-02-24 US/Pacific.\nWe will provide more information by Thursday, 2022-02-24 21:00 US/Pacific.\nDiagnosis: Affected customers will see \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request is made using HTTP/2 or gRPC.\nWorkaround: If using .NET 6, settings KestrelServerOptions.AllowAlternateSchemes to true will avoid the issue:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.server.kestrel.core.kestrelserveroptions.allowalternateschemes?view=aspnetcore-6.0","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-24T21:06:18+00:00","modified":"2022-02-24T21:06:19+00:00","when":"2022-02-24T21:06:18+00:00","text":"Summary: Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-02-24 US/Pacific.\nWe will provide more information by Thursday, 2022-02-24 18:00 US/Pacific.\nDiagnosis: Affected customers will see \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request is made using HTTP/2 or gRPC.\nWorkaround: If using .NET 6, settings KestrelServerOptions.AllowAlternateSchemes to true will avoid the issue:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.server.kestrel.core.kestrelserveroptions.allowalternateschemes?view=aspnetcore-6.0","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-23T21:46:33+00:00","modified":"2022-02-23T21:46:35+00:00","when":"2022-02-23T21:46:33+00:00","text":"Summary: Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete by Thursday, 2022-02-24 US/Pacific.\nWe will provide more information by Thursday, 2022-02-24 14:00 US/Pacific.\nDiagnosis: Affected customers will see \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request is made using HTTP/2 or gRPC.\nWorkaround: If using .NET 6, settings KestrelServerOptions.AllowAlternateSchemes to true will avoid the issue:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.server.kestrel.core.kestrelserveroptions.allowalternateschemes?view=aspnetcore-6.0","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-23T19:18:53+00:00","modified":"2022-02-23T19:18:55+00:00","when":"2022-02-23T19:18:53+00:00","text":"Summary: Global: Requests to .NET Cloud Run applications fail if HTTP/2 or gRPC is used\nDescription: We are experiencing an issue with Cloud Run beginning at Thursday, 2022-02-10 18:50 US/Pacific.\nMitigation work is currently underway by our engineering team. We do not have an ETA for mitigation at this point.\nWe apologize to all who are affected by the disruption.\nWe will provide an update by Wednesday, 2022-02-23 15:30 US/Pacific with current details.\nDiagnosis: Affected customers will see \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request is made using HTTP/2 or gRPC.\nWorkaround: If using .NET 6, settings KestrelServerOptions.AllowAlternateSchemes to true will avoid the issue:\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.server.kestrel.core.kestrelserveroptions.allowalternateschemes?view=aspnetcore-6.0","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-25T18:41:39+00:00","modified":"2022-02-25T18:41:39+00:00","when":"2022-02-25T18:41:39+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 19 February 2022 09:01\n**Incident End:** 24 February 2022 20:48\n**Duration:** 5 days, 11 hours, 47 minutes\n**Affected Services and Features:**\nGoogle Cloud Run - .NET application failures using HTTP/2 or gRPC\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Run services using .NET HTTP/2 or gRPC experienced elevated errors. From preliminary analysis, the root cause of the issue is a change triggered by a recent rollout.\n**Customer Impact:**\nAffected .Net services observed \"upstream connect error or disconnect/reset before headers. reset reason: remote reset\" when a request was made using HTTP/2 or gRPC.\n**Additional Details:**\nThe ability to disable \"preserve_downstream_scheme\" was removed upstream in Envoy proxy [1] which led to an unintentional breaking change in Cloud Run. The breaking change introduces an incompatibility with .NET default enforcement between incoming transport-layer security and “:scheme” header (see details [2] ). The Cloud Run and Envoy teams at Google were able to mitigate the issue once identified, and have taken steps to limit and better manage such changes in the future.\nThe issue was fully resolved on 24 February 2022 at 20:48 US/Pacific once a rollback of the change was completed.\n* [1] - https://www.envoyproxy.io/docs/envoy/latest/version_history/current#removed-config-or-runtime\n* [2] - https://github.com/dotnet/aspnetcore/issues/30532","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9D7d2iNBQWN24zc1VamE","service_name":"Cloud Run","affected_products":[{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"}],"uri":"incidents/qfgJm8m4WPn2Ej2Z7vc2","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"MqpDy4VdUKuQkw1GXPTo","number":"17820096163428229993","begin":"2022-02-15T17:14:00+00:00","created":"2022-02-15T17:49:25+00:00","end":"2022-02-19T18:46:00+00:00","modified":"2022-02-24T02:13:58+00:00","external_desc":"Global: Cloud SQL PostgreSQL password validation errors with high connection load.","updates":[{"created":"2022-02-24T02:10:59+00:00","modified":"2022-02-24T02:13:29+00:00","when":"2022-02-24T02:10:59+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 15 February 2022 09:14\n**Incident End:** 19 February 2022 10:46\n**Duration:** 4 days, 1 hour, 32 minutes\n**Affected Services and Features:**\nCloudSQL- PostgreSQL connection errors\n**Regions/Zones:** Global\n**Description:**\nApplications using close to maximum number of connections, intermittently failed to connect to database instances. The connection error happened because Cloud SQL for PostgreSQL was using additional connections for internal use.\n**Customer Impact:**\nCustomers impacted by this issue would have seen errors when establishing new connections to Cloud SQL for PostgreSQL instances. The error message would have been: FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already :: proc.c:347\n**Additional details:**\nThe issue was fully resolved on 19 February 2022 at 10:46 US/Pacific. In addition, the following prevention actions were completed:\n* For impacted instances, Cloud SQL has disabled the use of additional connections.\n* The maintenance rollout was canceled to prevent further instances from being affected.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-22T22:45:09+00:00","modified":"2022-02-22T22:45:11+00:00","when":"2022-02-22T22:45:09+00:00","text":"The issue with Cloud SQL has been resolved for all affected instances as of Tuesday, 2022-02-22 14:30 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-22T19:22:35+00:00","modified":"2022-02-22T19:22:41+00:00","when":"2022-02-22T19:22:35+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load.\nDescription: Engineering team is currently working on mitigating the remainder of the affected instances (ETA EOB Feb 22, 2022).\nAffected customer instances have been mitigated and will not observe the password validation errors. If you are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe will provide an update by Tuesday, 2022-02-22 19:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections to instances with high connection load - \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-18T19:42:10+00:00","modified":"2022-02-18T19:42:17+00:00","when":"2022-02-18T19:42:10+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load.\nDescription: Engineering team is currently working on mitigating the non-HA instances (ETA Feb 22, 2022). The mitigation efforts are still underway for HA instances which continue to be affected.\nAffected customer instances have been mitigated and will not observe the password validation errors. If you are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe will provide an update by Tuesday, 2022-02-22 12:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections to instances with high connection load - \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-17T22:31:16+00:00","modified":"2022-02-17T22:31:22+00:00","when":"2022-02-17T22:31:16+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load.\nDescription: Engineering team continues to work on deploying the fix.\nAffected customer instances have been mitigated and will not observe the password validation errors. If you are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe will provide an update by Friday, 2022-02-18 12:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections to instances with high connection load - \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-17T19:30:36+00:00","modified":"2022-02-17T19:30:43+00:00","when":"2022-02-17T19:30:36+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load.\nDescription: Engineering team continues to work on deploying the fix.\nAffected customer instances have been mitigated and will not observe the password validation errors.\nWe will provide an update by Thursday, 2022-02-17 17:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-16T21:08:47+00:00","modified":"2022-02-16T21:08:49+00:00","when":"2022-02-16T21:08:47+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load.\nDescription: Affected customer instances have been mitigated and will not observe the password validation errors.\nEngineering team is currently working on rolling out a fix. ETA for rollout is unknown at this time.\nWe will provide an update by Thursday, 2022-02-17 12:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-16T18:11:14+00:00","modified":"2022-02-16T18:11:16+00:00","when":"2022-02-16T18:11:14+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load\nDescription: Engineering team is currently working on mitigation of the issue.\nWe will provide an update by Wednesday, 2022-02-16 14:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-16T14:22:56+00:00","modified":"2022-02-16T14:23:05+00:00","when":"2022-02-16T14:22:56+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load\nDescription: We believe the issue with FEATURE is partially resolved. We are currently performing checks to see if any instances have been missed.\nFull resolution is expected to complete by Wednesday, 2022-02-16 10:00 US/Pacific.\nWe will provide an update by Wednesday, 2022-02-16 10:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-16T03:28:30+00:00","modified":"2022-02-16T03:28:31+00:00","when":"2022-02-16T03:28:30+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load\nDescription: We believe the issue with Cloud SQL is partially resolved.\nFull resolution is expected to complete by Wednesday, 2022-02-16 06:30 US/Pacific.\nWe will provide an update by Wednesday, 2022-02-16 06:30 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-15T23:18:57+00:00","modified":"2022-02-15T23:18:59+00:00","when":"2022-02-15T23:18:57+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load\nDescription: Our engineering team continues to work on the mitigation of the issue.\nWe will provide more information by Tuesday, 2022-02-15 19:30 US/Pacific.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection load.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-15T20:44:48+00:00","modified":"2022-02-15T20:44:50+00:00","when":"2022-02-15T20:44:48+00:00","text":"Summary: Global: Cloud SQL PostgreSQL password validation errors with high connection load\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-02-15 15:30 US/Pacific.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection rate.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-15T19:26:59+00:00","modified":"2022-02-15T19:27:02+00:00","when":"2022-02-15T19:26:59+00:00","text":"Summary: Global: Cloud SQL Postgres instances experiences password validation error on some connections.\nDescription: We are experiencing an issue with Cloud SQL beginning at Tuesday, 2022-01-26 11:24 US/Pacific.\nOur engineering team continues to investigate the issue, and after further investigation it was determined that the trigger conditions are not actually due to \u003e50 QPS.\nWe will provide an update by Tuesday, 2022-02-15 13:00 US/Pacific with current details.\nDiagnosis: Affected customers may see a password validation error message when establishing new connections: \"FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already...\".\nWorkaround: Users can enable connection pooling to reduce the connection rate.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-15T17:49:24+00:00","modified":"2022-02-15T17:49:26+00:00","when":"2022-02-15T17:49:24+00:00","text":"Summary: Global: Some Cloud SQL Postgres instances have the following flag set and are unable to disable: cloudsql.enable_password_validation=on\nDescription: All Postgres instances connections have been rate-limited to 50/sec to prevent triggering the issue.\nCustomers may consider using the workaround to pool connections to avoid hitting the temporarily rate limit.\nWe will provide more information by Tuesday, 2022-02-15 12:00 US/Pacific.\nDiagnosis: Affected postgres instances from a recent release have the following flag set and are unable to remove or disable this flag: cloudsql.enable_password_validation=on. This flag does not appear in Cloud Console, and attempting to disable flag via gcloud returns error where the flag is not recognized or supported. Password validation occurs on every new client connection but is limited to 50 QPS, and thus higher rates will return errors.\nWorkaround: Users can enable connection pooling to avoid connecting more than 50 times a second.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-24T02:10:59+00:00","modified":"2022-02-24T02:13:29+00:00","when":"2022-02-24T02:10:59+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 15 February 2022 09:14\n**Incident End:** 19 February 2022 10:46\n**Duration:** 4 days, 1 hour, 32 minutes\n**Affected Services and Features:**\nCloudSQL- PostgreSQL connection errors\n**Regions/Zones:** Global\n**Description:**\nApplications using close to maximum number of connections, intermittently failed to connect to database instances. The connection error happened because Cloud SQL for PostgreSQL was using additional connections for internal use.\n**Customer Impact:**\nCustomers impacted by this issue would have seen errors when establishing new connections to Cloud SQL for PostgreSQL instances. The error message would have been: FATAL: pwd_validation: Failed to connect to admin database, error: FATAL: sorry, too many clients already :: proc.c:347\n**Additional details:**\nThe issue was fully resolved on 19 February 2022 at 10:46 US/Pacific. In addition, the following prevention actions were completed:\n* For impacted instances, Cloud SQL has disabled the use of additional connections.\n* The maintenance rollout was canceled to prevent further instances from being affected.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/MqpDy4VdUKuQkw1GXPTo","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"oAxmtvN5RuKAYHMG4ToR","number":"17366090916923453747","begin":"2022-02-15T13:41:00+00:00","created":"2022-02-17T13:42:31+00:00","end":"2022-02-15T17:07:00+00:00","modified":"2022-02-17T13:45:08+00:00","external_desc":"We experienced an intermittent issue with Cloud Networking.","updates":[{"created":"2022-02-17T13:44:45+00:00","modified":"2022-02-17T13:44:45+00:00","when":"2022-02-17T13:44:45+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 15 February 2022 05:41\n**Incident End:** 15 February 2022 09:07\n**Duration:** 3 hours, 26 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking - Global External HTTPS load balancer SSL certificates\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced issues with global external HTTPS load balancer SSL certificate configuration updates for a duration of 3 hours, 26 minutes. A configuration change caused a large amount of data to be unintentionally rewritten, and the component responsible for processing the updated data was overwhelmed.\n**Customer Impact:**\nCustomers experienced delays with initial provisioning of managed SSL certificates.\nCustomers experienced issues with programming of newly uploaded, updated, or deleted SSL certificates that were not applied to the dataplane.\n**Additional details:**\nThe issue was fully resolved on 15 February 2022 at 09:07 US/Pacific after:\nOperators modified the configuration push system to handle the increase in data volume.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-17T13:42:32+00:00","modified":"2022-02-17T13:42:32+00:00","when":"2022-02-17T13:42:32+00:00","text":"We experienced an intermittent issue with Cloud Networking beginning at Tuesday, 2022-02-15 05:41 US/Pacific.\nDiagnosis: Affected customers may have experienced delays when provisioning new or updated certificates.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-17T13:44:45+00:00","modified":"2022-02-17T13:44:45+00:00","when":"2022-02-17T13:44:45+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 15 February 2022 05:41\n**Incident End:** 15 February 2022 09:07\n**Duration:** 3 hours, 26 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking - Global External HTTPS load balancer SSL certificates\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced issues with global external HTTPS load balancer SSL certificate configuration updates for a duration of 3 hours, 26 minutes. A configuration change caused a large amount of data to be unintentionally rewritten, and the component responsible for processing the updated data was overwhelmed.\n**Customer Impact:**\nCustomers experienced delays with initial provisioning of managed SSL certificates.\nCustomers experienced issues with programming of newly uploaded, updated, or deleted SSL certificates that were not applied to the dataplane.\n**Additional details:**\nThe issue was fully resolved on 15 February 2022 at 09:07 US/Pacific after:\nOperators modified the configuration push system to handle the increase in data volume.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/oAxmtvN5RuKAYHMG4ToR","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"xtW5y29FeYgjfLW3AwKY","number":"12290226274247929876","begin":"2022-02-11T20:00:00+00:00","created":"2022-02-11T23:18:10+00:00","end":"2022-02-12T02:26:00+00:00","modified":"2022-02-15T15:27:38+00:00","external_desc":"Global: Delays provisioning SSL certificates for HTTPS load balancers","updates":[{"created":"2022-02-15T04:08:06+00:00","modified":"2022-02-15T15:27:38+00:00","when":"2022-02-15T04:08:06+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 11 February 2022 12:00\n**Incident End:** 11 February 2022 18:26\n**Duration:** 6 hours, 26 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking - Global External HTTPS load balancer SSL certificates\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced issues with global external HTTPS load balancer SSL certificate configuration updates for a duration of 6 hours, 26 minutes. This was triggered by a component rollback, which tripped a safety check that prevented changes from taking effect. The backlog required further intervention from operators to clear; when it did the issue was mitigated.\n**Customer Impact:**\n- Customers experienced delays with initial provisioning of managed SSL certificates.\n- Customers experienced issues with programming of newly uploaded, updated, or deleted SSL certificates that were not applied to the dataplane.\n**Additional details:**\nThe issue was fully resolved on 11 February 2022 at 18:26 US/Pacific after:\nModifying the safety check.\nSupervising the pipeline until it successfully completed, removing the delta and resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-12T02:32:18+00:00","modified":"2022-02-12T02:32:21+00:00","when":"2022-02-12T02:32:18+00:00","text":"The issue with Cloud Networking has been resolved for all affected users as of Friday, 2022-02-11 18:26 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-12T01:54:11+00:00","modified":"2022-02-12T01:54:13+00:00","when":"2022-02-12T01:54:11+00:00","text":"Summary: Global: Delays provisioning SSL certificates for HTTPS load balancers\nDescription: Mitigation work is still underway by our engineering team. A configuration change is rolling out as a potential fix.\nWe will provide more information by Friday, 2022-02-11 20:30 US/Pacific.\nDiagnosis: Affected customers may experience delays when provisioning new or updated certificates.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-11T23:18:04+00:00","modified":"2022-02-11T23:18:11+00:00","when":"2022-02-11T23:18:04+00:00","text":"Summary: Global: Delays provisioning SSL certificates for HTTPS load balancers\nDescription: We are experiencing an intermittent issue with Cloud Networking beginning at Friday, 2022-02-11 12:00 US/Pacific.\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point. We apologize to all who are affected by the disruption\nWe will provide more information by Friday, 2022-02-11 18:00 US/Pacific.\nDiagnosis: Affected customers may experience delays when provisioning new or updated certificates.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-15T04:08:06+00:00","modified":"2022-02-15T15:27:38+00:00","when":"2022-02-15T04:08:06+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 11 February 2022 12:00\n**Incident End:** 11 February 2022 18:26\n**Duration:** 6 hours, 26 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking - Global External HTTPS load balancer SSL certificates\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Networking experienced issues with global external HTTPS load balancer SSL certificate configuration updates for a duration of 6 hours, 26 minutes. This was triggered by a component rollback, which tripped a safety check that prevented changes from taking effect. The backlog required further intervention from operators to clear; when it did the issue was mitigated.\n**Customer Impact:**\n- Customers experienced delays with initial provisioning of managed SSL certificates.\n- Customers experienced issues with programming of newly uploaded, updated, or deleted SSL certificates that were not applied to the dataplane.\n**Additional details:**\nThe issue was fully resolved on 11 February 2022 at 18:26 US/Pacific after:\nModifying the safety check.\nSupervising the pipeline until it successfully completed, removing the delta and resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/xtW5y29FeYgjfLW3AwKY","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"46bP9UWxaLXHyCUQdjPR","number":"6197302924433084519","begin":"2022-02-10T08:32:00+00:00","created":"2022-02-10T10:01:11+00:00","end":"2022-02-10T14:34:00+00:00","modified":"2022-02-10T22:01:44+00:00","external_desc":"Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST","updates":[{"created":"2022-02-10T22:01:11+00:00","modified":"2022-02-10T22:01:11+00:00","when":"2022-02-10T22:01:11+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 10 February 2022 00:32\n**Incident End:** 10 February 2022 06:34\n**Duration:** 6 hours, 32 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking, Google App Engine, Google Cloud Storage, Google Compute Engine\n**Regions/Zones:** asia-south1\n**Description:**\nGoogle Cloud Networking experienced elevated latency in the asia-south1 region for 6 hours and 32 minutes. From preliminary analysis, the root cause of the issue was increased memory utilization related to a query workload.\n**Customer Impact:**\nCustomers may have experienced elevated latency in the asia-south1 region between Google Cloud Load Balancers (GCLB) and downstream services including Google App Engine, Google Cloud Storage, and Google Compute Engine.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-10T14:18:36+00:00","modified":"2022-02-10T14:18:37+00:00","when":"2022-02-10T14:18:36+00:00","text":"The issue with Google App Engine, Google Cloud Storage, Cloud Networking, Google Compute Engine has been resolved for all affected users as of Thursday, 2022-02-10 06:18 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-10T11:58:16+00:00","modified":"2022-02-10T11:58:17+00:00","when":"2022-02-10T11:58:16+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Thursday, 2022-02-10 06:30 US/Pacific.\nDiagnosis: Customer may see - increased latency.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T11:27:42+00:00","modified":"2022-02-10T11:27:42+00:00","when":"2022-02-10T11:27:42+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:32 US/Pacific\nOur engineering team is narrowing down the root cause and continues to investigate. Customer may see various error in the APAC region.\nWe will provide an update by Thursday, 2022-02-10 04:00 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times, increased latency.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T11:05:27+00:00","modified":"2022-02-10T11:05:28+00:00","when":"2022-02-10T11:05:27+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:32 US/Pacific\nOur engineering team is narrowing down the root cause and continues to investigate. Customer may see various error in the APAC region.\nWe will provide an update by Thursday, 2022-02-10 03:30 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times, increased latency.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:59:22+00:00","modified":"2022-02-10T10:59:23+00:00","when":"2022-02-10T10:59:22+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:32 US/Pacific\nOur engineering team continues to investigate the issue. Customer may see various error in the APAC region\nWe will provide an update by Thursday, 2022-02-10 03:30 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:26:08+00:00","modified":"2022-02-10T10:26:08+00:00","when":"2022-02-10T10:26:08+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:32 US/Pacific\nOur engineering team continues to investigate the issue. Customer may see various error in the APAC region\nWe will provide an update by Thursday, 2022-02-10 03:00 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:15:42+00:00","modified":"2022-02-10T10:15:43+00:00","when":"2022-02-10T10:15:42+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking, starting at 2022-02-10 00:32:56 PST\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:32 US/Pacific\nOur engineering team continues to investigate the issue. Customer maybe see various error in the APAC region\nWe will provide an update by Thursday, 2022-02-10 03:00 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:06:18+00:00","modified":"2022-02-10T10:06:19+00:00","when":"2022-02-10T10:06:18+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking,\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:00 US/Pacific\nOur engineering team continues to investigate the issue. Customer maybe see various error in the APAC region\nWe will provide an update by Thursday, 2022-02-10 02:30 US/Pacific with current details.\nDiagnosis: Customer may see - Time outs, 502 error, and slow response times\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:03:28+00:00","modified":"2022-02-10T10:03:29+00:00","when":"2022-02-10T10:03:28+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking,\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:00 US/Pacific\nOur engineering team continues to investigate the issue. Customer maybe see various error in the APAC region\nWe will provide an update by Thursday, 2022-02-10 02:30 US/Pacific with current details.\nDiagnosis: Customer may see issue with APP engine, GCS, GCLP - Time outs, 502 error, and slow response times\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T10:01:05+00:00","modified":"2022-02-10T10:01:11+00:00","when":"2022-02-10T10:01:05+00:00","text":"Summary: Google engineering are investigating issues with Cloud Networking,\nDescription: We are experiencing an issue with Cloud Networking Thursday, 2022-02-10 00:00 US/Pacific\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-02-10 02:30 US/Pacific with current details.\nDiagnosis: Customer may see with APP engine, GCS, GCLP - Time out, 502 error, and slow response\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-10T22:01:11+00:00","modified":"2022-02-10T22:01:11+00:00","when":"2022-02-10T22:01:11+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 10 February 2022 00:32\n**Incident End:** 10 February 2022 06:34\n**Duration:** 6 hours, 32 minutes\n**Affected Services and Features:**\nGoogle Cloud Networking, Google App Engine, Google Cloud Storage, Google Compute Engine\n**Regions/Zones:** asia-south1\n**Description:**\nGoogle Cloud Networking experienced elevated latency in the asia-south1 region for 6 hours and 32 minutes. From preliminary analysis, the root cause of the issue was increased memory utilization related to a query workload.\n**Customer Impact:**\nCustomers may have experienced elevated latency in the asia-south1 region between Google Cloud Load Balancers (GCLB) and downstream services including Google App Engine, Google Cloud Storage, and Google Compute Engine.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google App Engine","id":"kchyUtnkMHJWaAva8aYc"},{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"},{"title":"Virtual Private Cloud (VPC)","id":"BSGtCUnz6ZmyajsjgTKv"}],"uri":"incidents/46bP9UWxaLXHyCUQdjPR","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"m6gcTj6EdTDt7oLjR5da","number":"12694478571410041419","begin":"2022-02-10T06:00:00+00:00","created":"2022-02-10T11:34:42+00:00","end":"2022-02-10T12:05:00+00:00","modified":"2022-02-11T17:00:09+00:00","external_desc":"Contact Support Widget is down","updates":[{"created":"2022-02-11T17:00:05+00:00","modified":"2022-02-11T17:00:05+00:00","when":"2022-02-11T17:00:05+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 09 February 2022 22:00\n**Incident End:** 10 February 2022 04:05\n**Duration:** 6 hours, 5 minutes\n**Affected Services and Features:**\nGoogle Cloud Console - Support Widget\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Contact Support widgets experienced elevated errors and were unavailable in the Cloud Console for 6 hours, 5 minutes. From preliminary analysis, the root cause of the issue is due to a rollout of the UI server.\n**Customer Impact:**\nGoogle Cloud Platform customers were unable to create billing support cases via the Support Widget in the Google Cloud Console.\n**Additional details:**\nThe issue was fully resolved on 10 February 2022 at 04:05 US/Pacific after a rollback of the change was completed.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-10T12:04:19+00:00","modified":"2022-02-10T12:04:20+00:00","when":"2022-02-10T12:04:19+00:00","text":"The issue with Cloud Console has been resolved for all affected users as of Thursday, 2022-02-10 04:03 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-10T11:36:56+00:00","modified":"2022-02-10T11:36:56+00:00","when":"2022-02-10T11:36:56+00:00","text":"Summary: Contact Support Widget is down\nDescription: We are experiencing an issue with the Contact Support Widget for GCP billing support not loading for users.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-02-10 04:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer will be unable to access billing support widget\nWorkaround: Customer can navigate to https://apps.google.com/supportwidget/helphome?product_name=Cloud+Platform for direct billing support.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-10T11:34:42+00:00","modified":"2022-02-10T11:34:43+00:00","when":"2022-02-10T11:34:42+00:00","text":"Summary: Contact Support Widget is down\nDescription: We are experiencing an issue with the Contact Support Widget for GCP billing support not loading for users.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Thursday, 2022-02-10 04:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer will be unable to access billing support widget\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-11T17:00:05+00:00","modified":"2022-02-11T17:00:05+00:00","when":"2022-02-11T17:00:05+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 09 February 2022 22:00\n**Incident End:** 10 February 2022 04:05\n**Duration:** 6 hours, 5 minutes\n**Affected Services and Features:**\nGoogle Cloud Console - Support Widget\n**Regions/Zones:** Global\n**Description:**\nGoogle Cloud Contact Support widgets experienced elevated errors and were unavailable in the Cloud Console for 6 hours, 5 minutes. From preliminary analysis, the root cause of the issue is due to a rollout of the UI server.\n**Customer Impact:**\nGoogle Cloud Platform customers were unable to create billing support cases via the Support Widget in the Google Cloud Console.\n**Additional details:**\nThe issue was fully resolved on 10 February 2022 at 04:05 US/Pacific after a rollback of the change was completed.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Console","id":"Wdsr1n5vyDvCt78qEifm"},{"title":"Google Cloud Support","id":"bGThzF7oEGP5jcuDdMuk"}],"uri":"incidents/m6gcTj6EdTDt7oLjR5da","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"bRpbkj2tcGDGQ6j4d8Uv","number":"12173750429148254762","begin":"2022-02-07T11:42:00+00:00","created":"2022-02-07T12:00:13+00:00","end":"2022-02-07T12:20:00+00:00","modified":"2022-05-26T19:46:01+00:00","external_desc":"Cloud Interconnect can see packet loss for users accessing VMs and Google Services","updates":[{"created":"2022-02-07T12:20:06+00:00","modified":"2022-02-07T12:20:10+00:00","when":"2022-02-07T12:20:06+00:00","text":"This incident with Cloud Interconnect was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-07T12:00:10+00:00","modified":"2022-02-07T12:00:15+00:00","when":"2022-02-07T12:00:10+00:00","text":"Summary: Cloud Interconnect can see packet loss for users accessing VMs and Google Services\nDescription: We are investigating a potential issue with Cloud Interconnect.\nWe will provide more information by Monday, 2022-02-07 05:00 US/Pacific.\nDiagnosis: Potential packet loss over interconnects\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-07T12:20:06+00:00","modified":"2022-02-07T12:20:10+00:00","when":"2022-02-07T12:20:06+00:00","text":"This incident with Cloud Interconnect was initially triggered by our internal monitoring systems.\nUpon further investigation, our engineering teams believe that the scope is very limited and/or no customers were impacted.\nIf you have questions or feel that you may be impacted, please open a case with the Support Team and we will work with you until the issue is resolved. No further updates will be provided here.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"}],"uri":"incidents/bRpbkj2tcGDGQ6j4d8Uv","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"1cPiGbWDMYHFMcTaLADd","number":"16268067613416205109","begin":"2022-02-02T20:00:00+00:00","created":"2022-02-08T19:22:23+00:00","end":"2022-02-09T13:48:00+00:00","modified":"2022-02-10T23:13:01+00:00","external_desc":"Global: Cloud build unable to create github triggers","updates":[{"created":"2022-02-10T23:12:33+00:00","modified":"2022-02-10T23:12:33+00:00","when":"2022-02-10T23:12:33+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 02 February 2022 12:00\n**Incident End:** 09 February 2022 05:48\n**Duration:** 6 days, 17 hours, 48 minutes\n**Affected Services and Features:**\nCloud Build\n**Regions/Zones:** Global\n**Description:**\nCreating Cloud Build GitHub triggers in the Cloud Console failed when the URL of the page ended with a project ID as the last argument (e.g. https://console.cloud.google.com/cloud-build/triggers/add?project=project-id-1234) Creation of triggers via gcloud was not impacted. From preliminary analysis, the root cause of the issue was that the Cloud Console began sending resource names in a format Cloud Build could not parse.\n**Customer Impact:**\nCustomers attempting to create GitHub triggers when using a Cloud Console URL that ended in their project ID would have experienced pages that displayed “Failed to load” errors.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-09T14:07:35+00:00","modified":"2022-02-09T14:07:39+00:00","when":"2022-02-09T14:07:35+00:00","text":"The issue with Cloud Build has been resolved for all affected projects as of Wednesday, 2022-02-09 05:48 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-02-08T23:16:39+00:00","modified":"2022-02-08T23:16:46+00:00","when":"2022-02-08T23:16:39+00:00","text":"Summary: Global: Cloud build unable to create github triggers\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Wednesday, 2022-02-09 07:00 US/Pacific.\nDiagnosis: Customers attempting to create github triggers using a Cloud Console URL that ends in their project id (example: https://console.cloud.google.com/cloud-build/triggers/add?project=$project-id) will see a \"Failed to load\" error with following message:\n\"There was an error while loading /cloud-build/triggers?project=\nPlease try again\"\nWorkaround: Modify the URL in the browser to end with the project number instead of project id\ne.g. https://console.cloud.google.com/cloud-build/triggers/add?project=$project-num","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-08T20:13:20+00:00","modified":"2022-02-08T20:13:21+00:00","when":"2022-02-08T20:13:20+00:00","text":"Summary: Global: Cloud build unable to create github triggers\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Tuesday, 2022-02-08 15:00 US/Pacific.\nDiagnosis: Customers attempting to create github triggers using a Cloud Console URL that ends in their project id (example: https://console.cloud.google.com/cloud-build/triggers/add?project=$project-id) will see a \"Failed to load\" error with following message:\n\"There was an error while loading /cloud-build/triggers?project=\nPlease try again\"\nWorkaround: Modify the URL in the browser to end with the project number instead of project id\ne.g. https://console.cloud.google.com/cloud-build/triggers/add?project=$project-num","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-08T19:56:33+00:00","modified":"2022-02-08T19:56:34+00:00","when":"2022-02-08T19:56:33+00:00","text":"Summary: Global: Cloud build unable to create github triggers\nDescription: We are experiencing an issue with Cloud Build beginning at Wednesday, 2022-02-02 12:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-02-08 13:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see a \"Failed to load\" error with following message:\n\"There was an error while loading /cloud-build/triggers?project=\nPlease try again\"\nWorkaround: Modify the URL in the browser to end with the project number\ne.g. https://console.cloud.google.com/cloud-build/triggers/add?project=$project-id ---\u003e https://console.cloud.google.com/cloud-build/triggers/add?project=$project-num","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-02-08T19:22:23+00:00","modified":"2022-02-08T19:22:23+00:00","when":"2022-02-08T19:22:23+00:00","text":"Summary: Global: Cloud build unable to create github triggers\nDescription: We are experiencing an issue with Cloud Build beginning at Wednesday, 2022-02-02 12:00 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-02-08 12:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customers will see a \"Failed to load\" error with following message:\n\"There was an error while loading /cloud-build/triggers?project=\nPlease try again\"\nWorkaround: Modify the URL in the browser to end with the project number\ne.g. https://console.cloud.google.com/cloud-build/triggers/add?project=$project-id ---\u003e https://console.cloud.google.com/cloud-build/triggers/add?project=$project-num","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-02-10T23:12:33+00:00","modified":"2022-02-10T23:12:33+00:00","when":"2022-02-10T23:12:33+00:00","text":"We apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 02 February 2022 12:00\n**Incident End:** 09 February 2022 05:48\n**Duration:** 6 days, 17 hours, 48 minutes\n**Affected Services and Features:**\nCloud Build\n**Regions/Zones:** Global\n**Description:**\nCreating Cloud Build GitHub triggers in the Cloud Console failed when the URL of the page ended with a project ID as the last argument (e.g. https://console.cloud.google.com/cloud-build/triggers/add?project=project-id-1234) Creation of triggers via gcloud was not impacted. From preliminary analysis, the root cause of the issue was that the Cloud Console began sending resource names in a format Cloud Build could not parse.\n**Customer Impact:**\nCustomers attempting to create GitHub triggers when using a Cloud Console URL that ended in their project ID would have experienced pages that displayed “Failed to load” errors.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Cloud Developer Tools","id":"BGJQ6jbGK4kUuBTQFZ1G"},{"title":"Cloud Build","id":"fw8GzBdZdqy4THau7e1y"}],"uri":"incidents/1cPiGbWDMYHFMcTaLADd","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"whAt3eeGhT2SbR2aQXwA","number":"15275509219608406501","begin":"2022-01-16T08:49:46+00:00","created":"2022-01-16T08:49:54+00:00","end":"2022-01-16T10:10:36+00:00","modified":"2022-01-16T10:10:36+00:00","external_desc":"Users will not receive alerts on Firebase console.","updates":[{"created":"2022-01-16T10:10:36+00:00","modified":"2022-01-16T10:10:36+00:00","when":"2022-01-16T10:10:36+00:00","text":"The issue with Firebase Console is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-16T10:07:27+00:00","modified":"2022-01-16T10:07:27+00:00","when":"2022-01-16T10:07:27+00:00","text":"Summary: Users will not receive alerts on Firebase console.\nDescription: We believe the issue with Firebase Console is mitigated. Alerts may be delayed by up to 30 minutes but are still being processed.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Sunday, 2022-01-16 04:00 US/Pacific with current details.\nDiagnosis: Users will not receive alerts on Firebase console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-01-16T09:27:18+00:00","modified":"2022-01-16T09:27:18+00:00","when":"2022-01-16T09:27:18+00:00","text":"Summary: Users will not receive alerts on Firebase console.\nDescription: We are experiencing an issue with Firebase Console.Our engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-01-16 04:30 US/Pacific with current details.\nDiagnosis: Users will not receive alerts on Firebase console.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-01-16T09:26:04+00:00","modified":"2022-01-16T09:26:10+00:00","when":"2022-01-16T09:26:04+00:00","text":"Summary: Users will not receive alerts on Firebase console.\nDescription: We are experiencing an issue with Firebase Console.Our engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-01-16 04:30 US/Pacific with current details.\nDiagnosis: Users will not receive alerts on Firebase console.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]},{"created":"2022-01-16T08:49:48+00:00","modified":"2022-01-16T08:49:54+00:00","when":"2022-01-16T08:49:48+00:00","text":"Summary: Users will not receive alerts on Firebase console.\nDescription: We've received a report of an issue with Firebase Console as of Sunday, 2022-01-16 00:29 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Sunday, 2022-01-16 01:25 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: None at this time.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]}],"most_recent_update":{"created":"2022-01-16T10:10:36+00:00","modified":"2022-01-16T10:10:36+00:00","when":"2022-01-16T10:10:36+00:00","text":"The issue with Firebase Console is believed to be affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"CETSkT92V21G6A1x28me","service_name":"Cloud Firestore","affected_products":[{"title":"Cloud Firestore","id":"CETSkT92V21G6A1x28me"}],"uri":"incidents/whAt3eeGhT2SbR2aQXwA","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"NYcRpDHwjnhD6Gh2yUyK","number":"15829028318356552113","begin":"2022-01-11T21:20:00+00:00","created":"2022-01-11T21:30:39+00:00","end":"2022-01-11T22:16:00+00:00","modified":"2022-05-26T20:02:06+00:00","external_desc":"us-east1-c: Load balancing creation/modifications not taking effect.","updates":[{"created":"2022-01-11T22:16:34+00:00","modified":"2022-01-11T22:16:35+00:00","when":"2022-01-11T22:16:34+00:00","text":"The issue with Cloud Networking has been resolved for all affected projects as of Tuesday, 2022-01-11 14:14 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-11T21:30:33+00:00","modified":"2022-01-11T21:30:39+00:00","when":"2022-01-11T21:30:33+00:00","text":"Summary: us-east1-c: Load balancing creation/modifications not taking effect.\nDescription: We are experiencing an issue with Cloud Networking. Customers are unable to make changes to load balancer in us-east1-c region.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-01-11 14:42 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Create or modify load balancers actions do not take effect.\nWorkaround: Utilize other zones in us-east1.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-01-11T22:16:34+00:00","modified":"2022-01-11T22:16:35+00:00","when":"2022-01-11T22:16:34+00:00","text":"The issue with Cloud Networking has been resolved for all affected projects as of Tuesday, 2022-01-11 14:14 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Cloud Load Balancing","id":"ix7u9beT8ivBdjApTif3"}],"uri":"incidents/NYcRpDHwjnhD6Gh2yUyK","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"izF3BTJMavU36BBKJNAz","number":"12681297379738414769","begin":"2022-01-11T20:50:00+00:00","created":"2022-01-11T22:53:17+00:00","end":"2022-01-11T23:04:00+00:00","modified":"2022-01-12T21:43:01+00:00","external_desc":"Apigee is experiencing issues loading the Apigee UI at apigee.google.com.","updates":[{"created":"2022-01-12T21:43:01+00:00","modified":"2022-01-12T21:43:01+00:00","when":"2022-01-12T21:43:01+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 11 January 2022 12:50\n**Incident End:** 11 January 2022 15:04\n**Duration:** 2 hours, 14 minutes\n**Affected Services and Features:**\n- Apigee X - management UI\n- Apigee Hybrid - management UI\n**Regions/Zones:** Global\n**Description:**\nApigee X and Apigee Hybrid experienced elevated page errors loading the console user interface globally for 2 hours, 14 minutes. From preliminary analysis, the root cause of the issue was due to an uncaught error in a new release.\n**Customer Impact:**\n- Users with custom Google Workspace domains were unable to load Apigee console pages at apigee.google.com.\n- Page banners were visible with an \"Internal Server Error\" message\n**Additional details:**\n- This only impacted users with email domains other than @gmail.com\n- Runtime traffic was unaffected.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-12T00:00:32+00:00","modified":"2022-01-12T00:00:32+00:00","when":"2022-01-12T00:00:32+00:00","text":"The issue with Apigee has been resolved for all affected users as of Tuesday, 2022-01-11 15:58 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-11T23:22:21+00:00","modified":"2022-01-11T23:22:22+00:00","when":"2022-01-11T23:22:21+00:00","text":"Summary: Apigee is experiencing issues loading the Apigee UI at apigee.google.com.\nDescription: We believe the issue with loading the Apigee UI is resolved. Engineers are working to confirm full resolution.\nWe will provide an update by Tuesday, 2022-01-11 16:30 US/Pacific with current details.\nDiagnosis: Users may receive a message \"Internal Server Error\". Runtime traffic is unaffected.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2022-01-11T22:53:16+00:00","modified":"2022-01-11T22:53:17+00:00","when":"2022-01-11T22:53:16+00:00","text":"Summary: Apigee is experiencing issues loading the Apigee UI at apigee.google.com.\nDescription: We are experiencing an issue with Apigee beginning at Tuesday, 2022-01-11 12:50 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2022-01-11 15:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Users may receive a message \"Internal Server Error\". Runtime traffic is unaffected.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-01-12T21:43:01+00:00","modified":"2022-01-12T21:43:01+00:00","when":"2022-01-12T21:43:01+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 11 January 2022 12:50\n**Incident End:** 11 January 2022 15:04\n**Duration:** 2 hours, 14 minutes\n**Affected Services and Features:**\n- Apigee X - management UI\n- Apigee Hybrid - management UI\n**Regions/Zones:** Global\n**Description:**\nApigee X and Apigee Hybrid experienced elevated page errors loading the console user interface globally for 2 hours, 14 minutes. From preliminary analysis, the root cause of the issue was due to an uncaught error in a new release.\n**Customer Impact:**\n- Users with custom Google Workspace domains were unable to load Apigee console pages at apigee.google.com.\n- Page banners were visible with an \"Internal Server Error\" message\n**Additional details:**\n- This only impacted users with email domains other than @gmail.com\n- Runtime traffic was unaffected.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9Y13BNFy4fJydvjdsN3X","service_name":"Apigee","affected_products":[{"title":"Apigee","id":"9Y13BNFy4fJydvjdsN3X"}],"uri":"incidents/izF3BTJMavU36BBKJNAz","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"NMcnk6aE8xMHHwRGmyry","number":"328163091910127973","begin":"2022-01-08T23:15:00+00:00","created":"2022-01-09T00:54:20+00:00","end":"2022-01-09T02:36:00+00:00","modified":"2022-01-21T15:56:50+00:00","external_desc":"US-WEST1: Multiple cloud products experiencing network issues","updates":[{"created":"2022-01-21T15:56:50+00:00","modified":"2022-01-21T15:56:50+00:00","when":"2022-01-21T15:56:50+00:00","text":"# UPDATED INCIDENT REPORT\n## Summary\nOn Saturday, 8 January 2022, multiple GCP products in us-west1-b experienced increased network latency for a duration of 3 hours and 22 minutes. To our affected customers in us-west1-b who were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n## Root Cause\nGoogle leverages \"Software-defined Networking” (SDN) to simplify and automate the growth and expansion of our data center networks. This allows us to dynamically scale up data center networks to meet customer demand. This outage began when a routine maintenance event was performed on one of the SDN components. This maintenance event triggered an application failover that prompted a newly active replica to perform reconciliation from a previous checkpoint. These events are expected to be seamless and cause no network disruption. However, the checkpoint data was incorrectly missing a particular piece of configuration information; this was propagated to ~15% of the network switches serving us-west1-b.\nSeconds after this event, the SDN automatically corrected the incomplete configuration. Reprogramming of the affected switches triggered a race condition within the switch firmware, eventually causing them to crash. Automatic repair and mitigation actions were invoked within 10 minutes of switches failing. However, the unexpectedly large number, and network proximity, of the failures prevented a fully automatic recovery. As such, the outage was not mitigated until on-call engineers manually recovered the affected switches. The corrupted checkpoint data was only present in a single location and therefore no other cloud zone was ever at risk.\n## Remediation and Prevention\nThe outage was detected by Google Engineers on Saturday, 8 January at 15:25 US/Pacific, who immediately started an investigation. At 16:03, engineers tried to migrate traffic away from the impacted switches in the switch fabric, but this did not resolve the issue. At 17:19, engineers ascertained that the impacted switches needed to have their services restarted, and at 17:37, they began to do so. The network issue was mitigated at 18:00, when enough switches had been restarted to successfully serve all network traffic. The issue was fully resolved by 18:36, when all services were marked as recovered.\nThe conditions that caused this disruption existed only in a small subset of Google's network. The function responsible for causing it has been disabled and will not be reenabled until the steps below have been fully implemented.\n1. Avoiding the trigger: - We have audited and disabled the SDN feature that triggered this incident. - We have identified test coverage gaps in our SDN release process, which will be addressed to prevent a repeat of this and other similar issues. - Our systems will be modified to validate SDN checkpoint data before it is persisted for later recovery. - Our SDN maintenance workflow safety checks will be enhanced to automatically stop the workflow during an outage.\n2. Ensure changes are applied to the SDN more progressively: - We will redistribute SDN services to limit the areas impacted by failed maintenance workflows. - We will be developing new SDN safety components that validate potentially disruptive operations by applying them to network devices that are similarly configured, but not currently active, before deploying them further.\n3. Reduce time to resolution: - We will improve network management tooling to simplify and expedite mass switch recovery. - We will deploy monitoring improvements to more quickly identify broad network switch failures.\n## Detailed Description of Impact\nOn Saturday, 8 January from 15:15 to 18:36 US/Pacific:\n#### Cloud Router\nAffected Cloud Router customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud VPN\nAffected Cloud VPN customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud DNS\nCloud DNS customers experienced increased latency and errors on DNS requests.\n#### Cloud AI\nCloud AI customers experienced elevated latency on prediction requests.\n#### Cloud Run\nCloud Run customers experienced network connectivity issues.\n#### Cloud Spanner\nCloud Spanner Customers experienced elevated latency.\n#### Google Compute Engine\nGoogle Compute Engine customers experienced network latency, connectivity issues and slow input/output (I/O) operations on disks due to network latency, which may have manifested as unresponsive Compute Engine instances, including Google Kubernetes instances.\n#### Other Services\nOther services that require Google Cloud Networking in us-west1-b were also affected. Customers would experience latency, errors, and delays.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-19T15:39:36+00:00","modified":"2022-01-19T15:39:36+00:00","when":"2022-01-19T15:39:36+00:00","text":"INCIDENT REPORT\n## Summary\nOn Saturday, 8 January 2022, multiple GCP products in us-west1-b experienced increased network latency for a duration of 3 hours and 22 minutes. To our affected customers in us-west1-b who were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n## Root Cause\nGoogle leverages \"Software-defined Networking” (SDN) to simplify and automate the growth and expansion of our data center networks. This allows us to dynamically scale up data center networks to meet customer demand. This outage began when a routine maintenance event was performed on one of the SDN components. This maintenance event triggered an application failover that prompted a newly active replica to perform reconciliation from a previous checkpoint. These events are expected to be seamless and cause no network disruption. However, the checkpoint data was incorrectly missing a particular piece of configuration information; this was propagated to ~15% of the network switches serving us-west1-b.\nSeconds after this event, the SDN automatically corrected the incomplete configuration. Reprogramming of the affected switches triggered a race condition within the switch firmware, eventually causing them to crash. Automatic repair and mitigation actions were invoked within 10 minutes of switches failing. However, the unexpectedly large number, and network proximity, of the failures prevented a fully automatic recovery. As such, the outage was not mitigated until on-call engineers manually recovered the affected switches. The corrupted checkpoint data was only present in a single location and therefore no other cloud zone was ever at risk.\n## Remediation and Prevention\nThe outage was detected by Google Engineers on Saturday, 8 January at 15:25 US/Pacific, who immediately started an investigation. At 16:03, engineers tried to migrate traffic away from the impacted switches in the switch fabric, but this did not resolve the issue. At 17:19 engineers ascertained that the impacted switches needed to have their services restarted, and at 17:37 they began to do so. The network issue was mitigated at 18:00 when enough switches had been restarted to successfully serve all network traffic. The issue was fully resolved by 18:36 when all services were marked as recovered.\nWe are still working on the details of steps to avert further issues of this type, which in line with Google’s standard practice, are being designed to ensure the following:\n- Prevention of a reoccurrence of an outage of this nature.\n- Detection and mitigation of similar, future outages more quickly.\nThe conditions that caused this disruption existed only in a small part of the network. The function responsible for causing it has been disabled and will not be re-enabled until the steps above have been fully implemented.\n## Detailed Description of Impact\nOn Saturday, 8 January from 15:15 to 18:36 US/Pacific:\n#### Cloud Router\nAffected Cloud Router customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud VPN\nAffected Cloud VPN customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud DNS\nCloud DNS customers experienced increased latency and errors on DNS requests.\n#### Cloud AI\nCloud AI customers experienced elevated latency on prediction requests.\n#### Cloud Run\nCloud Run customers experienced network connectivity issues.\n#### Cloud Spanner\nCloud Spanner Customers experienced elevated latency.\n#### Google Compute Engine\nGoogle Compute Engine customers experienced network latency, connectivity issues and slow input/output (I/O) operations on disks due to network latency, which may have manifested as unresponsive Compute Engine instances, including Google Kubernetes instances.\n#### Other Services\nOther services that require Google Cloud Networking in us-west1-b were also affected. Customers would experience latency, errors, and delays.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-11T02:34:49+00:00","modified":"2022-01-11T02:34:49+00:00","when":"2022-01-11T02:34:49+00:00","text":"Mini Incident Report (Full Incident Report To Follow)\nWe apologize for the inconvenience this service disruption/outage may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 08 January 2022 15:14\n**Incident End:** 08 January 2022 18:36\n**Duration:** 3 hours, 22 minutes\n**Affected Services and Features:**\n- Cloud Router\n- Cloud VPN\n- Cloud DNS\n- Cloud AI\n- Cloud Run\n- Cloud Spanner\n- Persistent DIsk\n**Regions/Zones:** us-west1-b\n**Description:**\nMultiple GCP products experienced network issues in the us-west1 region for 3 hours and 22 minutes. From preliminary analysis, the root cause of the issue is related to an unexpected port/switch configuration and we are continuing investigations.\n**Customer Impact:**\n- Cloud Router - Customers may experience elevated packet loss.\n- Cloud DNS - Increased latency and/or errors reaching out to Cloud DNS\n- Cloud AI - Elevated prediction latencies\n- Cloud Run - Network connectivity issues\n- Cloud Spanner - Elevated network latencies\n- Persistent Disk - Short period of slow I/O operations on disks, which may have manifested as unresponsive -Compute Engine instances.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-09T02:42:53+00:00","modified":"2022-01-09T02:42:54+00:00","when":"2022-01-09T02:42:53+00:00","text":"The issue with Cloud Networking has been resolved for all affected projects as of Saturday, 2022-01-08 18:36 US/Pacific.\nWe will publish an analysis of this incident once we have completed our internal investigation.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2022-01-09T02:02:08+00:00","modified":"2022-01-09T02:02:09+00:00","when":"2022-01-09T02:02:08+00:00","text":"Summary: US-WEST1: Multiple cloud products experiencing network issues\nDescription: We are experiencing network issues in us-west1.\nBelow is the list of affected products:\n* Cloud Router - Customers may experience elevated packet loss.\n* Cloud DNS - Increased latency and/or errors reaching out to Cloud DNS\n* Cloud AI - Elevated prediction latencies\n* Cloud Run - Network connectivity issues\n* Cloud Spanner - Elevated network latencies\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-01-08 18:53 US/Pacific.\nDiagnosis: Affected customer will see packet loss.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]},{"created":"2022-01-09T01:49:22+00:00","modified":"2022-01-09T01:49:23+00:00","when":"2022-01-09T01:49:22+00:00","text":"Summary: US-WEST1: Multiple cloud products experiencing network issues\nDescription: We are experiencing network issues in us-west1.\nBelow is the list of affected products:\n* Cloud Router - Customers may experience elevated packet loss.\n* Cloud DNS - Increased latency and/or errors reaching out to Cloud DNS\n* Cloud AI - Elevated prediction latencies\n* Cloud Run - Network connectivity issues\nMitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-01-08 18:53 US/Pacific.\nDiagnosis: Affected customer will see packet loss.\nWorkaround: None at this time.","status":"SERVICE_OUTAGE","affected_locations":[]},{"created":"2022-01-09T00:54:13+00:00","modified":"2022-01-09T00:54:21+00:00","when":"2022-01-09T00:54:13+00:00","text":"Summary: Multiple cloud connectivity products experiencing packet loss in US-WEST1\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Saturday, 2022-01-08 17:53 US/Pacific.\nDiagnosis: Affected customer will see packet loss.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2022-01-21T15:56:50+00:00","modified":"2022-01-21T15:56:50+00:00","when":"2022-01-21T15:56:50+00:00","text":"# UPDATED INCIDENT REPORT\n## Summary\nOn Saturday, 8 January 2022, multiple GCP products in us-west1-b experienced increased network latency for a duration of 3 hours and 22 minutes. To our affected customers in us-west1-b who were impacted during this outage, we sincerely apologize. This is not the level of quality and reliability we strive to offer you, and we are taking immediate steps to improve the platform’s performance and availability.\n## Root Cause\nGoogle leverages \"Software-defined Networking” (SDN) to simplify and automate the growth and expansion of our data center networks. This allows us to dynamically scale up data center networks to meet customer demand. This outage began when a routine maintenance event was performed on one of the SDN components. This maintenance event triggered an application failover that prompted a newly active replica to perform reconciliation from a previous checkpoint. These events are expected to be seamless and cause no network disruption. However, the checkpoint data was incorrectly missing a particular piece of configuration information; this was propagated to ~15% of the network switches serving us-west1-b.\nSeconds after this event, the SDN automatically corrected the incomplete configuration. Reprogramming of the affected switches triggered a race condition within the switch firmware, eventually causing them to crash. Automatic repair and mitigation actions were invoked within 10 minutes of switches failing. However, the unexpectedly large number, and network proximity, of the failures prevented a fully automatic recovery. As such, the outage was not mitigated until on-call engineers manually recovered the affected switches. The corrupted checkpoint data was only present in a single location and therefore no other cloud zone was ever at risk.\n## Remediation and Prevention\nThe outage was detected by Google Engineers on Saturday, 8 January at 15:25 US/Pacific, who immediately started an investigation. At 16:03, engineers tried to migrate traffic away from the impacted switches in the switch fabric, but this did not resolve the issue. At 17:19, engineers ascertained that the impacted switches needed to have their services restarted, and at 17:37, they began to do so. The network issue was mitigated at 18:00, when enough switches had been restarted to successfully serve all network traffic. The issue was fully resolved by 18:36, when all services were marked as recovered.\nThe conditions that caused this disruption existed only in a small subset of Google's network. The function responsible for causing it has been disabled and will not be reenabled until the steps below have been fully implemented.\n1. Avoiding the trigger: - We have audited and disabled the SDN feature that triggered this incident. - We have identified test coverage gaps in our SDN release process, which will be addressed to prevent a repeat of this and other similar issues. - Our systems will be modified to validate SDN checkpoint data before it is persisted for later recovery. - Our SDN maintenance workflow safety checks will be enhanced to automatically stop the workflow during an outage.\n2. Ensure changes are applied to the SDN more progressively: - We will redistribute SDN services to limit the areas impacted by failed maintenance workflows. - We will be developing new SDN safety components that validate potentially disruptive operations by applying them to network devices that are similarly configured, but not currently active, before deploying them further.\n3. Reduce time to resolution: - We will improve network management tooling to simplify and expedite mass switch recovery. - We will deploy monitoring improvements to more quickly identify broad network switch failures.\n## Detailed Description of Impact\nOn Saturday, 8 January from 15:15 to 18:36 US/Pacific:\n#### Cloud Router\nAffected Cloud Router customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud VPN\nAffected Cloud VPN customers would have experienced elevated packet loss from 40% to 100%.\n#### Cloud DNS\nCloud DNS customers experienced increased latency and errors on DNS requests.\n#### Cloud AI\nCloud AI customers experienced elevated latency on prediction requests.\n#### Cloud Run\nCloud Run customers experienced network connectivity issues.\n#### Cloud Spanner\nCloud Spanner Customers experienced elevated latency.\n#### Google Compute Engine\nGoogle Compute Engine customers experienced network latency, connectivity issues and slow input/output (I/O) operations on disks due to network latency, which may have manifested as unresponsive Compute Engine instances, including Google Kubernetes instances.\n#### Other Services\nOther services that require Google Cloud Networking in us-west1-b were also affected. Customers would experience latency, errors, and delays.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_OUTAGE","severity":"high","service_key":"zall","service_name":"Multiple Products","affected_products":[{"title":"Google Cloud Networking","id":"VNJxzcH58QmTt5H6pnT6"},{"title":"Google Cloud DNS","id":"TUZUsWSJUVJGW97Jq2sH"},{"title":"Cloud Run","id":"9D7d2iNBQWN24zc1VamE"},{"title":"Cloud Spanner","id":"EcNGGUgBtBLrtm4mWvqC"},{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"},{"title":"AI Platform Prediction","id":"eFCqAnWci3AZiqsz1NjQ"},{"title":"Hybrid Connectivity","id":"5x6CGnZvSHQZ26KtxpK1"}],"uri":"incidents/NMcnk6aE8xMHHwRGmyry","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"cBRgkAaxS8Rq3vvbPHaw","number":"17207454738058883218","begin":"2021-12-21T12:31:14+00:00","created":"2021-12-21T13:07:19+00:00","end":"2021-12-21T14:03:27+00:00","modified":"2021-12-21T14:03:27+00:00","external_desc":"Internal errors for Dataset commands insert/update in us-central1","updates":[{"created":"2021-12-21T14:03:25+00:00","modified":"2021-12-21T14:03:28+00:00","when":"2021-12-21T14:03:25+00:00","text":"Upon further investigation we believe that the issue with Google BigQuery is affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-21T13:07:11+00:00","modified":"2021-12-21T13:07:20+00:00","when":"2021-12-21T13:07:11+00:00","text":"Summary: Internal errors for Dataset commands insert/update in us-central1\nDescription: We are experiencing an issue with Google BigQuery beginning at Tuesday, 2021-12-21 03:30 US/Pacific.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-12-21 05:59 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Customer may observe an internal error for Dataset commands insert/update in us-central1.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2021-12-21T14:03:25+00:00","modified":"2021-12-21T14:03:28+00:00","when":"2021-12-21T14:03:25+00:00","text":"Upon further investigation we believe that the issue with Google BigQuery is affecting a very small number of customers and our Engineering Team is working on it.\nIf you have questions or are impacted, please open a case with the Support Team and we will work with you until this issue is resolved.\nWe thank you for your patience while we're working on resolving the issue.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"9CcrhHUcFevXPSVaSxkf","service_name":"Google BigQuery","affected_products":[{"title":"Google BigQuery","id":"9CcrhHUcFevXPSVaSxkf"}],"uri":"incidents/cBRgkAaxS8Rq3vvbPHaw","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"fniZhzAhYdcJuosEwwtZ","number":"13628602836948027359","begin":"2021-12-17T17:10:00+00:00","created":"2021-12-17T18:43:10+00:00","end":"2021-12-18T06:11:00+00:00","modified":"2021-12-20T18:05:19+00:00","external_desc":"us multiregion: Elevated tail latency on read operations for GCS buckets","updates":[{"created":"2021-12-20T18:04:45+00:00","modified":"2021-12-20T18:04:45+00:00","when":"2021-12-20T18:04:45+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 17 December 2021 09:10\n**Incident End:** 17 December 2021 22:11\n**Incident Duration:** 13 hours, 1 minute\n**Affected Services and Features:**\nGoogle Cloud Storage (GCS) - Read and Write object operations\n**Regions/Zones:** US multi-region\n**Description:**\nGoogle Cloud Storage buckets experienced elevated tail latency on read and write object operations for a total duration of 13 hours, 1 minute. From preliminary analysis, an internal job incorrectly placed a significant load on the backend database.\nThis originally presented as increased tailed latency. The database was significantly overloaded leading to elevated 5xx errors for a 47 minute period between 10:50 and 11:37. The 5XX errors were resolved at 11:37 by adding additional resources and stopping the offending job. However, the job caused an extended backlog of work, which took until 22:11 to clear.\n**Customer Impact:**\n* Elevated 5xx errors related to read timeouts between 10:50 and 11:37\n* Elevated tail latency on read operations from GCS buckets for the duration of the incident.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-17T20:49:56+00:00","modified":"2021-12-17T20:49:57+00:00","when":"2021-12-17T20:49:56+00:00","text":"The issue with Google Cloud Storage has been resolved for all affected users as of Friday, 2021-12-17 11:36 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-17T19:47:03+00:00","modified":"2021-12-17T19:47:05+00:00","when":"2021-12-17T19:47:03+00:00","text":"Summary: us multiregion: Elevated tail latency on read operations for GCS buckets\nDescription: We believe the issue with Google Cloud Storage is partially resolved and the error rates decreased significantly.\nWe do not have an ETA for full resolution at this point.\nWe will provide an update by Friday, 2021-12-17 13:30 US/Pacific with current details.\nDiagnosis: Affected customers may experience elevated tail latency on read operations for buckets in the us multiregion.\nWorkaround: Retrying failed or slow requests may succeed due to the relatively low error rate.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-17T19:22:47+00:00","modified":"2021-12-17T19:22:49+00:00","when":"2021-12-17T19:22:47+00:00","text":"Summary: us multiregion: Elevated tail latency on read operations for GCS buckets\nDescription: Mitigation work is currently underway by our engineering team.\nWe do not have an ETA for mitigation at this point.\nWe will provide more information by Friday, 2021-12-17 13:00 US/Pacific.\nDiagnosis: Affected customers may experience elevated tail latency on read operations for buckets in the us multiregion.\nWorkaround: Retrying failed or slow requests may succeed due to the relatively low error rate.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-17T19:00:57+00:00","modified":"2021-12-17T19:01:04+00:00","when":"2021-12-17T19:00:57+00:00","text":"Summary: us: Elevated latency in us GCS buckets\nDescription: We are experiencing an issue with Google Cloud Storage beginning at Friday, 2021-12-17 09:00 US/Pacific.\nOur engineering team continues to investigate the issue. Current estimates indicates that 1% of GCS requests are impacted.\nWe will provide an update by Friday, 2021-12-17 13:00 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Affected customers may experience elevated tail latency on their buckets in the us multiregion.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-17T18:43:08+00:00","modified":"2021-12-17T18:43:10+00:00","when":"2021-12-17T18:43:08+00:00","text":"Summary: us: Elevated latency in us GCS buckets\nDescription: We are investigating a potential issue with Google Cloud Storage.\nWe will provide more information by Friday, 2021-12-17 11:56 US/Pacific.\nDiagnosis: Affected customers may experience elevated latency on their buckets in the us multiregion.\nWorkaround: None at this time.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2021-12-20T18:04:45+00:00","modified":"2021-12-20T18:04:45+00:00","when":"2021-12-20T18:04:45+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 17 December 2021 09:10\n**Incident End:** 17 December 2021 22:11\n**Incident Duration:** 13 hours, 1 minute\n**Affected Services and Features:**\nGoogle Cloud Storage (GCS) - Read and Write object operations\n**Regions/Zones:** US multi-region\n**Description:**\nGoogle Cloud Storage buckets experienced elevated tail latency on read and write object operations for a total duration of 13 hours, 1 minute. From preliminary analysis, an internal job incorrectly placed a significant load on the backend database.\nThis originally presented as increased tailed latency. The database was significantly overloaded leading to elevated 5xx errors for a 47 minute period between 10:50 and 11:37. The 5XX errors were resolved at 11:37 by adding additional resources and stopping the offending job. However, the job caused an extended backlog of work, which took until 22:11 to clear.\n**Customer Impact:**\n* Elevated 5xx errors related to read timeouts between 10:50 and 11:37\n* Elevated tail latency on read operations from GCS buckets for the duration of the incident.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"UwaYoXQ5bHYHG6EdiPB8","service_name":"Google Cloud Storage","affected_products":[{"title":"Google Cloud Storage","id":"UwaYoXQ5bHYHG6EdiPB8"}],"uri":"incidents/fniZhzAhYdcJuosEwwtZ","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"SjJ3FN51MAEJy7cZmoss","number":"4933937362309678094","begin":"2021-12-07T09:56:00+00:00","created":"2021-12-13T14:16:00+00:00","end":"2021-12-14T00:59:00+00:00","modified":"2021-12-14T19:59:08+00:00","external_desc":"Global: pubsub.googleapis.com autoscaling not worked as expected","updates":[{"created":"2021-12-14T19:59:05+00:00","modified":"2021-12-14T19:59:05+00:00","when":"2021-12-14T19:59:05+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 07 Dec 2021 01:56 PST\n**Incident End:** 13 Dec 2021 16:59 PST\n**Duration:** 6 Days, 15 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Compute Engine (GCE) Autoscaler - Autoscaling using the “pubsub.googleapis.com/subscription/num_undelivered_messages” metric.\n**Regions/Zones:** Global\n**Description:**\nGCE autoscaling service configured to use the “pubsub.googleapis.com/subscription/num_undelivered_messages” metric, experienced an issue while processing the autoscaling function. From preliminary analysis, the root cause was identified as code changes affecting the autoscaler policy validation that was misconfigured for the affected metric.\n**Customer Impact:**\nCustomers using the metric pubsub.googleapis.com/subscription/num_undelivered_messages for autoscaling observed the autoscaling did not complete successfully.\nAutoscaling did not work for existing and new managed instance groups created by customers for the duration of the incident.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-14T01:12:31+00:00","modified":"2021-12-14T01:12:33+00:00","when":"2021-12-14T01:12:31+00:00","text":"The issue with Google Compute Engine has been resolved for all affected users as of Monday, 2021-12-13 16:59 US/Pacific.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-13T18:52:25+00:00","modified":"2021-12-13T18:52:29+00:00","when":"2021-12-13T18:52:25+00:00","text":"Summary: Global: pubsub.googleapis.com autoscaling not worked as expected\nDescription: We believe the issue with Google Compute Engine is partially resolved for previously impacted projects. Newly created projects may still experience the issue until the rollout of the fix completes.\nFull resolution is expected to complete on Tuesday, 2021-12-14.\nDiagnosis: Customers that are use scaling on the pubsub.googleapis.com/subscription/num_undelivered_messages may see auto scaling not working.\nWorkaround: As known workarounds, if customers have a filter with resource.label.subscription_id = ... they could change it to resource.labels.subscription_id = ... to make auto-scaling work.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-13T16:21:17+00:00","modified":"2021-12-13T16:21:20+00:00","when":"2021-12-13T16:21:17+00:00","text":"Summary: GCP engineer are investigating an issue with auto-scaling pubsub.googleapis.com may not be working as intended.\nDescription: Mitigation work is currently underway by our engineering team.\nThe mitigation is expected to complete by Tuesday, 2021-12-14.\nDiagnosis: Customers that are use scaling on the pubsub.googleapis.com/subscription/num_undelivered_messages may see auto scaling not working.\nWorkaround: As known workarounds, if customers have a filter with resource.label.subscription_id = ... they could change it to resource.labels.subscription_id = ... to make auto-scaling work.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-13T14:48:37+00:00","modified":"2021-12-13T14:48:40+00:00","when":"2021-12-13T14:48:37+00:00","text":"Summary: GCP engineer are investigating an issue with auto-scaling - pubsub.googleapis.com may not be working as intended.\nDescription: Beginning at Monday, 2021-12-13 00:00 US/Pacific. We are experiencing an issue with Google Compute Engine beginning at Monday, 2021-12-13 05:21:05 PST.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-12-13 09:15 US/Pacific with current details.\nDiagnosis: Customers that are use scaling on the pubsub.googleapis.com/subscription/num_undelivered_messages may see auto scaling not working.\nWorkaround: As known workarounds, if customers have a filter with resource.label.subscription_id = ... they could change it to resource.labels.subscription_id = ... to make auto-scaling work.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-13T14:26:15+00:00","modified":"2021-12-13T14:26:18+00:00","when":"2021-12-13T14:26:15+00:00","text":"Summary: GCP engineer are investigating an issue with auto-scaling - pubsub.googleapis.com may not be working as intended.\nDescription: Beginning at Monday, 2021-12-13 00:00 US/Pacific. We are experiencing an issue with Google Compute Engine beginning at Monday, 2021-12-13 05:21:05 PST.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-12-13 07:15 US/Pacific with current details.\nDiagnosis: Customers that are use scaling on the pubsub.googleapis.com/subscription/num_undelivered_messages may see auto scaling not working.\nWorkaround: As known workarounds, if customers have a filter with resource.label.subscription_id = ... they could change it to resource.labels.subscription_id = ... to make auto-scaling work.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-13T14:15:58+00:00","modified":"2021-12-13T14:16:01+00:00","when":"2021-12-13T14:15:58+00:00","text":"Summary: GCP engineer are investigating an issue with auto-scaling - pubsub.googleapis.com may not be working as intended.\nDescription: Beginning at Monday, 2021-12-13 00:00 US/Pacific. We are experiencing an issue with Google Compute Engine beginning at Monday, 2021-12-13 05:21:05 PST.\nOur engineering team continues to investigate the issue.\nWe will provide an update by Monday, 2021-12-13 07:15 US/Pacific with current details.\nDiagnosis: Customers that are use scaling on the pubsub.googleapis.com/subscription/num_undelivered_messages masy see auto scaling not working.\nWorkaround: As known workarounds, if customers have a filter with resource.label.subscription_id = ... they could change it to resource.labels.subscription_id = ... to make auto-scaling work.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2021-12-14T19:59:05+00:00","modified":"2021-12-14T19:59:05+00:00","when":"2021-12-14T19:59:05+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 07 Dec 2021 01:56 PST\n**Incident End:** 13 Dec 2021 16:59 PST\n**Duration:** 6 Days, 15 hours, 3 minutes\n**Affected Services and Features:**\nGoogle Compute Engine (GCE) Autoscaler - Autoscaling using the “pubsub.googleapis.com/subscription/num_undelivered_messages” metric.\n**Regions/Zones:** Global\n**Description:**\nGCE autoscaling service configured to use the “pubsub.googleapis.com/subscription/num_undelivered_messages” metric, experienced an issue while processing the autoscaling function. From preliminary analysis, the root cause was identified as code changes affecting the autoscaler policy validation that was misconfigured for the affected metric.\n**Customer Impact:**\nCustomers using the metric pubsub.googleapis.com/subscription/num_undelivered_messages for autoscaling observed the autoscaling did not complete successfully.\nAutoscaling did not work for existing and new managed instance groups created by customers for the duration of the incident.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"L3ggmi3Jy4xJmgodFA9K","service_name":"Google Compute Engine","affected_products":[{"title":"Google Compute Engine","id":"L3ggmi3Jy4xJmgodFA9K"}],"uri":"incidents/SjJ3FN51MAEJy7cZmoss","currently_affected_locations":[],"previously_affected_locations":[]},{"id":"aCXLk4u6GJoLn9PqSMm1","number":"13045675828271798087","begin":"2021-11-02T12:13:00+00:00","created":"2021-12-07T21:14:09+00:00","end":"2021-12-16T20:25:00+00:00","modified":"2021-12-20T20:29:09+00:00","external_desc":"Global: Issues with Cloud SQL for MySQL instance migration to 5.7 when source databases have gtid_mode set to ON.","updates":[{"created":"2021-12-20T20:28:34+00:00","modified":"2021-12-20T20:28:34+00:00","when":"2021-12-20T20:28:34+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 02 November 2021 04:13\n**Incident End:** 16 December 2021 12:25\n**Duration:** 44 days, 8 hours, 12 minutes\n**Affected Services and Features:**\nCloudSQL- MySQL instance migration.\n**Regions/Zones:** Global\n**Description:**\nCloudSQL experienced an issue with MySQL instance migration to 5.7.36 with source database gtid_mode set to ON for a duration of 44 days, 8 hours, 12 minutes. The root cause of the issue is a MySQL bug https://bugs.mysql.com/bug.php?id=105761 that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021, from a source database that had gtid_mode set to ON.\n**Customer Impact:**\nCloud SQL External Server or Database Migration Service (DMS) users who migrated to Cloud SQL for MySQL 5.7.36, with replication using managed dumps may have experienced replication failures if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those jobs during the replication phase, the migration job may have failed.\nThe issue was observed when ALL the following conditions are met:\n* Cloud SQL MySQL version migrated to is 5.7.36.\n* Source database gtid_mode is ON.\n* Customer is running continuous migration (see DMS doc https://cloud.google.com/database-migration/docs/mysql/create-migration-job).\n* Customer is not migrating with a file, i.e. migration is using a managed dump.\nNew instances should not experience this issue, but please follow the below recommended workaround for existing instances that are impacted. We will be sending out targeted communications to the affected customers.\n***Workaround:*** Customers should start a new migration by dumping the data from a source database instance running MySQL 5.7.35 or lower versions to Google Cloud Storage (GCS) manually (Cloud SQL, DMS), using a mysqldump file, and then migrate using the dump file to Cloud SQL for MySQL 5.7.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-16T21:13:01+00:00","modified":"2021-12-16T21:13:04+00:00","when":"2021-12-16T21:13:01+00:00","text":"The issue with Cloud SQL has been resolved as of Thursday, 2021-12-16 12:25 US/Pacific.\nNew instances will no longer experience this issue, but please follow the recommended workaround for existing instances that are impacted. We will be sending out targeted communications to the affected customers.\nWe thank you for your patience while we worked on resolving the issue.","status":"AVAILABLE","affected_locations":[]},{"created":"2021-12-13T22:00:09+00:00","modified":"2021-12-13T22:00:12+00:00","when":"2021-12-13T22:00:09+00:00","text":"Summary: Global: Issues with Cloud SQL for MySQL instance migration to 5.7 when source databases have gtid_mode set to ON.\nDescription: Mitigation work is still underway by our engineering team.\nThe mitigation is expected to complete over the next few days.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL for MySQL 5.7 with GTID replication using managed dumps may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those jobs during the replication phase, the migration job may fail.\nWorkaround: Customers should start a new migration by dumping the data from a source database instance running MySQL 5.7.35 or lower versions to Google Cloud Storage (GCS) manually (Cloud SQL, DMS), using a mysqldump file, and then migrate using the dump file to Cloud SQL for MySQL 5.7.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-09T06:04:17+00:00","modified":"2021-12-09T06:04:17+00:00","when":"2021-12-09T06:04:17+00:00","text":"Summary: Global: Issues with Cloud SQL for MySQL instance migration to 5.7 when source databases have gtid_mode set to ON.\nDescription: Our engineering team continues to investigate the issue caused by a MySQL bug https://bugs.mysql.com/bug.php?id=105761 that may affect customers who migrated to MySQL 5.7.36 on or after November 2nd 2021, from a source database that had gtid_mode set to ON.\nThe issue is being observed when ALL of the following conditions are met:\n1. Cloud SQL for MySQL version migrated to is 5.7.36\n2. source database gtid_mode is ON\n3. The migration was a continuous migration (see DMS doc https://cloud.google.com/database-migration/docs/mysql/configure-source-database)\n4. The migration was performed using an auto-generated initial dump, also called a managed dump.\nWe will provide further updates by Monday, 2021-12-13 17:00 US/Pacific with details.\nIn the meantime, we recommend halting any migrations to Cloud SQL for MySQL 5.7 where the source database has gtid_mode set to ON and is using managed dumps, to prevent this scenario from occurring. The workaround outlined below may be used for these migrations instead.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL for MySQL 5.7 with GTID replication using managed dumps may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those jobs during the replication phase, the migration job may fail.\nWorkaround: Customers should start a new migration by dumping the data from a source database instance running MySQL 5.7.35 or lower versions to Google Cloud Storage (GCS) manually (Cloud SQL, DMS), using a mysqldump file, and then migrate using the dump file to Cloud SQL for MySQL 5.7.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-09T01:21:58+00:00","modified":"2021-12-09T01:21:59+00:00","when":"2021-12-09T01:21:58+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36 from source databases that have gtid_mode set to ON.\nDescription: Our engineering team continues to investigate the issue caused by a MySQL bug https://bugs.mysql.com/bug.php?id=105761 that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021, from a source database that had gtid_mode set to ON.\nThe issue is being observed when ALL of the following conditions are met:\n1. Cloud SQL MySQL version migrated to is 5.7.36\n2. source database gtid_mode is ON\n3. Customer is running continuous migration (see DMS doc https://cloud.google.com/database-migration/docs/postgres/create-migration-job)\n4. Customer is not migrating with a file, i.e. migration is using a managed dump.\nWe will provide further updates by Monday, 2021-12-13 17:00 US/Pacific with details.\nIn the meantime, we recommend halting any migrations to Cloud SQL MySQL version 5.7 where the source database has gtid_mode set to ON to prevent this scenario from occurring. The workaround outlined below may be used for these migrations.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those jobs during the replication phase, the migration job may fail.\nWorkaround: Customers should start a new migration by dumping the data from source MySQL 5.7.35 or lower versions to Google Cloud Storage (GCS) manually (Cloud SQL, DMS), using mysqldump, and then migrate using the file to Cloud SQL MySQL 5.7 version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-08T21:59:06+00:00","modified":"2021-12-08T21:59:12+00:00","when":"2021-12-08T21:59:06+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36.\nDescription: Our engineering team continues to investigate the issue that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021\nWe will provide an update by Wednesday, 2021-12-08 17:00 US/Pacific with current details.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those data during replication phase, the migration job may fail.\nWorkaround: Customers may need to start a new migration by dumping the data from source mysql 5.7.35 or lower versions to Google Cloud Storage (GCS) manually, using mysqldump, and then migrate the file to destination mysql version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-08T06:28:36+00:00","modified":"2021-12-08T06:28:37+00:00","when":"2021-12-08T06:28:36+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36.\nDescription: Our engineering team continues to investigate the issue that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021\nWe will provide an update by Wednesday, 2021-12-08 14:00 US/Pacific with current details.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those data during replication phase, the migration job may fail.\nWorkaround: Customers may need to start a new migration by dumping the data from source mysql 5.7.35 or lower versions to Google Cloud Storage (GCS) manually, using mysqldump, and then migrate the file to destination mysql version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-08T03:31:31+00:00","modified":"2021-12-08T03:31:32+00:00","when":"2021-12-08T03:31:31+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36.\nDescription: Our engineering team continues to investigate the issue that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021\nWe will provide an update by Tuesday, 2021-12-07 23:30 US/Pacific with current details.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those data during replication phase, the migration job may fail.\nWorkaround: Customers may need to start a new migration by dumping the data from source mysql 5.7.35 or lower versions to Google Cloud Storage (GCS) manually, using mysqldump, and then migrate the file to destination mysql version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-08T00:35:07+00:00","modified":"2021-12-08T00:35:08+00:00","when":"2021-12-08T00:35:07+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36.\nDescription: Our engineering team continues to investigate the issue that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021\nWe will provide an update by Tuesday, 2021-12-07 19:30 US/Pacific with current details.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those data during replication phase, the migration job may fail.\nWorkaround: Customers may need to start a new migration by dumping the data from source mysql 5.7.35 or lower versions to Google Cloud Storage (GCS) manually, using mysqldump, and then migrate the file to destination mysql version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-07T22:36:00+00:00","modified":"2021-12-07T22:36:01+00:00","when":"2021-12-07T22:36:00+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36\nDescription: Our engineering team continues to investigate the issue that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021.\nWe will provide an update by Tuesday, 2021-12-07 16:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who migrate to Cloud SQL MySQL 5.7 with GTID replication may experience errors if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those data during replication phase, the migration job may fail.\nWorkaround: Customers need to start a new migration by dumping the data from source mysql 5.7.35 or lower versions to Google Cloud Storage (GCS) manually, using mysqldump, and then migrate the file to destination mysql version.","status":"SERVICE_DISRUPTION","affected_locations":[]},{"created":"2021-12-07T21:14:09+00:00","modified":"2021-12-07T21:14:10+00:00","when":"2021-12-07T21:14:09+00:00","text":"Summary: Global: Issues with Cloud SQL migrating to MySQL version 5.7.36\nDescription: We are experiencing an issue with Cloud SQL when migrating to MySQL version 5.7.36.\nThe issue may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021\nOur engineering team continues to investigate the issue.\nWe will provide an update by Tuesday, 2021-12-07 14:30 US/Pacific with current details.\nWe apologize to all who are affected by the disruption.\nDiagnosis: Cloud SQL External Server or Database Migration Service (DMS) users who want to migrate to Cloud SQL MySQL 5.7 with GTID replication may experience data inconsistency (i.e. data in Cloud SQL may not be consistent with data on the source) issue if they have insert/update/delete transactions during the dump phase. Further more, if customer has updates to those inconsistent data during replication phase, the migration job may fail.\nWorkaround: Customers needs to start a new migration by dumping the data from source by themselves to Google Cloud Storage (GCS) and then migrate with the file.","status":"SERVICE_DISRUPTION","affected_locations":[]}],"most_recent_update":{"created":"2021-12-20T20:28:34+00:00","modified":"2021-12-20T20:28:34+00:00","when":"2021-12-20T20:28:34+00:00","text":"We apologize for the inconvenience this service disruption may have caused. We would like to provide some information about this incident below. Please note, this information is based on our best knowledge at the time of posting and is subject to change as our investigation continues. If you have experienced impact outside of what is listed below, please reach out to Google Support by opening a case using https://cloud.google.com/support.\n(All Times US/Pacific)\n**Incident Start:** 02 November 2021 04:13\n**Incident End:** 16 December 2021 12:25\n**Duration:** 44 days, 8 hours, 12 minutes\n**Affected Services and Features:**\nCloudSQL- MySQL instance migration.\n**Regions/Zones:** Global\n**Description:**\nCloudSQL experienced an issue with MySQL instance migration to 5.7.36 with source database gtid_mode set to ON for a duration of 44 days, 8 hours, 12 minutes. The root cause of the issue is a MySQL bug https://bugs.mysql.com/bug.php?id=105761 that may affect customers who migrated to MySQL version 5.7.36 on or after November 2nd 2021, from a source database that had gtid_mode set to ON.\n**Customer Impact:**\nCloud SQL External Server or Database Migration Service (DMS) users who migrated to Cloud SQL for MySQL 5.7.36, with replication using managed dumps may have experienced replication failures if they have insert/update/delete transactions during the dump phase. Furthermore, if updates were made to those jobs during the replication phase, the migration job may have failed.\nThe issue was observed when ALL the following conditions are met:\n* Cloud SQL MySQL version migrated to is 5.7.36.\n* Source database gtid_mode is ON.\n* Customer is running continuous migration (see DMS doc https://cloud.google.com/database-migration/docs/mysql/create-migration-job).\n* Customer is not migrating with a file, i.e. migration is using a managed dump.\nNew instances should not experience this issue, but please follow the below recommended workaround for existing instances that are impacted. We will be sending out targeted communications to the affected customers.\n***Workaround:*** Customers should start a new migration by dumping the data from a source database instance running MySQL 5.7.35 or lower versions to Google Cloud Storage (GCS) manually (Cloud SQL, DMS), using a mysqldump file, and then migrate using the dump file to Cloud SQL for MySQL 5.7.","status":"AVAILABLE","affected_locations":[]},"status_impact":"SERVICE_DISRUPTION","severity":"medium","service_key":"hV87iK5DcEXKgWU2kDri","service_name":"Google Cloud SQL","affected_products":[{"title":"Google Cloud SQL","id":"hV87iK5DcEXKgWU2kDri"}],"uri":"incidents/aCXLk4u6GJoLn9PqSMm1","currently_affected_locations":[],"previously_affected_locations":[]}]